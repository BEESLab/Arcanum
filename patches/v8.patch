diff --git a/BUILD.gn b/BUILD.gn
index 61187af3053..d9e924c10da 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -124,7 +124,7 @@ declare_args() {
   v8_enable_verify_csa = false
 
   # Enable pointer compression (sets -dV8_COMPRESS_POINTERS).
-  v8_enable_pointer_compression = ""
+  v8_enable_pointer_compression = false # xqg
   v8_enable_pointer_compression_shared_cage = ""
   v8_enable_31bit_smis_on_64bit_arch = false
 
@@ -2750,6 +2750,7 @@ v8_header_set("v8_internal_headers") {
     "src/codegen/code-desc.h",
     "src/codegen/code-factory.h",
     "src/codegen/code-reference.h",
+    "src/commons.h",  ### xqg ###
     "src/codegen/compilation-cache.h",
     "src/codegen/compiler.h",
     "src/codegen/constant-pool.h",
@@ -3458,6 +3459,7 @@ v8_header_set("v8_internal_headers") {
     "src/roots/roots-inl.h",
     "src/roots/roots.h",
     "src/runtime/runtime-utils.h",
+    "src/runtime/runtime-taint.h", ### xqg ###
     "src/runtime/runtime.h",
     "src/sandbox/bounded-size-inl.h",
     "src/sandbox/bounded-size.h",
@@ -4344,6 +4346,7 @@ v8_source_set("v8_base_without_compiler") {
     "src/codegen/code-desc.cc",
     "src/codegen/code-factory.cc",
     "src/codegen/code-reference.cc",
+    "src/commons.cc", ### xqg ###
     "src/codegen/compilation-cache.cc",
     "src/codegen/compiler.cc",
     "src/codegen/constant-pool.cc",
@@ -4671,6 +4674,7 @@ v8_source_set("v8_base_without_compiler") {
     "src/runtime/runtime-shadow-realm.cc",
     "src/runtime/runtime-strings.cc",
     "src/runtime/runtime-symbol.cc",
+    "src/runtime/runtime-taint.cc",  ### xqg ###
     "src/runtime/runtime-temporal.cc",
     "src/runtime/runtime-test.cc",
     "src/runtime/runtime-trace.cc",
diff --git a/include/v8-isolate.h b/include/v8-isolate.h
index 2f8acc88682..a24e8126e85 100644
--- a/include/v8-isolate.h
+++ b/include/v8-isolate.h
@@ -1596,6 +1596,16 @@ class V8_EXPORT Isolate {
    */
   void VisitExternalResources(ExternalResourceVisitor* visitor);
 
+  // xqg start
+  void MarkAsExtensionContext(Local<Context> context, bool is_background);
+
+  bool IsExtensionContext(Local<Context> context);
+
+  bool IsThirdPartySetCookie(Local<String> cookieURL);
+
+  bool InHoneyPage();
+  // xqg end
+
   /**
    * Check if this isolate is in use.
    * True if at least one thread Enter'ed this isolate.
diff --git a/include/v8-local-handle.h b/include/v8-local-handle.h
index cbf87f949d0..48ca4823f7f 100644
--- a/include/v8-local-handle.h
+++ b/include/v8-local-handle.h
@@ -100,6 +100,11 @@ class V8_EXPORT V8_NODISCARD HandleScope {
   static internal::Address* CreateHandle(internal::Isolate* i_isolate,
                                          internal::Address value);
 
+  // xqg start
+  static internal::Address* CreatePersistentHandle(internal::Isolate* i_isolate,
+                                                     internal::Address value);
+  // xqg end
+
  private:
   // Declaring operator new and delete as deleted is not spec compliant.
   // Therefore declare them private instead to disable dynamic alloc
@@ -271,6 +276,23 @@ class Local {
     return New(isolate, *that);
   }
 
+    // xqg start
+    explicit V8_INLINE Local(T* that) : val_(that) {}
+
+    V8_INLINE Local<T> MakePersistentCopy(v8::Isolate* v8_isolate){
+        Local<T> ret(*this);
+
+        internal::Address *slot = reinterpret_cast<internal::Address*>(this->val_);
+
+        if ((*this)->IsHeapAllocated()) {
+            internal::Isolate *isolate = reinterpret_cast<internal::Isolate *>(v8_isolate);
+            internal::Address *new_slot = HandleScope::CreatePersistentHandle(isolate, *slot);
+            ret = Local<T>(reinterpret_cast<T *>(new_slot));
+        }
+        return ret;
+    }
+    // xqg end
+
  private:
   friend class TracedReferenceBase;
   friend class Utils;
@@ -314,7 +336,7 @@ class Local {
   template <class F>
   friend class TracedReference;
 
-  explicit V8_INLINE Local(T* that) : val_(that) {}
+  // explicit V8_INLINE Local(T* that) : val_(that) {} xqg
   V8_INLINE static Local<T> New(Isolate* isolate, T* that) {
     if (that == nullptr) return Local<T>();
     T* that_ptr = that;
diff --git a/include/v8-message.h b/include/v8-message.h
index 09f9a0a97dd..f0b6c78dd67 100644
--- a/include/v8-message.h
+++ b/include/v8-message.h
@@ -188,6 +188,7 @@ class V8_EXPORT Message {
   bool IsOpaque() const;
 
   static void PrintCurrentStackTrace(Isolate* isolate, std::ostream& out);
+  static void PrintCurrentStackTrace(Isolate* isolate, FILE* out); // xqg
 
   static const int kNoLineNumberInfo = 0;
   static const int kNoColumnInfo = 0;
diff --git a/include/v8-promise.h b/include/v8-promise.h
index 9da8e4b4e86..f13e5f623de 100644
--- a/include/v8-promise.h
+++ b/include/v8-promise.h
@@ -9,6 +9,7 @@
 #include "v8-object.h"        // NOLINT(build/include_directory)
 #include "v8config.h"         // NOLINT(build/include_directory)
 
+#include <string>
 namespace v8 {
 
 class Context;
@@ -47,7 +48,10 @@ class V8_EXPORT Promise : public Object {
      * Ignored if the promise is no longer pending.
      */
     V8_WARN_UNUSED_RESULT Maybe<bool> Resolve(Local<Context> context,
-                                              Local<Value> value);
+                                              Local<Value> value,
+                                              bool is_tainted=false,
+                                              std::vector<v8::Local<v8::Value>> tainted_strs=std::vector<v8::Local<v8::Value>>(),
+                                              const std::string& from=std::string()); // xqg
 
     V8_WARN_UNUSED_RESULT Maybe<bool> Reject(Local<Context> context,
                                              Local<Value> value);
diff --git a/include/v8-script.h b/include/v8-script.h
index e2ba845268d..fc9bfaf61fe 100644
--- a/include/v8-script.h
+++ b/include/v8-script.h
@@ -342,6 +342,11 @@ class V8_EXPORT Script {
    */
   Local<UnboundScript> GetUnboundScript();
 
+  // xqg start
+  void SetTaint(Local<String> report);
+  bool IsTainted();
+  // xqg end
+
   /**
    * The name that was passed by the embedder as ResourceName to the
    * ScriptOrigin. This can be either a v8::String or v8::Undefined.
diff --git a/include/v8-value.h b/include/v8-value.h
index adca989e002..9846132f542 100644
--- a/include/v8-value.h
+++ b/include/v8-value.h
@@ -11,6 +11,10 @@
 #include "v8-maybe.h"         // NOLINT(build/include_directory)
 #include "v8config.h"         // NOLINT(build/include_directory)
 
+// xqg start
+#include <vector>
+// xqg end
+
 /**
  * The v8 JavaScript engine.
  */
@@ -23,12 +27,55 @@ class Number;
 class Object;
 class String;
 class Uint32;
+class Function;  // xqg
 
 /**
  * The superclass of all JavaScript values and objects.
  */
 class V8_EXPORT Value : public Data {
  public:
+
+    // xqg start
+    void Print(); // ok
+
+//  Isolate *GetIsolate();
+
+    bool IsHeapAllocated(); // ok
+
+    void ShowValue();
+    void SetTaint(v8::Isolate* v8_isolate, std::vector<bool> tainted_bytes=std::vector<bool>()); // ok
+    bool IsTainted(v8::Isolate* v8_isolate); // ok
+
+    std::vector<bool> GetTaintedBytes(v8::Isolate* v8_isolate); // ok
+
+    void PrintTaintSinkDetails(Isolate *isolate, FILE *out); // ok
+
+    void RuntimeSetTaint(v8::Isolate* v8_isolate);
+    bool RuntimeIsTainted(v8::Isolate* v8_isolate);
+    void RuntimeSetAsTaintSource(v8::Isolate* v8_isolate, v8::Local<v8::Function> v8_function, const std::string& from);
+    void RuntimeLogTaintSink(v8::Isolate* v8_isolate, v8::Local<v8::String> report, v8::Local<v8::String> where);
+    void RuntimeMarkAsTaintSource(v8::Isolate* v8_isolate);
+
+    v8::Local<v8::Value> GetPropagationPaths(v8::Isolate* v8_isolate);
+    v8::Local<v8::Value> GetAllPropagationPaths(v8::Isolate* v8_isolate);
+    void RuntimeSetPropagationPaths(v8::Isolate* v8_isolate, v8::Local<v8::Value> report);
+
+    bool ContainsTaintedValue(Local<Context> context, v8::Isolate* v8_isolate); //xqg
+    bool ContainsTaintedValueRecursive(Local<Context> context, v8::Isolate* v8_isolate,
+                                           std::vector<void*>& visited);
+    void SetTaintForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Value> report);
+    void DoSetTaintForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Value> report, std::vector<void*>& visited);
+
+    void SetTaintForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Function> v8_function, const std::string& from);
+    void DoSetTaintForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Function> v8_function, const std::string& from,
+                          std::vector<void*>& visited);
+
+    void SetTaintSourceForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Function> v8_function,
+                                  const std::string& from);
+    void DoSetTaintSourceForAll(Local<Context> contexIsUndefinedt, v8::Isolate* v8_isolate, v8::Local<v8::Function> v8_function,
+                                    std::vector<void*>& visited, const std::string& from);
+    // xqg end
+
   /**
    * Returns true if this value is the undefined value.  See ECMA-262
    * 4.3.10.
diff --git a/src/api/api.cc b/src/api/api.cc
index 14b7c541b3a..15233c37339 100644
--- a/src/api/api.cc
+++ b/src/api/api.cc
@@ -923,6 +923,15 @@ int HandleScope::NumberOfHandles(Isolate* v8_isolate) {
       reinterpret_cast<i::Isolate*>(v8_isolate));
 }
 
+
+// xqg start
+// ===== v8-local-handle.h start ======
+i::Address* HandleScope::CreatePersistentHandle(i::Isolate* i_isolate, i::Address value) {
+    return i::HandleScope::CreatePersistentHandle(i_isolate, value);
+}
+// ===== v8-local-handle.h end ======
+// xqg end
+
 i::Address* HandleScope::CreateHandle(i::Isolate* i_isolate, i::Address value) {
   return i::HandleScope::CreateHandle(i_isolate, value);
 }
@@ -2903,6 +2912,19 @@ MaybeLocal<Script> Script::Compile(Local<Context> context, Local<String> source,
   return ScriptCompiler::Compile(context, &script_source);
 }
 
+// xqg start
+void Script::SetTaint(Local<String> report) {
+    i::Handle<i::JSFunction> function = Utils::OpenHandle(this);
+    i::Isolate* isolate = function->GetIsolate();
+    isolate->MarkAsTaintSource(function);
+    isolate->TaintJSFunction(function, Utils::OpenHandle(*report));
+}
+
+bool Script::IsTainted() {
+    return false;
+}
+// xqg end
+
 // --- E x c e p t i o n s ---
 
 v8::TryCatch::TryCatch(v8::Isolate* v8_isolate)
@@ -3217,6 +3239,13 @@ void Message::PrintCurrentStackTrace(Isolate* v8_isolate, std::ostream& out) {
   i_isolate->PrintCurrentStackTrace(out);
 }
 
+// xqg start
+void Message::PrintCurrentStackTrace(Isolate* v8_isolate, FILE* out) {
+    i::Isolate* i_isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    ENTER_V8_NO_SCRIPT_NO_EXCEPTION(i_isolate);
+    i_isolate->PrintCurrentStackTrace(out);
+}
+// xqg end
 // --- S t a c k T r a c e ---
 
 Local<StackFrame> StackTrace::GetFrame(Isolate* v8_isolate,
@@ -3623,6 +3652,424 @@ bool ValueDeserializer::ReadRawBytes(size_t length, const void** data) {
 
 // --- D a t a ---
 
+// xqg start
+// ===== v8-value.h start ======
+void Value::Print() {
+    i::Handle<i::Object> object = Utils::OpenHandle(this);
+    object->Print();
+}
+
+bool Value::IsHeapAllocated() {
+    i::Handle<i::Object> object = Utils::OpenHandle(this);
+    return object->IsHeapObject();
+}
+
+void Value::SetTaint(v8::Isolate* v8_isolate, std::vector<bool> tainted_bytes) {
+    i::Handle<i::Object> object = Utils::OpenHandle(this);
+    CHECK(object->IsHeapObject());  // No Smi.
+
+    i::OFStream os(stdout);
+    i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    i::JavaScriptFrameIterator it(isolate);
+    if (!it.done()) {
+        i::Handle<i::JSFunction> function(it.frame()->function(), isolate);
+        if (isolate->InExtensionContext(function) &&
+            !isolate->IsBackgroundPageContext(function)) { // TODO: why not background?
+            isolate->MarkAsTaintSource(function);
+            isolate->SetTaintForV8Object(object, tainted_bytes);
+            isolate->SetV8ObjectAsTaintSource(object, function, "blink");
+        }
+
+//        if (isolate->InExtensionContext(function)){
+//            if (isolate->IsBackgroundPageContext(function)){
+//            }
+//        }
+    }
+}
+
+bool Value::IsTainted(v8::Isolate* v8_isolate) {
+    i::Handle<i::Object> object = Utils::OpenHandle(this);
+    i::OFStream os(stdout);
+    if (object->IsHeapObject()) {
+        i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+        return isolate->IsV8ObjectTainted(object);
+    }
+    return false;
+}
+
+std::vector<bool> Value::GetTaintedBytes(v8::Isolate* v8_isolate) {
+    i::Handle<i::Object> object = Utils::OpenHandle(this);
+    if (object->IsString()) {
+        i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+        std::vector<bool> *tainted_bytes =
+                isolate->GetStringTaintedBytes(i::Handle<i::String>::cast(object));
+        if (tainted_bytes != nullptr)
+            return *tainted_bytes;
+    }
+//    else if (object->IsJSArray() || object->IsJSArrayBuffer() ||object->IsJSArrayBufferView() || object->IsJSTypedArray()){
+//        i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+//        std::vector<bool> *tainted_bytes =
+//                isolate->GetStringTaintedBytes(i::Handle<i::String>::cast(object));
+//        if (tainted_bytes != nullptr)
+//            return *tainted_bytes;
+//    }
+    return std::vector<bool>();
+}
+
+void Value::PrintTaintSinkDetails(Isolate *isolate, FILE *out) {
+    i::Handle<i::Object> object = Utils::OpenHandle(this);
+    fprintf(out, "** Sink object: ");
+    if (object->IsString()) {
+        i::Handle<i::String> str = i::Handle<i::String>::cast(object);
+        fprintf(out, "%s", str->ToCString().get());
+    } else {
+        object->ShortPrint(out);
+    }
+    fprintf(out, "\n\n");
+    reinterpret_cast<i::Isolate *>(isolate)->PrintPropagationPaths(object, out);
+}
+
+// ===== xqg newly added runtime ======
+void Value::ShowValue(){
+    i::OFStream os(stdout);
+    i::Handle < i::Object > object = Utils::OpenHandle(this);
+    os << "value="<<object<<"\n";
+}
+void Value::RuntimeSetTaint(v8::Isolate* v8_isolate) {
+    i::OFStream os(stdout);
+    bool show = false;
+    if (show) os << "xqg-v8: =================in RuntimeSetTaint=====================" << std::endl;
+    i::Handle < i::Object > object = Utils::OpenHandle(this);
+    if (show) os << "obj is " << object << "," << object->ptr() <<"\n";
+//    CHECK(object->IsHeapObject());  // No Smi.
+    i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    // no need filter.
+    isolate->SetTaintForV8Object(object);
+    if (show) os << "RuntimeSetTaint return\n";
+}
+
+bool Value::RuntimeIsTainted(v8::Isolate* v8_isolate) {
+    i::OFStream os(stdout);
+//    os << "xqg-v8: =================in RuntimeIsTainted=====================" << std::endl;
+    i::Handle < i::Object > object = Utils::OpenHandle(this);
+//    os << "obj is " << object << "," << object->ptr() <<"\n";
+    if (!object->IsHeapObject()){
+//        os << "it's not HeapObject(), return\n";
+        return false;
+    }
+    i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    if (isolate->IsV8ObjectTainted(object)) return true;
+//    os << "the result is false\n";
+    return false;
+}
+
+void Value::RuntimeSetAsTaintSource(v8::Isolate* v8_isolate, v8::Local<v8::Function> v8_function, const std::string& from){
+    i::OFStream os(stdout);
+    bool show = false;
+    if (show) os << "xqg-v8: =================in RuntimeSetAsTaintSource=====================" << std::endl;
+    i::Handle < i::Object > object = Utils::OpenHandle(this);
+    i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    auto function =  Utils::OpenHandle(*v8_function);
+    if (!function->IsJSFunction()) {
+        if (show)os << "is not JSFUNCTION\n";
+        return;
+    }
+    auto func = i::Handle<i::JSFunction>::cast(function);
+    isolate->SetV8ObjectAsTaintSource(object, func, from);
+}
+
+void Value::RuntimeLogTaintSink(v8::Isolate* v8_isolate, v8::Local<v8::String> report, v8::Local<v8::String> where){
+//    i::OFStream os(stdout);
+    i::Handle < i::Object > object = Utils::OpenHandle(this);
+    i::Handle < i::String> report_handle = Utils::OpenHandle(*report);
+    i::Handle < i::String> where_handle = Utils::OpenHandle(*where);
+//    os << "inside RuntimeLogTaintSink, "<<object<<","<<report_handle<<","<<where_handle<<"\n";
+
+    i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    if (isolate->IsV8ObjectTainted(object))
+        isolate->LogTaintSink(object, report_handle, where_handle);
+}
+
+void Value::RuntimeMarkAsTaintSource(v8::Isolate* v8_isolate){
+    i::Handle < i::Object > object = Utils::OpenHandle(this);
+//    CHECK(object->IsJSFunction());
+    i::OFStream os(stdout);
+    CHECK((object->IsJSFunction() || object->IsJSBoundFunction()));
+    i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    auto func = i::Handle<i::JSFunction>::cast(object);
+    isolate->MarkAsTaintSource(func);
+}
+
+v8::Local<v8::Value> Value::GetPropagationPaths(v8::Isolate* v8_isolate){
+    i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    i::Handle < i::Object > object = Utils::OpenHandle(this);
+    if (!isolate->IsV8ObjectTainted(object))
+        return Utils::ToLocal(isolate->factory()->empty_string());
+    return Utils::ToLocal(isolate->GetPropagationPaths(object));
+}
+
+v8::Local<v8::Value> Value::GetAllPropagationPaths(v8::Isolate* v8_isolate){
+    i::Isolate *isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    i::Handle < i::Object > object = Utils::OpenHandle(this);
+    return Utils::ToLocal(object->GetAllPropagationPaths(isolate).ToHandleChecked());
+}
+
+void Value::RuntimeSetPropagationPaths(v8::Isolate* v8_isolate, v8::Local<v8::Value> report){
+    i::OFStream os(stdout);
+    i::Isolate* i_isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    auto obj = Utils::OpenHandle(this);
+    i::Handle < i::Object > report_handle = Utils::OpenHandle(*report);
+//    os << "Enter RuntimeSetPropagationPaths, obj="<<obj<<",report="<<report_handle<<"\n";
+//    i::JavaScriptFrameIterator it(i_isolate);
+//    os << "after isolate";
+//    i_isolate->AddPropagatedFrom(obj,
+//                                 i::Handle<i::JSFunction>(it.frame()->function(), i_isolate),
+//                                         i::Handle<i::String>::cast(report_handle));
+    i_isolate->AddPropagatedFrom(obj,
+        i::Handle<i::String>::cast(report_handle));
+}
+
+
+bool Value::ContainsTaintedValue(Local<Context> context, v8::Isolate* v8_isolate){
+    std::vector<void*> visited;
+    return this->ContainsTaintedValueRecursive(context, v8_isolate, visited);
+}
+
+bool Value::ContainsTaintedValueRecursive(Local<Context> context, v8::Isolate* v8_isolate,
+                                          std::vector<void*>& visited){
+    i::Handle<i::Object> obj = Utils::OpenHandle(this);
+    if (this->RuntimeIsTainted(v8_isolate)) return true;
+
+    if (obj->IsSmi()) return false;
+    i::OFStream os(stdout);
+    visited.push_back(reinterpret_cast<void*>(obj->ptr()));
+    if (obj->IsString() || obj->IsStringWrapper()) return false;
+    if (obj->IsJSArrayBuffer() || obj->IsJSArrayBufferView() || obj->IsJSTypedArray()) return false;
+    if (!obj->IsJSReceiver()) return false;
+
+    Local<v8::Object> local_obj = Utils::ToLocal(obj).As<v8::Object>();
+    v8::Local <v8::Array> propertyNames;
+    if (!local_obj->GetOwnPropertyNames(context).ToLocal(&propertyNames)) return false;
+
+    v8::MicrotasksScope microtasks_scope(v8_isolate, context->GetMicrotaskQueue(),
+                                         v8::MicrotasksScope::kDoNotRunMicrotasks);
+
+    for (uint32_t i = 0; i < propertyNames->Length(); ++i) {
+        v8::Local<v8::Value> key;
+        if (!propertyNames->Get(context, i).ToLocal(&key)) continue;
+        v8::HandleScope handle_scope(v8_isolate);
+        if (key->IsUint32()) {
+            uint32_t index = key->ToUint32(context).ToLocalChecked()->Value();
+            if (!local_obj->HasOwnProperty(context, index).FromJust()) continue;
+        } else if (!local_obj->HasOwnProperty(context, key.As<v8::String>()).FromJust()) continue;
+
+        v8::Local<v8::Value> value = local_obj->Get(context, key).ToLocalChecked();
+        bool include = false;
+        auto self = Utils::OpenHandle(*value);
+        if (self->IsSmi()) continue;
+        for (size_t j = 0; j < visited.size(); ++j) {
+//            i::Object other = i::Object(reinterpret_cast<i::Address>(visited.at(j)));
+            if (visited.at(j) == reinterpret_cast<void*>(self->ptr())){
+//                os << "equal in api, obj="<<self<<"\n";
+                include = true;
+                break;
+            }
+        }
+        if (include == false && value->ContainsTaintedValueRecursive(context, v8_isolate, visited))
+            return true;
+    }
+    return false;
+}
+
+void Value::SetTaintForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Function> v8_function,
+                           const std::string& from){
+    std::vector<void*> visited; // Cycle avoidance.
+    this->DoSetTaintForAll(context, v8_isolate, v8_function, from, visited);
+}
+
+void Value::DoSetTaintForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Function> v8_function, const std::string& from,
+                             std::vector<void*>& visited){
+    i::Handle<i::Object> obj = Utils::OpenHandle(this);
+    if (obj->IsNull() || obj->IsUndefined()) return;
+    if (obj->IsSmi()){
+        // TODO: Replace Smi.
+    }
+    this->RuntimeSetTaint(v8_isolate);
+    this->RuntimeSetAsTaintSource(v8_isolate, v8_function, from);
+
+    visited.push_back(reinterpret_cast<void*>(obj->ptr()));
+
+    if (obj->IsString() || obj->IsStringWrapper()) return;
+    if (obj->IsJSArrayBuffer() || obj->IsJSArrayBufferView() || obj->IsJSTypedArray()) return;
+    if (!obj->IsJSReceiver()) return;
+
+    Local<v8::Object> local_obj = Utils::ToLocal(obj).As<v8::Object>();
+    v8::Local <v8::Array> propertyNames;
+    if (!local_obj->GetOwnPropertyNames(context).ToLocal(&propertyNames)) return;
+
+    v8::MicrotasksScope microtasks_scope(v8_isolate, context->GetMicrotaskQueue(),
+                                         v8::MicrotasksScope::kDoNotRunMicrotasks);
+
+    for (uint32_t i = 0; i < propertyNames->Length(); ++i) {
+        v8::Local<v8::Value> key;
+        if (!propertyNames->Get(context, i).ToLocal(&key)) continue;
+        if (key->IsUint32()) {
+            uint32_t index = key->ToUint32(context).ToLocalChecked()->Value();
+            if (!local_obj->HasOwnProperty(context, index).FromJust()) continue;
+        }
+        else {
+            if (!local_obj->HasOwnProperty(context, key.As<v8::String>()).FromJust()) continue;
+        }
+        v8::Local<v8::Value> value = local_obj->Get(context, key).ToLocalChecked();
+        bool include = false;
+        auto self = Utils::OpenHandle(*value);
+        for (size_t j = 0; j < visited.size(); ++j){
+            i::Object other = i::Object(reinterpret_cast<i::Address>(visited.at(j)));
+            if (self->SameValueZero(other)){
+                include = true;
+                break;
+            }
+        }
+        if (include == false){
+            value->DoSetTaintForAll(context, v8_isolate, v8_function, from, visited);
+        }
+    }
+}
+
+
+void Value::SetTaintForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Value> report){
+    std::vector<void*> visited; // Cycle avoidance.
+//    if (Utils::OpenHandle(this)->IsName()) //working
+    i::OFStream os(stdout);
+    if (!Utils::OpenHandle(*report)->IsString()){
+        os << "it's not string, report=" << Utils::OpenHandle(*report)<<"\n";
+    }
+    v8::Local<v8::Value> parsed_report;
+    if (!JSON::Parse(context, report.As<v8::String>()).ToLocal(&parsed_report)) {
+        return;
+    }
+    this->DoSetTaintForAll(context, v8_isolate, parsed_report, visited);
+}
+
+void Value::DoSetTaintForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Value> report,
+                             std::vector<void*>& visited){
+    i::Handle<i::Object> obj = Utils::OpenHandle(this);
+    if (obj->IsNull() || obj->IsUndefined()) return;
+    if (obj->IsSmi()){
+        // TODO: Replace Smi.
+    }
+    i::Isolate* i_isolate = reinterpret_cast<i::Isolate*>(v8_isolate);
+    v8::Local<v8::Value> tainted = report.As<v8::Object>()
+        ->Get(context,Utils::ToLocal(i_isolate->factory()->NewStringFromAsciiChecked("tainted"))).ToLocalChecked();
+    if (tainted->IsTrue())
+        this->RuntimeSetTaint(v8_isolate);
+
+    v8::Local<v8::Value> details = report.As<v8::Object>()->Get(context, Utils::ToLocal(i_isolate->factory()->NewStringFromAsciiChecked("details"))).ToLocalChecked();
+    this->RuntimeSetPropagationPaths(v8_isolate, details); // check empty?
+
+    v8::Local<v8::Value> recursive = report.As<v8::Object>()->Get(context, Utils::ToLocal(i_isolate->factory()->NewStringFromAsciiChecked("recursive"))).ToLocalChecked();
+    visited.push_back(reinterpret_cast<void*>(obj->ptr()));
+
+    if (obj->IsString() || obj->IsStringWrapper()) return;
+    if (obj->IsJSArrayBuffer() || obj->IsJSArrayBufferView() || obj->IsJSTypedArray()) return;
+    if (!obj->IsJSReceiver()) return;
+
+    Local<v8::Object> local_obj = Utils::ToLocal(obj).As<v8::Object>();
+    v8::Local <v8::Array> propertyNames;
+    if (!local_obj->GetOwnPropertyNames(context).ToLocal(&propertyNames)) return;
+
+    v8::MicrotasksScope microtasks_scope(v8_isolate, context->GetMicrotaskQueue(),
+                                         v8::MicrotasksScope::kDoNotRunMicrotasks);
+
+    for (uint32_t i = 0; i < propertyNames->Length(); ++i) {
+        v8::Local<v8::Value> key;
+        if (!propertyNames->Get(context, i).ToLocal(&key)) continue;
+        bool has_recursive_property = false;
+        if (key->IsUint32()) {
+            uint32_t index = key->ToUint32(context).ToLocalChecked()->Value();
+            if (!local_obj->HasOwnProperty(context, index).FromJust()) continue;
+            if (recursive.As<v8::Object>()->HasOwnProperty(context, index).FromJust()) has_recursive_property = true;
+        }
+        else {
+            if (!local_obj->HasOwnProperty(context, key.As<v8::String>()).FromJust()) continue;
+            if (recursive.As<v8::Object>()->HasOwnProperty(context, key.As<v8::String>()).FromJust()) has_recursive_property = true;
+        }
+
+        v8::Local<v8::Value> value = local_obj->Get(context, key).ToLocalChecked();
+        bool include = false;
+        auto self = Utils::OpenHandle(*value);
+        for (size_t j = 0; j < visited.size(); ++j){
+            i::Object other = i::Object(reinterpret_cast<i::Address>(visited.at(j)));
+            if (self->SameValueZero(other)){
+                include = true;
+                break;
+            }
+        }
+        if (include == false && has_recursive_property == true){
+            value->DoSetTaintForAll(context, v8_isolate, recursive.As<v8::Object>()->Get(context, key).ToLocalChecked(), visited);
+        }
+    }
+}
+
+void Value::SetTaintSourceForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Function> v8_function,
+                                 const std::string& from){
+    std::vector<void*> visited;
+    this->DoSetTaintSourceForAll(context, v8_isolate, v8_function, visited, from);
+}
+
+void Value::DoSetTaintSourceForAll(Local<Context> context, v8::Isolate* v8_isolate, v8::Local<v8::Function> v8_function,
+                                   std::vector<void*>& visited, const std::string& from){
+    i::Handle<i::Object> obj = Utils::OpenHandle(this);
+    if (obj->IsNull() || obj->IsUndefined()) return;
+    if (obj->IsSmi()){
+        // TODO: Replace Smi.
+    }
+    if (this->RuntimeIsTainted(v8_isolate))
+        this->RuntimeSetAsTaintSource(v8_isolate, v8_function, from);
+
+    visited.push_back(reinterpret_cast<void*>(obj->ptr()));
+
+    if (obj->IsString() || obj->IsStringWrapper()) return;
+    if (obj->IsJSArrayBuffer() || obj->IsJSArrayBufferView() || obj->IsJSTypedArray()) return;
+    if (!obj->IsJSReceiver()) return;
+
+    Local<v8::Object> local_obj = Utils::ToLocal(obj).As<v8::Object>();
+    v8::Local <v8::Array> propertyNames;
+    if (!local_obj->GetOwnPropertyNames(context).ToLocal(&propertyNames)) return;
+
+    v8::MicrotasksScope microtasks_scope(v8_isolate, context->GetMicrotaskQueue(),
+                                     v8::MicrotasksScope::kDoNotRunMicrotasks);
+    for (uint32_t i = 0; i < propertyNames->Length(); ++i) {
+        v8::Local<v8::Value> key;
+        if (!propertyNames->Get(context, i).ToLocal(&key)) continue;
+
+        if (key->IsUint32()) {
+            uint32_t index = key->ToUint32(context).ToLocalChecked()->Value();
+            if (!local_obj->HasOwnProperty(context, index).FromJust()) continue;
+        } else if (!local_obj->HasOwnProperty(context, key.As<v8::String>()).FromJust())
+            continue;
+
+        v8::Local<v8::Value> value = local_obj->Get(context, key).ToLocalChecked();
+        bool include = false;
+        auto self = Utils::OpenHandle(*value);
+
+        for (size_t j = 0; j < visited.size(); ++j){
+            i::Object other = i::Object(reinterpret_cast<i::Address>(visited.at(j)));
+            if (self->SameValue(other)){
+                include = true;
+                break;
+            }
+        }
+        if (include == false)
+            value->DoSetTaintSourceForAll(context, v8_isolate, v8_function, visited, from);
+    }
+}
+
+
+// ===== v8-value.h end ======
+
+// xqg end
+
 bool Value::FullIsUndefined() const {
   i::Handle<i::Object> object = Utils::OpenHandle(this);
   bool result = object->IsUndefined();
@@ -7795,7 +8242,8 @@ Local<Promise> Promise::Resolver::GetPromise() {
 }
 
 Maybe<bool> Promise::Resolver::Resolve(Local<Context> context,
-                                       Local<Value> value) {
+                                       Local<Value> value, bool is_tainted,
+        std::vector<v8::Local<v8::Value>> tainted_strs, const std::string& from) { // xqg
   auto i_isolate = reinterpret_cast<i::Isolate*>(context->GetIsolate());
   ENTER_V8(i_isolate, context, Promise_Resolver, Resolve, Nothing<bool>(),
            i::HandleScope);
@@ -7806,10 +8254,24 @@ Maybe<bool> Promise::Resolver::Resolve(Local<Context> context,
     return Just(true);
   }
 
-  has_pending_exception =
-      i::JSPromise::Resolve(promise, Utils::OpenHandle(*value)).is_null();
-  RETURN_ON_FAILED_EXECUTION_PRIMITIVE(bool);
-  return Just(true);
+
+  if (is_tainted){
+      std::vector<i::Handle<i::Object>> tainted_objs;
+      for (size_t i = 0; i < tainted_strs.size(); ++i) {
+          tainted_objs.push_back(Utils::OpenHandle(*tainted_strs.data()[i]));
+      }
+
+      has_pending_exception =
+              i::JSPromise::Resolve(promise, Utils::OpenHandle(*value), is_tainted,
+                                    tainted_objs, from).is_null();
+      RETURN_ON_FAILED_EXECUTION_PRIMITIVE(bool);
+      return Just(true);
+  } else {
+     has_pending_exception =
+             i::JSPromise::Resolve(promise, Utils::OpenHandle(*value)).is_null();
+     RETURN_ON_FAILED_EXECUTION_PRIMITIVE(bool);
+     return Just(true);
+  }
 }
 
 Maybe<bool> Promise::Resolver::Reject(Local<Context> context,
@@ -8248,6 +8710,9 @@ static_assert(
     i::Handle<i::JSArrayBuffer> buffer = Utils::OpenHandle(*array_buffer);  \
     i::Handle<i::JSTypedArray> obj = i_isolate->factory()->NewJSTypedArray( \
         i::kExternal##Type##Array, buffer, byte_offset, length);            \
+    if (i_isolate->IsV8ObjectTainted(buffer))  {                            \
+            i_isolate->SetTaintForV8Object(obj);                            \
+    }                                                                       \
     return Utils::ToLocal##Type##Array(obj);                                \
   }                                                                         \
   Local<Type##Array> Type##Array::New(                                      \
@@ -8269,6 +8734,9 @@ static_assert(
         Utils::OpenHandle(*shared_array_buffer);                            \
     i::Handle<i::JSTypedArray> obj = i_isolate->factory()->NewJSTypedArray( \
         i::kExternal##Type##Array, buffer, byte_offset, length);            \
+    if (i_isolate->IsV8ObjectTainted(buffer))  {                            \
+            i_isolate->SetTaintForV8Object(obj);                            \
+    }                                                                       \
     return Utils::ToLocal##Type##Array(obj);                                \
   }
 
@@ -8523,6 +8991,28 @@ void BigInt::ToWordsArray(int* sign_bit, int* word_count,
   return handle->ToWordsArray64(sign_bit, word_count, words);
 }
 
+
+// xqg start
+// ===== v8-isolate.h start ======
+void Isolate::MarkAsExtensionContext(Local<Context> context,bool is_background) {
+i::Isolate* isolate = reinterpret_cast<i::Isolate*>(this);
+isolate->MarkAsExtensionContext(Utils::OpenHandle(*context), is_background);
+}
+
+bool Isolate::IsExtensionContext(Local<Context> context) {
+    i::Isolate* isolate = reinterpret_cast<i::Isolate*>(this);
+    return isolate->IsExtensionContext(Utils::OpenHandle(*context));
+}
+
+bool Isolate::InHoneyPage() {
+    i::Isolate* isolate = reinterpret_cast<i::Isolate*>(this);
+    return isolate->InHoneyPage();
+}
+
+// ===== v8-isolate.h end ======
+
+// xqg end
+
 void Isolate::ReportExternalAllocationLimitReached() {
   i::Heap* heap = reinterpret_cast<i::Isolate*>(this)->heap();
   if (heap->gc_state() != i::Heap::NOT_IN_GC) return;
diff --git a/src/ast/ast.h b/src/ast/ast.h
index 8473f7fb67e..504a177e851 100644
--- a/src/ast/ast.h
+++ b/src/ast/ast.h
@@ -24,6 +24,8 @@
 #include "src/runtime/runtime.h"
 #include "src/zone/zone-list.h"
 
+#include "src/utils/ostreams.h"
+
 namespace v8 {
 namespace internal {
 
@@ -770,7 +772,9 @@ class TryStatement : public Statement {
 
 class TryCatchStatement final : public TryStatement {
  public:
-  Scope* scope() { return scope_; }
+  Scope* scope() {
+      return scope_;
+  }
   Block* catch_block() const { return catch_block_; }
   void set_catch_block(Block* b) { catch_block_ = b; }
 
@@ -2730,6 +2734,7 @@ class AstVisitor {
   }
 
   void VisitStatements(const ZonePtrList<Statement>* statements) {
+
     for (int i = 0; i < statements->length(); i++) {
       Statement* stmt = statements->at(i);
       Visit(stmt);
diff --git a/src/baseline/baseline-compiler.cc b/src/baseline/baseline-compiler.cc
index 25123cb7cd8..a127c282653 100644
--- a/src/baseline/baseline-compiler.cc
+++ b/src/baseline/baseline-compiler.cc
@@ -2042,6 +2042,16 @@ void BaselineCompiler::VisitJumpIfUndefinedOrNull() {
   __ Bind(&dont_jump);
 }
 
+// xqg start
+void BaselineCompiler::VisitJumpIfNotSmi() {
+    Label is_smi;
+    __ JumpIfSmi(kInterpreterAccumulatorRegister, &is_smi, Label::kNear);
+    UpdateInterruptBudgetAndDoInterpreterJump();
+
+    __ Bind(&is_smi);
+}
+// xqg end
+
 void BaselineCompiler::VisitJumpIfJSReceiver() {
   BaselineAssembler::ScratchRegisterScope scratch_scope(&basm_);
 
diff --git a/src/builtins/array-join.tq b/src/builtins/array-join.tq
index c88a0c28000..cb1ebe39a8b 100644
--- a/src/builtins/array-join.tq
+++ b/src/builtins/array-join.tq
@@ -2,6 +2,13 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
+// xqg start
+namespace runtime {
+extern transitioning runtime TaintAnalysis_SetTaint(implicit context: Context)(JSAny): void;
+extern transitioning runtime TaintAnalysis_ContainsTaintedValue(implicit context: Context)(JSAny): JSAny;
+extern transitioning runtime TaintAnalysis_SetPropagationPaths(implicit context: Context)(JSAny, JSAny): void;
+}  // namespace runtime
+// xqg end
 namespace array {
 
 type LoadJoinElementFn = builtin(Context, JSReceiver, uintptr) => JSAny;
@@ -599,8 +606,19 @@ ArrayPrototypeJoin(
     ThrowTypeError(MessageTemplate::kInvalidArrayLength);
   }
 
-  return CycleProtectedArrayJoin<JSArray>(
-      false, o, len, separator, Undefined, Undefined);
+  // xqg start
+  const res: JSAny = CycleProtectedArrayJoin<JSArray>(
+        false, o, len, separator, Undefined, Undefined);
+
+  if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(o))){
+        runtime::TaintAnalysis_SetTaint(res);
+        runtime::TaintAnalysis_SetPropagationPaths(o, res);
+  }
+  return res;
+  // xqg end
+
+  // return CycleProtectedArrayJoin<JSArray>(
+  //     false, o, len, separator, Undefined, Undefined);
 }
 
 // https://tc39.github.io/ecma262/#sec-array.prototype.tolocalestring
@@ -621,7 +639,15 @@ transitioning javascript builtin ArrayPrototypeToLocaleString(
     ThrowTypeError(MessageTemplate::kInvalidArrayLength);
   }
 
-  return CycleProtectedArrayJoin<JSArray>(true, o, len, ',', locales, options);
+  // xqg start
+  const res: JSAny = CycleProtectedArrayJoin<JSArray>(true, o, len, ',', locales, options);
+  if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(o))){
+          runtime::TaintAnalysis_SetTaint(res);
+          runtime::TaintAnalysis_SetPropagationPaths(o, res);
+  }
+  return res;
+  // xqg end
+  // return CycleProtectedArrayJoin<JSArray>(true, o, len, ',', locales, options);
 }
 
 // https://tc39.github.io/ecma262/#sec-array.prototype.tostring
@@ -648,6 +674,8 @@ transitioning javascript builtin ArrayPrototypeToString(
 transitioning javascript builtin TypedArrayPrototypeJoin(
     js-implicit context: NativeContext, receiver: JSAny)(...arguments): JSAny {
   const separator: JSAny = arguments[0];
+  if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(receiver))){
+  }
 
   // Spec: ValidateTypedArray is applied to the this value prior to evaluating
   // the algorithm.
@@ -655,9 +683,20 @@ transitioning javascript builtin TypedArrayPrototypeJoin(
       context, receiver, '%TypedArray%.prototype.join');
   const typedArray: JSTypedArray = UnsafeCast<JSTypedArray>(receiver);
 
-  return CycleProtectedArrayJoin<JSTypedArray>(
-      false, typedArray, Convert<Number>(length), separator, Undefined,
-      Undefined);
+  // xqg start
+  const res: JSAny = CycleProtectedArrayJoin<JSTypedArray>(
+                           false, typedArray, Convert<Number>(length), separator, Undefined,
+                           Undefined);
+  if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(receiver))){
+         runtime::TaintAnalysis_SetTaint(res);
+         runtime::TaintAnalysis_SetPropagationPaths(receiver, res);
+  }
+  return res;
+  // xqg end
+
+  // return CycleProtectedArrayJoin<JSTypedArray>(
+  //    false, typedArray, Convert<Number>(length), separator, Undefined,
+  //    Undefined);
 }
 
 // https://tc39.github.io/ecma262/#sec-%typedarray%.prototype.tolocalestring
@@ -672,7 +711,18 @@ transitioning javascript builtin TypedArrayPrototypeToLocaleString(
       context, receiver, '%TypedArray%.prototype.toLocaleString');
   const typedArray: JSTypedArray = UnsafeCast<JSTypedArray>(receiver);
 
-  return CycleProtectedArrayJoin<JSTypedArray>(
-      true, typedArray, Convert<Number>(length), ',', locales, options);
+  // xqg start
+
+  const res: JSAny = CycleProtectedArrayJoin<JSTypedArray>(
+                            true, typedArray, Convert<Number>(length), ',', locales, options);
+  if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(typedArray))){
+           runtime::TaintAnalysis_SetTaint(res);
+           runtime::TaintAnalysis_SetPropagationPaths(typedArray, res);
+   }
+  return res;
+  // xqg end
+
+  // return CycleProtectedArrayJoin<JSTypedArray>(
+  //     true, typedArray, Convert<Number>(length), ',', locales, options);
 }
 }
diff --git a/src/builtins/base.tq b/src/builtins/base.tq
index 40f702549d9..37aa231c01f 100644
--- a/src/builtins/base.tq
+++ b/src/builtins/base.tq
@@ -221,6 +221,7 @@ extern class NameDictionary extends HashTable;
 extern class GlobalDictionary extends HashTable;
 extern class SimpleNumberDictionary extends HashTable;
 extern class EphemeronHashTable extends HashTable;
+extern class ObjectPointerHashTable extends HashTable; // xqg
 type ObjectHashTable extends HashTable
     generates 'TNode<ObjectHashTable>' constexpr 'ObjectHashTable';
 extern class NumberDictionary extends HashTable;
@@ -1140,11 +1141,15 @@ extern operator '.length_smi' macro LoadStringLengthAsSmi(String): Smi;
 
 extern builtin StringAdd_CheckNone(implicit context: Context)(
     String, String): String;
+extern builtin StringAdd_CheckNone1(implicit context: Context)(
+    String, String): String;
 operator '+' macro StringAdd(implicit context: Context)(
     a: String, b: String): String {
-  return StringAdd_CheckNone(a, b);
+  return StringAdd_CheckNone1(a, b); // xqg
 }
 
+
+
 operator '==' macro PromiseStateEquals(
     s1: PromiseState, s2: PromiseState): bool {
   return Word32Equal(s1, s2);
diff --git a/src/builtins/builtins-arraybuffer.cc b/src/builtins/builtins-arraybuffer.cc
index fbe29b434fa..edbd4c898e0 100644
--- a/src/builtins/builtins-arraybuffer.cc
+++ b/src/builtins/builtins-arraybuffer.cc
@@ -339,6 +339,11 @@ static Object SliceHelper(BuiltinArguments args, Isolate* isolate,
     } else {
       CopyBytes(to_data, from_data, new_len_size);
     }
+    // xqg start, in this case, new array length != 0 and the old != 0
+    if (isolate->IsV8ObjectTainted(array_buffer)){
+        isolate->SetTaintForV8Object(new_);
+    }
+    // xqg end
   }
 
   return *new_;
@@ -457,6 +462,9 @@ static Object ResizeHelper(BuiltinArguments args, Isolate* isolate,
     // BackingStore).
     CHECK_EQ(0, array_buffer->byte_length());
   }
+  // xqg start
+  isolate->UntaintV8Object(array_buffer);
+  // xqg end
   return ReadOnlyRoots(isolate).undefined_value();
 }
 
@@ -559,6 +567,9 @@ BUILTIN(ArrayBufferPrototypeTransfer) {
 
     // 13. Perform ? DetachArrayBuffer(O).
     array_buffer->Detach();
+    // xqg start
+    isolate->UntaintV8Object(array_buffer); // untaint this old one.
+    // xqg end
 
     // 14. Return new.
     return *isolate->factory()
@@ -582,6 +593,14 @@ BUILTIN(ArrayBufferPrototypeTransfer) {
 
     // 13. Perform ? DetachArrayBuffer(O).
     array_buffer->Detach();
+    // xqg start
+    if (isolate->IsV8ObjectTainted(array_buffer)){
+        isolate->UntaintV8Object(array_buffer); // untaint this old one.
+        Handle <JSArrayBuffer> prop_taint_new_buffer = isolate->factory()->NewJSArrayBuffer(std::move(from_backing_store));
+        isolate->SetTaintForV8Object(prop_taint_new_buffer);
+        return *prop_taint_new_buffer;
+    }
+    // xqg end
 
     // 14. Return new.
     return *isolate->factory()->NewJSArrayBuffer(std::move(from_backing_store));
@@ -625,6 +644,13 @@ BUILTIN(ArrayBufferPrototypeTransfer) {
   // 13. Perform ? DetachArrayBuffer(O).
   array_buffer->Detach();
 
+  // xqg start
+  if (isolate->IsV8ObjectTainted(array_buffer)){
+      isolate->UntaintV8Object(array_buffer); // untaint this old one.
+      isolate->SetTaintForV8Object(new_);
+  }
+  // xqg end
+
   // 14. Return new.
   return *new_;
 }
diff --git a/src/builtins/builtins-definitions.h b/src/builtins/builtins-definitions.h
index c656b02e755..7f61e4ad4c8 100644
--- a/src/builtins/builtins-definitions.h
+++ b/src/builtins/builtins-definitions.h
@@ -1087,7 +1087,9 @@ namespace internal {
                                                                                \
   /* String helpers */                                                         \
   TFS(StringAdd_CheckNone, kLeft, kRight)                                      \
+  TFS(StringAdd_CheckNone1, kLeft, kRight)                                     \
   TFS(SubString, kString, kFrom, kTo)                                          \
+  TFS(SubString1, kString, kFrom, kTo)                                         \
                                                                                \
   /* Miscellaneous */                                                          \
   ASM(DoubleToI, Void)                                                         \
diff --git a/src/builtins/builtins-json.cc b/src/builtins/builtins-json.cc
index 5ac1cd2bfc5..b793afa0238 100644
--- a/src/builtins/builtins-json.cc
+++ b/src/builtins/builtins-json.cc
@@ -10,9 +10,38 @@
 #include "src/objects/js-raw-json.h"
 #include "src/objects/objects-inl.h"
 
+// xqg start
+#include "src/execution/frames-inl.h"
+#include "src/runtime/runtime-taint.h"
+#include <fcntl.h>
+#include <iostream>
+#include <unistd.h>
+
+// xqg end
+
 namespace v8 {
 namespace internal {
 
+#define TESTLOCK_FILE  PROPAGATION_PATHS_OUT_DIR"testlock"
+#define LOCK_FILE      PROPAGATION_PATHS_OUT_DIR"lockfile"
+
+static void acquire_lock() {
+    // First test if we are in sandbox.
+            FILE *fp = fopen(TESTLOCK_FILE, "a");
+            if (fp == nullptr)
+                return;  // Nothing to synchronize.
+            fclose(fp);
+
+            int fd = open(LOCK_FILE, O_CREAT | O_EXCL);
+            while (fd == -1)
+                fd = open(LOCK_FILE, O_CREAT | O_EXCL);
+            close(fd);
+}
+
+static void release_lock() {
+    unlink(LOCK_FILE);
+}
+
 // ES6 section 24.3.1 JSON.parse.
 BUILTIN(JsonParse) {
   HandleScope scope(isolate);
@@ -22,10 +51,42 @@ BUILTIN(JsonParse) {
   ASSIGN_RETURN_FAILURE_ON_EXCEPTION(isolate, string,
                                      Object::ToString(isolate, source));
   string = String::Flatten(isolate, string);
-  RETURN_RESULT_OR_FAILURE(
-      isolate, String::IsOneByteRepresentationUnderneath(*string)
-                   ? JsonParser<uint8_t>::Parse(isolate, string, reviver)
-                   : JsonParser<uint16_t>::Parse(isolate, string, reviver));
+//  RETURN_RESULT_OR_FAILURE(
+//      isolate, String::IsOneByteRepresentationUnderneath(*string)
+//                   ? JsonParser<uint8_t>::Parse(isolate, string, reviver)
+//                   : JsonParser<uint16_t>::Parse(isolate, string, reviver));
+
+  Handle<Object> __result__;
+  if (String::IsOneByteRepresentationUnderneath(*string)){
+      if (!(JsonParser<uint8_t>::Parse(isolate, string, reviver)).ToHandle(&__result__)) {
+          DCHECK(isolate->has_pending_exception());
+          return ReadOnlyRoots(isolate).exception();
+      }
+  } else {
+      if (!(JsonParser<uint16_t>::Parse(isolate, string, reviver)).ToHandle(&__result__)) {
+          DCHECK(isolate->has_pending_exception());
+          return ReadOnlyRoots(isolate).exception();
+      }
+  }
+  DCHECK(!isolate->has_pending_exception());
+  if (isolate->IsV8ObjectTainted(source)){
+      Handle <String> report = Handle <String>::cast(source->GetAllPropagationPaths(isolate).ToHandleChecked());
+      JavaScriptFrameIterator it(isolate);
+      __result__->SetTaintForAll(isolate, Handle<JSFunction>(it.frame()->function(), isolate), "JsonParse");
+      isolate->AddPropagatedFrom(__result__, Handle<JSFunction>(it.frame()->function(), isolate), report);
+
+
+      acquire_lock();
+      FILE *fp = fopen(PROPAGATION_PATHS_OUT_DIR"taint_specific.log", "a");
+      if (fp != nullptr) {
+          fprintf(fp, "[SPECIFIC CHECK]##[BUILTIN(JsonParse)]##[string=");
+          fprintf(fp, "%s", string->ToCString().get());
+          fprintf(fp, "]\n");
+          fclose(fp);
+      }
+      release_lock();
+  }
+  return *__result__;
 }
 
 // ES6 section 24.3.2 JSON.stringify.
@@ -34,8 +95,39 @@ BUILTIN(JsonStringify) {
   Handle<Object> object = args.atOrUndefined(isolate, 1);
   Handle<Object> replacer = args.atOrUndefined(isolate, 2);
   Handle<Object> indent = args.atOrUndefined(isolate, 3);
-  RETURN_RESULT_OR_FAILURE(isolate,
-                           JsonStringify(isolate, object, replacer, indent));
+
+  // xqg start
+  Handle<Object> __result__;
+  Isolate* __isolate__ = (isolate);
+  if (!(JsonStringify(isolate, object, replacer, indent)).ToHandle(&__result__)) {
+      DCHECK(__isolate__->has_pending_exception());
+      return ReadOnlyRoots(__isolate__).exception();
+  }
+  DCHECK(!__isolate__->has_pending_exception());
+  if (!object.is_null() && object->ContainsTaintedValue(isolate)){
+      Handle <String> report = Handle <String>::cast(object->GetAllPropagationPaths(isolate).ToHandleChecked());
+      isolate->SetTaintForV8Object(__result__);
+      JavaScriptFrameIterator it(isolate);
+      isolate->AddPropagatedFrom(__result__, Handle<JSFunction>(it.frame()->function(), isolate), report);
+  }
+  if (__isolate__->has_pending_exception()){
+      __isolate__->clear_pending_exception();
+//      i::OFStream os(stdout);
+//      Handle<Object> exception(isolate->pending_exception(), isolate);
+//      os << "has pending exception:" << exception<<"\n";
+//      Handle<JSObject> error_object = Handle<JSObject>::cast(exception);
+//      Handle<String> message = Handle<String>::cast(JSReceiver::GetDataProperty(
+//                        isolate, error_object, isolate->factory()->message_string()));
+//      os << "message="<<message<<"\n";
+//      isolate->clear_pending_exception();
+//message=0x07f65abc4a49 <String[134]: c"'caller', 'callee', and 'arguments' properties may not be accessed on strict mode functions or the arguments objects for calls to them">
+  }
+  DCHECK(!__isolate__->has_pending_exception());
+
+  return *__result__;
+  // xqg end
+//  RETURN_RESULT_OR_FAILURE(isolate,
+//                           JsonStringify(isolate, object, replacer, indent));
 }
 
 // https://tc39.es/proposal-json-parse-with-source/#sec-json.rawjson
diff --git a/src/builtins/builtins-regexp-gen.cc b/src/builtins/builtins-regexp-gen.cc
index c40e21b1a1c..ec631d2bc78 100644
--- a/src/builtins/builtins-regexp-gen.cc
+++ b/src/builtins/builtins-regexp-gen.cc
@@ -236,7 +236,7 @@ TNode<JSRegExpResult> RegExpBuiltinsAssembler::ConstructNewResultFromMatchInfo(
   // to avoid an unnecessary write barrier storing the first result.
 
   TNode<String> first =
-      CAST(CallBuiltin(Builtin::kSubString, context, string, start, end));
+      CAST(CallBuiltin(Builtin::kSubString1, context, string, start, end));
 
   // Load flags and check if the result object needs to have indices.
   const TNode<Smi> flags =
@@ -278,7 +278,7 @@ TNode<JSRegExpResult> RegExpBuiltinsAssembler::ConstructNewResultFromMatchInfo(
     TNode<Smi> end_cursor =
         CAST(UnsafeLoadFixedArrayElement(match_info, from_cursor_plus1));
 
-    TNode<String> capture = CAST(CallBuiltin(Builtin::kSubString, context,
+    TNode<String> capture = CAST(CallBuiltin(Builtin::kSubString1, context,
                                              string, start_cursor, end_cursor));
     UnsafeStoreFixedArrayElement(result_elements, to_cursor, capture);
     Goto(&next_iter);
@@ -1652,7 +1652,7 @@ TNode<JSArray> RegExpBuiltinsAssembler::RegExpPrototypeSplitBody(
     {
       const TNode<Smi> from = last_matched_until;
       const TNode<Smi> to = match_from;
-      array.Push(CallBuiltin(Builtin::kSubString, context, string, from, to));
+      array.Push(CallBuiltin(Builtin::kSubString1, context, string, from, to));
       GotoIf(WordEqual(array.length(), int_limit), &out);
     }
 
@@ -1688,7 +1688,7 @@ TNode<JSArray> RegExpBuiltinsAssembler::RegExpPrototypeSplitBody(
         BIND(&select_capture);
         {
           var_value =
-              CallBuiltin(Builtin::kSubString, context, string, from, to);
+              CallBuiltin(Builtin::kSubString1, context, string, from, to);
           Goto(&store_value);
         }
 
@@ -1723,7 +1723,7 @@ TNode<JSArray> RegExpBuiltinsAssembler::RegExpPrototypeSplitBody(
   {
     const TNode<Smi> from = var_last_matched_until.value();
     const TNode<Smi> to = string_length;
-    array.Push(CallBuiltin(Builtin::kSubString, context, string, from, to));
+    array.Push(CallBuiltin(Builtin::kSubString1, context, string, from, to));
     Goto(&out);
   }
 
diff --git a/src/builtins/builtins-string-gen.cc b/src/builtins/builtins-string-gen.cc
index 37f78793576..5cbbf93f4d1 100644
--- a/src/builtins/builtins-string-gen.cc
+++ b/src/builtins/builtins-string-gen.cc
@@ -337,7 +337,122 @@ TNode<String> StringBuiltinsAssembler::AllocateConsString(TNode<Uint32T> length,
   StoreObjectFieldNoWriteBarrier(result, ConsString::kSecondOffset, right);
   return CAST(result);
 }
+// xqg start
+TNode<String> StringBuiltinsAssembler::StringAdd1(
+        TNode<ContextOrEmptyContext> context, TNode<String> left,
+        TNode<String> right) {
+    CSA_DCHECK(this, IsZeroOrContext(context));
+
+    TVARIABLE(String, result);
+    Label check_right(this), runtime(this, Label::kDeferred), cons(this),
+                done(this, &result);
+
+    TNode<Uint32T> left_length = LoadStringLengthAsWord32(left);
+    GotoIfNot(Word32Equal(left_length, Uint32Constant(0)), &check_right);
+    result = right;
+    Goto(&done);
+
+    BIND(&check_right);
+    TNode<Uint32T> right_length = LoadStringLengthAsWord32(right);
+    GotoIfNot(Word32Equal(right_length, Uint32Constant(0)), &cons);
+    result = left;
+    Goto(&done);
+
+    BIND(&cons);
+    {
+        TNode<Uint32T> new_length = Uint32Add(left_length, right_length);
+
+        // If new length is greater than String::kMaxLength, goto runtime to
+        // throw. Note: we also need to invalidate the string length protector, so
+        // can't just throw here directly.
+        GotoIf(Uint32GreaterThan(new_length, Uint32Constant(String::kMaxLength)),
+                   &runtime);
+
+        TVARIABLE(String, var_left, left);
+        TVARIABLE(String, var_right, right);
+        Label non_cons(this, {&var_left, &var_right});
+        Label slow(this, Label::kDeferred);
+        GotoIf(Uint32LessThan(new_length, Uint32Constant(ConsString::kMinLength)),
+                   &non_cons);
+
+//        result =
+//                AllocateConsString(new_length, var_left.value(), var_right.value());
+//        Goto(&done);
+        {
+            Goto(&runtime);
+        }
+
+        BIND(&non_cons);
+
+        Comment("Full string concatenate");
+        TNode<Int32T> left_instance_type = LoadInstanceType(var_left.value());
+        TNode<Int32T> right_instance_type = LoadInstanceType(var_right.value());
+        // Compute intersection and difference of instance types.
+
+        TNode<Int32T> ored_instance_types =
+                    Word32Or(left_instance_type, right_instance_type);
+        TNode<Word32T> xored_instance_types =
+                    Word32Xor(left_instance_type, right_instance_type);
+
+        // Check if both strings have the same encoding and both are sequential.
+        GotoIf(IsSetWord32(xored_instance_types, kStringEncodingMask), &runtime);
+        GotoIf(IsSetWord32(ored_instance_types, kStringRepresentationMask), &slow);
+
+        {
+            Goto(&runtime);
+        }
 
+//        TNode<IntPtrT> word_left_length = Signed(ChangeUint32ToWord(left_length));
+//        TNode<IntPtrT> word_right_length = Signed(ChangeUint32ToWord(right_length));
+//
+//        Label two_byte(this);
+//        GotoIf(Word32Equal(Word32And(ored_instance_types,
+//                                         Int32Constant(kStringEncodingMask)),
+//                               Int32Constant(kTwoByteStringTag)),
+//                   &two_byte);
+//        // One-byte sequential string case
+//        result = AllocateSeqOneByteString(new_length);
+//        CopyStringCharacters(var_left.value(), result.value(), IntPtrConstant(0),
+//                                 IntPtrConstant(0), word_left_length,
+//                                 String::ONE_BYTE_ENCODING, String::ONE_BYTE_ENCODING);
+//        CopyStringCharacters(var_right.value(), result.value(), IntPtrConstant(0),
+//                                 word_left_length, word_right_length,
+//                                 String::ONE_BYTE_ENCODING, String::ONE_BYTE_ENCODING);
+//        Goto(&done);
+//
+//        BIND(&two_byte);
+//        {
+//                // Two-byte sequential string case
+//                result = AllocateSeqTwoByteString(new_length);
+//                CopyStringCharacters(var_left.value(), result.value(), IntPtrConstant(0),
+//                                     IntPtrConstant(0), word_left_length,
+//                                     String::TWO_BYTE_ENCODING,
+//                                     String::TWO_BYTE_ENCODING);
+//                CopyStringCharacters(var_right.value(), result.value(), IntPtrConstant(0),
+//                                     word_left_length, word_right_length,
+//                                     String::TWO_BYTE_ENCODING,
+//                                     String::TWO_BYTE_ENCODING);
+//                Goto(&done);
+//        }
+
+        BIND(&slow);
+        {
+            // Try to unwrap indirect strings, restart the above attempt on success.
+            MaybeDerefIndirectStrings(&var_left, left_instance_type, &var_right,
+                                          right_instance_type, &non_cons);
+            Goto(&runtime);
+        }
+    }
+    BIND(&runtime);
+    {
+        result = CAST(CallRuntime(Runtime::kStringAdd, context, left, right));
+        Goto(&done);
+    }
+
+    BIND(&done);
+    return result.value();
+}
+// xqg end
 TNode<String> StringBuiltinsAssembler::StringAdd(
     TNode<ContextOrEmptyContext> context, TNode<String> left,
     TNode<String> right) {
@@ -544,6 +659,25 @@ TF_BUILTIN(SubString, StringBuiltinsAssembler) {
   Return(SubString(string, SmiUntag(from), SmiUntag(to)));
 }
 
+// xqg start
+TF_BUILTIN(StringAdd_CheckNone1, StringBuiltinsAssembler) {
+    auto left = Parameter<String>(Descriptor::kLeft);
+    auto right = Parameter<String>(Descriptor::kRight);
+    TNode<ContextOrEmptyContext> context =
+            UncheckedParameter<ContextOrEmptyContext>(Descriptor::kContext);
+    CSA_DCHECK(this, IsZeroOrContext(context));
+    Return(StringAdd1(context, left, right));
+}
+
+TF_BUILTIN(SubString1, StringBuiltinsAssembler) {
+    auto string = Parameter<String>(Descriptor::kString);
+    auto from = Parameter<Smi>(Descriptor::kFrom);
+    auto to = Parameter<Smi>(Descriptor::kTo);
+    Return(SubString1(string, SmiUntag(from), SmiUntag(to)));
+}
+// xqg end
+
+
 void StringBuiltinsAssembler::GenerateStringRelationalComparison(
     TNode<String> left, TNode<String> right, Operation op) {
   TVARIABLE(String, var_left, left);
@@ -1422,7 +1556,8 @@ TF_BUILTIN(StringSubstring, StringBuiltinsAssembler) {
   auto from = UncheckedParameter<IntPtrT>(Descriptor::kFrom);
   auto to = UncheckedParameter<IntPtrT>(Descriptor::kTo);
 
-  Return(SubString(string, from, to));
+  // Return(SubString(string, from, to));
+  Return(SubString1(string, from, to));
 }
 
 
@@ -1619,6 +1754,139 @@ TNode<String> StringBuiltinsAssembler::AllocAndCopyStringCharacters(
   return var_result.value();
 }
 
+// xqg start
+
+TNode<String> StringBuiltinsAssembler::SubString1(TNode<String> string,
+                                                 TNode<IntPtrT> from,
+                                                 TNode<IntPtrT> to) {
+    TVARIABLE(String, var_result);
+    ToDirectStringAssembler to_direct(state(), string);
+    Label end(this), runtime(this);
+
+    const TNode<IntPtrT> substr_length = IntPtrSub(to, from);
+    const TNode<IntPtrT> string_length = LoadStringLengthAsWord(string);
+
+    // Begin dispatching based on substring length.
+
+    Label original_string_or_invalid_length(this);
+    GotoIf(UintPtrGreaterThanOrEqual(substr_length, string_length),
+           &original_string_or_invalid_length);
+
+    // A real substring (substr_length < string_length).
+    Label empty(this);
+    GotoIf(IntPtrEqual(substr_length, IntPtrConstant(0)), &empty);
+
+//    Label single_char(this);
+//    GotoIf(IntPtrEqual(substr_length, IntPtrConstant(1)), &single_char);
+    GotoIf(IntPtrEqual(substr_length, IntPtrConstant(1)), &runtime); // xqg: let's go to runtime if it's a single byte
+
+    {
+        Goto(&runtime);
+    }
+    // Deal with different string types: update the index if necessary
+    // and extract the underlying string.
+
+//    TNode<String> direct_string = to_direct.TryToDirect(&runtime);
+//    TNode<IntPtrT> offset = IntPtrAdd(from, to_direct.offset());
+//    const TNode<Int32T> instance_type = to_direct.instance_type();
+//
+//    // The subject string can only be external or sequential string of either
+//    // encoding at this point.
+//    Label external_string(this);
+//    {
+//        if (v8_flags.string_slices) {
+//            Label next(this);
+//
+//            // Short slice.  Copy instead of slicing.
+//            GotoIf(IntPtrLessThan(substr_length,
+//                                  IntPtrConstant(SlicedString::kMinLength)),
+//                   &next);
+//
+//            // Allocate new sliced string.
+//            Label one_byte_slice(this), two_byte_slice(this);
+//            Branch(IsOneByteStringInstanceType(to_direct.instance_type()),
+//                   &one_byte_slice, &two_byte_slice);
+//
+//            BIND(&one_byte_slice);
+//            {
+//                var_result = AllocateSlicedOneByteString(
+//                        Unsigned(TruncateIntPtrToInt32(substr_length)), direct_string,
+//                        SmiTag(offset));
+//                Goto(&end);
+//            }
+//
+//            BIND(&two_byte_slice);
+//            {
+//                var_result = AllocateSlicedTwoByteString(
+//                        Unsigned(TruncateIntPtrToInt32(substr_length)), direct_string,
+//                        SmiTag(offset));
+//                Goto(&end);
+//            }
+//
+//            BIND(&next);
+//        }
+//
+//        // The subject string can only be external or sequential string of either
+//        // encoding at this point.
+//        GotoIf(to_direct.is_external(), &external_string);
+//
+//        var_result = AllocAndCopyStringCharacters(direct_string, instance_type,
+//                                                  offset, substr_length);
+//        Goto(&end);
+//    }
+//
+//    // Handle external string.
+//    BIND(&external_string);
+//    {
+//        const TNode<RawPtrT> fake_sequential_string =
+//                to_direct.PointerToString(&runtime);
+//
+//        var_result = AllocAndCopyStringCharacters(
+//                fake_sequential_string, instance_type, offset, substr_length);
+//
+//        Goto(&end);
+//    }
+
+    BIND(&empty);
+    {
+        var_result = EmptyStringConstant();
+        Goto(&end);
+    }
+
+    // Substrings of length 1 are generated through CharCodeAt and FromCharCode.
+//    BIND(&single_char);
+//    {
+//        TNode<Int32T> char_code = StringCharCodeAt(string, Unsigned(from));
+//        var_result = StringFromSingleCharCode(char_code);
+//        Goto(&end);
+//    }
+
+    BIND(&original_string_or_invalid_length); // xqg: keep this
+    {
+        CSA_DCHECK(this, IntPtrEqual(substr_length, string_length));
+
+        // Equal length - check if {from, to} == {0, str.length}.
+        GotoIf(UintPtrGreaterThan(from, IntPtrConstant(0)), &runtime);
+
+        // Return the original string (substr_length == string_length).
+        var_result = string;
+        Goto(&end);
+    }
+
+    // Fall back to a runtime call.
+    BIND(&runtime);
+    {
+        var_result =
+                CAST(CallRuntime(Runtime::kStringSubstring, NoContextConstant(), string,
+                                 SmiTag(from), SmiTag(to)));
+        Goto(&end);
+    }
+
+    BIND(&end);
+    return var_result.value();
+}
+// xqg end
+
 // TODO(v8:9880): Use UintPtrT here.
 TNode<String> StringBuiltinsAssembler::SubString(TNode<String> string,
                                                  TNode<IntPtrT> from,
@@ -1746,5 +2014,6 @@ TNode<String> StringBuiltinsAssembler::SubString(TNode<String> string,
   return var_result.value();
 }
 
+
 }  // namespace internal
 }  // namespace v8
diff --git a/src/builtins/builtins-string-gen.h b/src/builtins/builtins-string-gen.h
index bd1390dc24d..0de0afbc95d 100644
--- a/src/builtins/builtins-string-gen.h
+++ b/src/builtins/builtins-string-gen.h
@@ -47,6 +47,15 @@ class StringBuiltinsAssembler : public CodeStubAssembler {
     return SubString(string, Signed(from), Signed(to));
   }
 
+  // xqg start
+  TNode<String> SubString1(TNode<String> string, TNode<IntPtrT> from,
+                          TNode<IntPtrT> to);
+  TNode<String> SubString1(TNode<String> string, TNode<UintPtrT> from,
+                          TNode<UintPtrT> to) {
+      return SubString1(string, Signed(from), Signed(to));
+  }
+  // xqg end
+
   // Copies |character_count| elements from |from_string| to |to_string|
   // starting at the |from_index|'th character. |from_string| and |to_string|
   // can either be one-byte strings or two-byte strings, although if
@@ -124,6 +133,10 @@ class StringBuiltinsAssembler : public CodeStubAssembler {
 
   TNode<String> StringAdd(TNode<ContextOrEmptyContext> context,
                           TNode<String> left, TNode<String> right);
+  // xqg start
+  TNode<String> StringAdd1(TNode<ContextOrEmptyContext> context,
+                            TNode<String> left, TNode<String> right);
+  // xqg end
 
   // Check if |string| is an indirect (thin or flat cons) string type that can
   // be dereferenced by DerefIndirectString.
diff --git a/src/builtins/builtins-string.tq b/src/builtins/builtins-string.tq
index 769b3223bcb..48ffd8d63b9 100644
--- a/src/builtins/builtins-string.tq
+++ b/src/builtins/builtins-string.tq
@@ -46,6 +46,9 @@ transitioning builtin ToString(context: Context, o: JSAny): String {
 extern macro StringBuiltinsAssembler::SubString(
     String, uintptr, uintptr): String;
 
+extern macro StringBuiltinsAssembler::SubString1(
+       String, uintptr, uintptr): String;
+
 // ES6 #sec-string.prototype.tostring
 transitioning javascript builtin
 StringPrototypeToString(
diff --git a/src/builtins/regexp-match.tq b/src/builtins/regexp-match.tq
index ff2dcf2c33c..62d98b51a6c 100644
--- a/src/builtins/regexp-match.tq
+++ b/src/builtins/regexp-match.tq
@@ -71,7 +71,7 @@ transitioning macro RegExpPrototypeMatchBody(implicit context: Context)(
               matchIndices, kRegExpMatchInfoFirstCaptureIndex);
           const matchTo = UnsafeLoadFixedArrayElement(
               matchIndices, kRegExpMatchInfoFirstCaptureIndex + 1);
-          match = SubString(
+          match = SubString1(
               string, UnsafeCast<Smi>(matchFrom), UnsafeCast<Smi>(matchTo));
         }
       } else {
diff --git a/src/builtins/regexp-replace.tq b/src/builtins/regexp-replace.tq
index ecd99af0320..a8961cae6cf 100644
--- a/src/builtins/regexp-replace.tq
+++ b/src/builtins/regexp-replace.tq
@@ -9,6 +9,11 @@ namespace regexp {
 extern builtin
 SubString(implicit context: Context)(String, Smi, Smi): String;
 
+// xqg start
+extern builtin
+SubString1(implicit context: Context)(String, Smi, Smi): String;
+// xqg end
+
 extern runtime RegExpExecMultiple(implicit context: Context)(
     JSRegExp, String, RegExpMatchInfo, JSArray): Null|JSArray;
 extern transitioning runtime
@@ -145,7 +150,7 @@ transitioning macro RegExpReplaceFastString(implicit context: Context)(
 
     // TODO(jgruber): We could skip many of the checks that using SubString
     // here entails.
-    result = result + SubString(string, lastMatchEnd, matchStart);
+    result = result + SubString1(string, lastMatchEnd, matchStart);
     lastMatchEnd = matchEnd;
 
     if (replaceLength != 0) result = result + replaceString;
@@ -171,7 +176,7 @@ transitioning macro RegExpReplaceFastString(implicit context: Context)(
     }
   }
 
-  return result + SubString(string, lastMatchEnd, string.length_smi);
+  return result + SubString1(string, lastMatchEnd, string.length_smi);
 }
 
 transitioning builtin RegExpReplace(implicit context: Context)(
diff --git a/src/builtins/string-replaceall.tq b/src/builtins/string-replaceall.tq
index cd670208ad9..b0fdc456cf6 100644
--- a/src/builtins/string-replaceall.tq
+++ b/src/builtins/string-replaceall.tq
@@ -126,7 +126,7 @@ transitioning javascript builtin StringPrototypeReplaceAll(
     // c. Let stringSlice be the substring of string consisting of the code
     //    units from endOfLastMatch (inclusive) up through position
     //    (exclusive).
-    const stringSlice = string::SubString(
+    const stringSlice = string::SubString1(
         string, Unsigned(SmiUntag(endOfLastMatch)),
         Unsigned(SmiUntag(position)));
 
@@ -149,7 +149,7 @@ transitioning javascript builtin StringPrototypeReplaceAll(
     //    of string consisting of the code units from endOfLastMatch
     //    (inclusive) up through the final code unit of string (inclusive).
     result = result +
-        string::SubString(
+        string::SubString1(
                  string, Unsigned(SmiUntag(endOfLastMatch)),
                  Unsigned(string.length_intptr));
   }
diff --git a/src/builtins/string-slice.tq b/src/builtins/string-slice.tq
index 7a953418e71..31146a1ba62 100644
--- a/src/builtins/string-slice.tq
+++ b/src/builtins/string-slice.tq
@@ -29,6 +29,6 @@ transitioning javascript builtin StringPrototypeSlice(
     return kEmptyString;
   }
 
-  return SubString(string, start, end);
+  return SubString1(string, start, end);
 }
 }
diff --git a/src/builtins/string-substr.tq b/src/builtins/string-substr.tq
index 81ea82ab7ef..06f2d3c8cdc 100644
--- a/src/builtins/string-substr.tq
+++ b/src/builtins/string-substr.tq
@@ -37,6 +37,6 @@ transitioning javascript builtin StringPrototypeSubstr(
 
   // 9. Return the String value containing resultLength consecutive code units
   // from S beginning with the code unit at index intStart.
-  return SubString(string, initStart, initStart + resultLength);
+  return SubString1(string, initStart, initStart + resultLength);
 }
 }
diff --git a/src/builtins/string-substring.tq b/src/builtins/string-substring.tq
index 099a28b5057..11fd795c90e 100644
--- a/src/builtins/string-substring.tq
+++ b/src/builtins/string-substring.tq
@@ -24,6 +24,6 @@ transitioning javascript builtin StringPrototypeSubstring(
     end = start;
     start = tmp;
   }
-  return SubString(string, start, end);
+  return SubString1(string, start, end);
 }
 }
diff --git a/src/builtins/string-trim.tq b/src/builtins/string-trim.tq
index daaec997388..abf769500b2 100644
--- a/src/builtins/string-trim.tq
+++ b/src/builtins/string-trim.tq
@@ -130,7 +130,7 @@ transitioning macro StringTrimBody<T: type>(implicit context: Context)(
     }
   }
 
-  return SubString(string, Unsigned(startIndex), Unsigned(endIndex + 1));
+  return SubString1(string, Unsigned(startIndex), Unsigned(endIndex + 1));
 }
 
 transitioning macro StringTrim(implicit context: Context)(
diff --git a/src/builtins/typed-array-filter.tq b/src/builtins/typed-array-filter.tq
index 736dff0affb..cedc899c684 100644
--- a/src/builtins/typed-array-filter.tq
+++ b/src/builtins/typed-array-filter.tq
@@ -78,6 +78,12 @@ transitioning javascript builtin TypedArrayPrototypeFilter(
     const lengthNumber = Convert<Number>(Unsigned(kept.length));
     TypedArrayCopyElements(context, typedArray, kept.ToJSArray(), lengthNumber);
 
+    // xqg start
+    if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(array))){
+             runtime::TaintAnalysis_SetTaint(typedArray);
+             runtime::TaintAnalysis_SetPropagationPaths(array, typedArray);
+    }
+    // xqg end
     // 13. Return A.
     return typedArray;
   } label IsDetachedOrOutOfBounds deferred {
diff --git a/src/builtins/typed-array-from.tq b/src/builtins/typed-array-from.tq
index aca548f3247..66b324b4086 100644
--- a/src/builtins/typed-array-from.tq
+++ b/src/builtins/typed-array-from.tq
@@ -203,6 +203,13 @@ TypedArrayFrom(js-implicit context: NativeContext, receiver: JSAny)(
 
       // 12f. Set k to k + 1. (done by the loop).
     }
+
+    // xqg start
+    if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(source))){
+                 runtime::TaintAnalysis_SetTaint(targetObj);
+                 runtime::TaintAnalysis_SetPropagationPaths(source, targetObj);
+    }
+    // xqg end
     return targetObj;
   } label NotConstructor deferred {
     ThrowTypeError(MessageTemplate::kNotConstructor, receiver);
diff --git a/src/builtins/typed-array-of.tq b/src/builtins/typed-array-of.tq
index b5d42ef9a2f..13095e2656c 100644
--- a/src/builtins/typed-array-of.tq
+++ b/src/builtins/typed-array-of.tq
@@ -29,12 +29,19 @@ TypedArrayOf(js-implicit context: NativeContext, receiver: JSAny)(...arguments):
     const accessor: TypedArrayAccessor =
         GetTypedArrayAccessor(newObj.elements_kind);
 
+    let tainted: bool = false;
+
     // 6. Let k be 0.
     // 7. Repeat, while k < len
     for (let k: uintptr = 0; k < len; k++) {
       // 7a. Let kValue be items[k].
       const kValue: JSAny = arguments[Signed(k)];
 
+      if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(kValue))){
+            tainted = true;
+            runtime::TaintAnalysis_SetPropagationPaths(kValue, newObj);
+      }
+
       // 7b. Let Pk be ! ToString(k).
       // 7c. Perform ? Set(newObj, Pk, kValue, true).
       // Buffer may be detached during executing ToNumber/ToBigInt.
@@ -43,6 +50,12 @@ TypedArrayOf(js-implicit context: NativeContext, receiver: JSAny)(...arguments):
       // 7d. Increase k by 1. (done by the loop).
     }
 
+    // xqg start
+    if (tainted) {
+        runtime::TaintAnalysis_SetTaint(newObj);
+    }
+    // xqg end
+
     // 8. Return newObj.
     return newObj;
   } label NotConstructor deferred {
diff --git a/src/builtins/typed-array-slice.tq b/src/builtins/typed-array-slice.tq
index 0ac50a3ec75..f0d0b1efb8c 100644
--- a/src/builtins/typed-array-slice.tq
+++ b/src/builtins/typed-array-slice.tq
@@ -112,6 +112,12 @@ transitioning javascript builtin TypedArrayPrototypeSlice(
       // If the backing buffer is a RAB, it's possible that the length has
       // decreased since the last time we loaded it.
       if (k >= newLength) {
+        // xqg start
+        if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(receiver))) {
+                runtime::TaintAnalysis_SetTaint(dest);
+                runtime::TaintAnalysis_SetPropagationPaths(receiver, dest);
+          }
+        // xqg end
         return dest;
       }
       if (final > newLength) {
@@ -126,6 +132,12 @@ transitioning javascript builtin TypedArrayPrototypeSlice(
       SlowCopy(src, dest, k, final);
     }
   }
+  // xqg start
+  if (count > 0 && ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(receiver))) {
+        runtime::TaintAnalysis_SetTaint(dest);
+        runtime::TaintAnalysis_SetPropagationPaths(receiver, dest);
+  }
+  // xqg end
 
   return dest;
 }
diff --git a/src/builtins/typed-array-subarray.tq b/src/builtins/typed-array-subarray.tq
index d9506321b82..24202b32857 100644
--- a/src/builtins/typed-array-subarray.tq
+++ b/src/builtins/typed-array-subarray.tq
@@ -77,12 +77,22 @@ transitioning javascript builtin TypedArrayPrototypeSubArray(
       srcByteOffset + elementsInfo.CalculateByteLength(begin)
       otherwise ThrowRangeError(MessageTemplate::kInvalidArrayBufferLength);
 
+  // xqg start
+  const res: JSTypedArray = TypedArraySpeciesCreateByBuffer(
+                                  methodName, source, buffer, beginByteOffset, newLength);
+  if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(receiver))){
+           runtime::TaintAnalysis_SetTaint(res);
+           runtime::TaintAnalysis_SetPropagationPaths(receiver, res);
+  }
+  return res;
+  // xqg end
+
   // 18. If newLength is undefined, then
   //   a. Let argumentsList be  buffer, (beginByteOffset) .
   // 19. Else,
   //   a. Let argumentsList be  buffer, (beginByteOffset), (newLength) .
   // 20. Return ? TypedArraySpeciesCreate(O, argumentsList).
-  return TypedArraySpeciesCreateByBuffer(
-      methodName, source, buffer, beginByteOffset, newLength);
+  // return TypedArraySpeciesCreateByBuffer(
+  //    methodName, source, buffer, beginByteOffset, newLength);
 }
 }
diff --git a/src/builtins/typed-array-to-reversed.tq b/src/builtins/typed-array-to-reversed.tq
index d812e60a9fe..25180f8a9de 100644
--- a/src/builtins/typed-array-to-reversed.tq
+++ b/src/builtins/typed-array-to-reversed.tq
@@ -36,8 +36,14 @@ transitioning javascript builtin TypedArrayPrototypeToReversed(
     // e. Set k to k + 1.
     ++k;
   }
-
-  // 7. Return A.
+  // xqg start
+  if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(src))){
+         runtime::TaintAnalysis_SetTaint(copy);
+         runtime::TaintAnalysis_SetPropagationPaths(src, copy);
+  }
   return copy;
+  // xqg end
+  // 7. Return A.
+  // return copy;
 }
 }
diff --git a/src/builtins/typed-array-to-sorted.tq b/src/builtins/typed-array-to-sorted.tq
index c73821a9fc5..6da6d668d40 100644
--- a/src/builtins/typed-array-to-sorted.tq
+++ b/src/builtins/typed-array-to-sorted.tq
@@ -54,6 +54,14 @@ transitioning javascript builtin TypedArrayPrototypeToSorted(
   }
 
   const kIsSort: constexpr bool = false;
-  return TypedArraySortCommon(copy, len, comparefn, kIsSort);
+  // xqg start
+  const res: JSTypedArray = TypedArraySortCommon(copy, len, comparefn, kIsSort);
+  if (ToBoolean(runtime::TaintAnalysis_ContainsTaintedValue(obj))){
+         runtime::TaintAnalysis_SetTaint(res);
+         runtime::TaintAnalysis_SetPropagationPaths(obj, res);
+  }
+  return res;
+  // xqg end
+  // return TypedArraySortCommon(copy, len, comparefn, kIsSort);
 }
 }
diff --git a/src/codegen/code-factory.cc b/src/codegen/code-factory.cc
index c611445512c..73eb5e54467 100644
--- a/src/codegen/code-factory.cc
+++ b/src/codegen/code-factory.cc
@@ -121,7 +121,7 @@ Callable CodeFactory::OrdinaryToPrimitive(Isolate* isolate,
 Callable CodeFactory::StringAdd(Isolate* isolate, StringAddFlags flags) {
   switch (flags) {
     case STRING_ADD_CHECK_NONE:
-      return Builtins::CallableFor(isolate, Builtin::kStringAdd_CheckNone);
+      return Builtins::CallableFor(isolate, Builtin::kStringAdd_CheckNone1); // xqg
     case STRING_ADD_CONVERT_LEFT:
       return Builtins::CallableFor(isolate, Builtin::kStringAddConvertLeft);
     case STRING_ADD_CONVERT_RIGHT:
diff --git a/src/codegen/code-stub-assembler.cc b/src/codegen/code-stub-assembler.cc
index a069126f94d..8fb82c0d42e 100644
--- a/src/codegen/code-stub-assembler.cc
+++ b/src/codegen/code-stub-assembler.cc
@@ -6948,6 +6948,12 @@ TNode<BoolT> CodeStubAssembler::IsEphemeronHashTable(TNode<HeapObject> object) {
   return HasInstanceType(object, EPHEMERON_HASH_TABLE_TYPE);
 }
 
+// xqg start
+TNode<BoolT> CodeStubAssembler::IsObjectPointerHashTable(TNode<HeapObject> object) {
+    return HasInstanceType(object, OBJECT_POINTER_HASH_TABLE_TYPE);
+}
+// xqg end
+
 TNode<BoolT> CodeStubAssembler::IsNameDictionary(TNode<HeapObject> object) {
   return HasInstanceType(object, NAME_DICTIONARY_TYPE);
 }
@@ -7223,16 +7229,26 @@ TNode<String> CodeStubAssembler::StringFromSingleCharCode(TNode<Int32T> code) {
          &if_codeisonebyte, &if_codeistwobyte);
   BIND(&if_codeisonebyte);
   {
-    // Load the isolate wide single character string cache.
-    TNode<FixedArray> cache = SingleCharacterStringTableConstant();
-    TNode<IntPtrT> code_index = Signed(ChangeUint32ToWord(code));
+    // xqg start
 
-    TNode<Object> entry = UnsafeLoadFixedArrayElement(cache, code_index);
-    CSA_DCHECK(this, Word32BinaryNot(IsUndefined(entry)));
+//    // Load the isolate wide single character string cache.
+//    TNode<FixedArray> cache = SingleCharacterStringTableConstant();
+//    TNode<IntPtrT> code_index = Signed(ChangeUint32ToWord(code));
+//
+//    TNode<Object> entry = UnsafeLoadFixedArrayElement(cache, code_index);
+//    CSA_DCHECK(this, Word32BinaryNot(IsUndefined(entry)));
+//
+//    // Return the entry from the {cache}.
+//    var_result = CAST(entry);
+//    Goto(&if_done);
 
-    // Return the entry from the {cache}.
-    var_result = CAST(entry);
+    TNode<String> result = AllocateSeqOneByteString(1);
+    StoreNoWriteBarrier(
+            MachineRepresentation::kWord8, result,
+            IntPtrConstant(SeqOneByteString::kHeaderSize - kHeapObjectTag), code);
+    var_result = result;
     Goto(&if_done);
+    // xqg end
   }
 
   BIND(&if_codeistwobyte);
diff --git a/src/codegen/code-stub-assembler.h b/src/codegen/code-stub-assembler.h
index 6d654b5d5fa..94732e18bc5 100644
--- a/src/codegen/code-stub-assembler.h
+++ b/src/codegen/code-stub-assembler.h
@@ -2620,6 +2620,7 @@ class V8_EXPORT_PRIVATE CodeStubAssembler
   TNode<BoolT> IsFunctionWithPrototypeSlotMap(TNode<Map> map);
   TNode<BoolT> IsHashTable(TNode<HeapObject> object);
   TNode<BoolT> IsEphemeronHashTable(TNode<HeapObject> object);
+  TNode<BoolT> IsObjectPointerHashTable(TNode<HeapObject> object); // xqg
   TNode<BoolT> IsHeapNumberInstanceType(TNode<Int32T> instance_type);
   TNode<BoolT> IsOddball(TNode<HeapObject> object);
   TNode<BoolT> IsOddballInstanceType(TNode<Int32T> instance_type);
diff --git a/src/codegen/unoptimized-compilation-info.cc b/src/codegen/unoptimized-compilation-info.cc
index d0bc2d159d7..60d625a57a8 100644
--- a/src/codegen/unoptimized-compilation-info.cc
+++ b/src/codegen/unoptimized-compilation-info.cc
@@ -21,7 +21,10 @@ UnoptimizedCompilationInfo::UnoptimizedCompilationInfo(Zone* zone,
     : flags_(parse_info->flags()),
       dispatcher_(parse_info->dispatcher()),
       character_stream_(parse_info->character_stream()),
-      feedback_vector_spec_(zone) {
+      feedback_vector_spec_(zone),
+      zone_(zone), // xqg
+      parse_info_(parse_info) // xqg
+      {
   // NOTE: The parse_info passed here represents the global information gathered
   // during parsing, but does not represent specific details of the actual
   // function literal being compiled for this OptimizedCompilationInfo. As such,
diff --git a/src/codegen/unoptimized-compilation-info.h b/src/codegen/unoptimized-compilation-info.h
index b7fb1e8de63..1df1f964f63 100644
--- a/src/codegen/unoptimized-compilation-info.h
+++ b/src/codegen/unoptimized-compilation-info.h
@@ -42,6 +42,11 @@ class V8_EXPORT_PRIVATE UnoptimizedCompilationInfo final {
 
   // Accessors for the input data of the function being compiled.
 
+  // xqg start
+  Zone* zone() { return zone_;}
+  ParseInfo* parse_info() {return parse_info_;}
+  // xqg end
+
   FunctionLiteral* literal() const { return literal_; }
   void set_literal(FunctionLiteral* literal) {
     DCHECK_NOT_NULL(literal);
@@ -112,6 +117,11 @@ class V8_EXPORT_PRIVATE UnoptimizedCompilationInfo final {
 
   // Holds the feedback vector spec generated during compilation
   FeedbackVectorSpec feedback_vector_spec_;
+
+  // xqg start
+  Zone* zone_;
+  ParseInfo* parse_info_;
+  // xqg end
 };
 
 }  // namespace internal
diff --git a/src/common/assert-scope.h b/src/common/assert-scope.h
index 10e5e3907e1..ac641039082 100644
--- a/src/common/assert-scope.h
+++ b/src/common/assert-scope.h
@@ -208,20 +208,30 @@ using DisallowHandleAllocation =
 using AllowHandleAllocation =
     PerThreadAssertScopeDebugOnly<HANDLE_ALLOCATION_ASSERT, true>;
 
+// xqg start
 // Scope to document where we do not expect safepoints to be entered.
+//using DisallowSafepoints =
+//    PerThreadAssertScopeDebugOnly<SAFEPOINTS_ASSERT, false>;
 using DisallowSafepoints =
-    PerThreadAssertScopeDebugOnly<SAFEPOINTS_ASSERT, false>;
+    PerThreadAssertScope<SAFEPOINTS_ASSERT, false>;
 
 // Scope to introduce an exception to DisallowSafepoints.
-using AllowSafepoints = PerThreadAssertScopeDebugOnly<SAFEPOINTS_ASSERT, true>;
+//using AllowSafepoints = PerThreadAssertScopeDebugOnly<SAFEPOINTS_ASSERT, true>;
+using AllowSafepoints = PerThreadAssertScope<SAFEPOINTS_ASSERT, true>;
+
 
 // Scope to document where we do not expect any allocation.
+//using DisallowHeapAllocation =
+//    PerThreadAssertScopeDebugOnly<HEAP_ALLOCATION_ASSERT, false>;
 using DisallowHeapAllocation =
-    PerThreadAssertScopeDebugOnly<HEAP_ALLOCATION_ASSERT, false>;
+    PerThreadAssertScope<HEAP_ALLOCATION_ASSERT, false>;
 
 // Scope to introduce an exception to DisallowHeapAllocation.
+//using AllowHeapAllocation =
+//    PerThreadAssertScopeDebugOnly<HEAP_ALLOCATION_ASSERT, true>;
 using AllowHeapAllocation =
-    PerThreadAssertScopeDebugOnly<HEAP_ALLOCATION_ASSERT, true>;
+    PerThreadAssertScope<HEAP_ALLOCATION_ASSERT, true>;
+// xqg end
 
 // Scope to document where we do not expect any handle dereferences.
 using DisallowHandleDereference =
diff --git a/src/commons.cc b/src/commons.cc
new file mode 100644
index 00000000000..8f8ee0fa85c
--- /dev/null
+++ b/src/commons.cc
@@ -0,0 +1,291 @@
+#include "src/commons.h"
+#include <cstddef>
+
+namespace v8 {
+    namespace commons {
+
+        void LinkedList::initialize() {
+            fake_head_.prev = fake_tail_.next = NULL;
+            fake_head_.next = &fake_tail_;
+            fake_tail_.prev = &fake_head_;
+            size_ = 0;
+        }
+
+
+        void LinkedList::destroy() {
+            ListNode *prev, *cur;
+            for (cur = fake_head_.next; cur != &fake_tail_; ) {
+                prev = cur;
+                cur = cur->next;
+                delete prev;
+            }
+            initialize();
+        }
+
+
+        LinkedList::LinkedList() {
+            initialize();
+        }
+
+
+        LinkedList::~LinkedList() {
+            destroy();
+        }
+
+
+        static void IterateLinkedListCopy(void *key, void *value, void *data) {
+            LinkedList *list = (LinkedList *)data;
+            list->append(key, value);
+        }
+
+
+        LinkedList &LinkedList::operator=(const LinkedList &other) {
+            destroy();
+            other.iterate(IterateLinkedListCopy, this);
+            return *this;
+        }
+
+
+        LinkedList::LinkedList(LinkedList &other) {
+            initialize();
+            other.iterate(IterateLinkedListCopy, this);
+        }
+
+
+        void LinkedList::prepend(void *key, void *value) {
+            ListNode *node = new ListNode();
+            node->key = key;
+            node->value = value;
+
+            node->next = fake_head_.next;
+            node->prev = &fake_head_;
+            fake_head_.next->prev = node;
+            fake_head_.next = node;
+
+            size_ += 1;
+        }
+
+
+        void LinkedList::append(void *key, void *value) {
+            ListNode *node = new ListNode();
+            node->key = key;
+            node->value = value;
+
+            node->next = &fake_tail_;
+            node->prev = fake_tail_.prev;
+            fake_tail_.prev->next = node;
+            fake_tail_.prev = node;
+
+            size_ += 1;
+        }
+
+
+        void LinkedList::remove(void *key) {
+            ListNode *cur;
+            for (cur = &fake_head_; cur->next != &fake_tail_ &&
+                                    cur->next->key != key; cur = cur->next) {
+                ;
+            }
+            if (cur->next != &fake_tail_) {
+                ListNode *p = cur->next;
+                cur->next = p->next;
+                p->next->prev = cur;
+                delete p;
+                size_ -= 1;
+            }
+        }
+
+
+        bool LinkedList::search(void *key) {
+            for (ListNode *cur = fake_head_.next; cur != &fake_tail_; cur = cur->next)
+                if (cur->key == key)
+                    return true;
+            return false;
+        }
+
+
+        void *LinkedList::get(void *key) {
+            for (ListNode *cur = fake_head_.next; cur != &fake_tail_; cur = cur->next)
+                if (cur->key == key)
+                    return cur->value;
+            return NULL;
+        }
+
+
+        void LinkedList::iterate(IterateCallback callback, void *data) const {
+            for (ListNode *cur = fake_head_.next; cur != &fake_tail_; cur = cur->next) {
+                callback(cur->key, cur->value, data);
+            }
+        }
+
+
+        bool LinkedList::empty() { return (size_ == 0); }
+
+
+        void *LinkedList::head_key() {
+            if (!empty())
+                return fake_head_.next->key;
+            return NULL;
+        }
+
+
+        void *LinkedList::head_value() {
+            if (!empty())
+                return fake_head_.next->value;
+            return NULL;
+        }
+
+
+        void *LinkedList::tail_key() {
+            if (!empty())
+                return fake_tail_.prev->key;
+            return NULL;
+        }
+
+
+        void *LinkedList::tail_value() {
+            if (!empty())
+                return fake_tail_.prev->value;
+            return NULL;
+        }
+
+
+        void LinkedList::pop_head() {
+            if (!empty()) {
+                ListNode *p = fake_head_.next;
+                fake_head_.next = p->next;
+                p->next->prev = &fake_head_;
+                delete p;
+                size_ -= 1;
+            }
+        }
+
+
+        void LinkedList::pop_tail() {
+            if (!empty()) {
+                ListNode *p = fake_tail_.prev;
+                fake_tail_.prev = p->prev;
+                p->prev->next = &fake_tail_;
+                delete p;
+                size_ -= 1;
+            }
+        }
+
+
+        void LinkedList::clear() {
+            destroy();
+        }
+
+
+        HashTable::HashTable() {
+            buckets_ = new LinkedList[kMinCapacity];
+            capacity_ = kMinCapacity;
+            size_ = 0;
+        }
+
+
+        HashTable::~HashTable() {
+            delete[] buckets_;
+            buckets_ = NULL;
+            capacity_ = 0;
+            size_ = 0;
+        }
+
+
+        int HashTable::hash_pointer(void *ptr, int mod) {
+            unsigned long hash = reinterpret_cast<unsigned long>(ptr);
+            hash = ~hash + (hash << 18);  // hash = (hash << 18) - hash - 1;
+            hash = hash ^ (hash >> 31);
+            hash = hash * 21;  // hash = (hash + (hash << 2)) + (hash << 4);
+            hash = hash ^ (hash >> 11);
+            hash = hash + (hash << 6);
+            hash = hash ^ (hash >> 22);
+            hash = hash % ((unsigned long)mod);
+
+            CHECK((int)hash >= 0 && (int)hash < mod);
+            return (int)hash;
+        }
+
+
+        void HashTable::insert(void *key, void *value) {
+            remove(key);  // Overwrite if duplicate key.
+            int idx = hash_pointer(key, capacity_);
+            buckets_[idx].append(key, value);
+            size_ += 1;
+            check_load_factor();
+        }
+
+
+        void HashTable::remove(void *key) {
+            int idx = hash_pointer(key, capacity_);
+            if (buckets_[idx].search(key)) {
+                buckets_[idx].remove(key);
+                size_ -= 1;
+                check_load_factor();
+            }
+        }
+
+
+        bool HashTable::search(void *key) {
+            int idx = hash_pointer(key, capacity_);
+            return buckets_[idx].search(key);
+        }
+
+
+        void *HashTable::get(void *key) {
+            int idx = hash_pointer(key, capacity_);
+            return buckets_[idx].get(key);
+        }
+
+
+        void HashTable::clear() {
+            delete[] buckets_;
+            buckets_ = new LinkedList[kMinCapacity];
+            capacity_ = kMinCapacity;
+            size_ = 0;
+        }
+
+
+        void HashTable::iterate(IterateCallback callback, void *data) {
+            for (int idx = 0; idx < capacity_; idx++) {
+                buckets_[idx].iterate(callback, data);
+            }
+        }
+
+
+        bool HashTable::empty() { return (size_ == 0); }
+
+
+        struct ResizeHashTable_Data {
+            LinkedList *new_buckets;
+            int new_capacity;
+        };
+
+        void HashTable::Iterate_ResizeHashTable(void *key, void *value, void *data) {
+            ResizeHashTable_Data *d = static_cast<ResizeHashTable_Data *>(data);
+            int idx = hash_pointer(key, d->new_capacity);
+            d->new_buckets[idx].append(key, value);
+        }
+
+
+        void HashTable::resize_table(int new_capacity) {
+            LinkedList *new_buckets = new LinkedList[new_capacity];
+            ResizeHashTable_Data data = { new_buckets, new_capacity };
+            this->iterate(Iterate_ResizeHashTable, &data);
+            delete[] buckets_;
+            buckets_ = new_buckets;
+            capacity_ = new_capacity;
+        }
+
+
+        void HashTable::check_load_factor() {
+            int upper_limit = (capacity_ / 4) * 3;
+            int lower_limit = (capacity_ / 4);
+            if (size_ < lower_limit && capacity_ / 2 >= kMinCapacity)
+                resize_table(capacity_ / 2);
+            else if (size_ > upper_limit)
+                resize_table(capacity_ * 2);
+        }
+
+    }  // namespace commons
+}  // namespace v8
diff --git a/src/commons.h b/src/commons.h
new file mode 100644
index 00000000000..35da7387269
--- /dev/null
+++ b/src/commons.h
@@ -0,0 +1,98 @@
+#ifndef V8_COMMONS_H_
+#define V8_COMMONS_H_
+
+#include "src/base/logging.h"
+
+namespace v8 {
+    namespace commons {
+
+        typedef void (*IterateCallback)(void *key, void *value, void *data);
+
+// Doubly-linked list.
+        class LinkedList {
+        public:
+            LinkedList();
+
+            LinkedList(LinkedList &other);
+
+            ~LinkedList();
+
+            LinkedList &operator=(const LinkedList &other);
+
+            bool empty();
+
+            void prepend(void *key, void *value);
+            void append(void *key, void *value);
+            void remove(void *key);
+            bool search(void *key);
+            void *get(void *key);
+
+            void *head_key();
+            void *head_value();
+            void *tail_key();
+            void *tail_value();
+
+            void pop_head();
+            void pop_tail();
+
+            void clear();
+
+            void iterate(IterateCallback callback, void *data) const;
+
+            int size() { return size_; }
+
+        private:
+            void initialize();
+            void destroy();
+
+            struct ListNode {
+                void *key;
+                void *value;
+                struct ListNode *prev;
+                struct ListNode *next;
+            };
+
+            ListNode fake_head_;
+            ListNode fake_tail_;
+            int size_;
+        };
+
+
+// Hash with chaining.
+        class HashTable {
+        public:
+            HashTable();
+
+            ~HashTable();
+
+            bool empty();
+
+            void insert(void *key, void *value);
+            void remove(void *key);
+            bool search(void *key);
+            void *get(void *key);
+
+            void clear();
+
+            void iterate(IterateCallback callback, void *data);
+
+            int size() { return size_; }
+
+        private:
+            static int hash_pointer(void *ptr, int mod);
+
+            static void Iterate_ResizeHashTable(void *key, void *value, void *data);
+            void resize_table(int new_capacity);
+            void check_load_factor();
+
+            static const int kMinCapacity = 8;
+
+            LinkedList *buckets_;
+            int capacity_;  // Number of buckets.
+            int size_;      // Total number of keys.
+        };
+
+    }  // namespace commons
+}  // namespace v8
+
+#endif
diff --git a/src/compiler/bytecode-graph-builder.cc b/src/compiler/bytecode-graph-builder.cc
index f43199cd37a..0041ec8ee98 100644
--- a/src/compiler/bytecode-graph-builder.cc
+++ b/src/compiler/bytecode-graph-builder.cc
@@ -332,6 +332,7 @@ class BytecodeGraphBuilder {
   void BuildJumpIfToBooleanFalse();
   void BuildJumpIfNotHole();
   void BuildJumpIfJSReceiver();
+  void BuildJumpIfNotSmi(); // xqg
 
   void BuildSwitchOnSmi(Node* condition);
   void BuildSwitchOnGeneratorState(
@@ -3478,6 +3479,10 @@ void BytecodeGraphBuilder::VisitJumpIfToBooleanFalseConstant() {
   BuildJumpIfToBooleanFalse();
 }
 
+// xqg start
+void BytecodeGraphBuilder::VisitJumpIfNotSmi() { BuildJumpIfNotSmi(); }
+// xqg end
+
 void BytecodeGraphBuilder::VisitJumpIfJSReceiver() { BuildJumpIfJSReceiver(); }
 
 void BytecodeGraphBuilder::VisitJumpIfJSReceiverConstant() {
@@ -4055,6 +4060,14 @@ void BytecodeGraphBuilder::BuildJumpIfNotHole() {
   BuildJumpIfNot(condition);
 }
 
+// xqg start
+void BytecodeGraphBuilder::BuildJumpIfNotSmi() {
+    Node* accumulator = environment()->LookupAccumulator();
+    Node* condition = NewNode(simplified()->ObjectIsSmi(), accumulator);
+    BuildJumpIfNot(condition);
+}
+// xqg end
+
 void BytecodeGraphBuilder::BuildJumpIfJSReceiver() {
   Node* accumulator = environment()->LookupAccumulator();
   Node* condition = NewNode(simplified()->ObjectIsReceiver(), accumulator);
diff --git a/src/debug/debug-evaluate.cc b/src/debug/debug-evaluate.cc
index 2813456b126..c8a4f70a9cd 100644
--- a/src/debug/debug-evaluate.cc
+++ b/src/debug/debug-evaluate.cc
@@ -1158,6 +1158,7 @@ static bool TransitivelyCalledBuiltinHasNoSideEffect(Builtin caller,
     case Builtin::kRecordWriteSaveFP:
     case Builtin::kRecordWriteIgnoreFP:
     case Builtin::kStringAdd_CheckNone:
+    case Builtin::kStringAdd_CheckNone1: // xqg
     case Builtin::kStringEqual:
     case Builtin::kStringIndexOf:
     case Builtin::kStringRepeat:
diff --git a/src/diagnostics/objects-debug.cc b/src/diagnostics/objects-debug.cc
index 0db2d9e2438..3a8d6c2c892 100644
--- a/src/diagnostics/objects-debug.cc
+++ b/src/diagnostics/objects-debug.cc
@@ -218,6 +218,7 @@ void HeapObject::HeapObjectVerify(Isolate* isolate) {
     case NUMBER_DICTIONARY_TYPE:
     case SIMPLE_NUMBER_DICTIONARY_TYPE:
     case EPHEMERON_HASH_TABLE_TYPE:
+    case OBJECT_POINTER_HASH_TABLE_TYPE: // xqg
     case SCRIPT_CONTEXT_TABLE_TYPE:
       FixedArray::cast(*this).FixedArrayVerify(isolate);
       break;
@@ -1344,7 +1345,8 @@ void JSFinalizationRegistry::JSFinalizationRegistryVerify(Isolate* isolate) {
 
 void JSWeakMap::JSWeakMapVerify(Isolate* isolate) {
   TorqueGeneratedClassVerifiers::JSWeakMapVerify(*this, isolate);
-  CHECK(table().IsEphemeronHashTable() || table().IsUndefined(isolate));
+//  CHECK(table().IsEphemeronHashTable() || table().IsUndefined(isolate));
+  CHECK(table().IsHashTable() || table().IsUndefined(isolate)); // xqg
 }
 
 void JSArrayIterator::JSArrayIteratorVerify(Isolate* isolate) {
diff --git a/src/diagnostics/objects-printer.cc b/src/diagnostics/objects-printer.cc
index ce4d15b2c27..1123b3e46a7 100644
--- a/src/diagnostics/objects-printer.cc
+++ b/src/diagnostics/objects-printer.cc
@@ -169,6 +169,9 @@ void HeapObject::HeapObjectPrint(std::ostream& os) {
     case EPHEMERON_HASH_TABLE_TYPE:
       EphemeronHashTable::cast(*this).EphemeronHashTablePrint(os);
       break;
+    case OBJECT_POINTER_HASH_TABLE_TYPE: // xqg
+      ObjectPointerHashTable::cast(*this).ObjectPointerHashTablePrint(os);
+      break;
     case OBJECT_BOILERPLATE_DESCRIPTION_TYPE:
       ObjectBoilerplateDescription::cast(*this)
           .ObjectBoilerplateDescriptionPrint(os);
@@ -1008,6 +1011,13 @@ void EphemeronHashTable::EphemeronHashTablePrint(std::ostream& os) {
   PrintHashMapContentsFull(os, *this);
 }
 
+// xqg start
+void ObjectPointerHashTable::ObjectPointerHashTablePrint(std::ostream& os) {
+  PrintHashTableHeader(os, *this, "ObjectPointerHashTable");
+  PrintHashMapContentsFull(os, *this);
+}
+// xqg end
+
 void NameDictionary::NameDictionaryPrint(std::ostream& os) {
   PrintHashTableHeader(os, *this, "NameDictionary");
   PrintDictionaryContentsFull(os, *this);
diff --git a/src/execution/isolate.cc b/src/execution/isolate.cc
index 3d6717a8778..e596385eacd 100644
--- a/src/execution/isolate.cc
+++ b/src/execution/isolate.cc
@@ -114,6 +114,15 @@
 #include "src/utils/version.h"
 #include "src/zone/accounting-allocator.h"
 #include "src/zone/type-stats.h"
+
+// xqg start
+#include "src/objects/js-collection-inl.h"
+#include <fcntl.h>
+#include "src/runtime/runtime-taint.h"
+#include <iostream>
+#include <unistd.h> // for close() and unlink()
+// xqg end
+
 #ifdef V8_INTL_SUPPORT
 #include "src/objects/intl-objects.h"
 #include "unicode/locid.h"
@@ -700,6 +709,1192 @@ void Isolate::PushParamsAndDie(void* ptr1, void* ptr2, void* ptr3, void* ptr4,
   base::OS::Abort();
 }
 
+// xqg start
+        void Isolate::IterateTaintAnalysisStuff(RootVisitor *v) {
+            persistent_handle_table_.iterate(PersistentHandleData::IterateHandles, v);
+        }
+
+        void Isolate::PostGCHook() {
+            DestroyQueuedValues();
+        }
+
+// ======= Persistent Handle start ==========
+        void Isolate::EnterPersistentHandleMode(void *lookup) {
+            CHECK(!InPersistentHandleMode());
+            if (!persistent_handle_table_.search(lookup)) {
+                persistent_handle_data_ = new PersistentHandleData();
+                persistent_handle_table_.insert(lookup, persistent_handle_data_);
+            } else {
+                persistent_handle_data_ = (PersistentHandleData *)(persistent_handle_table_.get(lookup));
+            }
+            persistent_handle_lookup_ = lookup;
+        }
+
+        void Isolate::ExitPersistentHandleMode() {
+            CHECK(InPersistentHandleMode());
+            persistent_handle_data_ = nullptr;
+            persistent_handle_lookup_ = nullptr;
+        }
+
+        bool Isolate::InPersistentHandleMode() {
+            return (persistent_handle_data_ != nullptr);
+        }
+
+        Address* Isolate::CreatePersistentHandle(Address value) {
+            CHECK(InPersistentHandleMode());
+            return persistent_handle_data_->CreateHandle(value);
+        }
+
+        void Isolate::DestroyPersistentHandles(void *lookup) {
+            CHECK(persistent_handle_lookup_ != lookup);
+            PersistentHandleData *data = (PersistentHandleData *)(
+                    persistent_handle_table_.get(lookup));
+
+            if (data != nullptr) {
+                delete data;
+                persistent_handle_table_.remove(lookup);
+            }
+        }
+// ======= Persistent Handle end ==========
+
+// ======= AST generation and searching start ==========
+static v8::Extension *dummy_extension = new v8::Extension("DummyExtension");
+
+        UnoptimizedCompilationInfo *Isolate::GetCompilationInfo(Handle<JSFunction> function) {
+            UnoptimizedCompilationInfo* info = nullptr;
+            Handle<SharedFunctionInfo> shared(function->shared(), this);
+
+            info = (UnoptimizedCompilationInfo *)permanent_ast_cache_->get(reinterpret_cast<void*>(shared->ptr()));
+            if (info != nullptr)
+                return info;
+
+            lookup_count_ += 1;
+            if (lookup_count_ == 10240) {
+                //printf("Hit rate = %.2f\n", (double)hit_count_ / lookup_count_);
+                hit_count_ = lookup_count_ = 0;
+            }
+
+            info = (UnoptimizedCompilationInfo *)ast_cache_->get(reinterpret_cast<void*>(shared->ptr()));
+            if (info != nullptr) {
+                hit_count_ += 1;
+                return info;
+            }
+
+            /*
+             * Cache miss, parse for AST and insert into cache.
+             */
+
+#define AST_CACHE_LIMIT  (1 << 20)
+
+            Zone* zone = new Zone(this->allocator(), "TaintCompile");
+            EnterPersistentHandleMode(zone);
+
+            ReusableUnoptimizedCompileState* reusable_state = new ReusableUnoptimizedCompileState(this);
+            UnoptimizedCompileFlags flags =
+                    UnoptimizedCompileFlags::ForFunctionCompile(this, *shared);
+
+            UnoptimizedCompileState compile_state;
+            ParseInfo* parse_info = new ParseInfo(this, flags, &compile_state, reusable_state);
+
+            if (!shared->IsUserJavaScript())
+                parse_info->set_extension(dummy_extension);
+
+            CHECK(parsing::ParseAny(parse_info, Handle<SharedFunctionInfo>(function->shared(), this), this, parsing::ReportStatisticsMode::kYes));
+            info = new UnoptimizedCompilationInfo(zone, parse_info, parse_info->literal());
+
+            ExitPersistentHandleMode();
+
+            if (ast_cache_->size() == AST_CACHE_LIMIT) {
+                // Eviction. For now we just get the first valid entry in
+                // the |ast_cache_| hash table.
+                ReadOnlyRoots roots(this);
+                Handle<ObjectPointerHashTable> table(ast_cache_->get_table(), this);
+                Handle<SharedFunctionInfo> victim;
+                int capacity = table->Capacity();
+                for (int i = 0; i < capacity; i++) {
+                    InternalIndex entry(i);
+                    Object obj = table->KeyAt(entry);
+                    if (table->IsKey(roots, obj)){
+                        victim = Handle<SharedFunctionInfo>(SharedFunctionInfo::cast(obj), this);
+                        break;
+                    }
+                }
+                CHECK(!victim.is_null());
+                UnoptimizedCompilationInfo *victim_info = (UnoptimizedCompilationInfo *)ast_cache_->get(reinterpret_cast<void*>(victim->ptr()));
+                CHECK(victim_info != nullptr);
+                // Do enqueue before remove.
+                EnqueueValueForDestroy(victim_info, AstCacheValueDestructor);
+                ast_cache_->remove(reinterpret_cast<void*>(victim->ptr()));
+            }
+            CHECK(ast_cache_->size() < AST_CACHE_LIMIT);
+            ast_cache_->insert(reinterpret_cast<void*>(shared->ptr()), info);
+
+#undef AST_CACHE_LIMIT
+            return info;
+        }
+
+        ScopeDFG *Isolate::GetScopeDFG(UnoptimizedCompilationInfo *info, long position) {
+            // working....
+            i::OFStream os(stdout);
+//            os << "inside GetScopeDFG(), position="<<position<<"\n";
+            commons::HashTable *table = (commons::HashTable *)scope_dfg_cache_.get(info);
+            if (table == nullptr) {
+                table = new commons::HashTable();
+                scope_dfg_cache_.insert(info, table);
+            }
+            ScopeDFG *dfg = (ScopeDFG *)table->get((void *)position);
+            if (dfg == nullptr){
+//                os << "dfg=null, position="<<position<<"\n";
+                ScopeLocator locator(this, info->scope(), position);
+                locator.Locate(info->literal()->body());
+                if (locator.found()) {
+//                    os << "locator found\n";
+                    ScopeDFGBuilder builder(this, locator.LocatedScope(),
+                                            locator.scope_dependencies(), locator.dependency_scopes());
+//                    os << "before after\n";
+
+                    dfg = builder.Build(locator.LocatedScopeStatements());
+//                    os << "before build\n";
+
+                    CHECK(dfg != nullptr);
+                    table->insert((void*)position, dfg);
+                } else {
+//                    os << "locator found\n";
+                }
+            }
+            return dfg;
+        }
+
+        void Isolate::AddLocatedScopeAndNode(UnoptimizedCompilationInfo *info,
+                                             long type,
+                                             long position,
+                                             ScopeAndNode *cached){
+            commons::HashTable *table =
+                    (commons::HashTable *)located_scope_and_node_cache_.get(info);
+
+            if (table == nullptr){
+                table = new commons::HashTable();
+                located_scope_and_node_cache_.insert(info, table);
+            }
+
+            commons::HashTable *inner_table =
+                    (commons::HashTable *)table->get((void *)type);
+            if (inner_table == nullptr) {
+                inner_table = new commons::HashTable();
+                table->insert((void *)type, inner_table);
+            }
+
+            inner_table->insert((void *)position, cached);
+        }
+
+        ScopeAndNode *Isolate::LocatedScopeAndNode(UnoptimizedCompilationInfo *info,
+                                                   long type,
+                                                   long position){
+            commons::HashTable *table =
+                    (commons::HashTable *)located_scope_and_node_cache_.get(info);
+            if (table == nullptr)
+                return nullptr;
+
+            commons::HashTable *inner_table =
+                    (commons::HashTable *)table->get((void *)type);
+            if (inner_table == nullptr)
+                return nullptr;
+
+            return (ScopeAndNode *)inner_table->get((void *)position);
+        }
+
+// ======= AST generation and searching end ==========
+
+// ======= V8GCHashTable start ==========
+        Isolate::V8GCHashTable::V8GCHashTable(Isolate *isolate,
+                                              void (*value_destructor)(Isolate *,void *))
+                : isolate_(isolate) {
+            isolate_->EnterPersistentHandleMode(this);
+            weak_map_ = isolate_->factory()->NewJSWeakMap(true);
+            isolate_->ExitPersistentHandleMode();
+
+            {
+                // Initialize() is going to make a Handle of the backing
+                // ObjectHashTable - don't make it persistent!
+                HandleScope scope(isolate_);
+                JSWeakCollection::Initialize(weak_map_, isolate_, true);
+            }
+
+            if (value_destructor != nullptr){
+                // TODO: handle the Weak Collection GC problem later
+            }
+        }
+
+        Isolate::V8GCHashTable::~V8GCHashTable() {
+            // TODO: Invoke value destructor if set.
+            HandleScope scope(isolate_);
+            weak_map_ = Handle<JSWeakMap>::null();
+            isolate_->DestroyPersistentHandles(this);
+        }
+
+        bool Isolate::V8GCHashTable::empty() {
+            return (size() == 0);
+        }
+
+        int Isolate::V8GCHashTable::size() {
+            HandleScope scope(isolate_);
+            Handle<ObjectPointerHashTable> table(get_table(), isolate_);
+            return table->NumberOfElements();
+        }
+
+        ObjectPointerHashTable Isolate::V8GCHashTable::get_table() {
+            return ObjectPointerHashTable::cast(weak_map_->table());
+        }
+
+        void Isolate::V8GCHashTable::insert(void *key, void *value, bool local, LocalIsolate* local_isolate) {
+            if (local){
+                LocalHandleScope scope(local_isolate);
+                Handle<Object> obj_key(Object(reinterpret_cast<Address>(key)), local_isolate);
+                Handle<Object> obj_value(Object(reinterpret_cast<Address>(value)), isolate_);
+                obj_value = Handle<Object>(Object(reinterpret_cast<Address>(reinterpret_cast<void*>(obj_value->ptr()))), local_isolate);
+                CHECK(obj_key->IsHeapObject());
+                int32_t hash = obj_key->GetOrCreateHash(isolate_).value();
+                JSWeakCollection::Set(weak_map_, obj_key, obj_value, hash, true);
+                return;
+            }
+            HandleScope scope(isolate_);
+            Handle<Object> obj_key(Object(reinterpret_cast<Address>(key)), isolate_);
+            Handle<Object> obj_value(Object(reinterpret_cast<Address>(value)), isolate_);
+            obj_key = get_key_handle(reinterpret_cast<void*>(obj_key->ptr()));
+            obj_value = get_value_handle(reinterpret_cast<void*>(obj_value->ptr()));
+            CHECK(obj_key->IsHeapObject());
+            int32_t hash = obj_key->GetOrCreateHash(isolate_).value();
+            JSWeakCollection::Set(weak_map_, obj_key, obj_value, hash, true);
+        }
+
+        void Isolate::V8GCHashTable::remove(void *key, bool local, LocalIsolate* local_isolate) {
+            if (local){
+                LocalHandleScope scope(local_isolate);
+                Handle<Object> obj_key(Object(reinterpret_cast<Address>(key)), local_isolate);
+                int32_t hash = obj_key->GetOrCreateHash(isolate_).value();
+                JSWeakCollection::Delete(weak_map_, obj_key, hash, true);
+                return;
+            }
+
+            HandleScope scope(isolate_);
+            Handle<Object> obj_key = get_key_handle(key);
+            int32_t hash = obj_key->GetOrCreateHash(isolate_).value();
+            JSWeakCollection::Delete(weak_map_, obj_key, hash, true);
+        }
+
+        bool Isolate::V8GCHashTable::search(void *key, bool local, LocalIsolate* local_isolate) {
+            if (local) {
+                LocalHandleScope scope(local_isolate);
+                Handle <ObjectPointerHashTable> table(get_table(), local_isolate);
+                Handle<Object> obj_key(Object(reinterpret_cast<Address>(key)), local_isolate);
+                // local handle case are only from string concat, substring, thus they must be heap object.
+                // Therefore we don't need use get_key_handle function.
+                CHECK(obj_key->IsHeapObject());
+                return (table->Lookup(obj_key) != ReadOnlyRoots(isolate_).the_hole_value());
+            }
+
+            HandleScope scope(isolate_);
+            Handle<ObjectPointerHashTable> table(get_table(), isolate_);
+            Handle<Object> obj_key = get_key_handle(key);
+            return (table->Lookup(obj_key) != ReadOnlyRoots(isolate_).the_hole_value());
+
+        }
+
+        void* Isolate::V8GCHashTable::get(void *key, bool local, LocalIsolate* local_isolate) {
+            if (local){
+                LocalHandleScope scope(local_isolate);
+                Handle<ObjectPointerHashTable> table(get_table(), isolate_);
+                Handle<Object> obj_key(Object(reinterpret_cast<Address>(key)), local_isolate);
+                CHECK(obj_key->IsHeapObject());
+                Object value = table->Lookup(obj_key);
+                if (value == ReadOnlyRoots(isolate_).the_hole_value()) return nullptr;
+                if (value.IsZero()) return nullptr;
+
+                return reinterpret_cast<void*>(value.ptr());
+            }
+            HandleScope scope(isolate_);
+            Handle<ObjectPointerHashTable> table(get_table(), isolate_);
+            Handle<Object> obj_key = get_key_handle(key);
+            Object value = table->Lookup(obj_key);
+
+            if (value == ReadOnlyRoots(isolate_).the_hole_value())
+                return nullptr;
+            if (value.IsZero()) // myself, not sure?
+                return nullptr;
+            return reinterpret_cast<void*>(value.ptr());
+
+        }
+
+        void Isolate::V8GCHashTable::iterate(commons::IterateCallback callback,
+                                             void *data) {
+        }
+
+        Handle<Object> Isolate::V8GCHashTable::get_key_handle(void *key) {
+            Handle<Object> key_handle(Object(reinterpret_cast<Address>(key)), isolate_);
+            if (!key_handle->IsHeapObject()) {
+                Address* location = reinterpret_cast<Address*>(non_heap_keys_.get(key));
+                if (location == nullptr) {
+                    isolate_->EnterPersistentHandleMode(this);
+                    // Value does not really matter, we just need _some_ unique
+                    // heap object to map the key to.
+                    Handle<HeapNumber> heap_key_handle = isolate_->factory()->NewHeapNumber(
+                            static_cast<double>(reinterpret_cast<Address>(key)));
+                    isolate_->ExitPersistentHandleMode();
+
+                    location = reinterpret_cast<Address*>(heap_key_handle.location());
+                    non_heap_keys_.insert(key, reinterpret_cast<void*>(location));
+                }
+                key_handle = Handle<Object>(location);
+            }
+            return key_handle;
+        }
+
+        Handle<Object> Isolate::V8GCHashTable::get_value_handle(void *value) {
+            return Handle<Object>(Object(reinterpret_cast<Address>(value)), isolate_);
+        }
+// ======= V8GCHashTable end ==========
+
+        void Isolate::EnqueueValueForDestroy(
+                void *value, void (*value_destructor)(Isolate *, void *)) {
+            values_to_destroy_.insert(value, reinterpret_cast<void *>(value_destructor));
+        }
+
+        void Isolate::IterateDestroyQueuedValues(void *key, void *value, void *data) {
+            Isolate *isolate = reinterpret_cast<Isolate *>(data);
+            void (*value_destructor)(Isolate *, void *) =
+            reinterpret_cast<void (*)(Isolate *, void *)>(value);
+            value_destructor(isolate, key);
+        }
+
+        void Isolate::DestroyQueuedValues() {
+            values_to_destroy_.iterate(IterateDestroyQueuedValues, this);
+            values_to_destroy_.clear();
+        }
+
+        void Isolate::TaintTableValueDestructor(Isolate *isolate, void *value) {
+            if (value != nullptr)
+                delete static_cast<std::vector<bool> *>(value);
+        }
+
+        void Isolate::DisposeCompilationInfo(UnoptimizedCompilationInfo *info) {
+            CHECK(info != nullptr);
+
+            Zone *zone = info->zone();
+            delete zone;
+            delete info->parse_info(); // fine
+            delete info;
+            DestroyPersistentHandles(zone);
+
+            commons::HashTable *table;
+
+            table = (commons::HashTable *)scope_dfg_cache_.get(info);
+            if (table != nullptr) {
+                table->iterate(IterateScopeDFGDestructor, nullptr);
+                delete table;
+                scope_dfg_cache_.remove(info);
+            }
+
+            table = (commons::HashTable *)located_scope_and_node_cache_.get(info);
+            if (table != nullptr){
+                table->iterate(IterateScopeAndNodeDestructor, nullptr);
+                delete table;
+                located_scope_and_node_cache_.remove(info);
+            }
+        }
+
+        void Isolate::AstCacheValueDestructor(Isolate *isolate, void *value){
+            isolate->DisposeCompilationInfo((UnoptimizedCompilationInfo *)value);
+        }
+
+        void Isolate::IterateScopeDFGDestructor(void *key, void *value, void *data) {
+            delete (ScopeDFG *)value;
+        }
+
+        void Isolate::IterateScopeAndNodeDestructor(void *key,
+                                                    void *value,
+                                                    void *data) {
+            commons::HashTable *inner_table = (commons::HashTable *)value;
+            inner_table->iterate(IterateScopeAndNodeInnerDestructor, nullptr);
+            delete inner_table;
+        }
+
+        void Isolate::IterateScopeAndNodeInnerDestructor(void *key,
+                                                         void *value,
+                                                         void *data) {
+            delete (ScopeAndNode *)value;
+        }
+
+        void Isolate::MakeASTPermanent(Handle<JSFunction> function) {
+            if (permanent_ast_cache_->search(reinterpret_cast<void*>(function->shared().ptr())))
+                return;
+
+            EnterPersistentHandleMode(this);
+            Handle<SharedFunctionInfo> shared(function->shared(), this);  // Pin this first.
+            ExitPersistentHandleMode();
+
+            // XXX: I guess the reason for this CHECK was that
+            // the AST cache used to be LRU-replaced, so we can
+            // expect that the AST is never evicted.
+            // CHECK(ast_cache_->search(function->shared()));
+
+            UnoptimizedCompilationInfo *info = GetCompilationInfo(function);
+            // These statements might trigger GC.
+            permanent_ast_cache_->insert(reinterpret_cast<void*>(shared->ptr()), info);
+            ast_cache_->remove(reinterpret_cast<void*>(function->shared().ptr()));
+        }
+
+
+// ======= OBJ taint table operations start ==========
+void Isolate::SetTaintForV8Object(Handle<Object> obj,
+                                  std::vector<bool> tainted_bytes,
+                                  bool local,
+                                  LocalIsolate* local_isolate) {
+    obj = FilterInvalidV8Objects(this, obj);
+    if (obj.is_null() || obj->IsSmi())
+        return;
+
+    if (IsDoNotTaint(obj) || taint_table_->search(reinterpret_cast<void*>(obj->ptr()), local, local_isolate))  // Do not overwrite.
+        return;
+    i::OFStream os(stdout);
+    if (!obj->IsString()){
+//        os << "Enter Isolate::SetTaintForV8Object, not a string, obj="<<obj<<"\n";
+    }
+
+    if (obj->IsString() && !tainted_bytes.empty()) {
+        CHECK(Handle<String>::cast(obj)->length() == static_cast<int>(tainted_bytes.size()));
+        std::vector<bool> *ptb = new std::vector<bool>();
+        *ptb = tainted_bytes;
+        taint_table_->insert(reinterpret_cast<void*>(obj->ptr()), ptb, local, local_isolate);
+    } else {
+        taint_table_->insert(reinterpret_cast<void*>(obj->ptr()), nullptr, local, local_isolate);
+        if (obj->IsJSTypedArray()){
+            Handle<JSArrayBuffer> buffer = JSTypedArray::cast(*obj).GetBuffer();
+            if (IsDoNotTaint(buffer) || taint_table_->search(reinterpret_cast<void*>(buffer->ptr()), local, local_isolate))  // Do not overwrite.
+                return;
+            taint_table_->insert(reinterpret_cast<void*>(buffer->ptr()), nullptr, local, local_isolate);
+        }
+    }
+
+//        std::vector<bool> *ptb = new std::vector<bool>();
+//        *ptb = tainted_bytes;
+//        if (obj->IsJSArrayBuffer()){
+//            CHECK(Handle<JSArrayBuffer>::cast(obj)->byte_length() == tainted_bytes.size());
+//        } else if (obj->IsJSArrayBufferView()){
+//            CHECK(Handle<JSArrayBufferView>::cast(obj)->byte_length() == tainted_bytes.size());
+//        } else if (obj->IsJSTypedArray()){
+//            bool bounds = false;
+//            size_t length = Handle<JSTypedArray>::cast(obj)->GetLengthOrOutOfBounds(bounds);
+//            if (V8_UNLIKELY(bounds)) return;
+//            CHECK(length == tainted_bytes.size());
+//        } else UNREACHABLE();
+
+}
+
+void Isolate::UntaintV8Object(Handle<Object> obj) {
+    void *ptr = taint_table_->get(reinterpret_cast<void*>(obj->ptr()));
+    if (ptr != nullptr)
+        EnqueueValueForDestroy(ptr, TaintTableValueDestructor);
+    taint_table_->remove(reinterpret_cast<void*>(obj->ptr()));
+}
+
+bool Isolate::IsV8ObjectTainted(Handle<Object> obj, bool local, LocalIsolate* local_isolcate) {
+    i::OFStream os(stdout);
+    obj = FilterInvalidV8Objects(this, obj);
+    if (obj.is_null())
+        return false;
+    if (obj->IsJSTypedArray()){
+        bool res = taint_table_->search(reinterpret_cast<void*>(obj->ptr()), local, local_isolcate);
+        if (!res){
+            Handle<JSArrayBuffer> buffer = JSTypedArray::cast(*obj).GetBuffer();
+            bool buffer_res = taint_table_->search(reinterpret_cast<void*>(buffer->ptr()), local, local_isolcate);
+            if (buffer_res){
+                taint_table_->insert(reinterpret_cast<void*>(obj->ptr()), nullptr, local, local_isolcate);
+            }
+            return buffer_res;
+        }
+        return res;
+    }
+
+        return taint_table_->search(reinterpret_cast<void*>(obj->ptr()), local, local_isolcate);
+}
+
+        bool Isolate::IsStringTaintedAt(Handle<String> str, int idx) {
+            if (idx < 0 || idx >= str->length())
+                return false;
+            if (!IsV8ObjectTainted(Handle<Object>::cast(str)))
+                return false;
+
+            void *ptr = taint_table_->get(reinterpret_cast<void*>(str->ptr()));
+            if (ptr == nullptr)
+                return true;
+            std::vector<bool> *ptb = static_cast<std::vector<bool> *>(ptr);
+            CHECK(str->length() == static_cast<int32_t>(ptb->size()));
+            return ptb->at(idx);
+        }
+
+std::vector<bool> *Isolate::GetStringTaintedBytes(Handle<String> str, bool local, LocalIsolate* local_isolate) {
+    if (local) {
+        return static_cast<std::vector<bool> *>(taint_table_->get(reinterpret_cast<void*>(str->ptr()), local, local_isolate));
+    }
+
+    return static_cast<std::vector<bool> *>(taint_table_->get(reinterpret_cast<void *>(str->ptr())));
+}
+
+        bool Isolate::IsV8ObjectPartiallyTainted(Handle<Object> obj) {
+            obj = FilterInvalidV8Objects(this, obj);
+            if (obj.is_null())
+                return false;
+            return (obj->IsString() &&
+                    (GetStringTaintedBytes(Handle<String>::cast(obj)) != nullptr));
+        }
+
+// ======= OBJ taint table operations end ==========
+
+// ======= V8 objects that should not be tainted start ==========
+        void Isolate::SetDoNotTaint(Handle<Object> obj) {
+            obj = FilterInvalidV8Objects(this, obj);
+            if (!obj.is_null())
+                do_not_taint_->insert(reinterpret_cast<void*>(obj->ptr()), nullptr);
+        }
+
+        bool Isolate::IsDoNotTaint(Handle<Object> obj) {
+            return do_not_taint_->search(reinterpret_cast<void*>(obj->ptr()));
+        }
+// ======= V8 objects that should not be tainted end ==========
+
+// ======= Per-invocation AST taint table start ==========
+        commons::HashTable *Isolate::GetAstTaintTable(void *fp, bool alloc) {
+            commons::HashTable *table = (commons::HashTable *)(ast_taint_table_.get(fp));
+            if (table == nullptr && alloc) {
+                table = new commons::HashTable();
+                ast_taint_table_.insert(fp, table);
+            }
+            return table;
+        }
+
+        void Isolate::DropAstTaintTable(void *fp) {
+            commons::HashTable *table = (commons::HashTable *)(ast_taint_table_.get(fp));
+            if (table != nullptr) {
+                delete table;
+                ast_taint_table_.remove(fp);
+            }
+        }
+
+        void Isolate::SetTaintForAstNode(Handle<JSFunction> function,
+                                         void *fp,
+                                         int position,
+                                         int type) {
+            CHECK(type == AstNode::kVariableProxy ||
+                  type == AstNode::kProperty ||
+                  type == AstNode::kCall);
+            MakeASTPermanent(function);
+            commons::HashTable *table = GetAstTaintTable(fp, true);
+            table->insert(KEY_FROM_POSITION_AND_TYPE(position, type), nullptr);
+        }
+
+        void Isolate::UntaintAstNode(void *fp, int position, int type) {
+            CHECK(type == AstNode::kVariableProxy ||
+                  type == AstNode::kProperty ||
+                  type == AstNode::kCall);
+            commons::HashTable *table = GetAstTaintTable(fp, false);
+            if (table == nullptr)
+                return;
+            table->remove(KEY_FROM_POSITION_AND_TYPE(position, type));
+        }
+
+        bool Isolate::IsAstNodeTainted(void *fp, int position, int type) {
+            CHECK(type == AstNode::kVariableProxy ||
+                  type == AstNode::kProperty ||
+                  type == AstNode::kCall);
+            commons::HashTable *table = GetAstTaintTable(fp, false);
+            if (table == nullptr)
+                return false;
+            return table->search(KEY_FROM_POSITION_AND_TYPE(position, type));
+        }
+// ======= Per-invocation AST taint table end ==========
+
+// ======= Per-invocation mapping from AST node to V8 object start ==========
+        void Isolate::AddToObjectMap(void *fp,
+                                     int position,
+                                     int type,
+                                     Handle<Object> object) {
+
+            CHECK(type == AstNode::kVariableProxy ||
+                  type == AstNode::kProperty ||
+                  type == AstNode::kCall);
+
+
+            object = FilterInvalidV8Objects(this, object);
+            if (object.is_null()) return;
+
+            // AST for |function| must be already pinned.
+            if (!ast_taint_table_.search(fp))
+                return;
+
+            V8GCHashTable *table = reinterpret_cast<V8GCHashTable *>(object_map_.get(fp));
+            if (table == nullptr) {
+                table = new V8GCHashTable(this);
+                object_map_.insert(fp, table);
+            }
+            table->insert(KEY_FROM_POSITION_AND_TYPE(position, type), reinterpret_cast<void*>(object->ptr()));
+        }
+
+        Handle<Object> Isolate::LookupObjectMap(void *fp, int position, int type) {
+            CHECK(type == AstNode::kVariableProxy ||
+                  type == AstNode::kProperty ||
+                  type == AstNode::kCall);
+
+            V8GCHashTable *table = reinterpret_cast<V8GCHashTable *>(object_map_.get(fp));
+            if (table == nullptr)
+                return Handle<Object>::null();
+
+            void* obj_addr = table->get(KEY_FROM_POSITION_AND_TYPE(position, type));
+            if (obj_addr == nullptr)
+                return Handle<Object>::null();
+            return Handle<Object>(Object(reinterpret_cast<Address>(obj_addr)), this);
+        }
+
+        void Isolate::DropObjectMap(void *fp) {
+            V8GCHashTable *table = reinterpret_cast<V8GCHashTable *>(object_map_.get(fp));
+            if (table != nullptr) {
+                delete table;
+                object_map_.remove(fp);
+            }
+        }
+// ======= Per-invocation mapping from AST node to V8 object end ==========
+
+// ======= Extension JavaScript contexts start ==========
+        void Isolate::MarkAsExtensionContext(Handle<Context> context,
+                                             bool is_background) {
+            CHECK(context->IsNativeContext());
+            if (is_background)
+                extension_contexts_->insert(reinterpret_cast<void*>(context->ptr()), (void *)(0x2UL));
+            else
+                extension_contexts_->insert(reinterpret_cast<void*>(context->ptr()), nullptr);
+        }
+
+        bool Isolate::IsExtensionContext(Handle<Context> context){
+            return extension_contexts_->search(reinterpret_cast<void*>(context->ptr()));
+        }
+
+        bool Isolate::IsExtensionContextFast(void* context){
+            return extension_contexts_->search(context);
+        }
+
+        bool Isolate::InExtensionContext(Handle<JSFunction> function) {
+            return extension_contexts_->search(reinterpret_cast<void*>(function->context().native_context().ptr()));
+        }
+
+        bool Isolate::IsBackgroundPageContext(Handle<JSFunction> function) {
+            if (!InExtensionContext(function)) return false;
+            return (extension_contexts_->get(reinterpret_cast<void*>(function->context().native_context().ptr()))) != nullptr;
+        }
+// ======= Extension JavaScript contexts end ==========
+
+// ======= For propagation reports start ==========
+
+/*
+ * Locks for SetV8ObjectAsTaintSource() and LogTaintSink().
+ */
+
+#define TESTLOCK_FILE  PROPAGATION_PATHS_OUT_DIR"testlock"
+#define LOCK_FILE      PROPAGATION_PATHS_OUT_DIR"lockfile"
+
+static void acquire_lock() {
+            // First test if we are in sandbox.
+            FILE *fp = fopen(TESTLOCK_FILE, "a");
+            if (fp == nullptr)
+                return;  // Nothing to synchronize.
+            fclose(fp);
+
+            int fd = open(LOCK_FILE, O_CREAT | O_EXCL);
+            while (fd == -1)
+                fd = open(LOCK_FILE, O_CREAT | O_EXCL);
+            close(fd);
+}
+
+static void release_lock() {
+    unlink(LOCK_FILE);
+}
+#undef TESTLOCK_FILE
+#undef LOCK_FILE
+
+        void Isolate::SetV8ObjectAsTaintSource(Handle<Object> obj,
+                                               Handle<JSFunction> function,
+                                               const std::string& from) {
+            obj = FilterInvalidV8Objects(this, obj);
+            if (!obj.is_null()) {
+                taint_source_objects_->insert(reinterpret_cast<void*>(obj->ptr()), reinterpret_cast<void*>(function->ptr()));
+
+                acquire_lock();
+
+                // Log this taint source.
+                FILE *fp = fopen(PROPAGATION_PATHS_OUT_DIR"taint_sources.log", "a");
+                if (fp != nullptr) {
+                    fprintf(fp, ">>> Taint source: (invoked from %s)\n", from.c_str());
+
+                    obj->ShortPrint(fp);
+
+                    SharedFunctionInfo shared = function->shared();
+                    fprintf(fp, "\n** In function %p `", reinterpret_cast<void*>(function.location()));
+                    std::unique_ptr<char[]> name = shared.DebugNameCStr();
+                    fprintf(fp, "%s`, source code:\n", name.get());
+
+                    if (shared.HasSourceCode()) {
+                        String source = String::cast(Script::cast(shared.script()).source());
+                        int start = shared.StartPosition();
+                        int length = shared.EndPosition() - start;
+                        std::unique_ptr<char[]> source_string = source.ToCString(
+                                DISALLOW_NULLS, FAST_STRING_TRAVERSAL, start, length, nullptr);
+                        fprintf(fp, "%s\n", source_string.get());
+                    }
+
+                    fprintf(fp, ">>> END Taint source\n\n");
+                    fclose(fp);
+                }
+
+                release_lock();
+            }
+        }
+
+        void Isolate::LogTaintSink(Handle<Object> obj, Handle<String> report,
+                                   Handle<String> where) {
+
+            std::string c_where(where->ToCString().get());
+            std::cout << "Taint sink reached at `" << c_where << "`\n";
+
+            char buf[256];
+            snprintf(buf, 256, PROPAGATION_PATHS_OUT_DIR"taint_%s.log", c_where.c_str());
+
+            acquire_lock();
+
+            FILE *fp = fopen(buf, "a");
+            if (fp != nullptr){
+                fprintf(fp, ">>> TAINT SINK `%s` REACHED <<<\n", c_where.c_str());
+                fprintf(fp, "%s", GetCurrentStackTrace()->ToCString().get());
+                fprintf(fp, "\n///////////////////////// ");
+                fprintf(fp, "Details");
+                fprintf(fp, " /////////////////////////\n\n");
+
+                if (obj->IsString()) {
+                    Handle<String> str = Handle<String>::cast(obj);
+                    std::vector<bool> *tainted_bytes = GetStringTaintedBytes(str);
+                    fprintf(fp, "** Tainted bytes ");
+                    if (tainted_bytes != nullptr) {
+                        fprintf(fp, "(nullptr=0): ");
+                        for (size_t i = 0; i < tainted_bytes->size(); i++) {
+                            if (tainted_bytes->at(i))
+                                fprintf(fp, "1");
+                            else
+                                fprintf(fp, "0");
+                        }
+                    }
+                    else fprintf(fp, "(nullptr=1): ");
+                    fprintf(fp, "\n\n");
+
+                    fprintf(fp, "** Sink object: %s\n\n", str->ToCString().get());
+                } else {
+                    fprintf(fp, "** Sink object: ");
+                    obj->ShortPrint(fp);
+                    fprintf(fp, "\n\n");
+                }
+
+                fprintf(fp, "%s\n\n", report->ToCString().get());
+                fprintf(fp, ">>> END TAINT SINK REPORT <<<\n");
+                fclose(fp);
+            }
+
+            release_lock();
+        }
+
+        void Isolate::TaintJSFunction(Handle<JSFunction> function,
+                                      Handle<String> report) {
+            tainted_js_functions_->insert(reinterpret_cast<void*>(function->ptr()), reinterpret_cast<void*>(report->ptr()));
+        }
+
+        bool Isolate::IsJSFunctionTainted(Handle<JSFunction> function) {
+            return tainted_js_functions_->search(reinterpret_cast<void*>(function->ptr()));
+        }
+
+        Handle<String> Isolate::GetPropagationPathForJSFunction(
+                Handle<JSFunction> function) {
+            void* res = tainted_js_functions_->get(reinterpret_cast<void*>(function->ptr()));
+
+            if (res != nullptr) {
+                String report = String::cast(Object(reinterpret_cast<Address>(res)));
+                return Handle<String>(report, this);
+            }
+            return Handle<String>::null();
+        }
+
+        void Isolate::MarkAsTaintSource(Handle<JSFunction> function) {
+            if (!function.is_null()) {
+                Handle<String> stack_trace = GetCurrentStackTrace();
+                taint_sources_->insert(reinterpret_cast<void*>(function->ptr()), reinterpret_cast<void*>(stack_trace->ptr()));
+            }
+        }
+
+        bool Isolate::IsTaintSource(Handle<JSFunction> function) {
+            return taint_sources_->search(reinterpret_cast<void*>(function->ptr()));
+        }
+
+#ifdef DISABLE_PROPAGATION_REPORT
+        void Isolate::AddPropagatedFrom(Handle<Object> obj,
+                                Handle<JSFunction> function,
+                                AstNode *node,
+                                Handle<Object> from_obj){
+
+}
+
+void Isolate::AddPropagatedFrom(Handle<Object> obj,
+                                Handle<JSFunction> function,
+                                Handle<String> report){
+
+}
+
+// xqg newly added
+void Isolate::AddPropagatedFrom(Handle<Object> obj,
+                                        Handle<String> report){
+}
+// xqg newly add end
+
+Handle<String> Isolate::GetPropagationPaths(Handle<Object> obj) {
+      return factory()->empty_string();
+}
+
+void Isolate::PrintPropagationPaths(Handle<Object> obj, FILE *out) {}
+
+#else  // DISABLE_PROPAGATION_REPORT
+
+void * const Isolate::ipc_pseudo_node_ = (void * const)0xdeadbeefUL;
+
+void Isolate::AddPropagatedFromCommon(Handle<Object> obj,
+                                              Handle<JSFunction> function,
+                                              void *from_node,
+                                              PropagatedFrom::FromNodeType from_type,
+                                              Handle<Object> from_obj){
+    obj = FilterInvalidV8Objects(this, obj);
+    from_obj = FilterInvalidV8Objects(this, from_obj);
+    if (obj.is_null() || obj->IsSmi() || from_obj.is_null() || from_obj->IsSmi())
+        return;
+
+    commons::HashTable *table = (commons::HashTable *)propagated_from_->get(reinterpret_cast<void*>(obj->ptr()));
+    if (table == nullptr) {
+        table = new commons::HashTable();
+        propagated_from_->insert(reinterpret_cast<void*>(obj->ptr()), table);
+    }
+
+    if (table->search(reinterpret_cast<void*>(from_node)))
+        return;  // Do not overwrite.
+
+    struct PropagatedFrom *from_info = new struct PropagatedFrom;
+    from_info->from_type = from_type;
+
+    EnterPersistentHandleMode(table);
+    from_info->function = Handle<JSFunction>(*function, this); // have to create new handle here
+    from_info->from_obj = Handle<Object>(*from_obj, this);
+    ExitPersistentHandleMode();
+
+    table->insert(from_node, from_info);
+}
+
+// xqg newly added
+void Isolate::AddPropagatedFromCommon(Handle<Object> obj,
+                                              void *from_node,
+                                              PropagatedFrom::FromNodeType from_type,
+                                              Handle<Object> from_obj){
+    obj = FilterInvalidV8Objects(this, obj);
+    from_obj = FilterInvalidV8Objects(this, from_obj);
+    if (obj.is_null() || obj->IsSmi() || from_obj.is_null() || from_obj->IsSmi())
+        return;
+
+            commons::HashTable *table = (commons::HashTable *)propagated_from_->get(reinterpret_cast<void*>(obj->ptr()));
+            if (table == nullptr) {
+                table = new commons::HashTable();
+                propagated_from_->insert(reinterpret_cast<void*>(obj->ptr()), table);
+            }
+
+            if (table->search(reinterpret_cast<void*>(from_node)))
+                return;  // Do not overwrite.
+
+            struct PropagatedFrom *from_info = new struct PropagatedFrom;
+            from_info->from_type = from_type;
+
+            EnterPersistentHandleMode(table);
+            from_info->from_obj = Handle<Object>(*from_obj, this);
+            ExitPersistentHandleMode();
+
+            table->insert(from_node, from_info);
+} // xqg end
+
+void Isolate::AddPropagatedFrom(Handle<Object> obj,
+                                        Handle<JSFunction> function,
+                                        AstNode *node,
+                                        Handle<Object> from_obj){
+    i::OFStream os(stdout);
+//    os << "Enter AddPropagatedFrom(), obj="<<obj<<", from_obj="<<from_obj<<"\n";
+    AddPropagatedFromCommon(obj, function,
+                                    node, PropagatedFrom::ASTNODE, from_obj);
+}
+
+void Isolate::AddPropagatedFrom(Handle<Object> obj,
+                                        Handle<JSFunction> function,
+                                        Handle<String> report){
+    AddPropagatedFromCommon(obj, function, ipc_pseudo_node_, PropagatedFrom::PSEUDO, Handle<Object>::cast(report));
+}
+
+// xqg newly added
+void Isolate::AddPropagatedFrom(Handle<Object> obj,
+                                        Handle<String> report){
+    AddPropagatedFromCommon(obj, ipc_pseudo_node_, PropagatedFrom::PSEUDO, Handle<Object>::cast(report));
+}
+// xqg newly add end
+
+void Isolate::IteratePrintTaintSourceObjects(void *key,
+                                                     void *value,
+                                                     void *data) { // done
+    Isolate *isolate = (Isolate *)data;
+    Object obj = Object(reinterpret_cast<Address>(key));
+    Object obj_function = Object(reinterpret_cast<Address>(value));
+    JSFunction function = JSFunction::cast(obj_function);
+    SharedFunctionInfo shared = function.shared();
+
+    std::stringstream &ss = isolate->propagation_paths_ss_;
+    obj.Print(ss);
+    ss << ", in function " << function.ptr() << " `";
+    std::unique_ptr<char[]> name = shared.DebugNameCStr();
+    ss << name.get() << "`: " << shared.StartPosition() << "\n";
+}
+
+void Isolate::IteratePrintPropagationPathFunctions(void *key,
+                                                           void *value,
+                                                           void *data) { // done
+    Isolate *isolate = (Isolate *)data;
+    Object obj_function = Object(reinterpret_cast<Address>(key));
+    JSFunction function = JSFunction::cast(obj_function);
+    SharedFunctionInfo shared = function.shared();
+
+    std::stringstream &ss = isolate->propagation_paths_ss_;
+
+    ss << function << " `";
+    std::unique_ptr<char[]> name = shared.DebugNameCStr();
+    ss << name.get() << "`: " << shared.StartPosition() << "\n";
+
+    if (shared.HasSourceCode()) {
+                String source = String::cast(Script::cast(shared.script()).source());
+                int start = shared.StartPosition();
+                int length = shared.EndPosition() - start;
+                std::unique_ptr<char[]> source_string = source.ToCString(
+                        DISALLOW_NULLS, FAST_STRING_TRAVERSAL, start, length, nullptr);
+                ss << source_string.get();
+                ss << "\n";
+    }
+
+}
+
+
+
+void Isolate::IteratePrintPropagationPrev(void *key, void *value, void *data) { // done
+    Isolate *isolate = (Isolate *)data;
+    struct PropagatedFrom *from_info =
+                    reinterpret_cast<struct PropagatedFrom *>(value);
+    std::stringstream &ss = isolate->propagation_paths_ss_;
+
+    if (key == isolate->ipc_pseudo_node_) {
+        std::unique_ptr<char []> flat_report =
+                String::cast(*(from_info->from_obj)).ToCString();
+        ss << ">> IPC Object:\n" << flat_report.get() << "\n>> END IPC Object\n";
+    } else if (isolate->propagates_to_ != from_info->from_obj->ptr()){
+        Handle<JSFunction> function = from_info->function;
+        Handle<Object> obj = from_info->from_obj;
+
+        ss << "  ";
+        obj->Print(ss);
+
+        ss << ", in function " << function->ptr() << " `";
+        std::unique_ptr<char[]> name = function->shared().DebugNameCStr();
+        ss << name.get() << "`: " << function->shared().StartPosition() << ", ";
+
+        switch(from_info->from_type) {
+            case PropagatedFrom::ASTNODE:
+                ss << ((AstNode *)key)->position();
+                break;
+                case PropagatedFrom::PSEUDO:
+                    UNREACHABLE();
+        }
+        ss << "\n";
+    }
+}
+
+        void Isolate::IteratePrintTaintSourceFunctions(void *key,
+                                                       void *value,
+                                                       void *data) { // done
+            Isolate *isolate = (Isolate *)data;
+            Object obj_function = Object(reinterpret_cast<Address>(key));
+            JSFunction function = JSFunction::cast(obj_function);
+            SharedFunctionInfo shared = function.shared();
+
+            Object obj_stack_trace = Object(reinterpret_cast<Address>(value));
+            String stack_trace = String::cast(obj_stack_trace);
+
+            std::stringstream &ss = isolate->propagation_paths_ss_;
+            bool on_propagation_path = isolate->propagation_path_functions_.search(reinterpret_cast<void*>(function.ptr()));
+
+            if (on_propagation_path)
+                ss << "* ";
+
+            ss << function.ptr() << " `";
+            std::unique_ptr<char[]> name = shared.DebugNameCStr();
+            ss << name.get() << "`: " << shared.StartPosition() << "\n";
+
+            ss << stack_trace.ToCString().get() << "\n";
+            if (shared.HasSourceCode()) {
+                String source = String::cast(Script::cast(shared.script()).source());
+                int start = shared.StartPosition();
+                int length = shared.EndPosition() - start;
+                std::unique_ptr<char[]> source_string = source.ToCString(
+                        DISALLOW_NULLS, FAST_STRING_TRAVERSAL, start, length, nullptr);
+                ss << source_string.get();
+                ss << "\n";
+            }
+        }
+
+
+void Isolate::IteratePrintPropagationPath(void *key, void *value, void *data){ // done
+    Isolate *isolate = (Isolate *)data;
+    struct PropagatedFrom *from_info =
+            reinterpret_cast<struct PropagatedFrom *>(value);
+
+    if (key != isolate->ipc_pseudo_node_) {
+        Handle<JSFunction> function = from_info->function;
+        Handle<Object> obj = from_info->from_obj;
+        isolate->propagation_path_functions_.insert(reinterpret_cast<void*>(function->ptr()), nullptr);
+        if (isolate->propagated_from_->search(reinterpret_cast<void*>(obj->ptr())))
+            isolate->DoPrintPropagationPath(obj);
+    }
+}
+
+void Isolate::DoPrintPropagationPath(Handle<Object> obj) {
+    if (propagation_path_objects_.search(reinterpret_cast<void*>(obj->ptr())))
+        return;
+
+    propagation_path_objects_.insert(reinterpret_cast<void*>(obj->ptr()), nullptr);
+
+    std::stringstream &ss = propagation_paths_ss_;
+    obj->Print(ss);
+    ss << ":\n";
+
+    commons::HashTable *table = (commons::HashTable*)propagated_from_->get(reinterpret_cast<void*>(obj->ptr()));
+    if (table != nullptr) {
+        Address saved_propagates_to = propagates_to_;
+        propagates_to_ = obj->ptr();
+        table->iterate(IteratePrintPropagationPrev, this);
+        propagates_to_ = saved_propagates_to;
+        ss << "\n";
+        table->iterate(IteratePrintPropagationPath, this);
+    }
+
+}
+
+void Isolate::CollectPropagationPaths(Handle<Object> obj){
+    propagation_paths_ss_.str("");
+    if (!propagated_from_->search(reinterpret_cast<void*>(obj->ptr())))
+        return;
+    propagation_path_objects_.clear();
+    propagation_path_functions_.clear();
+
+    {
+        DisallowHeapAllocation no_gc; // Don't trigger GC here!
+        JavaScriptFrameIterator it(this);
+
+        propagation_path_functions_.insert(reinterpret_cast<void*>(it.frame()->function().ptr()), nullptr);
+
+        propagation_paths_ss_ << "** Propagation paths: \n\n";
+        DoPrintPropagationPath(obj);
+
+        propagation_paths_ss_ << "\n** Taint source objects:\n\n";
+        taint_source_objects_->iterate(IteratePrintTaintSourceObjects, this); // done
+
+        propagation_paths_ss_ << "\n** Propagation path functions: \n\n";
+        propagation_path_functions_.iterate(
+                IteratePrintPropagationPathFunctions, this);
+
+        propagation_paths_ss_ << "\n** Taint source functions: \n\n";
+        taint_sources_->iterate(IteratePrintTaintSourceFunctions, this); // done
+
+        propagation_paths_ss_ << "\n";
+    }
+}
+
+Handle<String> Isolate::GetPropagationPaths(Handle<Object> obj) {
+    CollectPropagationPaths(obj);
+    const std::string &paths = propagation_paths_ss_.str();
+    if (paths.empty())
+        return factory()->empty_string();
+    FILE *fp;
+    char buf[256];
+    snprintf(buf, 256, PROPAGATION_PATHS_OUT_DIR"%08x.log", 0);
+    if ((fp = fopen(buf, "w")) == nullptr)  // We are in sandbox.
+        return factory()->empty_string();
+
+    for (int i = 1; i < INT_MAX; i++) {
+        snprintf(buf, 256, PROPAGATION_PATHS_OUT_DIR"%08x.log", i);
+        if ((fp = fopen(buf, "r")) != nullptr) {
+            fclose(fp);  // File exists.
+            continue;
+        }
+        fp = fopen(buf, "w");
+        break;
+    }
+
+    if (fp == nullptr)
+        return factory()->empty_string();
+
+    fprintf(fp, "%s", paths.c_str());
+    fclose(fp);
+
+    return factory()->NewStringFromUtf8(base::Vector<const char>(buf, strlen(buf))).ToHandleChecked();
+}
+
+void Isolate::PrintPropagationPaths(Handle<Object> obj, FILE *out) {
+    CollectPropagationPaths(obj);
+    fprintf(out, "%s", propagation_paths_ss_.str().c_str());
+}
+
+#endif  // DISABLE_PROPAGATION_REPORT
+
+// ======= For propagation reports end ==========
+
+// ======= Do-not-propagate for special case functions start ==========
+        void Isolate::AddDoNotPropagate(Handle<JSFunction> caller,
+                                        Handle<JSFunction> callee) {
+            do_not_propagate_->insert(reinterpret_cast<void*>(caller->ptr()), reinterpret_cast<void*>(callee->ptr()));
+        }
+
+        bool Isolate::IsDoNotPropagate(Handle<JSFunction> caller,
+                                       Handle<JSFunction> callee) {
+            return (do_not_propagate_->get(reinterpret_cast<void*>(caller->ptr())) == reinterpret_cast<void*>(callee->ptr()));
+        }
+
+        void Isolate::ClearDoNotPropagate(Handle<JSFunction> caller) {
+            do_not_propagate_->remove(reinterpret_cast<void*>(caller->ptr()));
+        }
+
+        void Isolate::AddDoNotPropagateFunction(Handle<JSFunction> function) {
+            do_not_propagate_functions_->insert(reinterpret_cast<void*>(function->shared().ptr()), nullptr);
+        }
+
+        bool Isolate::IsDoNotPropagateFunction(Handle<JSFunction> function) {
+            return do_not_propagate_functions_->search(reinterpret_cast<void*>(function->shared().ptr()));
+        }
+// ======= Do-not-propagate for special case functions end ==========
+
+bool Isolate::InHoneyPage() {
+    return false;
+}
+
+// xqg end
+
 void StackTraceFailureMessage::Print() volatile {
   // Print the details of this failure message object, including its own address
   // to force stack allocation.
@@ -1291,6 +2486,23 @@ MaybeHandle<JSObject> Isolate::CaptureAndSetErrorStack(
   return error_object;
 }
 
+// xqg start
+
+Handle<String> Isolate::GetCurrentStackTrace(){
+  // the same as PrintCurrentStackTrace()
+  Handle<FixedArray> frames = CaptureSimpleStackTrace(
+          this, FixedArray::kMaxLength, SKIP_NONE, factory()->undefined_value());
+
+  IncrementalStringBuilder builder(this);
+  for (int i = 0; i < frames->length(); ++i) {
+      Handle<CallSiteInfo> frame(CallSiteInfo::cast(frames->get(i)), this);
+      SerializeCallSiteInfo(this, frame, &builder);
+  }
+  Handle<String> stack_trace = builder.Finish().ToHandleChecked();
+  return stack_trace;
+}
+// xqg end
+
 Handle<FixedArray> Isolate::GetDetailedStackTrace(
     Handle<JSReceiver> error_object) {
   Handle<Object> error_stack = JSReceiver::GetDataProperty(
@@ -2486,6 +3698,26 @@ void Isolate::PrintCurrentStackTrace(std::ostream& out) {
   stack_trace->PrintOn(out);
 }
 
+// xqg start
+void Isolate::PrintCurrentStackTrace(FILE* out) {
+      Handle<FixedArray> frames = CaptureSimpleStackTrace(
+                    this, FixedArray::kMaxLength, SKIP_NONE, factory()->undefined_value());
+
+            IncrementalStringBuilder builder(this);
+            for (int i = 0; i < frames->length(); ++i) {
+                Handle<CallSiteInfo> frame(CallSiteInfo::cast(frames->get(i)), this);
+                SerializeCallSiteInfo(this, frame, &builder);
+            }
+
+            Handle<String> stack_trace = builder.Finish().ToHandleChecked();
+            i::OFStream os(out);
+            os << "STACK TRACE START: \n";
+            os << stack_trace << "\n";
+            os << "STACK TRACE END.";
+            PrintF(out, "\n");
+}
+// xqg end
+
 bool Isolate::ComputeLocation(MessageLocation* target) {
   StackTraceFrameIterator it(this);
   if (it.done()) return false;
@@ -3451,7 +4683,26 @@ Isolate::Isolate(std::unique_ptr<i::IsolateAllocator> isolate_allocator,
 #endif
       next_module_async_evaluating_ordinal_(
           SourceTextModule::kFirstAsyncEvaluatingOrdinal),
-      cancelable_task_manager_(new CancelableTaskManager()) {
+      cancelable_task_manager_(new CancelableTaskManager()),
+      persistent_handle_lookup_(nullptr), // xqg start
+      persistent_handle_data_(nullptr),
+      permanent_ast_cache_(nullptr),
+      ast_cache_(nullptr),
+      hit_count_(0),
+      lookup_count_(0),
+      taint_table_(nullptr),
+      do_not_taint_(nullptr),
+      extension_contexts_(nullptr),
+      tainted_js_functions_(nullptr),
+      taint_source_objects_(nullptr),
+      taint_sources_(nullptr), // xqg end
+#ifndef DISABLE_PROPAGATION_REPORT
+      propagated_from_(nullptr),
+      propagates_to_(0),
+#endif
+      do_not_propagate_(nullptr),
+      do_not_propagate_functions_(nullptr)
+      {
   TRACE_ISOLATE(constructor);
   CheckIsolateLayout();
 
@@ -3550,6 +4801,28 @@ void Isolate::UpdateLogObjectRelocation() {
 
 void Isolate::Deinit() {
   TRACE_ISOLATE(deinit);
+
+    // xqg start
+    DestroyPersistentHandles(this);
+
+    delete permanent_ast_cache_;
+    delete ast_cache_;
+    delete taint_table_;
+    delete do_not_taint_;
+
+    delete extension_contexts_;
+    delete tainted_js_functions_;
+    delete taint_source_objects_;
+    delete taint_sources_;
+
+#ifndef DISABLE_PROPAGATION_REPORT
+    delete propagated_from_;
+#endif
+
+    delete do_not_propagate_;
+    delete do_not_propagate_functions_;
+    // xqg end
+
   DisallowHeapAllocation no_allocation;
 
   tracing_cpu_profiler_.reset();
@@ -4530,6 +5803,24 @@ bool Isolate::Init(SnapshotData* startup_snapshot_data,
 
   initialized_ = true;
 
+    // xqg start
+    permanent_ast_cache_ = new V8GCHashTable(this);
+    ast_cache_ = new V8GCHashTable(this);
+
+    taint_table_ = new V8GCHashTable(this);
+    do_not_taint_ = new V8GCHashTable(this);
+
+    extension_contexts_ = new V8GCHashTable(this);
+    tainted_js_functions_ = new V8GCHashTable(this);
+    taint_source_objects_ = new V8GCHashTable(this);
+    taint_sources_ = new V8GCHashTable(this);
+#ifndef DISABLE_PROPAGATION_REPORT
+    propagated_from_ = new V8GCHashTable(this);
+#endif
+    do_not_propagate_ = new V8GCHashTable(this);
+    do_not_propagate_functions_ = new V8GCHashTable(this);
+    // xqg end
+
   return true;
 }
 
diff --git a/src/execution/isolate.h b/src/execution/isolate.h
index c25ad662bf3..af3de732c41 100644
--- a/src/execution/isolate.h
+++ b/src/execution/isolate.h
@@ -43,6 +43,16 @@
 #include "src/sandbox/external-pointer.h"
 #include "src/utils/allocation.h"
 
+// xqg start #1
+#include <sstream>
+#include "src/commons.h"
+#include "src/zone/zone-list.h"
+#include "src/utils/detachable-vector.h"
+#include "src/utils/ostreams.h"
+#include "src/codegen/unoptimized-compilation-info.h"
+#include "include/v8-extension.h"
+// xqg end
+
 #ifdef DEBUG
 #include "src/runtime/runtime-utils.h"
 #endif
@@ -554,6 +564,15 @@ using DebugObjectCache = std::vector<Handle<HeapObject>>;
 #define THREAD_LOCAL_TOP_ADDRESS(type, name) \
   type* name##_address() { return &thread_local_top()->name##_; }
 
+// xqg start add class
+class UnoptimizedCompilationInfo;
+class AstNode;
+class Property;
+class ScopeDFG;
+struct ScopeAndNode;
+class Extension;
+// xqg end add class
+
 // HiddenFactory exists so Isolate can privately inherit from it without making
 // Factory's members available to Isolate directly.
 class V8_EXPORT_PRIVATE HiddenFactory : private Factory {};
@@ -934,6 +953,7 @@ class V8_EXPORT_PRIVATE Isolate final : private HiddenFactory {
 
   enum PrintStackMode { kPrintStackConcise, kPrintStackVerbose };
   void PrintCurrentStackTrace(std::ostream& out);
+  void PrintCurrentStackTrace(FILE* out); // xqg
   void PrintStack(StringStream* accumulator,
                   PrintStackMode mode = kPrintStackVerbose);
   void PrintStack(FILE* out, PrintStackMode mode = kPrintStackVerbose);
@@ -1868,7 +1888,172 @@ class V8_EXPORT_PRIVATE Isolate final : private HiddenFactory {
 
   void IsolateInBackgroundNotification();
 
-  bool IsIsolateInBackground() { return is_isolate_in_background_; }
+    bool IsIsolateInBackground() { return is_isolate_in_background_; }
+
+    // xqg start 2
+
+    //
+    // Taint analysis stuff.
+    //
+    void IterateTaintAnalysisStuff(RootVisitor *v);
+    void PostGCHook();
+
+    // Another GCHashTable implementation.
+    class V8GCHashTable {
+    public:
+        V8GCHashTable(Isolate *isolate,
+                      void (*value_destructor)(Isolate *, void *) = nullptr);
+        ~V8GCHashTable();
+
+        bool empty();
+        int size();
+
+        void insert(void *key, void *value, bool local=false, LocalIsolate* local_isolate=nullptr);
+        void remove(void *key, bool local=false,  LocalIsolate* local_isolate=nullptr);
+        bool search(void *key, bool local=false, LocalIsolate* local_isolate=nullptr);
+        void* get(void *key, bool local=false, LocalIsolate* local_isolate=nullptr);
+
+        ObjectPointerHashTable get_table();
+
+        void iterate(commons::IterateCallback callback, void *data);
+
+    private:
+        Isolate *isolate_;
+        Handle<JSWeakMap> weak_map_;
+
+        Handle<Object> get_key_handle(void *key);
+        Handle<Object> get_value_handle(void *value);
+        commons::HashTable non_heap_keys_;
+    };
+
+    // Queue up V8GCHashTable values for which the corresponding destructors
+    // should be applied at GC epilogue.
+    void EnqueueValueForDestroy(void *value,
+                                void (*value_destructor)(Isolate *, void *));
+
+    // Called from PostGCHook().
+    void DestroyQueuedValues();
+
+    // Persistent Handle.  done !!!
+
+    void EnterPersistentHandleMode(void *lookup);
+    void ExitPersistentHandleMode();
+    bool InPersistentHandleMode();
+    Address* CreatePersistentHandle(Address value);
+    void DestroyPersistentHandles(void *lookup);
+
+    // AST generation and searching.
+
+    UnoptimizedCompilationInfo *GetCompilationInfo(Handle<JSFunction> function);
+    ScopeDFG *GetScopeDFG(UnoptimizedCompilationInfo *info, long position);
+    void AddLocatedScopeAndNode(UnoptimizedCompilationInfo *info, long type, long position, ScopeAndNode *cached); // ok
+    ScopeAndNode *LocatedScopeAndNode(UnoptimizedCompilationInfo *info, long type, long position); // ok
+
+    // OBJ taint table operations.   done !!!
+
+    void SetTaintForV8Object(Handle<Object> obj,
+                             std::vector<bool> tainted_bytes=std::vector<bool>(), bool local=false,
+            LocalIsolate* local_isolate=nullptr);
+    void UntaintV8Object(Handle<Object> obj);
+    bool IsV8ObjectTainted(Handle<Object> obj, bool local=false,
+                           LocalIsolate* local_isolate=nullptr);
+
+    bool IsStringTaintedAt(Handle<String> str, int idx);
+    std::vector<bool> *GetStringTaintedBytes(Handle<String> str, bool local=false, LocalIsolate* local_isolate=nullptr);
+
+    bool IsBufferTaintedAt(Handle<JSArrayBuffer>, int idx);          // newly added
+    std::vector<bool> *GetBufferTaintedBytes(Handle<JSArrayBuffer>,  // newly added
+                                             bool local=false, LocalIsolate* local_isolate=nullptr);
+
+    bool IsV8ObjectPartiallyTainted(Handle<Object> obj);
+
+    bool HasTaintedV8Objects() { return !taint_table_->empty(); }
+
+    // V8 objects that should not be tainted.  done !!!
+    void SetDoNotTaint(Handle<Object> obj);
+    bool IsDoNotTaint(Handle<Object> obj);
+
+    // Per-invocation AST taint table. done !!!
+
+    commons::HashTable *GetAstTaintTable(void *fp, bool alloc);
+    void DropAstTaintTable(void *fp);
+
+    void SetTaintForAstNode(Handle<JSFunction> function,
+                            void *fp,
+                            int position,
+    int type);
+    void UntaintAstNode(void *fp, int position, int type);
+    bool IsAstNodeTainted(void *fp, int position, int type);
+
+    // Per-invocation mapping from AST node to V8 object.
+
+    void AddToObjectMap(void *fp, int position, int type, Handle<Object> object);
+    Handle<Object> LookupObjectMap(void *fp, int position, int type); // ok
+    void DropObjectMap(void *fp); // ok
+
+    // Extension JavaScript contexts. done !!!
+
+    void MarkAsExtensionContext(Handle<Context> context, bool is_background);
+    bool IsExtensionContext(Handle<Context> context);
+    bool IsExtensionContextFast(void* context);
+    bool InExtensionContext(Handle<JSFunction> function);
+    bool IsBackgroundPageContext(Handle<JSFunction> function); // for mv3
+
+    // For propagation reports.
+
+    void SetV8ObjectAsTaintSource(Handle<Object> obj,
+                                  Handle<JSFunction> function,
+    const std::string& from); // ok
+
+    void LogTaintSink(Handle<Object> obj,
+                      Handle<String> report,
+                      Handle<String> where); // ok
+
+    void TaintJSFunction(Handle<JSFunction> function, Handle<String> report); // ok
+    bool IsJSFunctionTainted(Handle<JSFunction> function); // ok
+    Handle<String> GetPropagationPathForJSFunction(Handle<JSFunction> function); // ok
+
+    void MarkAsTaintSource(Handle<JSFunction> function); // ok
+    bool IsTaintSource(Handle<JSFunction> function); // ok
+
+    void AddPropagatedFrom(Handle<Object> obj,
+                           Handle<JSFunction> function,
+                           AstNode *node,
+                           Handle<Object> from_obj);
+
+    // Propagation paths for IPC'ed objects. |node| will be ipc_pseudo_node_.
+    void AddPropagatedFrom(Handle<Object> obj,
+                           Handle<JSFunction> function,
+                           Handle<String> report);
+
+    // xqg newly added
+    void AddPropagatedFrom(Handle<Object> obj,
+                           Handle<String> report);
+
+    Handle<String> GetPropagationPaths(Handle<Object> obj);
+    void PrintPropagationPaths(Handle<Object> obj, FILE *out = stdout);
+
+    Handle<String> GetCurrentStackTrace(); // ok
+
+    // Do-not-propagate for special case functions. done !!!
+
+    void AddDoNotPropagate(Handle<JSFunction> caller, Handle<JSFunction> callee);
+    bool IsDoNotPropagate(Handle<JSFunction> caller, Handle<JSFunction> callee);
+    void ClearDoNotPropagate(Handle<JSFunction> caller);
+
+    void AddDoNotPropagateFunction(Handle<JSFunction> function);
+    bool IsDoNotPropagateFunction(Handle<JSFunction> function);
+
+    //
+    Handle<String> prepend_marker();
+    Handle<String> append_marker();
+
+    bool InHoneyPage();
+
+    //
+    // End taint analysis stuff.
+    //
+    // xqg end 2
 
   void EnableMemorySavingsMode() { memory_savings_mode_active_ = true; }
 
@@ -2466,6 +2651,168 @@ class V8_EXPORT_PRIVATE Isolate final : private HiddenFactory {
   v8::Isolate::AbortOnUncaughtExceptionCallback
       abort_on_uncaught_exception_callback_ = nullptr;
 
+    // xqg start
+    /*
+     * Taint analysis stuff.
+     */
+
+    class PersistentHandleData {
+    public:
+        PersistentHandleData()
+                : next_(nullptr),
+                  limit_(nullptr) {}
+
+        ~PersistentHandleData() {
+            blocks_.free();
+            next_ = nullptr;
+            limit_ = nullptr;
+        }
+
+        Address* CreateHandle(Address value) {
+            Address* result = next_;
+            if (result == limit_) {
+                // Ask V8 for a new block of free handles.
+                result = NewArray<internal::Address>(kHandleBlockSize);
+                blocks_.push_back(result);
+                limit_ = &result[kHandleBlockSize];
+            }
+            *result = value; // Can I change the order?
+            next_ = reinterpret_cast<Address*>(reinterpret_cast<Address>(result) + sizeof(Address));
+            return result;
+        }
+
+        void Iterate(RootVisitor* v) {
+            // All blocks except the last one are full.
+            if (!blocks_.empty()) {
+                for (size_t i = 0; i < (blocks_.size() - 1); i++) {
+                    Address * block = blocks_.at(i);
+                    v->VisitRootPointers(Root::kHandleScope, nullptr, FullObjectSlot(block),
+                                         FullObjectSlot(&block[kHandleBlockSize]));
+                }
+            }
+            // Iterate over live handles in the last block.
+            if (!blocks_.empty())
+                v->VisitRootPointers(Root::kHandleScope, nullptr, FullObjectSlot(blocks_.back()), FullObjectSlot(next_));
+        }
+
+        static void IterateHandles(void *key, void *value, void *data) {
+            PersistentHandleData *handle_data = (PersistentHandleData *)(value);
+            RootVisitor* visitor = static_cast<RootVisitor *>(data);
+            handle_data->Iterate(visitor);
+        }
+
+    private:
+        const int kHandleBlockSize = v8::internal::KB - 2;
+        DetachableVector<Address*> blocks_;
+        Address* next_;
+        Address* limit_;
+
+    };
+
+    commons::HashTable persistent_handle_table_;
+    void *persistent_handle_lookup_;
+    PersistentHandleData *persistent_handle_data_;
+
+    static void IterateDestroyQueuedValues(void *key, void *value, void *data);
+    commons::HashTable values_to_destroy_;
+
+    void DisposeCompilationInfo(UnoptimizedCompilationInfo *info); // ok
+    static void AstCacheValueDestructor(Isolate *isolate, void *value); // ok
+    static void IterateScopeDFGDestructor(void *key, void *value, void *data); // ok
+    static void IterateScopeAndNodeDestructor(void *key, void *value, void *data); // ok
+    static void IterateScopeAndNodeInnerDestructor(void *key,
+                                                   void *value, void *data); // ok
+
+    void MakeASTPermanent(Handle<JSFunction> function); // ok
+
+    V8GCHashTable *permanent_ast_cache_;
+    V8GCHashTable *ast_cache_;
+
+    int hit_count_;
+    int lookup_count_;
+
+    // Cascade value destructor from |ast_cache_|.
+    commons::HashTable scope_dfg_cache_;
+    commons::HashTable located_scope_and_node_cache_;
+
+    static void TaintTableValueDestructor(Isolate *isolate, void *value); // ok
+    V8GCHashTable *taint_table_;
+
+    V8GCHashTable *do_not_taint_;
+
+    commons::HashTable ast_taint_table_;
+
+    commons::HashTable object_map_;  // For Property and Call.
+
+    V8GCHashTable *extension_contexts_;
+    V8GCHashTable *tainted_js_functions_;
+    V8GCHashTable *taint_source_objects_;
+    V8GCHashTable *taint_sources_;
+
+    #ifndef DISABLE_PROPAGATION_REPORT
+    struct PropagatedFrom {
+        enum FromNodeType { ASTNODE, PSEUDO };
+        FromNodeType from_type;
+        Handle<JSFunction> function;
+        Handle<Object> from_obj;
+    };
+
+    static void * const ipc_pseudo_node_;
+
+    void AddPropagatedFromCommon(Handle<Object> obj,
+                                 Handle<JSFunction> function,
+                                 void *from_node,
+                                 PropagatedFrom::FromNodeType from_type,
+    Handle<Object> from_obj);
+
+    void AddPropagatedFromCommon(Handle<Object> obj, // xqg
+                                 void *from_node,
+                                 PropagatedFrom::FromNodeType from_type,
+    Handle<Object> from_obj);
+
+    static void IteratePrintPropagationPrev(void *key, void *value, void *data);
+    static void IteratePrintPropagationPath(void *key, void *value, void *data);
+    void DoPrintPropagationPath(Handle<Object> obj);
+
+    static void IteratePrintTaintSourceObjects(void *key,
+                                               void *value,
+                                               void *data);
+
+    static void IteratePrintPropagationPathFunctions(void *key,
+                                                     void *value,
+                                                     void *data);
+
+    static void IteratePrintTaintSourceFunctions(void *key,
+                                                 void *value,
+                                                 void *data);
+
+    static void IteratePropagatedFromDestructor(void *key,
+                                                void *value,
+                                                void *data);
+
+    static void PropagatedFromValueDestructor(Isolate *isolate, void *value);
+
+    V8GCHashTable *propagated_from_;
+
+    Address propagates_to_;
+    commons::HashTable propagation_path_objects_;
+    commons::HashTable propagation_path_functions_;
+
+    void CollectPropagationPaths(Handle<Object> obj);
+    std::stringstream propagation_paths_ss_;
+    #endif  // DISABLE_PROPAGATION_REPORT
+
+    V8GCHashTable *do_not_propagate_;
+    V8GCHashTable *do_not_propagate_functions_;
+
+    Handle<String> prepend_marker_;
+    Handle<String> append_marker_;
+
+    /*
+     * End taint analysis stuff.
+     */
+    // xqg end
+
   bool allow_atomics_wait_ = true;
 
   base::Mutex managed_ptr_destructors_mutex_;
diff --git a/src/execution/local-isolate.h b/src/execution/local-isolate.h
index f67bc784529..ccdb0039018 100644
--- a/src/execution/local-isolate.h
+++ b/src/execution/local-isolate.h
@@ -79,6 +79,23 @@ class V8_EXPORT_PRIVATE LocalIsolate final : private HiddenLocalFactory {
     return isolate_->v8_file_logger();
   }
 
+  // xqg start
+  void SetTaintForV8Object(Handle<Object> obj, // done
+                             std::vector<bool> tainted_bytes = std::vector<bool>() ){
+        i::OFStream os(stdout);
+        isolate_->SetTaintForV8Object(obj, tainted_bytes, true, this);
+  }
+
+  bool IsV8ObjectTainted(Handle<Object> obj){
+        return isolate_->IsV8ObjectTainted(obj, true, this);
+  }
+
+  std::vector<bool> *GetStringTaintedBytes(Handle<String> str){
+        return isolate_->GetStringTaintedBytes(str, true, this);
+  }
+
+    // xqg end
+
   v8::internal::LocalFactory* factory() {
     // Upcast to the privately inherited base-class using c-style casts to avoid
     // undefined behavior (as static_cast cannot cast across private bases).
diff --git a/src/flags/flag-definitions.h b/src/flags/flag-definitions.h
index c31a3893047..a239d10c04d 100644
--- a/src/flags/flag-definitions.h
+++ b/src/flags/flag-definitions.h
@@ -787,7 +787,11 @@ DEFINE_INT(deopt_every_n_times, 0,
 DEFINE_BOOL(print_deopt_stress, false, "print number of possible deopt points")
 
 // Flags for TurboFan.
-DEFINE_BOOL(turbofan, true, "use the Turbofan optimizing compiler")
+// xqg start
+// DEFINE_BOOL(turbofan, true, "use the Turbofan optimizing compiler")
+DEFINE_BOOL(turbofan, false, "use the Turbofan optimizing compiler")
+// xqg end
+
 // TODO(leszeks): Temporary alias until we make sure all our infra is passing
 // --turbofan instead of --opt.
 DEFINE_ALIAS_BOOL(opt, turbofan)
@@ -1305,7 +1309,10 @@ DEFINE_BOOL(minor_mc_trace_fragmentation, false,
 DEFINE_BOOL(trace_evacuation, false, "report evacuation statistics")
 DEFINE_BOOL(trace_mutator_utilization, false,
             "print mutator utilization, allocation speed, gc speed")
-DEFINE_BOOL(incremental_marking, true, "use incremental marking")
+// xqg start
+// DEFINE_BOOL(incremental_marking, true, "use incremental marking")
+DEFINE_BOOL(incremental_marking, false, "use incremental marking")
+// xqg end
 DEFINE_BOOL(incremental_marking_wrappers, true,
             "use incremental marking for marking wrappers")
 DEFINE_BOOL(incremental_marking_task, true, "use tasks for incremental marking")
diff --git a/src/handles/handles-inl.h b/src/handles/handles-inl.h
index e47ee146bff..f89b5c4851c 100644
--- a/src/handles/handles-inl.h
+++ b/src/handles/handles-inl.h
@@ -159,8 +159,25 @@ Handle<T> HandleScope::CloseAndEscape(Handle<T> handle_value) {
   return result;
 }
 
+// xqg start added
+Address* HandleScope::CreatePersistentHandle(Isolate* isolate, Address value) {
+    DCHECK(AllowHandleAllocation::IsAllowed());
+
+    CHECK(!isolate->InPersistentHandleMode());
+    isolate->EnterPersistentHandleMode(isolate);
+    Address* ret = isolate->CreatePersistentHandle(value);
+    isolate->ExitPersistentHandleMode();
+    return ret;
+}
+// xqg end
+
+
 Address* HandleScope::CreateHandle(Isolate* isolate, Address value) {
   DCHECK(AllowHandleAllocation::IsAllowed());
+  // xqg start
+  if (isolate->InPersistentHandleMode())
+      return isolate->CreatePersistentHandle(value);
+  // xqg end
   HandleScopeData* data = isolate->handle_scope_data();
   Address* result = data->next;
   if (result == data->limit) {
@@ -181,6 +198,12 @@ Address* HandleScope::GetHandle(Isolate* isolate, Address value) {
   DCHECK(isolate->main_thread_local_heap()->IsRunning());
   DCHECK_WITH_MSG(isolate->thread_id() == ThreadId::Current(),
                   "main-thread handle can only be created on the main thread.");
+
+  // xqg start
+  if (isolate->InPersistentHandleMode())
+      return isolate->CreatePersistentHandle(value);
+  // xqg end
+  
   HandleScopeData* data = isolate->handle_scope_data();
   CanonicalHandleScope* canonical = data->canonical_scope;
   return canonical ? canonical->Lookup(value) : CreateHandle(isolate, value);
diff --git a/src/handles/handles.h b/src/handles/handles.h
index 29da54bf9fa..75f522577bb 100644
--- a/src/handles/handles.h
+++ b/src/handles/handles.h
@@ -227,6 +227,11 @@ class V8_NODISCARD HandleScope {
   // Create a new handle or lookup a canonical handle.
   V8_INLINE static Address* GetHandle(Isolate* isolate, Address value);
 
+  // xqg start
+  // Same as above but always persistent.
+  V8_INLINE static Address* CreatePersistentHandle(Isolate* isolate, Address value);
+  // xqg end
+
   // Creates a new handle with the given value.
   V8_INLINE static Address* CreateHandle(Isolate* isolate, Address value);
 
diff --git a/src/heap/factory-base.cc b/src/heap/factory-base.cc
index 0dec79f0345..0965f919317 100644
--- a/src/heap/factory-base.cc
+++ b/src/heap/factory-base.cc
@@ -54,6 +54,72 @@ FactoryBase<Factory>::NewHeapNumber<AllocationType::kSharedOld>();
 template V8_EXPORT_PRIVATE Handle<HeapNumber>
 FactoryBase<LocalFactory>::NewHeapNumber<AllocationType::kOld>();
 
+// xqg start
+template <typename Impl>
+inline void FactoryBase<Impl>::UpdateConsStringTaintedBytes(Handle<String> result,
+                                                            Handle<String> str1,
+                                                            Handle<String> str2) {
+    bool tainted1 = isolate()->IsV8ObjectTainted(str1);
+    bool tainted2 = isolate()->IsV8ObjectTainted(str2);
+
+    i::OFStream os(stdout);
+    if (tainted1 || tainted2) {
+//#ifdef DEBUG
+//
+//
+//        os << "at least one tainted: " << tainted1 <<","<<tainted2<<"\n";
+//        os << str1<< ","<<str2<<"\n";
+//#endif
+        std::vector<bool> *ptb1 = impl()->isolate()->GetStringTaintedBytes(str1);
+        std::vector<bool> *ptb2 = impl()->isolate()->GetStringTaintedBytes(str2);
+        if (!(tainted1 && tainted2 && ptb1 == nullptr && ptb2 == nullptr)) {
+            // We need to construct an explicit taint bytes array for the new string.
+            std::vector<bool> tainted_bytes;
+            if (tainted1) {
+                if (ptb1 == nullptr) {
+                    for (int i = 0; i < str1->length(); i++)
+                        tainted_bytes.push_back(true);
+                } else {
+                    CHECK(str1->length() == static_cast<int32_t>(ptb1->size()));
+                    for (size_t i = 0; i < ptb1->size(); i++)
+                        tainted_bytes.push_back(ptb1->at(i));
+                }
+            } else {
+                for (int i = 0; i < str1->length(); i++)
+                    tainted_bytes.push_back(false);
+            }
+
+            if (tainted2) {
+                if (ptb2 == nullptr) {
+                    for (int i = 0; i < str2->length(); i++)
+                        tainted_bytes.push_back(true);
+                } else {
+                    CHECK(str2->length() == static_cast<int32_t>(ptb2->size()));
+                    for (size_t i = 0; i < ptb2->size(); i++)
+                        tainted_bytes.push_back(ptb2->at(i));
+                }
+            } else {
+                for (int i = 0; i < str2->length(); i++)
+                    tainted_bytes.push_back(false);
+            }
+
+            CHECK_EQ(result->length(), tainted_bytes.size());
+            impl()->isolate()->SetTaintForV8Object(result, tainted_bytes);
+//#ifdef DEBUG
+//            os <<"Concat Tainted Bytes: ";
+//            for (size_t i = 0; i < tainted_bytes.size(); i++) os <<tainted_bytes.at(i);
+//            os <<"\n";
+//#endif
+        } else {
+            impl()->isolate()->SetTaintForV8Object(result);
+//#ifdef DEBUG
+//            os << "two strings are both wholly tainted\n";
+//#endif
+        }
+    }
+}
+// xqg end
+
 template <typename Impl>
 Handle<Struct> FactoryBase<Impl>::NewStruct(InstanceType type,
                                             AllocationType allocation) {
@@ -566,6 +632,8 @@ Handle<CoverageInfo> FactoryBase<Impl>::NewCoverageInfo(
   return handle(info, isolate());
 }
 
+// Now we can completely get rid of this.
+/*
 template <typename Impl>
 Handle<String> FactoryBase<Impl>::MakeOrFindTwoCharacterString(uint16_t c1,
                                                                uint16_t c2) {
@@ -575,7 +643,7 @@ Handle<String> FactoryBase<Impl>::MakeOrFindTwoCharacterString(uint16_t c1,
   }
   uint16_t buffer[] = {c1, c2};
   return InternalizeString(base::Vector<const uint16_t>(buffer, 2));
-}
+}*/
 
 template <typename Impl>
 template <class StringTableKey>
@@ -720,6 +788,7 @@ MaybeHandle<SeqTwoByteString> FactoryBase<Impl>::NewRawSharedTwoByteString(
 template <typename Impl>
 MaybeHandle<String> FactoryBase<Impl>::NewConsString(
     Handle<String> left, Handle<String> right, AllocationType allocation) {
+  i::OFStream os(stdout);
   if (left->IsThinString()) {
     left = handle(ThinString::cast(*left).actual(), isolate());
   }
@@ -733,11 +802,12 @@ MaybeHandle<String> FactoryBase<Impl>::NewConsString(
 
   int length = left_length + right_length;
 
-  if (length == 2) {
+  /*if (length == 2) {
     uint16_t c1 = left->Get(0, isolate());
     uint16_t c2 = right->Get(0, isolate());
+    os << "length is two, c1="<<c1<<",c2="<<c2<<"\n";
     return MakeOrFindTwoCharacterString(c1, c2);
-  }
+  }*/
 
   // Make sure that an out of memory exception is thrown if the length
   // of the new cons string is too large.
@@ -758,36 +828,41 @@ MaybeHandle<String> FactoryBase<Impl>::NewConsString(
 
     static_assert(ConsString::kMinLength <= String::kMaxLength);
     if (is_one_byte) {
-      Handle<SeqOneByteString> result =
-          NewRawOneByteString(length, allocation).ToHandleChecked();
-      DisallowGarbageCollection no_gc;
-      SharedStringAccessGuardIfNeeded access_guard(isolate());
-      uint8_t* dest = result->GetChars(no_gc, access_guard);
-      // Copy left part.
-      {
-        const uint8_t* src =
-            left->template GetChars<uint8_t>(isolate(), no_gc, access_guard);
-        CopyChars(dest, src, left_length);
-      }
-      // Copy right part.
-      {
-        const uint8_t* src =
-            right->template GetChars<uint8_t>(isolate(), no_gc, access_guard);
-        CopyChars(dest + left_length, src, right_length);
-      }
-      return result;
+        Handle <SeqOneByteString> result =
+                NewRawOneByteString(length, allocation).ToHandleChecked();
+        {
+            DisallowGarbageCollection no_gc;
+            SharedStringAccessGuardIfNeeded access_guard(isolate());
+            uint8_t *dest = result->GetChars(no_gc, access_guard);
+            // Copy left part.
+            {
+                const uint8_t *src =
+                    left->template GetChars<uint8_t>(isolate(), no_gc, access_guard);
+                CopyChars(dest, src, left_length);
+            }
+            // Copy right part.
+            {
+                const uint8_t *src =
+                    right->template GetChars<uint8_t>(isolate(), no_gc, access_guard);
+                CopyChars(dest + left_length, src, right_length);
+            }
+       }
+       UpdateConsStringTaintedBytes(result, left, right); // xqg
+       return result;
     }
 
     Handle<SeqTwoByteString> result =
         NewRawTwoByteString(length, allocation).ToHandleChecked();
-
-    DisallowGarbageCollection no_gc;
-    SharedStringAccessGuardIfNeeded access_guard(isolate());
-    base::uc16* sink = result->GetChars(no_gc, access_guard);
-    String::WriteToFlat(*left, sink, 0, left->length(), isolate(),
-                        access_guard);
-    String::WriteToFlat(*right, sink + left->length(), 0, right->length(),
-                        isolate(), access_guard);
+    {
+          DisallowGarbageCollection no_gc;
+          SharedStringAccessGuardIfNeeded access_guard(isolate());
+          base::uc16 *sink = result->GetChars(no_gc, access_guard);
+          String::WriteToFlat(*left, sink, 0, left->length(), isolate(),
+                              access_guard);
+          String::WriteToFlat(*right, sink + left->length(), 0, right->length(),
+                              isolate(), access_guard);
+    }
+    UpdateConsStringTaintedBytes(result, left, right); // xqg
     return result;
   }
 
@@ -809,27 +884,52 @@ Handle<String> FactoryBase<Impl>::NewConsString(Handle<String> left,
                      read_only_roots().cons_one_byte_string_map(), allocation)
                : NewWithImmortalMap(read_only_roots().cons_string_map(),
                                     allocation));
+  {
+      DisallowGarbageCollection no_gc;
+      WriteBarrierMode mode = result.GetWriteBarrierMode(no_gc);
+      result.set_raw_hash_field(String::kEmptyHashField);
+      result.set_length(length);
+      result.set_first(*left, mode);
+      result.set_second(*right, mode);
+  }
 
-  DisallowGarbageCollection no_gc;
-  WriteBarrierMode mode = result.GetWriteBarrierMode(no_gc);
-  result.set_raw_hash_field(String::kEmptyHashField);
-  result.set_length(length);
-  result.set_first(*left, mode);
-  result.set_second(*right, mode);
-  return handle(result, isolate());
+  Handle <String> res = handle(result, isolate());
+  UpdateConsStringTaintedBytes(res, left, right);
+  return res;
+  // return handle(result, isolate());
 }
 
 template <typename Impl>
 Handle<String> FactoryBase<Impl>::LookupSingleCharacterStringFromCode(
     uint16_t code) {
   if (code <= unibrow::Latin1::kMaxChar) {
+    /*
     DisallowGarbageCollection no_gc;
     Object value = single_character_string_table()->get(code);
     DCHECK_NE(value, *undefined_value());
     return handle(String::cast(value), isolate());
+    */
+    Handle <SeqOneByteString> result =
+              NewRawOneByteString(1, AllocationType::kOld).ToHandleChecked(); // TENURED
+      {
+          DisallowGarbageCollection no_gc;
+          SharedStringAccessGuardIfNeeded access_guard(isolate());
+          uint8_t *dest = result->GetChars(no_gc, access_guard);
+          dest[0] = static_cast<uint8_t>(code);
+      }
+      return result;
+
   }
-  uint16_t buffer[] = {code};
-  return InternalizeString(base::Vector<const uint16_t>(buffer, 1));
+    Handle<SeqTwoByteString> result =
+            NewRawTwoByteString(1).ToHandleChecked();
+    {
+        DisallowGarbageCollection no_gc;
+        SharedStringAccessGuardIfNeeded access_guard(isolate());
+        CopyChars(result->GetChars(no_gc, access_guard), &code, 1);
+    }
+    return result;
+//  uint16_t buffer[] = {code};
+//  return InternalizeString(base::Vector<const uint16_t>(buffer, 1));
 }
 
 template <typename Impl>
diff --git a/src/heap/factory-base.h b/src/heap/factory-base.h
index aea50e6cdbf..3e5d13f7f83 100644
--- a/src/heap/factory-base.h
+++ b/src/heap/factory-base.h
@@ -263,6 +263,13 @@ class FactoryBase : public TorqueGeneratedFactory<Impl> {
   V8_WARN_UNUSED_RESULT Handle<String> SmiToString(
       Smi number, NumberCacheMode mode = NumberCacheMode::kBoth);
 
+  // xqg start
+  void UpdateConsStringTaintedBytes(
+            Handle<String> result,
+            Handle<String> str1,
+            Handle<String> str2);
+  // xqg end
+
   V8_WARN_UNUSED_RESULT MaybeHandle<SeqOneByteString> NewRawSharedOneByteString(
       int length);
   V8_WARN_UNUSED_RESULT MaybeHandle<SeqTwoByteString> NewRawSharedTwoByteString(
diff --git a/src/heap/factory.cc b/src/heap/factory.cc
index bcb2f6475ec..9f3b3817566 100644
--- a/src/heap/factory.cc
+++ b/src/heap/factory.cc
@@ -1086,6 +1086,53 @@ Handle<String> Factory::NewSurrogatePairString(uint16_t lead, uint16_t trail) {
   return str;
 }
 
+// This potentially triggers GC.
+static void UpdateSubStringTaintedBytes(Isolate *isolate, std::vector<bool> *tainted_bytes,
+                                                int start,
+                                                int end,
+                                                Handle<String> result) {
+    bool ifshow = false;
+
+    i::OFStream os(stdout);
+
+    std::vector<bool> sub_tainted_bytes;
+    bool tainted = false;
+    bool wholly_tainted = true;
+
+    if (tainted_bytes != nullptr) {
+        for (int i = start; i < end; i++) {
+            bool tainted_byte = tainted_bytes->at(i);
+            sub_tainted_bytes.push_back(tainted_byte);
+            if (tainted_byte)
+                tainted = true;
+            else
+                wholly_tainted = false;
+        }
+    } else {
+        wholly_tainted = true;
+        tainted = true;
+    }
+
+    if (!tainted) {
+        isolate->SetDoNotTaint(result);
+        if (ifshow) os << "not taint at all\n";
+    }
+    else if (wholly_tainted) {
+        isolate->SetTaintForV8Object(result);
+        if (ifshow) os << "wholly_tainted\n";
+    }
+    else {
+        if (ifshow){
+            for (size_t i = 0; i < sub_tainted_bytes.size(); i++){
+                os << sub_tainted_bytes.at(i);
+            }
+            os <<"\n";
+        }
+        isolate->SetTaintForV8Object(result, sub_tainted_bytes);
+    }
+
+}
+
 Handle<String> Factory::NewProperSubString(Handle<String> str, int begin,
                                            int end) {
 #if VERIFY_HEAP
@@ -1093,11 +1140,35 @@ Handle<String> Factory::NewProperSubString(Handle<String> str, int begin,
 #endif
   DCHECK(begin > 0 || end < str->length());
 
+
+  bool tainted = isolate()->IsV8ObjectTainted(str);
+  bool show = false;
+    i::OFStream os(stdout);
+
+    if (tainted && show){
+      os << "Enter Factory::NewProperSubString, str="<<str<<"::\n";
+  }
+  std::vector<bool> *tainted_bytes = isolate()->GetStringTaintedBytes(str);
+  if (tainted && show){
+//      os << "Enter Factory::NewProperSubString, str="<<str<<"::";
+    if (tainted_bytes != nullptr) {
+        for (size_t i = 0; i < tainted_bytes->size(); i++) {
+            os << tainted_bytes->at(i);
+        }
+        os << "\n";
+    } else {
+        os << "tainted-bytes = nullptr\n";
+    }
+
+  }
+
   str = String::Flatten(isolate(), str);
 
   int length = end - begin;
   if (length <= 0) return empty_string();
-  if (length == 1) {
+
+  // Below is pointless since we disabled one/two-character string cache.
+  /*if (length == 1) {
     return LookupSingleCharacterStringFromCode(str->Get(begin));
   }
   if (length == 2) {
@@ -1107,22 +1178,28 @@ Handle<String> Factory::NewProperSubString(Handle<String> str, int begin,
     uint16_t c1 = str->Get(begin);
     uint16_t c2 = str->Get(begin + 1);
     return MakeOrFindTwoCharacterString(c1, c2);
-  }
+  }*/
 
   if (!v8_flags.string_slices || length < SlicedString::kMinLength) {
     if (str->IsOneByteRepresentation()) {
       Handle<SeqOneByteString> result =
           NewRawOneByteString(length).ToHandleChecked();
-      DisallowGarbageCollection no_gc;
-      uint8_t* dest = result->GetChars(no_gc);
-      String::WriteToFlat(*str, dest, begin, length);
+      {
+            DisallowGarbageCollection no_gc;
+            uint8_t *dest = result->GetChars(no_gc);
+            String::WriteToFlat(*str, dest, begin, length);
+      }
+      if (tainted) UpdateSubStringTaintedBytes(isolate(), tainted_bytes, begin, end, result);
       return result;
     } else {
       Handle<SeqTwoByteString> result =
           NewRawTwoByteString(length).ToHandleChecked();
-      DisallowGarbageCollection no_gc;
-      base::uc16* dest = result->GetChars(no_gc);
-      String::WriteToFlat(*str, dest, begin, length);
+      {
+            DisallowGarbageCollection no_gc;
+            base::uc16 *dest = result->GetChars(no_gc);
+            String::WriteToFlat(*str, dest, begin, length);
+      }
+      if (tainted) UpdateSubStringTaintedBytes(isolate(), tainted_bytes, begin, end, result);
       return result;
     }
   }
@@ -1144,12 +1221,21 @@ Handle<String> Factory::NewProperSubString(Handle<String> str, int begin,
                         ? sliced_one_byte_string_map()
                         : sliced_string_map();
   SlicedString slice = SlicedString::cast(New(map, AllocationType::kYoung));
-  DisallowGarbageCollection no_gc;
-  slice.set_raw_hash_field(String::kEmptyHashField);
-  slice.set_length(length);
-  slice.set_parent(*str);
-  slice.set_offset(offset);
-  return handle(slice, isolate());
+  {
+        DisallowGarbageCollection no_gc;
+        slice.set_raw_hash_field(String::kEmptyHashField);
+        slice.set_length(length);
+        slice.set_parent(*str);
+        slice.set_offset(offset);
+  }
+
+  // return handle(slice, isolate());
+  // working
+  // xqg start
+  Handle<String> res = handle(slice, isolate());
+  if (tainted) UpdateSubStringTaintedBytes(isolate(), tainted_bytes, begin, end, res);
+  return res;
+  // xqg end;
 }
 
 MaybeHandle<String> Factory::NewExternalStringFromOneByte(
@@ -2898,7 +2984,17 @@ Handle<FixedArrayBase> Factory::NewJSArrayStorage(
   return elms;
 }
 
-Handle<JSWeakMap> Factory::NewJSWeakMap() {
+Handle<JSWeakMap> Factory::NewJSWeakMap(bool is_pointer_map) {
+  // xqg start
+  if (is_pointer_map){
+      HandleScope scope(isolate());
+      Handle<Map> map = isolate()->factory()->NewMap(JS_WEAK_MAP_TYPE, JSWeakMap::kHeaderSize);
+      Handle < JSWeakMap > weakmap(JSWeakMap::cast(*NewJSObjectFromMap(map)),
+                                     isolate());
+      return weakmap;
+  }
+  // xqg end
+
   NativeContext native_context = isolate()->raw_native_context();
   Handle<Map> map(native_context.js_weak_map_fun().initial_map(), isolate());
   Handle<JSWeakMap> weakmap(JSWeakMap::cast(*NewJSObjectFromMap(map)),
diff --git a/src/heap/factory.h b/src/heap/factory.h
index 6c9cc2d4d8e..b2060c2da9d 100644
--- a/src/heap/factory.h
+++ b/src/heap/factory.h
@@ -613,7 +613,7 @@ class V8_EXPORT_PRIVATE Factory : public FactoryBase<Factory> {
       Handle<JSArray> array, int length, int capacity,
       ArrayStorageAllocationMode mode = DONT_INITIALIZE_ARRAY_ELEMENTS);
 
-  Handle<JSWeakMap> NewJSWeakMap();
+  Handle<JSWeakMap> NewJSWeakMap(bool is_pointer_map=false); // xqg
 
   Handle<JSGeneratorObject> NewJSGeneratorObject(Handle<JSFunction> function);
 
diff --git a/src/heap/heap.cc b/src/heap/heap.cc
index c607af98801..c20425db752 100644
--- a/src/heap/heap.cc
+++ b/src/heap/heap.cc
@@ -1305,6 +1305,8 @@ void Heap::GarbageCollectionEpilogueInSafepoint(GarbageCollector collector) {
 
   // Resume all threads waiting for the GC.
   collection_barrier_->ResumeThreadsAwaitingCollection();
+
+  isolate_->PostGCHook(); // xqg
 }
 
 void Heap::GarbageCollectionEpilogue(GarbageCollector collector) {
@@ -1609,7 +1611,8 @@ bool Heap::CollectGarbage(AllocationSpace space,
   // collection is triggered. Note that these callbacks may trigger another
   // garbage collection since they may allocate.
 
-  DCHECK(AllowGarbageCollection::IsAllowed());
+  // DCHECK(AllowGarbageCollection::IsAllowed());
+  CHECK(AllowGarbageCollection::IsAllowed()); // xqg
 
   GarbageCollector collector;
   const char* collector_reason = nullptr;
@@ -4628,6 +4631,12 @@ void Heap::IterateRoots(RootVisitor* v, base::EnumSet<SkipRoot> options) {
       v->Synchronize(VisitorSynchronization::kStackRoots);
     }
 
+    // xqg start
+    if (!options.contains(SkipRoot::kUnserializable)) {
+        isolate_->IterateTaintAnalysisStuff(v);
+    }
+    // xqg end
+
     // Iterate over main thread handles in handle scopes.
     if (!options.contains(SkipRoot::kMainThreadHandles)) {
       // Clear main thread handles with stale references to left-trimmed
@@ -4636,6 +4645,12 @@ void Heap::IterateRoots(RootVisitor* v, base::EnumSet<SkipRoot> options) {
       isolate_->handle_scope_implementer()->Iterate(&left_trim_visitor);
 
       isolate_->handle_scope_implementer()->Iterate(v);
+
+      // xqg start
+      if (!options.contains(SkipRoot::kUnserializable)) {
+          isolate_->IterateTaintAnalysisStuff(&left_trim_visitor);
+      }
+      // xqg end
     }
 
     // Iterate local handles for all local heaps.
diff --git a/src/ic/binary-op-assembler.cc b/src/ic/binary-op-assembler.cc
index 403d4b9bbe4..122dd96d8d3 100644
--- a/src/ic/binary-op-assembler.cc
+++ b/src/ic/binary-op-assembler.cc
@@ -183,7 +183,7 @@ TNode<Object> BinaryOpAssembler::Generate_AddWithFeedback(
         UpdateFeedback(var_type_feedback.value(), maybe_feedback_vector(),
                        slot_id, update_feedback_mode);
         var_result =
-            CallBuiltin(Builtin::kStringAdd_CheckNone, context(), lhs, rhs);
+            CallBuiltin(Builtin::kStringAdd_CheckNone1, context(), lhs, rhs); // xqg
 
         Goto(&end);
       }
diff --git a/src/interpreter/bytecode-array-builder.cc b/src/interpreter/bytecode-array-builder.cc
index 784d88a9a8f..56a33fe788d 100644
--- a/src/interpreter/bytecode-array-builder.cc
+++ b/src/interpreter/bytecode-array-builder.cc
@@ -1251,6 +1251,15 @@ BytecodeArrayBuilder& BytecodeArrayBuilder::JumpIfNotNil(BytecodeLabel* label,
   }
 }
 
+// xqg start
+BytecodeArrayBuilder& BytecodeArrayBuilder::JumpIfNotSmi(BytecodeLabel* label) {
+    DCHECK(!label->is_bound());
+    OutputJumpIfNotSmi(label, 0);
+    return *this;
+}
+// xqg end
+
+
 BytecodeArrayBuilder& BytecodeArrayBuilder::JumpIfJSReceiver(
     BytecodeLabel* label) {
   DCHECK(!label->is_bound());
diff --git a/src/interpreter/bytecode-array-builder.h b/src/interpreter/bytecode-array-builder.h
index a9d21998405..91e0ba01b2e 100644
--- a/src/interpreter/bytecode-array-builder.h
+++ b/src/interpreter/bytecode-array-builder.h
@@ -441,6 +441,10 @@ class V8_EXPORT_PRIVATE BytecodeArrayBuilder final {
   BytecodeArrayBuilder& JumpIfNotNil(BytecodeLabel* label, Token::Value op,
                                      NilValue nil);
 
+  // xqg start
+  BytecodeArrayBuilder& JumpIfNotSmi(BytecodeLabel* label);
+  // xqg end
+
   BytecodeArrayBuilder& SwitchOnSmiNoFeedback(BytecodeJumpTable* jump_table);
 
   // Sets the pending message to the value in the accumulator, and returns the
diff --git a/src/interpreter/bytecode-generator.cc b/src/interpreter/bytecode-generator.cc
index 706d897d8a7..a50c8c6c872 100644
--- a/src/interpreter/bytecode-generator.cc
+++ b/src/interpreter/bytecode-generator.cc
@@ -37,1008 +37,1035 @@
 #include "src/utils/ostreams.h"
 
 namespace v8 {
-namespace internal {
-namespace interpreter {
+    namespace internal {
+        namespace interpreter {
 
 // Scoped class tracking context objects created by the visitor. Represents
 // mutations of the context chain within the function body, allowing pushing and
 // popping of the current {context_register} during visitation.
-class V8_NODISCARD BytecodeGenerator::ContextScope {
- public:
-  ContextScope(BytecodeGenerator* generator, Scope* scope,
-               Register outer_context_reg = Register())
-      : generator_(generator),
-        scope_(scope),
-        outer_(generator_->execution_context()),
-        register_(Register::current_context()),
-        depth_(0) {
-    DCHECK(scope->NeedsContext() || outer_ == nullptr);
-    if (outer_) {
-      depth_ = outer_->depth_ + 1;
-
-      // Push the outer context into a new context register.
-      if (!outer_context_reg.is_valid()) {
-        outer_context_reg = generator_->register_allocator()->NewRegister();
-      }
-      outer_->set_register(outer_context_reg);
-      generator_->builder()->PushContext(outer_context_reg);
-    }
-    generator_->set_execution_context(this);
-  }
-
-  ~ContextScope() {
-    if (outer_) {
-      DCHECK_EQ(register_.index(), Register::current_context().index());
-      generator_->builder()->PopContext(outer_->reg());
-      outer_->set_register(register_);
-    }
-    generator_->set_execution_context(outer_);
-  }
-
-  ContextScope(const ContextScope&) = delete;
-  ContextScope& operator=(const ContextScope&) = delete;
-
-  // Returns the depth of the given |scope| for the current execution context.
-  int ContextChainDepth(Scope* scope) {
-    return scope_->ContextChainLength(scope);
-  }
-
-  // Returns the execution context at |depth| in the current context chain if it
-  // is a function local execution context, otherwise returns nullptr.
-  ContextScope* Previous(int depth) {
-    if (depth > depth_) {
-      return nullptr;
-    }
-
-    ContextScope* previous = this;
-    for (int i = depth; i > 0; --i) {
-      previous = previous->outer_;
-    }
-    return previous;
-  }
-
-  Register reg() const { return register_; }
-
- private:
-  const BytecodeArrayBuilder* builder() const { return generator_->builder(); }
-
-  void set_register(Register reg) { register_ = reg; }
-
-  BytecodeGenerator* generator_;
-  Scope* scope_;
-  ContextScope* outer_;
-  Register register_;
-  int depth_;
-};
+            class V8_NODISCARD BytecodeGenerator::ContextScope {
+                    public:
+                    ContextScope(BytecodeGenerator* generator, Scope* scope,
+                    Register outer_context_reg = Register())
+                    : generator_(generator),
+                    scope_(scope),
+                    outer_(generator_->execution_context()),
+                    register_(Register::current_context()),
+                    depth_(0) {
+                        DCHECK(scope->NeedsContext() || outer_ == nullptr);
+                        if (outer_) {
+                            depth_ = outer_->depth_ + 1;
+
+                            // Push the outer context into a new context register.
+                            if (!outer_context_reg.is_valid()) {
+                                outer_context_reg = generator_->register_allocator()->NewRegister();
+                            }
+                            outer_->set_register(outer_context_reg);
+                            generator_->builder()->PushContext(outer_context_reg);
+                        }
+                        generator_->set_execution_context(this);
+                    }
+
+                    ~ContextScope() {
+                        if (outer_) {
+                            DCHECK_EQ(register_.index(), Register::current_context().index());
+                            generator_->builder()->PopContext(outer_->reg());
+                            outer_->set_register(register_);
+                        }
+                        generator_->set_execution_context(outer_);
+                    }
+
+                    ContextScope(const ContextScope&) = delete;
+                    ContextScope& operator=(const ContextScope&) = delete;
+
+                    // Returns the depth of the given |scope| for the current execution context.
+                    int ContextChainDepth(Scope* scope) {
+                        return scope_->ContextChainLength(scope);
+                    }
+
+                    // Returns the execution context at |depth| in the current context chain if it
+                    // is a function local execution context, otherwise returns nullptr.
+                    ContextScope* Previous(int depth) {
+                        if (depth > depth_) {
+                            return nullptr;
+                        }
+
+                        ContextScope* previous = this;
+                        for (int i = depth; i > 0; --i) {
+                            previous = previous->outer_;
+                        }
+                        return previous;
+                    }
+
+                    Register reg() const { return register_; }
+
+                    private:
+                    const BytecodeArrayBuilder* builder() const { return generator_->builder(); }
+
+                    void set_register(Register reg) { register_ = reg; }
+
+                    BytecodeGenerator* generator_;
+                    Scope* scope_;
+                    ContextScope* outer_;
+                    Register register_;
+                    int depth_;
+            };
 
 // Scoped class for tracking control statements entered by the
 // visitor.
-class V8_NODISCARD BytecodeGenerator::ControlScope {
- public:
-  explicit ControlScope(BytecodeGenerator* generator)
-      : generator_(generator),
-        outer_(generator->execution_control()),
-        context_(generator->execution_context()) {
-    generator_->set_execution_control(this);
-  }
-  ~ControlScope() { generator_->set_execution_control(outer()); }
-  ControlScope(const ControlScope&) = delete;
-  ControlScope& operator=(const ControlScope&) = delete;
-
-  void Break(Statement* stmt) {
-    PerformCommand(CMD_BREAK, stmt, kNoSourcePosition);
-  }
-  void Continue(Statement* stmt) {
-    PerformCommand(CMD_CONTINUE, stmt, kNoSourcePosition);
-  }
-  void ReturnAccumulator(int source_position) {
-    PerformCommand(CMD_RETURN, nullptr, source_position);
-  }
-  void AsyncReturnAccumulator(int source_position) {
-    PerformCommand(CMD_ASYNC_RETURN, nullptr, source_position);
-  }
-
-  class DeferredCommands;
-
- protected:
-  enum Command {
-    CMD_BREAK,
-    CMD_CONTINUE,
-    CMD_RETURN,
-    CMD_ASYNC_RETURN,
-    CMD_RETHROW
-  };
-  static constexpr bool CommandUsesAccumulator(Command command) {
-    return command != CMD_BREAK && command != CMD_CONTINUE;
-  }
-
-  void PerformCommand(Command command, Statement* statement,
-                      int source_position);
-  virtual bool Execute(Command command, Statement* statement,
-                       int source_position) = 0;
-
-  // Helper to pop the context chain to a depth expected by this control scope.
-  // Note that it is the responsibility of each individual {Execute} method to
-  // trigger this when commands are handled and control-flow continues locally.
-  void PopContextToExpectedDepth();
-
-  BytecodeGenerator* generator() const { return generator_; }
-  ControlScope* outer() const { return outer_; }
-  ContextScope* context() const { return context_; }
-
- private:
-  BytecodeGenerator* generator_;
-  ControlScope* outer_;
-  ContextScope* context_;
-};
+            class V8_NODISCARD BytecodeGenerator::ControlScope {
+                    public:
+                    explicit ControlScope(BytecodeGenerator* generator)
+                    : generator_(generator),
+                    outer_(generator->execution_control()),
+                    context_(generator->execution_context()) {
+                        generator_->set_execution_control(this);
+                    }
+                    ~ControlScope() { generator_->set_execution_control(outer()); }
+                    ControlScope(const ControlScope&) = delete;
+                    ControlScope& operator=(const ControlScope&) = delete;
+
+                    void Break(Statement* stmt) {
+                        PerformCommand(CMD_BREAK, stmt, kNoSourcePosition);
+                    }
+                    void Continue(Statement* stmt) {
+                        PerformCommand(CMD_CONTINUE, stmt, kNoSourcePosition);
+                    }
+                    void ReturnAccumulator(int source_position) {
+                        PerformCommand(CMD_RETURN, nullptr, source_position);
+                    }
+                    void AsyncReturnAccumulator(int source_position) {
+                        PerformCommand(CMD_ASYNC_RETURN, nullptr, source_position);
+                    }
+
+                    class DeferredCommands;
+
+                    protected:
+                    enum Command {
+                        CMD_BREAK,
+                                CMD_CONTINUE,
+                                CMD_RETURN,
+                                CMD_ASYNC_RETURN,
+                                CMD_RETHROW
+                    };
+                    static constexpr bool CommandUsesAccumulator(Command command) {
+                        return command != CMD_BREAK && command != CMD_CONTINUE;
+                    }
+
+                    void PerformCommand(Command command, Statement* statement,
+                    int source_position);
+                    virtual bool Execute(Command command, Statement* statement,
+                    int source_position) = 0;
+
+                    // Helper to pop the context chain to a depth expected by this control scope.
+                    // Note that it is the responsibility of each individual {Execute} method to
+                    // trigger this when commands are handled and control-flow continues locally.
+                    void PopContextToExpectedDepth();
+
+                    BytecodeGenerator* generator() const { return generator_; }
+                    ControlScope* outer() const { return outer_; }
+                    ContextScope* context() const { return context_; }
+
+                    private:
+                    BytecodeGenerator* generator_;
+                    ControlScope* outer_;
+                    ContextScope* context_;
+            };
 
 // Helper class for a try-finally control scope. It can record intercepted
 // control-flow commands that cause entry into a finally-block, and re-apply
 // them after again leaving that block. Special tokens are used to identify
 // paths going through the finally-block to dispatch after leaving the block.
-class V8_NODISCARD BytecodeGenerator::ControlScope::DeferredCommands final {
- public:
-  // Fixed value tokens for paths we know we need.
-  // Fallthrough is set to -1 to make it the fallthrough case of the jump table,
-  // where the remaining cases start at 0.
-  static const int kFallthroughToken = -1;
-  // TODO(leszeks): Rethrow being 0 makes it use up a valuable LdaZero, which
-  // means that other commands (such as break or return) have to use LdaSmi.
-  // This can very slightly bloat bytecode, so perhaps token values should all
-  // be shifted down by 1.
-  static const int kRethrowToken = 0;
-
-  DeferredCommands(BytecodeGenerator* generator, Register token_register,
-                   Register result_register)
-      : generator_(generator),
-        deferred_(generator->zone()),
-        token_register_(token_register),
-        result_register_(result_register),
-        return_token_(-1),
-        async_return_token_(-1) {
-    // There's always a rethrow path.
-    // TODO(leszeks): We could decouple deferred_ index and token to allow us
-    // to still push this lazily.
-    static_assert(kRethrowToken == 0);
-    deferred_.push_back({CMD_RETHROW, nullptr, kRethrowToken});
-  }
-
-  // One recorded control-flow command.
-  struct Entry {
-    Command command;       // The command type being applied on this path.
-    Statement* statement;  // The target statement for the command or {nullptr}.
-    int token;             // A token identifying this particular path.
-  };
-
-  // Records a control-flow command while entering the finally-block. This also
-  // generates a new dispatch token that identifies one particular path. This
-  // expects the result to be in the accumulator.
-  void RecordCommand(Command command, Statement* statement) {
-    int token = GetTokenForCommand(command, statement);
-
-    DCHECK_LT(token, deferred_.size());
-    DCHECK_EQ(deferred_[token].command, command);
-    DCHECK_EQ(deferred_[token].statement, statement);
-    DCHECK_EQ(deferred_[token].token, token);
-
-    if (CommandUsesAccumulator(command)) {
-      builder()->StoreAccumulatorInRegister(result_register_);
-    }
-    builder()->LoadLiteral(Smi::FromInt(token));
-    builder()->StoreAccumulatorInRegister(token_register_);
-    if (!CommandUsesAccumulator(command)) {
-      // If we're not saving the accumulator in the result register, shove a
-      // harmless value there instead so that it is still considered "killed" in
-      // the liveness analysis. Normally we would LdaUndefined first, but the
-      // Smi token value is just as good, and by reusing it we save a bytecode.
-      builder()->StoreAccumulatorInRegister(result_register_);
-    }
-  }
-
-  // Records the dispatch token to be used to identify the re-throw path when
-  // the finally-block has been entered through the exception handler. This
-  // expects the exception to be in the accumulator.
-  void RecordHandlerReThrowPath() {
-    // The accumulator contains the exception object.
-    RecordCommand(CMD_RETHROW, nullptr);
-  }
-
-  // Records the dispatch token to be used to identify the implicit fall-through
-  // path at the end of a try-block into the corresponding finally-block.
-  void RecordFallThroughPath() {
-    builder()->LoadLiteral(Smi::FromInt(kFallthroughToken));
-    builder()->StoreAccumulatorInRegister(token_register_);
-    // Since we're not saving the accumulator in the result register, shove a
-    // harmless value there instead so that it is still considered "killed" in
-    // the liveness analysis. Normally we would LdaUndefined first, but the Smi
-    // token value is just as good, and by reusing it we save a bytecode.
-    builder()->StoreAccumulatorInRegister(result_register_);
-  }
-
-  // Applies all recorded control-flow commands after the finally-block again.
-  // This generates a dynamic dispatch on the token from the entry point.
-  void ApplyDeferredCommands() {
-    if (deferred_.size() == 0) return;
-
-    BytecodeLabel fall_through;
-
-    if (deferred_.size() == 1) {
-      // For a single entry, just jump to the fallthrough if we don't match the
-      // entry token.
-      const Entry& entry = deferred_[0];
-
-      builder()
-          ->LoadLiteral(Smi::FromInt(entry.token))
-          .CompareReference(token_register_)
-          .JumpIfFalse(ToBooleanMode::kAlreadyBoolean, &fall_through);
+            class V8_NODISCARD BytecodeGenerator::ControlScope::DeferredCommands final {
+            public:
+            // Fixed value tokens for paths we know we need.
+            // Fallthrough is set to -1 to make it the fallthrough case of the jump table,
+            // where the remaining cases start at 0.
+            static const int kFallthroughToken = -1;
+            // TODO(leszeks): Rethrow being 0 makes it use up a valuable LdaZero, which
+            // means that other commands (such as break or return) have to use LdaSmi.
+            // This can very slightly bloat bytecode, so perhaps token values should all
+            // be shifted down by 1.
+            static const int kRethrowToken = 0;
+
+            DeferredCommands(BytecodeGenerator* generator, Register token_register,
+                    Register result_register)
+            : generator_(generator),
+            deferred_(generator->zone()),
+            token_register_(token_register),
+            result_register_(result_register),
+            return_token_(-1),
+            async_return_token_(-1) {
+                // There's always a rethrow path.
+                // TODO(leszeks): We could decouple deferred_ index and token to allow us
+                // to still push this lazily.
+                static_assert(kRethrowToken == 0);
+                deferred_.push_back({CMD_RETHROW, nullptr, kRethrowToken});
+            }
 
-      if (CommandUsesAccumulator(entry.command)) {
-        builder()->LoadAccumulatorWithRegister(result_register_);
-      }
-      execution_control()->PerformCommand(entry.command, entry.statement,
-                                          kNoSourcePosition);
-    } else {
-      // For multiple entries, build a jump table and switch on the token,
-      // jumping to the fallthrough if none of them match.
+            // One recorded control-flow command.
+            struct Entry {
+                Command command;       // The command type being applied on this path.
+                Statement* statement;  // The target statement for the command or {nullptr}.
+                int token;             // A token identifying this particular path.
+            };
+
+            // Records a control-flow command while entering the finally-block. This also
+            // generates a new dispatch token that identifies one particular path. This
+            // expects the result to be in the accumulator.
+            void RecordCommand(Command command, Statement* statement) {
+                int token = GetTokenForCommand(command, statement);
+
+                DCHECK_LT(token, deferred_.size());
+                DCHECK_EQ(deferred_[token].command, command);
+                DCHECK_EQ(deferred_[token].statement, statement);
+                DCHECK_EQ(deferred_[token].token, token);
+
+                if (CommandUsesAccumulator(command)) {
+                    builder()->StoreAccumulatorInRegister(result_register_);
+                }
+                builder()->LoadLiteral(Smi::FromInt(token));
+                builder()->StoreAccumulatorInRegister(token_register_);
+                if (!CommandUsesAccumulator(command)) {
+                    // If we're not saving the accumulator in the result register, shove a
+                    // harmless value there instead so that it is still considered "killed" in
+                    // the liveness analysis. Normally we would LdaUndefined first, but the
+                    // Smi token value is just as good, and by reusing it we save a bytecode.
+                    builder()->StoreAccumulatorInRegister(result_register_);
+                }
+            }
 
-      BytecodeJumpTable* jump_table =
-          builder()->AllocateJumpTable(static_cast<int>(deferred_.size()), 0);
-      builder()
-          ->LoadAccumulatorWithRegister(token_register_)
-          .SwitchOnSmiNoFeedback(jump_table)
-          .Jump(&fall_through);
-      for (const Entry& entry : deferred_) {
-        builder()->Bind(jump_table, entry.token);
+            // Records the dispatch token to be used to identify the re-throw path when
+            // the finally-block has been entered through the exception handler. This
+            // expects the exception to be in the accumulator.
+            void RecordHandlerReThrowPath() {
+                // The accumulator contains the exception object.
+                RecordCommand(CMD_RETHROW, nullptr);
+            }
 
-        if (CommandUsesAccumulator(entry.command)) {
-          builder()->LoadAccumulatorWithRegister(result_register_);
-        }
-        execution_control()->PerformCommand(entry.command, entry.statement,
-                                            kNoSourcePosition);
-      }
-    }
+            // Records the dispatch token to be used to identify the implicit fall-through
+            // path at the end of a try-block into the corresponding finally-block.
+            void RecordFallThroughPath() {
+                builder()->LoadLiteral(Smi::FromInt(kFallthroughToken));
+                builder()->StoreAccumulatorInRegister(token_register_);
+                // Since we're not saving the accumulator in the result register, shove a
+                // harmless value there instead so that it is still considered "killed" in
+                // the liveness analysis. Normally we would LdaUndefined first, but the Smi
+                // token value is just as good, and by reusing it we save a bytecode.
+                builder()->StoreAccumulatorInRegister(result_register_);
+            }
 
-    builder()->Bind(&fall_through);
-  }
+            // Applies all recorded control-flow commands after the finally-block again.
+            // This generates a dynamic dispatch on the token from the entry point.
+            void ApplyDeferredCommands() {
+                if (deferred_.size() == 0) return;
+
+                BytecodeLabel fall_through;
+
+                if (deferred_.size() == 1) {
+                    // For a single entry, just jump to the fallthrough if we don't match the
+                    // entry token.
+                    const Entry& entry = deferred_[0];
+
+                    builder()
+                            ->LoadLiteral(Smi::FromInt(entry.token))
+                            .CompareReference(token_register_)
+                            .JumpIfFalse(ToBooleanMode::kAlreadyBoolean, &fall_through);
+
+                    if (CommandUsesAccumulator(entry.command)) {
+                        builder()->LoadAccumulatorWithRegister(result_register_);
+                    }
+                    execution_control()->PerformCommand(entry.command, entry.statement,
+                                                        kNoSourcePosition);
+                } else {
+                    // For multiple entries, build a jump table and switch on the token,
+                    // jumping to the fallthrough if none of them match.
+
+                    BytecodeJumpTable* jump_table =
+                            builder()->AllocateJumpTable(static_cast<int>(deferred_.size()), 0);
+                    builder()
+                            ->LoadAccumulatorWithRegister(token_register_)
+                            .SwitchOnSmiNoFeedback(jump_table)
+                            .Jump(&fall_through);
+                    for (const Entry& entry : deferred_) {
+                        builder()->Bind(jump_table, entry.token);
+
+                        if (CommandUsesAccumulator(entry.command)) {
+                            builder()->LoadAccumulatorWithRegister(result_register_);
+                        }
+                        execution_control()->PerformCommand(entry.command, entry.statement,
+                                                            kNoSourcePosition);
+                    }
+                }
+
+                builder()->Bind(&fall_through);
+            }
 
-  BytecodeArrayBuilder* builder() { return generator_->builder(); }
-  ControlScope* execution_control() { return generator_->execution_control(); }
-
- private:
-  int GetTokenForCommand(Command command, Statement* statement) {
-    switch (command) {
-      case CMD_RETURN:
-        return GetReturnToken();
-      case CMD_ASYNC_RETURN:
-        return GetAsyncReturnToken();
-      case CMD_RETHROW:
-        return kRethrowToken;
-      default:
-        // TODO(leszeks): We could also search for entries with the same
-        // command and statement.
-        return GetNewTokenForCommand(command, statement);
-    }
-  }
+            BytecodeArrayBuilder* builder() { return generator_->builder(); }
+            ControlScope* execution_control() { return generator_->execution_control(); }
+
+            private:
+            int GetTokenForCommand(Command command, Statement* statement) {
+                switch (command) {
+                    case CMD_RETURN:
+                        return GetReturnToken();
+                    case CMD_ASYNC_RETURN:
+                        return GetAsyncReturnToken();
+                    case CMD_RETHROW:
+                        return kRethrowToken;
+                    default:
+                        // TODO(leszeks): We could also search for entries with the same
+                        // command and statement.
+                        return GetNewTokenForCommand(command, statement);
+                }
+            }
 
-  int GetReturnToken() {
-    if (return_token_ == -1) {
-      return_token_ = GetNewTokenForCommand(CMD_RETURN, nullptr);
-    }
-    return return_token_;
-  }
+            int GetReturnToken() {
+                if (return_token_ == -1) {
+                    return_token_ = GetNewTokenForCommand(CMD_RETURN, nullptr);
+                }
+                return return_token_;
+            }
 
-  int GetAsyncReturnToken() {
-    if (async_return_token_ == -1) {
-      async_return_token_ = GetNewTokenForCommand(CMD_ASYNC_RETURN, nullptr);
-    }
-    return async_return_token_;
-  }
+            int GetAsyncReturnToken() {
+                if (async_return_token_ == -1) {
+                    async_return_token_ = GetNewTokenForCommand(CMD_ASYNC_RETURN, nullptr);
+                }
+                return async_return_token_;
+            }
 
-  int GetNewTokenForCommand(Command command, Statement* statement) {
-    int token = static_cast<int>(deferred_.size());
-    deferred_.push_back({command, statement, token});
-    return token;
-  }
+            int GetNewTokenForCommand(Command command, Statement* statement) {
+                int token = static_cast<int>(deferred_.size());
+                deferred_.push_back({command, statement, token});
+                return token;
+            }
 
-  BytecodeGenerator* generator_;
-  ZoneVector<Entry> deferred_;
-  Register token_register_;
-  Register result_register_;
+            BytecodeGenerator* generator_;
+            ZoneVector<Entry> deferred_;
+            Register token_register_;
+            Register result_register_;
 
-  // Tokens for commands that don't need a statement.
-  int return_token_;
-  int async_return_token_;
-};
+            // Tokens for commands that don't need a statement.
+            int return_token_;
+            int async_return_token_;
+        };
 
 // Scoped class for dealing with control flow reaching the function level.
-class BytecodeGenerator::ControlScopeForTopLevel final
-    : public BytecodeGenerator::ControlScope {
- public:
-  explicit ControlScopeForTopLevel(BytecodeGenerator* generator)
-      : ControlScope(generator) {}
-
- protected:
-  bool Execute(Command command, Statement* statement,
-               int source_position) override {
-    switch (command) {
-      case CMD_BREAK:  // We should never see break/continue in top-level.
-      case CMD_CONTINUE:
-        UNREACHABLE();
-      case CMD_RETURN:
-        // No need to pop contexts, execution leaves the method body.
-        generator()->BuildReturn(source_position);
-        return true;
-      case CMD_ASYNC_RETURN:
-        // No need to pop contexts, execution leaves the method body.
-        generator()->BuildAsyncReturn(source_position);
-        return true;
-      case CMD_RETHROW:
-        // No need to pop contexts, execution leaves the method body.
-        generator()->BuildReThrow();
-        return true;
-    }
-    return false;
-  }
-};
+        class BytecodeGenerator::ControlScopeForTopLevel final
+                : public BytecodeGenerator::ControlScope {
+        public:
+            explicit ControlScopeForTopLevel(BytecodeGenerator* generator)
+                    : ControlScope(generator) {}
+
+        protected:
+            bool Execute(Command command, Statement* statement,
+                         int source_position) override {
+                switch (command) {
+                    case CMD_BREAK:  // We should never see break/continue in top-level.
+                    case CMD_CONTINUE:
+                        UNREACHABLE();
+                    case CMD_RETURN:
+                        // No need to pop contexts, execution leaves the method body.
+                        generator()->BuildReturn(source_position);
+                        return true;
+                    case CMD_ASYNC_RETURN:
+                        // No need to pop contexts, execution leaves the method body.
+                        generator()->BuildAsyncReturn(source_position);
+                        return true;
+                    case CMD_RETHROW:
+                        // No need to pop contexts, execution leaves the method body.
+                        generator()->BuildReThrow();
+                        return true;
+                }
+                return false;
+            }
+        };
 
 // Scoped class for enabling break inside blocks and switch blocks.
-class BytecodeGenerator::ControlScopeForBreakable final
-    : public BytecodeGenerator::ControlScope {
- public:
-  ControlScopeForBreakable(BytecodeGenerator* generator,
-                           BreakableStatement* statement,
-                           BreakableControlFlowBuilder* control_builder)
-      : ControlScope(generator),
-        statement_(statement),
-        control_builder_(control_builder) {}
-
- protected:
-  bool Execute(Command command, Statement* statement,
-               int source_position) override {
-    if (statement != statement_) return false;
-    switch (command) {
-      case CMD_BREAK:
-        PopContextToExpectedDepth();
-        control_builder_->Break();
-        return true;
-      case CMD_CONTINUE:
-      case CMD_RETURN:
-      case CMD_ASYNC_RETURN:
-      case CMD_RETHROW:
-        break;
-    }
-    return false;
-  }
+        class BytecodeGenerator::ControlScopeForBreakable final
+                : public BytecodeGenerator::ControlScope {
+        public:
+            ControlScopeForBreakable(BytecodeGenerator* generator,
+                                     BreakableStatement* statement,
+                                     BreakableControlFlowBuilder* control_builder)
+                    : ControlScope(generator),
+                      statement_(statement),
+                      control_builder_(control_builder) {}
+
+        protected:
+            bool Execute(Command command, Statement* statement,
+                         int source_position) override {
+                if (statement != statement_) return false;
+                switch (command) {
+                    case CMD_BREAK:
+                        PopContextToExpectedDepth();
+                        control_builder_->Break();
+                        return true;
+                    case CMD_CONTINUE:
+                    case CMD_RETURN:
+                    case CMD_ASYNC_RETURN:
+                    case CMD_RETHROW:
+                        break;
+                }
+                return false;
+            }
 
- private:
-  Statement* statement_;
-  BreakableControlFlowBuilder* control_builder_;
-};
+        private:
+            Statement* statement_;
+            BreakableControlFlowBuilder* control_builder_;
+        };
 
 // Scoped class for enabling 'break' and 'continue' in iteration
 // constructs, e.g. do...while, while..., for...
-class BytecodeGenerator::ControlScopeForIteration final
-    : public BytecodeGenerator::ControlScope {
- public:
-  ControlScopeForIteration(BytecodeGenerator* generator,
-                           IterationStatement* statement,
-                           LoopBuilder* loop_builder)
-      : ControlScope(generator),
-        statement_(statement),
-        loop_builder_(loop_builder) {}
-
- protected:
-  bool Execute(Command command, Statement* statement,
-               int source_position) override {
-    if (statement != statement_) return false;
-    switch (command) {
-      case CMD_BREAK:
-        PopContextToExpectedDepth();
-        loop_builder_->Break();
-        return true;
-      case CMD_CONTINUE:
-        PopContextToExpectedDepth();
-        loop_builder_->Continue();
-        return true;
-      case CMD_RETURN:
-      case CMD_ASYNC_RETURN:
-      case CMD_RETHROW:
-        break;
-    }
-    return false;
-  }
+        class BytecodeGenerator::ControlScopeForIteration final
+                : public BytecodeGenerator::ControlScope {
+        public:
+            ControlScopeForIteration(BytecodeGenerator* generator,
+                                     IterationStatement* statement,
+                                     LoopBuilder* loop_builder)
+                    : ControlScope(generator),
+                      statement_(statement),
+                      loop_builder_(loop_builder) {}
+
+        protected:
+            bool Execute(Command command, Statement* statement,
+                         int source_position) override {
+                if (statement != statement_) return false;
+                switch (command) {
+                    case CMD_BREAK:
+                        PopContextToExpectedDepth();
+                        loop_builder_->Break();
+                        return true;
+                    case CMD_CONTINUE:
+                        PopContextToExpectedDepth();
+                        loop_builder_->Continue();
+                        return true;
+                    case CMD_RETURN:
+                    case CMD_ASYNC_RETURN:
+                    case CMD_RETHROW:
+                        break;
+                }
+                return false;
+            }
 
- private:
-  Statement* statement_;
-  LoopBuilder* loop_builder_;
-};
+        private:
+            Statement* statement_;
+            LoopBuilder* loop_builder_;
+        };
 
 // Scoped class for enabling 'throw' in try-catch constructs.
-class BytecodeGenerator::ControlScopeForTryCatch final
-    : public BytecodeGenerator::ControlScope {
- public:
-  ControlScopeForTryCatch(BytecodeGenerator* generator,
-                          TryCatchBuilder* try_catch_builder)
-      : ControlScope(generator) {}
-
- protected:
-  bool Execute(Command command, Statement* statement,
-               int source_position) override {
-    switch (command) {
-      case CMD_BREAK:
-      case CMD_CONTINUE:
-      case CMD_RETURN:
-      case CMD_ASYNC_RETURN:
-        break;
-      case CMD_RETHROW:
-        // No need to pop contexts, execution re-enters the method body via the
-        // stack unwinding mechanism which itself restores contexts correctly.
-        generator()->BuildReThrow();
-        return true;
-    }
-    return false;
-  }
-};
+        class BytecodeGenerator::ControlScopeForTryCatch final
+                : public BytecodeGenerator::ControlScope {
+        public:
+            ControlScopeForTryCatch(BytecodeGenerator* generator,
+                                    TryCatchBuilder* try_catch_builder)
+                    : ControlScope(generator) {}
+
+        protected:
+            bool Execute(Command command, Statement* statement,
+                         int source_position) override {
+                switch (command) {
+                    case CMD_BREAK:
+                    case CMD_CONTINUE:
+                    case CMD_RETURN:
+                    case CMD_ASYNC_RETURN:
+                        break;
+                    case CMD_RETHROW:
+                        // No need to pop contexts, execution re-enters the method body via the
+                        // stack unwinding mechanism which itself restores contexts correctly.
+                        generator()->BuildReThrow();
+                        return true;
+                }
+                return false;
+            }
+        };
 
 // Scoped class for enabling control flow through try-finally constructs.
-class BytecodeGenerator::ControlScopeForTryFinally final
-    : public BytecodeGenerator::ControlScope {
- public:
-  ControlScopeForTryFinally(BytecodeGenerator* generator,
-                            TryFinallyBuilder* try_finally_builder,
-                            DeferredCommands* commands)
-      : ControlScope(generator),
-        try_finally_builder_(try_finally_builder),
-        commands_(commands) {}
-
- protected:
-  bool Execute(Command command, Statement* statement,
-               int source_position) override {
-    switch (command) {
-      case CMD_BREAK:
-      case CMD_CONTINUE:
-      case CMD_RETURN:
-      case CMD_ASYNC_RETURN:
-      case CMD_RETHROW:
-        PopContextToExpectedDepth();
-        // We don't record source_position here since we don't generate return
-        // bytecode right here and will generate it later as part of finally
-        // block. Each return bytecode generated in finally block will get own
-        // return source position from corresponded return statement or we'll
-        // use end of function if no return statement is presented.
-        commands_->RecordCommand(command, statement);
-        try_finally_builder_->LeaveTry();
-        return true;
-    }
-    return false;
-  }
+        class BytecodeGenerator::ControlScopeForTryFinally final
+                : public BytecodeGenerator::ControlScope {
+        public:
+            ControlScopeForTryFinally(BytecodeGenerator* generator,
+                                      TryFinallyBuilder* try_finally_builder,
+                                      DeferredCommands* commands)
+                    : ControlScope(generator),
+                      try_finally_builder_(try_finally_builder),
+                      commands_(commands) {}
+
+        protected:
+            bool Execute(Command command, Statement* statement,
+                         int source_position) override {
+                switch (command) {
+                    case CMD_BREAK:
+                    case CMD_CONTINUE:
+                    case CMD_RETURN:
+                    case CMD_ASYNC_RETURN:
+                    case CMD_RETHROW:
+                        PopContextToExpectedDepth();
+                        // We don't record source_position here since we don't generate return
+                        // bytecode right here and will generate it later as part of finally
+                        // block. Each return bytecode generated in finally block will get own
+                        // return source position from corresponded return statement or we'll
+                        // use end of function if no return statement is presented.
+                        commands_->RecordCommand(command, statement);
+                        try_finally_builder_->LeaveTry();
+                        return true;
+                }
+                return false;
+            }
 
- private:
-  TryFinallyBuilder* try_finally_builder_;
-  DeferredCommands* commands_;
-};
+        private:
+            TryFinallyBuilder* try_finally_builder_;
+            DeferredCommands* commands_;
+        };
 
 // Allocate and fetch the coverage indices tracking NaryLogical Expressions.
-class BytecodeGenerator::NaryCodeCoverageSlots {
- public:
-  NaryCodeCoverageSlots(BytecodeGenerator* generator, NaryOperation* expr)
-      : generator_(generator) {
-    if (generator_->block_coverage_builder_ == nullptr) return;
-    for (size_t i = 0; i < expr->subsequent_length(); i++) {
-      coverage_slots_.push_back(
-          generator_->AllocateNaryBlockCoverageSlotIfEnabled(expr, i));
-    }
-  }
-
-  int GetSlotFor(size_t subsequent_expr_index) const {
-    if (generator_->block_coverage_builder_ == nullptr) {
-      return BlockCoverageBuilder::kNoCoverageArraySlot;
-    }
-    DCHECK(coverage_slots_.size() > subsequent_expr_index);
-    return coverage_slots_[subsequent_expr_index];
-  }
+        class BytecodeGenerator::NaryCodeCoverageSlots {
+        public:
+            NaryCodeCoverageSlots(BytecodeGenerator* generator, NaryOperation* expr)
+                    : generator_(generator) {
+                if (generator_->block_coverage_builder_ == nullptr) return;
+                for (size_t i = 0; i < expr->subsequent_length(); i++) {
+                    coverage_slots_.push_back(
+                            generator_->AllocateNaryBlockCoverageSlotIfEnabled(expr, i));
+                }
+            }
 
- private:
-  BytecodeGenerator* generator_;
-  std::vector<int> coverage_slots_;
-};
+            int GetSlotFor(size_t subsequent_expr_index) const {
+                if (generator_->block_coverage_builder_ == nullptr) {
+                    return BlockCoverageBuilder::kNoCoverageArraySlot;
+                }
+                DCHECK(coverage_slots_.size() > subsequent_expr_index);
+                return coverage_slots_[subsequent_expr_index];
+            }
 
-void BytecodeGenerator::ControlScope::PerformCommand(Command command,
-                                                     Statement* statement,
-                                                     int source_position) {
-  ControlScope* current = this;
-  do {
-    if (current->Execute(command, statement, source_position)) {
-      return;
-    }
-    current = current->outer();
-  } while (current != nullptr);
-  UNREACHABLE();
-}
+        private:
+            BytecodeGenerator* generator_;
+            std::vector<int> coverage_slots_;
+        };
+
+        void BytecodeGenerator::ControlScope::PerformCommand(Command command,
+                                                             Statement* statement,
+                                                             int source_position) {
+            ControlScope* current = this;
+            do {
+                if (current->Execute(command, statement, source_position)) {
+                    return;
+                }
+                current = current->outer();
+            } while (current != nullptr);
+            UNREACHABLE();
+        }
 
-void BytecodeGenerator::ControlScope::PopContextToExpectedDepth() {
-  // Pop context to the expected depth. Note that this can in fact pop multiple
-  // contexts at once because the {PopContext} bytecode takes a saved register.
-  if (generator()->execution_context() != context()) {
-    generator()->builder()->PopContext(context()->reg());
-  }
-}
+        void BytecodeGenerator::ControlScope::PopContextToExpectedDepth() {
+            // Pop context to the expected depth. Note that this can in fact pop multiple
+            // contexts at once because the {PopContext} bytecode takes a saved register.
+            if (generator()->execution_context() != context()) {
+                generator()->builder()->PopContext(context()->reg());
+            }
+        }
 
-class V8_NODISCARD BytecodeGenerator::RegisterAllocationScope final {
- public:
-  explicit RegisterAllocationScope(BytecodeGenerator* generator)
-      : generator_(generator),
+        class V8_NODISCARD BytecodeGenerator::RegisterAllocationScope final {
+        public:
+        explicit RegisterAllocationScope(BytecodeGenerator* generator)
+        : generator_(generator),
         outer_next_register_index_(
-            generator->register_allocator()->next_register_index()) {}
-
-  ~RegisterAllocationScope() {
-    generator_->register_allocator()->ReleaseRegisters(
-        outer_next_register_index_);
-  }
-
-  RegisterAllocationScope(const RegisterAllocationScope&) = delete;
-  RegisterAllocationScope& operator=(const RegisterAllocationScope&) = delete;
+                generator->register_allocator()->next_register_index()) {}
 
-  BytecodeGenerator* generator() const { return generator_; }
-
- private:
-  BytecodeGenerator* generator_;
-  int outer_next_register_index_;
-};
+        ~RegisterAllocationScope() {
+            generator_->register_allocator()->ReleaseRegisters(
+                    outer_next_register_index_);
+        }
 
-class V8_NODISCARD BytecodeGenerator::AccumulatorPreservingScope final {
- public:
-  explicit AccumulatorPreservingScope(BytecodeGenerator* generator,
-                                      AccumulatorPreservingMode mode)
-      : generator_(generator) {
-    if (mode == AccumulatorPreservingMode::kPreserve) {
-      saved_accumulator_register_ =
-          generator_->register_allocator()->NewRegister();
-      generator_->builder()->StoreAccumulatorInRegister(
-          saved_accumulator_register_);
+        RegisterAllocationScope(const RegisterAllocationScope&) = delete;
+        RegisterAllocationScope& operator=(const RegisterAllocationScope&) = delete;
+
+        BytecodeGenerator* generator() const { return generator_; }
+
+        private:
+        BytecodeGenerator* generator_;
+        int outer_next_register_index_;
+    };
+
+    class V8_NODISCARD BytecodeGenerator::AccumulatorPreservingScope final {
+    public:
+    explicit AccumulatorPreservingScope(BytecodeGenerator* generator,
+    AccumulatorPreservingMode mode)
+    : generator_(generator) {
+            if (mode == AccumulatorPreservingMode::kPreserve) {
+                saved_accumulator_register_ =
+                        generator_->register_allocator()->NewRegister();
+                generator_->builder()->StoreAccumulatorInRegister(
+                        saved_accumulator_register_);
+            }
     }
-  }
 
-  ~AccumulatorPreservingScope() {
-    if (saved_accumulator_register_.is_valid()) {
-      generator_->builder()->LoadAccumulatorWithRegister(
-          saved_accumulator_register_);
+    ~AccumulatorPreservingScope() {
+        if (saved_accumulator_register_.is_valid()) {
+            generator_->builder()->LoadAccumulatorWithRegister(
+                    saved_accumulator_register_);
+        }
     }
-  }
 
-  AccumulatorPreservingScope(const AccumulatorPreservingScope&) = delete;
-  AccumulatorPreservingScope& operator=(const AccumulatorPreservingScope&) =
-      delete;
+    AccumulatorPreservingScope(const AccumulatorPreservingScope&) = delete;
+    AccumulatorPreservingScope& operator=(const AccumulatorPreservingScope&) =
+    delete;
 
- private:
-  BytecodeGenerator* generator_;
-  Register saved_accumulator_register_;
+    private:
+    BytecodeGenerator* generator_;
+    Register saved_accumulator_register_;
 };
 
 // Scoped base class for determining how the result of an expression will be
 // used.
 class V8_NODISCARD BytecodeGenerator::ExpressionResultScope {
- public:
-  ExpressionResultScope(BytecodeGenerator* generator, Expression::Context kind)
-      : outer_(generator->execution_result()),
+        public:
+        ExpressionResultScope(BytecodeGenerator* generator, Expression::Context kind)
+        : outer_(generator->execution_result()),
         allocator_(generator),
         kind_(kind),
         type_hint_(TypeHint::kAny) {
-    generator->set_execution_result(this);
-  }
+            generator->set_execution_result(this);
+        }
 
-  ~ExpressionResultScope() {
-    allocator_.generator()->set_execution_result(outer_);
-  }
+        ~ExpressionResultScope() {
+            allocator_.generator()->set_execution_result(outer_);
+        }
 
-  ExpressionResultScope(const ExpressionResultScope&) = delete;
-  ExpressionResultScope& operator=(const ExpressionResultScope&) = delete;
+        ExpressionResultScope(const ExpressionResultScope&) = delete;
+        ExpressionResultScope& operator=(const ExpressionResultScope&) = delete;
 
-  bool IsEffect() const { return kind_ == Expression::kEffect; }
-  bool IsValue() const { return kind_ == Expression::kValue; }
-  bool IsTest() const { return kind_ == Expression::kTest; }
+        bool IsEffect() const { return kind_ == Expression::kEffect; }
+        bool IsValue() const { return kind_ == Expression::kValue; }
+        bool IsTest() const { return kind_ == Expression::kTest; }
 
-  TestResultScope* AsTest() {
-    DCHECK(IsTest());
-    return reinterpret_cast<TestResultScope*>(this);
-  }
+        TestResultScope* AsTest() {
+            DCHECK(IsTest());
+            return reinterpret_cast<TestResultScope*>(this);
+        }
 
-  // Specify expression always returns a Boolean result value.
-  void SetResultIsBoolean() {
-    DCHECK_EQ(type_hint_, TypeHint::kAny);
-    type_hint_ = TypeHint::kBoolean;
-  }
+        // Specify expression always returns a Boolean result value.
+        void SetResultIsBoolean() {
+            DCHECK_EQ(type_hint_, TypeHint::kAny);
+            type_hint_ = TypeHint::kBoolean;
+        }
 
-  void SetResultIsString() {
-    DCHECK_EQ(type_hint_, TypeHint::kAny);
-    type_hint_ = TypeHint::kString;
-  }
+        void SetResultIsString() {
+            DCHECK_EQ(type_hint_, TypeHint::kAny);
+            type_hint_ = TypeHint::kString;
+        }
 
-  TypeHint type_hint() const { return type_hint_; }
+        TypeHint type_hint() const { return type_hint_; }
 
- private:
-  ExpressionResultScope* outer_;
-  RegisterAllocationScope allocator_;
-  Expression::Context kind_;
-  TypeHint type_hint_;
+        private:
+        ExpressionResultScope* outer_;
+        RegisterAllocationScope allocator_;
+        Expression::Context kind_;
+        TypeHint type_hint_;
 };
 
 // Scoped class used when the result of the current expression is not
 // expected to produce a result.
 class BytecodeGenerator::EffectResultScope final
-    : public ExpressionResultScope {
- public:
-  explicit EffectResultScope(BytecodeGenerator* generator)
-      : ExpressionResultScope(generator, Expression::kEffect) {}
+        : public ExpressionResultScope {
+public:
+    explicit EffectResultScope(BytecodeGenerator* generator)
+            : ExpressionResultScope(generator, Expression::kEffect) {}
 };
 
 // Scoped class used when the result of the current expression to be
 // evaluated should go into the interpreter's accumulator.
 class V8_NODISCARD BytecodeGenerator::ValueResultScope final
-    : public ExpressionResultScope {
- public:
-  explicit ValueResultScope(BytecodeGenerator* generator)
-      : ExpressionResultScope(generator, Expression::kValue) {}
+: public ExpressionResultScope {
+public:
+explicit ValueResultScope(BytecodeGenerator* generator)
+: ExpressionResultScope(generator, Expression::kValue) {}
 };
 
 // Scoped class used when the result of the current expression to be
 // evaluated is only tested with jumps to two branches.
 class V8_NODISCARD BytecodeGenerator::TestResultScope final
-    : public ExpressionResultScope {
- public:
-  TestResultScope(BytecodeGenerator* generator, BytecodeLabels* then_labels,
-                  BytecodeLabels* else_labels, TestFallthrough fallthrough)
-      : ExpressionResultScope(generator, Expression::kTest),
-        result_consumed_by_test_(false),
-        fallthrough_(fallthrough),
-        then_labels_(then_labels),
-        else_labels_(else_labels) {}
-
-  TestResultScope(const TestResultScope&) = delete;
-  TestResultScope& operator=(const TestResultScope&) = delete;
-
-  // Used when code special cases for TestResultScope and consumes any
-  // possible value by testing and jumping to a then/else label.
-  void SetResultConsumedByTest() { result_consumed_by_test_ = true; }
-  bool result_consumed_by_test() { return result_consumed_by_test_; }
-
-  // Inverts the control flow of the operation, swapping the then and else
-  // labels and the fallthrough.
-  void InvertControlFlow() {
+: public ExpressionResultScope {
+public:
+TestResultScope(BytecodeGenerator* generator, BytecodeLabels* then_labels,
+        BytecodeLabels* else_labels, TestFallthrough fallthrough)
+: ExpressionResultScope(generator, Expression::kTest),
+result_consumed_by_test_(false),
+fallthrough_(fallthrough),
+then_labels_(then_labels),
+else_labels_(else_labels) {}
+
+TestResultScope(const TestResultScope&) = delete;
+TestResultScope& operator=(const TestResultScope&) = delete;
+
+// Used when code special cases for TestResultScope and consumes any
+// possible value by testing and jumping to a then/else label.
+void SetResultConsumedByTest() { result_consumed_by_test_ = true; }
+bool result_consumed_by_test() { return result_consumed_by_test_; }
+
+// Inverts the control flow of the operation, swapping the then and else
+// labels and the fallthrough.
+void InvertControlFlow() {
     std::swap(then_labels_, else_labels_);
     fallthrough_ = inverted_fallthrough();
-  }
+}
 
-  BytecodeLabel* NewThenLabel() { return then_labels_->New(); }
-  BytecodeLabel* NewElseLabel() { return else_labels_->New(); }
+BytecodeLabel* NewThenLabel() { return then_labels_->New(); }
+BytecodeLabel* NewElseLabel() { return else_labels_->New(); }
 
-  BytecodeLabels* then_labels() const { return then_labels_; }
-  BytecodeLabels* else_labels() const { return else_labels_; }
+BytecodeLabels* then_labels() const { return then_labels_; }
+BytecodeLabels* else_labels() const { return else_labels_; }
 
-  void set_then_labels(BytecodeLabels* then_labels) {
+void set_then_labels(BytecodeLabels* then_labels) {
     then_labels_ = then_labels;
-  }
-  void set_else_labels(BytecodeLabels* else_labels) {
+}
+void set_else_labels(BytecodeLabels* else_labels) {
     else_labels_ = else_labels;
-  }
+}
 
-  TestFallthrough fallthrough() const { return fallthrough_; }
-  TestFallthrough inverted_fallthrough() const {
+TestFallthrough fallthrough() const { return fallthrough_; }
+TestFallthrough inverted_fallthrough() const {
     switch (fallthrough_) {
-      case TestFallthrough::kThen:
-        return TestFallthrough::kElse;
-      case TestFallthrough::kElse:
-        return TestFallthrough::kThen;
-      default:
-        return TestFallthrough::kNone;
+        case TestFallthrough::kThen:
+            return TestFallthrough::kElse;
+        case TestFallthrough::kElse:
+            return TestFallthrough::kThen;
+        default:
+            return TestFallthrough::kNone;
     }
-  }
-  void set_fallthrough(TestFallthrough fallthrough) {
+}
+void set_fallthrough(TestFallthrough fallthrough) {
     fallthrough_ = fallthrough;
-  }
+}
 
- private:
-  bool result_consumed_by_test_;
-  TestFallthrough fallthrough_;
-  BytecodeLabels* then_labels_;
-  BytecodeLabels* else_labels_;
+private:
+bool result_consumed_by_test_;
+TestFallthrough fallthrough_;
+BytecodeLabels* then_labels_;
+BytecodeLabels* else_labels_;
 };
 
 // Used to build a list of toplevel declaration data.
 class BytecodeGenerator::TopLevelDeclarationsBuilder final : public ZoneObject {
- public:
-  template <typename IsolateT>
-  Handle<FixedArray> AllocateDeclarations(UnoptimizedCompilationInfo* info,
-                                          BytecodeGenerator* generator,
-                                          Handle<Script> script,
-                                          IsolateT* isolate) {
-    DCHECK(has_constant_pool_entry_);
-
-    Handle<FixedArray> data =
-        isolate->factory()->NewFixedArray(entry_slots_, AllocationType::kOld);
-
-    int array_index = 0;
-    if (info->scope()->is_module_scope()) {
-      for (Declaration* decl : *info->scope()->declarations()) {
-        Variable* var = decl->var();
-        if (!var->is_used()) continue;
-        if (var->location() != VariableLocation::MODULE) continue;
+public:
+    template <typename IsolateT>
+    Handle<FixedArray> AllocateDeclarations(UnoptimizedCompilationInfo* info,
+                                            BytecodeGenerator* generator,
+                                            Handle<Script> script,
+                                            IsolateT* isolate) {
+        DCHECK(has_constant_pool_entry_);
+
+        Handle<FixedArray> data =
+                isolate->factory()->NewFixedArray(entry_slots_, AllocationType::kOld);
+
+        int array_index = 0;
+        if (info->scope()->is_module_scope()) {
+            for (Declaration* decl : *info->scope()->declarations()) {
+                Variable* var = decl->var();
+                if (!var->is_used()) continue;
+                if (var->location() != VariableLocation::MODULE) continue;
 #ifdef DEBUG
-        int start = array_index;
+                int start = array_index;
 #endif
-        if (decl->IsFunctionDeclaration()) {
-          FunctionLiteral* f = static_cast<FunctionDeclaration*>(decl)->fun();
-          Handle<SharedFunctionInfo> sfi(
-              Compiler::GetSharedFunctionInfo(f, script, isolate));
-          // Return a null handle if any initial values can't be created. Caller
-          // will set stack overflow.
-          if (sfi.is_null()) return Handle<FixedArray>();
-          data->set(array_index++, *sfi);
-          int literal_index = generator->GetCachedCreateClosureSlot(f);
-          data->set(array_index++, Smi::FromInt(literal_index));
-          DCHECK(var->IsExport());
-          data->set(array_index++, Smi::FromInt(var->index()));
-          DCHECK_EQ(start + kModuleFunctionDeclarationSize, array_index);
-        } else if (var->IsExport() && var->binding_needs_init()) {
-          data->set(array_index++, Smi::FromInt(var->index()));
-          DCHECK_EQ(start + kModuleVariableDeclarationSize, array_index);
-        }
-      }
-    } else {
-      for (Declaration* decl : *info->scope()->declarations()) {
-        Variable* var = decl->var();
-        if (!var->is_used()) continue;
-        if (var->location() != VariableLocation::UNALLOCATED) continue;
+                if (decl->IsFunctionDeclaration()) {
+                    FunctionLiteral* f = static_cast<FunctionDeclaration*>(decl)->fun();
+                    Handle<SharedFunctionInfo> sfi(
+                            Compiler::GetSharedFunctionInfo(f, script, isolate));
+                    // Return a null handle if any initial values can't be created. Caller
+                    // will set stack overflow.
+                    if (sfi.is_null()) return Handle<FixedArray>();
+                    data->set(array_index++, *sfi);
+                    int literal_index = generator->GetCachedCreateClosureSlot(f);
+                    data->set(array_index++, Smi::FromInt(literal_index));
+                    DCHECK(var->IsExport());
+                    data->set(array_index++, Smi::FromInt(var->index()));
+                    DCHECK_EQ(start + kModuleFunctionDeclarationSize, array_index);
+                } else if (var->IsExport() && var->binding_needs_init()) {
+                    data->set(array_index++, Smi::FromInt(var->index()));
+                    DCHECK_EQ(start + kModuleVariableDeclarationSize, array_index);
+                }
+            }
+        } else {
+            for (Declaration* decl : *info->scope()->declarations()) {
+                Variable* var = decl->var();
+                if (!var->is_used()) continue;
+                if (var->location() != VariableLocation::UNALLOCATED) continue;
 #ifdef DEBUG
-        int start = array_index;
+                int start = array_index;
 #endif
-        if (decl->IsVariableDeclaration()) {
-          data->set(array_index++, *var->raw_name()->string());
-          DCHECK_EQ(start + kGlobalVariableDeclarationSize, array_index);
-        } else {
-          FunctionLiteral* f = static_cast<FunctionDeclaration*>(decl)->fun();
-          Handle<SharedFunctionInfo> sfi(
-              Compiler::GetSharedFunctionInfo(f, script, isolate));
-          // Return a null handle if any initial values can't be created. Caller
-          // will set stack overflow.
-          if (sfi.is_null()) return Handle<FixedArray>();
-          data->set(array_index++, *sfi);
-          int literal_index = generator->GetCachedCreateClosureSlot(f);
-          data->set(array_index++, Smi::FromInt(literal_index));
-          DCHECK_EQ(start + kGlobalFunctionDeclarationSize, array_index);
-        }
-      }
-    }
-    DCHECK_EQ(array_index, data->length());
-    return data;
-  }
+                if (decl->IsVariableDeclaration()) {
+                    data->set(array_index++, *var->raw_name()->string());
+                    DCHECK_EQ(start + kGlobalVariableDeclarationSize, array_index);
+                } else {
+                    FunctionLiteral* f = static_cast<FunctionDeclaration*>(decl)->fun();
+                    Handle<SharedFunctionInfo> sfi(
+                            Compiler::GetSharedFunctionInfo(f, script, isolate));
+                    // Return a null handle if any initial values can't be created. Caller
+                    // will set stack overflow.
+                    if (sfi.is_null()) return Handle<FixedArray>();
+                    data->set(array_index++, *sfi);
+                    int literal_index = generator->GetCachedCreateClosureSlot(f);
+                    data->set(array_index++, Smi::FromInt(literal_index));
+                    DCHECK_EQ(start + kGlobalFunctionDeclarationSize, array_index);
+                }
+            }
+        }
+        DCHECK_EQ(array_index, data->length());
+        return data;
+    }
 
-  size_t constant_pool_entry() {
-    DCHECK(has_constant_pool_entry_);
-    return constant_pool_entry_;
-  }
+    size_t constant_pool_entry() {
+        DCHECK(has_constant_pool_entry_);
+        return constant_pool_entry_;
+    }
 
-  void set_constant_pool_entry(size_t constant_pool_entry) {
-    DCHECK(has_top_level_declaration());
-    DCHECK(!has_constant_pool_entry_);
-    constant_pool_entry_ = constant_pool_entry;
-    has_constant_pool_entry_ = true;
-  }
+    void set_constant_pool_entry(size_t constant_pool_entry) {
+        DCHECK(has_top_level_declaration());
+        DCHECK(!has_constant_pool_entry_);
+        constant_pool_entry_ = constant_pool_entry;
+        has_constant_pool_entry_ = true;
+    }
 
-  void record_global_variable_declaration() {
-    entry_slots_ += kGlobalVariableDeclarationSize;
-  }
-  void record_global_function_declaration() {
-    entry_slots_ += kGlobalFunctionDeclarationSize;
-  }
-  void record_module_variable_declaration() {
-    entry_slots_ += kModuleVariableDeclarationSize;
-  }
-  void record_module_function_declaration() {
-    entry_slots_ += kModuleFunctionDeclarationSize;
-  }
-  bool has_top_level_declaration() { return entry_slots_ > 0; }
-  bool processed() { return processed_; }
-  void mark_processed() { processed_ = true; }
-
- private:
-  const int kGlobalVariableDeclarationSize = 1;
-  const int kGlobalFunctionDeclarationSize = 2;
-  const int kModuleVariableDeclarationSize = 1;
-  const int kModuleFunctionDeclarationSize = 3;
-
-  size_t constant_pool_entry_ = 0;
-  int entry_slots_ = 0;
-  bool has_constant_pool_entry_ = false;
-  bool processed_ = false;
+    void record_global_variable_declaration() {
+        entry_slots_ += kGlobalVariableDeclarationSize;
+    }
+    void record_global_function_declaration() {
+        entry_slots_ += kGlobalFunctionDeclarationSize;
+    }
+    void record_module_variable_declaration() {
+        entry_slots_ += kModuleVariableDeclarationSize;
+    }
+    void record_module_function_declaration() {
+        entry_slots_ += kModuleFunctionDeclarationSize;
+    }
+    bool has_top_level_declaration() { return entry_slots_ > 0; }
+    bool processed() { return processed_; }
+    void mark_processed() { processed_ = true; }
+
+private:
+    const int kGlobalVariableDeclarationSize = 1;
+    const int kGlobalFunctionDeclarationSize = 2;
+    const int kModuleVariableDeclarationSize = 1;
+    const int kModuleFunctionDeclarationSize = 3;
+
+    size_t constant_pool_entry_ = 0;
+    int entry_slots_ = 0;
+    bool has_constant_pool_entry_ = false;
+    bool processed_ = false;
 };
 
 class V8_NODISCARD BytecodeGenerator::CurrentScope final {
- public:
-  CurrentScope(BytecodeGenerator* generator, Scope* scope)
-      : generator_(generator), outer_scope_(generator->current_scope()) {
+public:
+CurrentScope(BytecodeGenerator* generator, Scope* scope)
+: generator_(generator), outer_scope_(generator->current_scope()) {
     if (scope != nullptr) {
-      DCHECK_EQ(outer_scope_, scope->outer_scope());
-      generator_->set_current_scope(scope);
+        DCHECK_EQ(outer_scope_, scope->outer_scope());
+        // xqg start scope, exit from current_scope()->start_position() to scope.
+        int init_reg_index = generator_->register_allocator()->next_register_index();
+        Register temp_arg = generator_->register_allocator()->NewRegister();
+        Register acc_init = generator_->register_allocator()->NewRegister();
+        generator_->builder()->StoreAccumulatorInRegister(acc_init);
+
+        generator_->builder()->LoadLiteral(Smi::FromInt(generator_->current_scope()->start_position()))
+                .StoreAccumulatorInRegister(temp_arg)
+                .CallRuntime(Runtime::kTaintAnalysis_OnScopeExit, temp_arg);
+
+        generator_->builder()->LoadAccumulatorWithRegister(acc_init);
+        generator_->register_allocator()->ReleaseRegisters(init_reg_index);
+
+        // xqg end scope
+        generator_->set_current_scope(scope);
     }
-  }
-  ~CurrentScope() {
+}
+~CurrentScope() {
     if (outer_scope_ != generator_->current_scope()) {
-      generator_->set_current_scope(outer_scope_);
+        // xqg start scope, exit from current scope to outer_scope_
+        int init_reg_index = generator_->register_allocator()->next_register_index();
+        Register temp_arg = generator_->register_allocator()->NewRegister();
+        Register acc_init = generator_->register_allocator()->NewRegister();
+        generator_->builder()->StoreAccumulatorInRegister(acc_init);
+
+        generator_->builder()->LoadLiteral(Smi::FromInt(generator_->current_scope()->start_position()))
+                .StoreAccumulatorInRegister(temp_arg)
+                .CallRuntime(Runtime::kTaintAnalysis_OnScopeExit, temp_arg);
+
+        generator_->builder()->LoadAccumulatorWithRegister(acc_init);
+        generator_->register_allocator()->ReleaseRegisters(init_reg_index);
+        // xqg end scope
+        generator_->set_current_scope(outer_scope_);
     }
-  }
-  CurrentScope(const CurrentScope&) = delete;
-  CurrentScope& operator=(const CurrentScope&) = delete;
+}
+CurrentScope(const CurrentScope&) = delete;
+CurrentScope& operator=(const CurrentScope&) = delete;
 
- private:
-  BytecodeGenerator* generator_;
-  Scope* outer_scope_;
+private:
+BytecodeGenerator* generator_;
+Scope* outer_scope_;
 };
 
 class V8_NODISCARD BytecodeGenerator::MultipleEntryBlockContextScope {
- public:
-  MultipleEntryBlockContextScope(BytecodeGenerator* generator, Scope* scope)
-      : generator_(generator), scope_(scope), is_in_scope_(false) {
-    if (scope) {
-      inner_context_ = generator->register_allocator()->NewRegister();
-      outer_context_ = generator->register_allocator()->NewRegister();
-      generator->BuildNewLocalBlockContext(scope_);
-      generator->builder()->StoreAccumulatorInRegister(inner_context_);
-    }
-  }
+        public:
+        MultipleEntryBlockContextScope(BytecodeGenerator* generator, Scope* scope)
+        : generator_(generator), scope_(scope), is_in_scope_(false) {
+            if (scope) {
+                inner_context_ = generator->register_allocator()->NewRegister();
+                outer_context_ = generator->register_allocator()->NewRegister();
+                generator->BuildNewLocalBlockContext(scope_);
+                generator->builder()->StoreAccumulatorInRegister(inner_context_);
+            }
+        }
 
-  void SetEnteredIf(bool condition) {
-    RegisterAllocationScope register_scope(generator_);
-    if (condition && scope_ != nullptr && !is_in_scope_) {
-      EnterScope();
-    } else if (!condition && is_in_scope_) {
-      ExitScope();
-    }
-  }
+        void SetEnteredIf(bool condition) {
+            RegisterAllocationScope register_scope(generator_);
+            if (condition && scope_ != nullptr && !is_in_scope_) {
+                EnterScope();
+            } else if (!condition && is_in_scope_) {
+                ExitScope();
+            }
+        }
 
-  MultipleEntryBlockContextScope(const MultipleEntryBlockContextScope&) =
-      delete;
-  MultipleEntryBlockContextScope& operator=(
-      const MultipleEntryBlockContextScope&) = delete;
-
- private:
-  void EnterScope() {
-    DCHECK(inner_context_.is_valid());
-    DCHECK(outer_context_.is_valid());
-    DCHECK(!is_in_scope_);
-    Register temp = generator_->register_allocator()->NewRegister();
-    generator_->builder()->StoreAccumulatorInRegister(temp);
-    generator_->builder()->LoadAccumulatorWithRegister(inner_context_);
-    current_scope_.emplace(generator_, scope_);
-    context_scope_.emplace(generator_, scope_, outer_context_);
-    generator_->builder()->LoadAccumulatorWithRegister(temp);
-    is_in_scope_ = true;
-  }
+        MultipleEntryBlockContextScope(const MultipleEntryBlockContextScope&) =
+        delete;
+        MultipleEntryBlockContextScope& operator=(
+        const MultipleEntryBlockContextScope&) = delete;
+
+        private:
+        void EnterScope() {
+            DCHECK(inner_context_.is_valid());
+            DCHECK(outer_context_.is_valid());
+            DCHECK(!is_in_scope_);
+            Register temp = generator_->register_allocator()->NewRegister();
+            generator_->builder()->StoreAccumulatorInRegister(temp);
+            generator_->builder()->LoadAccumulatorWithRegister(inner_context_);
+            current_scope_.emplace(generator_, scope_);
+            context_scope_.emplace(generator_, scope_, outer_context_);
+            generator_->builder()->LoadAccumulatorWithRegister(temp);
+            is_in_scope_ = true;
+        }
 
-  void ExitScope() {
-    DCHECK(inner_context_.is_valid());
-    DCHECK(outer_context_.is_valid());
-    DCHECK(is_in_scope_);
-    Register temp = generator_->register_allocator()->NewRegister();
-    generator_->builder()->StoreAccumulatorInRegister(temp);
-    context_scope_ = base::nullopt;
-    current_scope_ = base::nullopt;
-    generator_->builder()->LoadAccumulatorWithRegister(temp);
-    is_in_scope_ = false;
-  }
+        void ExitScope() {
+            DCHECK(inner_context_.is_valid());
+            DCHECK(outer_context_.is_valid());
+            DCHECK(is_in_scope_);
+            Register temp = generator_->register_allocator()->NewRegister();
+            generator_->builder()->StoreAccumulatorInRegister(temp);
+            context_scope_ = base::nullopt;
+            current_scope_ = base::nullopt;
+            generator_->builder()->LoadAccumulatorWithRegister(temp);
+            is_in_scope_ = false;
+        }
 
-  BytecodeGenerator* generator_;
-  Scope* scope_;
-  Register inner_context_;
-  Register outer_context_;
-  bool is_in_scope_;
-  base::Optional<CurrentScope> current_scope_;
-  base::Optional<ContextScope> context_scope_;
+        BytecodeGenerator* generator_;
+        Scope* scope_;
+        Register inner_context_;
+        Register outer_context_;
+        bool is_in_scope_;
+        base::Optional<CurrentScope> current_scope_;
+        base::Optional<ContextScope> context_scope_;
 };
 
 class BytecodeGenerator::FeedbackSlotCache : public ZoneObject {
- public:
-  enum class SlotKind {
-    kStoreGlobalSloppy,
-    kStoreGlobalStrict,
-    kSetNamedStrict,
-    kSetNamedSloppy,
-    kLoadProperty,
-    kLoadSuperProperty,
-    kLoadGlobalNotInsideTypeof,
-    kLoadGlobalInsideTypeof,
-    kClosureFeedbackCell
-  };
-
-  explicit FeedbackSlotCache(Zone* zone) : map_(zone) {}
-
-  void Put(SlotKind slot_kind, Variable* variable, int slot_index) {
-    PutImpl(slot_kind, 0, variable, slot_index);
-  }
-  void Put(SlotKind slot_kind, AstNode* node, int slot_index) {
-    PutImpl(slot_kind, 0, node, slot_index);
-  }
-  void Put(SlotKind slot_kind, int variable_index, const AstRawString* name,
-           int slot_index) {
-    PutImpl(slot_kind, variable_index, name, slot_index);
-  }
-  void Put(SlotKind slot_kind, const AstRawString* name, int slot_index) {
-    PutImpl(slot_kind, 0, name, slot_index);
-  }
+public:
+    enum class SlotKind {
+        kStoreGlobalSloppy,
+        kStoreGlobalStrict,
+        kSetNamedStrict,
+        kSetNamedSloppy,
+        kLoadProperty,
+        kLoadSuperProperty,
+        kLoadGlobalNotInsideTypeof,
+        kLoadGlobalInsideTypeof,
+        kClosureFeedbackCell
+    };
 
-  int Get(SlotKind slot_kind, Variable* variable) const {
-    return GetImpl(slot_kind, 0, variable);
-  }
-  int Get(SlotKind slot_kind, AstNode* node) const {
-    return GetImpl(slot_kind, 0, node);
-  }
-  int Get(SlotKind slot_kind, int variable_index,
-          const AstRawString* name) const {
-    return GetImpl(slot_kind, variable_index, name);
-  }
-  int Get(SlotKind slot_kind, const AstRawString* name) const {
-    return GetImpl(slot_kind, 0, name);
-  }
+    explicit FeedbackSlotCache(Zone* zone) : map_(zone) {}
+
+    void Put(SlotKind slot_kind, Variable* variable, int slot_index) {
+        PutImpl(slot_kind, 0, variable, slot_index);
+    }
+    void Put(SlotKind slot_kind, AstNode* node, int slot_index) {
+        PutImpl(slot_kind, 0, node, slot_index);
+    }
+    void Put(SlotKind slot_kind, int variable_index, const AstRawString* name,
+             int slot_index) {
+        PutImpl(slot_kind, variable_index, name, slot_index);
+    }
+    void Put(SlotKind slot_kind, const AstRawString* name, int slot_index) {
+        PutImpl(slot_kind, 0, name, slot_index);
+    }
 
- private:
-  using Key = std::tuple<SlotKind, int, const void*>;
+    int Get(SlotKind slot_kind, Variable* variable) const {
+        return GetImpl(slot_kind, 0, variable);
+    }
+    int Get(SlotKind slot_kind, AstNode* node) const {
+        return GetImpl(slot_kind, 0, node);
+    }
+    int Get(SlotKind slot_kind, int variable_index,
+            const AstRawString* name) const {
+        return GetImpl(slot_kind, variable_index, name);
+    }
+    int Get(SlotKind slot_kind, const AstRawString* name) const {
+        return GetImpl(slot_kind, 0, name);
+    }
 
-  void PutImpl(SlotKind slot_kind, int index, const void* node,
-               int slot_index) {
-    Key key = std::make_tuple(slot_kind, index, node);
-    auto entry = std::make_pair(key, slot_index);
-    map_.insert(entry);
-  }
+private:
+    using Key = std::tuple<SlotKind, int, const void*>;
 
-  int GetImpl(SlotKind slot_kind, int index, const void* node) const {
-    Key key = std::make_tuple(slot_kind, index, node);
-    auto iter = map_.find(key);
-    if (iter != map_.end()) {
-      return iter->second;
+    void PutImpl(SlotKind slot_kind, int index, const void* node,
+                 int slot_index) {
+        Key key = std::make_tuple(slot_kind, index, node);
+        auto entry = std::make_pair(key, slot_index);
+        map_.insert(entry);
     }
-    return -1;
-  }
 
-  ZoneMap<Key, int> map_;
+    int GetImpl(SlotKind slot_kind, int index, const void* node) const {
+        Key key = std::make_tuple(slot_kind, index, node);
+        auto iter = map_.find(key);
+        if (iter != map_.end()) {
+            return iter->second;
+        }
+        return -1;
+    }
+
+    ZoneMap<Key, int> map_;
 };
 
 class BytecodeGenerator::IteratorRecord final {
- public:
-  IteratorRecord(Register object_register, Register next_register,
-                 IteratorType type = IteratorType::kNormal)
-      : type_(type), object_(object_register), next_(next_register) {
-    DCHECK(object_.is_valid() && next_.is_valid());
-  }
+public:
+    IteratorRecord(Register object_register, Register next_register,
+                   IteratorType type = IteratorType::kNormal)
+            : type_(type), object_(object_register), next_(next_register) {
+        DCHECK(object_.is_valid() && next_.is_valid());
+    }
 
-  inline IteratorType type() const { return type_; }
-  inline Register object() const { return object_; }
-  inline Register next() const { return next_; }
+    inline IteratorType type() const { return type_; }
+    inline Register object() const { return object_; }
+    inline Register next() const { return next_; }
 
- private:
-  IteratorType type_;
-  Register object_;
-  Register next_;
+private:
+    IteratorType type_;
+    Register object_;
+    Register next_;
 };
 
 class V8_NODISCARD BytecodeGenerator::OptionalChainNullLabelScope final {
- public:
-  explicit OptionalChainNullLabelScope(BytecodeGenerator* bytecode_generator)
-      : bytecode_generator_(bytecode_generator),
-        labels_(bytecode_generator->zone()) {
+public:
+explicit OptionalChainNullLabelScope(BytecodeGenerator* bytecode_generator)
+: bytecode_generator_(bytecode_generator),
+labels_(bytecode_generator->zone()) {
     prev_ = bytecode_generator_->optional_chaining_null_labels_;
     bytecode_generator_->optional_chaining_null_labels_ = &labels_;
-  }
+}
 
-  ~OptionalChainNullLabelScope() {
+~OptionalChainNullLabelScope() {
     bytecode_generator_->optional_chaining_null_labels_ = prev_;
-  }
+}
 
-  BytecodeLabels* labels() { return &labels_; }
+BytecodeLabels* labels() { return &labels_; }
 
- private:
-  BytecodeGenerator* bytecode_generator_;
-  BytecodeLabels labels_;
-  BytecodeLabels* prev_;
+private:
+BytecodeGenerator* bytecode_generator_;
+BytecodeLabels labels_;
+BytecodeLabels* prev_;
 };
 
 // LoopScope delimits the scope of {loop}, from its header to its final jump.
@@ -1046,74 +1073,74 @@ class V8_NODISCARD BytecodeGenerator::OptionalChainNullLabelScope final {
 // the case of creating a LoopBuilder but never emitting the loop, it is valid
 // to skip the creation of LoopScope.
 class V8_NODISCARD BytecodeGenerator::LoopScope final {
- public:
-  explicit LoopScope(BytecodeGenerator* bytecode_generator, LoopBuilder* loop)
-      : bytecode_generator_(bytecode_generator),
-        parent_loop_scope_(bytecode_generator_->current_loop_scope()),
-        loop_builder_(loop) {
+public:
+explicit LoopScope(BytecodeGenerator* bytecode_generator, LoopBuilder* loop)
+: bytecode_generator_(bytecode_generator),
+parent_loop_scope_(bytecode_generator_->current_loop_scope()),
+loop_builder_(loop) {
     loop_builder_->LoopHeader();
     bytecode_generator_->set_current_loop_scope(this);
     bytecode_generator_->loop_depth_++;
-  }
+}
 
-  ~LoopScope() {
+~LoopScope() {
     bytecode_generator_->loop_depth_--;
     bytecode_generator_->set_current_loop_scope(parent_loop_scope_);
     DCHECK_GE(bytecode_generator_->loop_depth_, 0);
     loop_builder_->JumpToHeader(
-        bytecode_generator_->loop_depth_,
-        parent_loop_scope_ ? parent_loop_scope_->loop_builder_ : nullptr);
-  }
+            bytecode_generator_->loop_depth_,
+            parent_loop_scope_ ? parent_loop_scope_->loop_builder_ : nullptr);
+}
 
- private:
-  BytecodeGenerator* const bytecode_generator_;
-  LoopScope* const parent_loop_scope_;
-  LoopBuilder* const loop_builder_;
+private:
+BytecodeGenerator* const bytecode_generator_;
+LoopScope* const parent_loop_scope_;
+LoopBuilder* const loop_builder_;
 };
 
 namespace {
 
-template <typename PropertyT>
-struct Accessors : public ZoneObject {
-  Accessors() : getter(nullptr), setter(nullptr) {}
-  PropertyT* getter;
-  PropertyT* setter;
-};
+    template <typename PropertyT>
+    struct Accessors : public ZoneObject {
+        Accessors() : getter(nullptr), setter(nullptr) {}
+        PropertyT* getter;
+        PropertyT* setter;
+    };
 
 // A map from property names to getter/setter pairs allocated in the zone that
 // also provides a way of accessing the pairs in the order they were first
 // added so that the generated bytecode is always the same.
-template <typename PropertyT>
-class AccessorTable
-    : public base::TemplateHashMap<Literal, Accessors<PropertyT>,
-                                   bool (*)(void*, void*),
-                                   ZoneAllocationPolicy> {
- public:
-  explicit AccessorTable(Zone* zone)
-      : base::TemplateHashMap<Literal, Accessors<PropertyT>,
-                              bool (*)(void*, void*), ZoneAllocationPolicy>(
-            Literal::Match, ZoneAllocationPolicy(zone)),
-        zone_(zone) {}
-
-  Accessors<PropertyT>* LookupOrInsert(Literal* key) {
-    auto it = this->find(key, true);
-    if (it->second == nullptr) {
-      it->second = zone_->New<Accessors<PropertyT>>();
-      ordered_accessors_.push_back({key, it->second});
-    }
-    return it->second;
-  }
+    template <typename PropertyT>
+    class AccessorTable
+            : public base::TemplateHashMap<Literal, Accessors<PropertyT>,
+                    bool (*)(void*, void*),
+                    ZoneAllocationPolicy> {
+    public:
+        explicit AccessorTable(Zone* zone)
+                : base::TemplateHashMap<Literal, Accessors<PropertyT>,
+                bool (*)(void*, void*), ZoneAllocationPolicy>(
+                Literal::Match, ZoneAllocationPolicy(zone)),
+                  zone_(zone) {}
+
+        Accessors<PropertyT>* LookupOrInsert(Literal* key) {
+            auto it = this->find(key, true);
+            if (it->second == nullptr) {
+                it->second = zone_->New<Accessors<PropertyT>>();
+                ordered_accessors_.push_back({key, it->second});
+            }
+            return it->second;
+        }
 
-  const std::vector<std::pair<Literal*, Accessors<PropertyT>*>>&
-  ordered_accessors() {
-    return ordered_accessors_;
-  }
+        const std::vector<std::pair<Literal*, Accessors<PropertyT>*>>&
+        ordered_accessors() {
+            return ordered_accessors_;
+        }
 
- private:
-  std::vector<std::pair<Literal*, Accessors<PropertyT>*>> ordered_accessors_;
+    private:
+        std::vector<std::pair<Literal*, Accessors<PropertyT>*>> ordered_accessors_;
 
-  Zone* zone_;
-};
+        Zone* zone_;
+    };
 
 }  // namespace
 
@@ -1131,135 +1158,135 @@ static bool IsInEagerLiterals(
 #endif  // DEBUG
 
 BytecodeGenerator::BytecodeGenerator(
-    LocalIsolate* local_isolate, Zone* compile_zone,
-    UnoptimizedCompilationInfo* info,
-    const AstStringConstants* ast_string_constants,
-    std::vector<FunctionLiteral*>* eager_inner_literals, Handle<Script> script)
-    : local_isolate_(local_isolate),
-      zone_(compile_zone),
-      builder_(zone(), info->num_parameters_including_this(),
-               info->scope()->num_stack_slots(), info->feedback_vector_spec(),
-               info->SourcePositionRecordingMode()),
-      info_(info),
-      ast_string_constants_(ast_string_constants),
-      closure_scope_(info->scope()),
-      current_scope_(info->scope()),
-      eager_inner_literals_(eager_inner_literals),
-      script_(script),
-      feedback_slot_cache_(zone()->New<FeedbackSlotCache>(zone())),
-      top_level_builder_(zone()->New<TopLevelDeclarationsBuilder>()),
-      block_coverage_builder_(nullptr),
-      function_literals_(0, zone()),
-      native_function_literals_(0, zone()),
-      object_literals_(0, zone()),
-      array_literals_(0, zone()),
-      class_literals_(0, zone()),
-      template_objects_(0, zone()),
-      execution_control_(nullptr),
-      execution_context_(nullptr),
-      execution_result_(nullptr),
-      incoming_new_target_or_generator_(),
-      optional_chaining_null_labels_(nullptr),
-      dummy_feedback_slot_(feedback_spec(), FeedbackSlotKind::kCompareOp),
-      generator_jump_table_(nullptr),
-      suspend_count_(0),
-      loop_depth_(0),
-      current_loop_scope_(nullptr),
-      catch_prediction_(HandlerTable::UNCAUGHT) {
-  DCHECK_EQ(closure_scope(), closure_scope()->GetClosureScope());
-  if (info->has_source_range_map()) {
-    block_coverage_builder_ = zone()->New<BlockCoverageBuilder>(
-        zone(), builder(), info->source_range_map());
-  }
+        LocalIsolate* local_isolate, Zone* compile_zone,
+        UnoptimizedCompilationInfo* info,
+        const AstStringConstants* ast_string_constants,
+        std::vector<FunctionLiteral*>* eager_inner_literals, Handle<Script> script)
+        : local_isolate_(local_isolate),
+          zone_(compile_zone),
+          builder_(zone(), info->num_parameters_including_this(),
+                   info->scope()->num_stack_slots(), info->feedback_vector_spec(),
+                   info->SourcePositionRecordingMode()),
+          info_(info),
+          ast_string_constants_(ast_string_constants),
+          closure_scope_(info->scope()),
+          current_scope_(info->scope()),
+          eager_inner_literals_(eager_inner_literals),
+          script_(script),
+          feedback_slot_cache_(zone()->New<FeedbackSlotCache>(zone())),
+          top_level_builder_(zone()->New<TopLevelDeclarationsBuilder>()),
+          block_coverage_builder_(nullptr),
+          function_literals_(0, zone()),
+          native_function_literals_(0, zone()),
+          object_literals_(0, zone()),
+          array_literals_(0, zone()),
+          class_literals_(0, zone()),
+          template_objects_(0, zone()),
+          execution_control_(nullptr),
+          execution_context_(nullptr),
+          execution_result_(nullptr),
+          incoming_new_target_or_generator_(),
+          optional_chaining_null_labels_(nullptr),
+          dummy_feedback_slot_(feedback_spec(), FeedbackSlotKind::kCompareOp),
+          generator_jump_table_(nullptr),
+          suspend_count_(0),
+          loop_depth_(0),
+          current_loop_scope_(nullptr),
+          catch_prediction_(HandlerTable::UNCAUGHT) {
+    DCHECK_EQ(closure_scope(), closure_scope()->GetClosureScope());
+    if (info->has_source_range_map()) {
+        block_coverage_builder_ = zone()->New<BlockCoverageBuilder>(
+                zone(), builder(), info->source_range_map());
+    }
 }
 
 namespace {
 
-template <typename Isolate>
-struct NullContextScopeHelper;
+    template <typename Isolate>
+    struct NullContextScopeHelper;
 
-template <>
-struct NullContextScopeHelper<Isolate> {
-  using Type = NullContextScope;
-};
+    template <>
+    struct NullContextScopeHelper<Isolate> {
+        using Type = NullContextScope;
+    };
 
-template <>
-struct NullContextScopeHelper<LocalIsolate> {
-  class V8_NODISCARD DummyNullContextScope {
-   public:
-    explicit DummyNullContextScope(LocalIsolate*) {}
-  };
-  using Type = DummyNullContextScope;
-};
+    template <>
+    struct NullContextScopeHelper<LocalIsolate> {
+        class V8_NODISCARD DummyNullContextScope {
+                public:
+                explicit DummyNullContextScope(LocalIsolate*) {}
+        };
+        using Type = DummyNullContextScope;
+    };
 
-template <typename Isolate>
-using NullContextScopeFor = typename NullContextScopeHelper<Isolate>::Type;
+    template <typename Isolate>
+    using NullContextScopeFor = typename NullContextScopeHelper<Isolate>::Type;
 
 }  // namespace
 
 template <typename IsolateT>
 Handle<BytecodeArray> BytecodeGenerator::FinalizeBytecode(
-    IsolateT* isolate, Handle<Script> script) {
-  DCHECK_EQ(ThreadId::Current(), isolate->thread_id());
+        IsolateT* isolate, Handle<Script> script) {
+    DCHECK_EQ(ThreadId::Current(), isolate->thread_id());
 #ifdef DEBUG
-  // Unoptimized compilation should be context-independent. Verify that we don't
+    // Unoptimized compilation should be context-independent. Verify that we don't
   // access the native context by nulling it out during finalization.
   NullContextScopeFor<IsolateT> null_context_scope(isolate);
 #endif
 
-  AllocateDeferredConstants(isolate, script);
+    AllocateDeferredConstants(isolate, script);
 
-  if (block_coverage_builder_) {
-    Handle<CoverageInfo> coverage_info =
-        isolate->factory()->NewCoverageInfo(block_coverage_builder_->slots());
-    info()->set_coverage_info(coverage_info);
-    if (v8_flags.trace_block_coverage) {
-      StdoutStream os;
-      coverage_info->CoverageInfoPrint(os, info()->literal()->GetDebugName());
+    if (block_coverage_builder_) {
+        Handle<CoverageInfo> coverage_info =
+                isolate->factory()->NewCoverageInfo(block_coverage_builder_->slots());
+        info()->set_coverage_info(coverage_info);
+        if (v8_flags.trace_block_coverage) {
+            StdoutStream os;
+            coverage_info->CoverageInfoPrint(os, info()->literal()->GetDebugName());
+        }
     }
-  }
 
-  if (HasStackOverflow()) return Handle<BytecodeArray>();
-  Handle<BytecodeArray> bytecode_array = builder()->ToBytecodeArray(isolate);
+    if (HasStackOverflow()) return Handle<BytecodeArray>();
+    Handle<BytecodeArray> bytecode_array = builder()->ToBytecodeArray(isolate);
 
-  if (incoming_new_target_or_generator_.is_valid()) {
-    bytecode_array->set_incoming_new_target_or_generator_register(
-        incoming_new_target_or_generator_);
-  }
+    if (incoming_new_target_or_generator_.is_valid()) {
+        bytecode_array->set_incoming_new_target_or_generator_register(
+                incoming_new_target_or_generator_);
+    }
 
-  return bytecode_array;
+    return bytecode_array;
 }
 
 template Handle<BytecodeArray> BytecodeGenerator::FinalizeBytecode(
-    Isolate* isolate, Handle<Script> script);
+        Isolate* isolate, Handle<Script> script);
 template Handle<BytecodeArray> BytecodeGenerator::FinalizeBytecode(
-    LocalIsolate* isolate, Handle<Script> script);
+        LocalIsolate* isolate, Handle<Script> script);
 
 template <typename IsolateT>
 Handle<ByteArray> BytecodeGenerator::FinalizeSourcePositionTable(
-    IsolateT* isolate) {
-  DCHECK_EQ(ThreadId::Current(), isolate->thread_id());
+        IsolateT* isolate) {
+    DCHECK_EQ(ThreadId::Current(), isolate->thread_id());
 #ifdef DEBUG
-  // Unoptimized compilation should be context-independent. Verify that we don't
+    // Unoptimized compilation should be context-independent. Verify that we don't
   // access the native context by nulling it out during finalization.
   NullContextScopeFor<IsolateT> null_context_scope(isolate);
 #endif
 
-  Handle<ByteArray> source_position_table =
-      builder()->ToSourcePositionTable(isolate);
+    Handle<ByteArray> source_position_table =
+            builder()->ToSourcePositionTable(isolate);
 
-  LOG_CODE_EVENT(isolate,
-                 CodeLinePosInfoRecordEvent(
-                     info_->bytecode_array()->GetFirstBytecodeAddress(),
-                     *source_position_table, JitCodeEvent::BYTE_CODE));
+    LOG_CODE_EVENT(isolate,
+                   CodeLinePosInfoRecordEvent(
+                           info_->bytecode_array()->GetFirstBytecodeAddress(),
+                           *source_position_table, JitCodeEvent::BYTE_CODE));
 
-  return source_position_table;
+    return source_position_table;
 }
 
 template Handle<ByteArray> BytecodeGenerator::FinalizeSourcePositionTable(
-    Isolate* isolate);
+        Isolate* isolate);
 template Handle<ByteArray> BytecodeGenerator::FinalizeSourcePositionTable(
-    LocalIsolate* isolate);
+        LocalIsolate* isolate);
 
 #ifdef DEBUG
 int BytecodeGenerator::CheckBytecodeMatches(BytecodeArray bytecode) {
@@ -1270,641 +1297,674 @@ int BytecodeGenerator::CheckBytecodeMatches(BytecodeArray bytecode) {
 template <typename IsolateT>
 void BytecodeGenerator::AllocateDeferredConstants(IsolateT* isolate,
                                                   Handle<Script> script) {
-  if (top_level_builder()->has_top_level_declaration()) {
-    // Build global declaration pair array.
-    Handle<FixedArray> declarations = top_level_builder()->AllocateDeclarations(
-        info(), this, script, isolate);
-    if (declarations.is_null()) return SetStackOverflow();
-    builder()->SetDeferredConstantPoolEntry(
-        top_level_builder()->constant_pool_entry(), declarations);
-  }
-
-  // Find or build shared function infos.
-  for (std::pair<FunctionLiteral*, size_t> literal : function_literals_) {
-    FunctionLiteral* expr = literal.first;
-    Handle<SharedFunctionInfo> shared_info =
-        Compiler::GetSharedFunctionInfo(expr, script, isolate);
-    if (shared_info.is_null()) return SetStackOverflow();
-    builder()->SetDeferredConstantPoolEntry(literal.second, shared_info);
-  }
-
-  // Find or build shared function infos for the native function templates.
-  for (std::pair<NativeFunctionLiteral*, size_t> literal :
-       native_function_literals_) {
-    // This should only happen for main-thread compilations.
-    DCHECK((std::is_same<Isolate, v8::internal::Isolate>::value));
-
-    NativeFunctionLiteral* expr = literal.first;
-    v8::Isolate* v8_isolate = reinterpret_cast<v8::Isolate*>(isolate);
-
-    // Compute the function template for the native function.
-    v8::Local<v8::FunctionTemplate> info =
-        expr->extension()->GetNativeFunctionTemplate(
-            v8_isolate, Utils::ToLocal(expr->name()));
-    DCHECK(!info.IsEmpty());
-
-    Handle<SharedFunctionInfo> shared_info =
-        FunctionTemplateInfo::GetOrCreateSharedFunctionInfo(
-            isolate, Utils::OpenHandle(*info), expr->name());
-    DCHECK(!shared_info.is_null());
-    builder()->SetDeferredConstantPoolEntry(literal.second, shared_info);
-  }
-
-  // Build object literal constant properties
-  for (std::pair<ObjectLiteralBoilerplateBuilder*, size_t> literal :
-       object_literals_) {
-    ObjectLiteralBoilerplateBuilder* object_literal_builder = literal.first;
-    if (object_literal_builder->properties_count() > 0) {
-      // If constant properties is an empty fixed array, we've already added it
-      // to the constant pool when visiting the object literal.
-      Handle<ObjectBoilerplateDescription> constant_properties =
-          object_literal_builder->GetOrBuildBoilerplateDescription(isolate);
-
-      builder()->SetDeferredConstantPoolEntry(literal.second,
-                                              constant_properties);
+    if (top_level_builder()->has_top_level_declaration()) {
+        // Build global declaration pair array.
+        Handle<FixedArray> declarations = top_level_builder()->AllocateDeclarations(
+                info(), this, script, isolate);
+        if (declarations.is_null()) return SetStackOverflow();
+        builder()->SetDeferredConstantPoolEntry(
+                top_level_builder()->constant_pool_entry(), declarations);
+    }
+
+    // Find or build shared function infos.
+    for (std::pair<FunctionLiteral*, size_t> literal : function_literals_) {
+        FunctionLiteral* expr = literal.first;
+        Handle<SharedFunctionInfo> shared_info =
+                Compiler::GetSharedFunctionInfo(expr, script, isolate);
+        if (shared_info.is_null()) return SetStackOverflow();
+        builder()->SetDeferredConstantPoolEntry(literal.second, shared_info);
+    }
+
+    // Find or build shared function infos for the native function templates.
+    for (std::pair<NativeFunctionLiteral*, size_t> literal :
+            native_function_literals_) {
+        // This should only happen for main-thread compilations.
+        DCHECK((std::is_same<Isolate, v8::internal::Isolate>::value));
+
+        NativeFunctionLiteral* expr = literal.first;
+        v8::Isolate* v8_isolate = reinterpret_cast<v8::Isolate*>(isolate);
+
+        // Compute the function template for the native function.
+        v8::Local<v8::FunctionTemplate> info =
+                expr->extension()->GetNativeFunctionTemplate(
+                        v8_isolate, Utils::ToLocal(expr->name()));
+        DCHECK(!info.IsEmpty());
+
+        Handle<SharedFunctionInfo> shared_info =
+                FunctionTemplateInfo::GetOrCreateSharedFunctionInfo(
+                        isolate, Utils::OpenHandle(*info), expr->name());
+        DCHECK(!shared_info.is_null());
+        builder()->SetDeferredConstantPoolEntry(literal.second, shared_info);
+    }
+
+    // Build object literal constant properties
+    for (std::pair<ObjectLiteralBoilerplateBuilder*, size_t> literal :
+            object_literals_) {
+        ObjectLiteralBoilerplateBuilder* object_literal_builder = literal.first;
+        if (object_literal_builder->properties_count() > 0) {
+            // If constant properties is an empty fixed array, we've already added it
+            // to the constant pool when visiting the object literal.
+            Handle<ObjectBoilerplateDescription> constant_properties =
+                    object_literal_builder->GetOrBuildBoilerplateDescription(isolate);
+
+            builder()->SetDeferredConstantPoolEntry(literal.second,
+                                                    constant_properties);
+        }
     }
-  }
 
-  // Build array literal constant elements
-  for (std::pair<ArrayLiteralBoilerplateBuilder*, size_t> literal :
-       array_literals_) {
-    ArrayLiteralBoilerplateBuilder* array_literal_builder = literal.first;
-    Handle<ArrayBoilerplateDescription> constant_elements =
-        array_literal_builder->GetOrBuildBoilerplateDescription(isolate);
-    builder()->SetDeferredConstantPoolEntry(literal.second, constant_elements);
-  }
+    // Build array literal constant elements
+    for (std::pair<ArrayLiteralBoilerplateBuilder*, size_t> literal :
+            array_literals_) {
+        ArrayLiteralBoilerplateBuilder* array_literal_builder = literal.first;
+        Handle<ArrayBoilerplateDescription> constant_elements =
+                array_literal_builder->GetOrBuildBoilerplateDescription(isolate);
+        builder()->SetDeferredConstantPoolEntry(literal.second, constant_elements);
+    }
 
-  // Build class literal boilerplates.
-  for (std::pair<ClassLiteral*, size_t> literal : class_literals_) {
-    ClassLiteral* class_literal = literal.first;
-    Handle<ClassBoilerplate> class_boilerplate =
-        ClassBoilerplate::BuildClassBoilerplate(isolate, class_literal);
-    builder()->SetDeferredConstantPoolEntry(literal.second, class_boilerplate);
-  }
+    // Build class literal boilerplates.
+    for (std::pair<ClassLiteral*, size_t> literal : class_literals_) {
+        ClassLiteral* class_literal = literal.first;
+        Handle<ClassBoilerplate> class_boilerplate =
+                ClassBoilerplate::BuildClassBoilerplate(isolate, class_literal);
+        builder()->SetDeferredConstantPoolEntry(literal.second, class_boilerplate);
+    }
 
-  // Build template literals.
-  for (std::pair<GetTemplateObject*, size_t> literal : template_objects_) {
-    GetTemplateObject* get_template_object = literal.first;
-    Handle<TemplateObjectDescription> description =
-        get_template_object->GetOrBuildDescription(isolate);
-    builder()->SetDeferredConstantPoolEntry(literal.second, description);
-  }
+    // Build template literals.
+    for (std::pair<GetTemplateObject*, size_t> literal : template_objects_) {
+        GetTemplateObject* get_template_object = literal.first;
+        Handle<TemplateObjectDescription> description =
+                get_template_object->GetOrBuildDescription(isolate);
+        builder()->SetDeferredConstantPoolEntry(literal.second, description);
+    }
 }
 
 template void BytecodeGenerator::AllocateDeferredConstants(
-    Isolate* isolate, Handle<Script> script);
+        Isolate* isolate, Handle<Script> script);
 template void BytecodeGenerator::AllocateDeferredConstants(
-    LocalIsolate* isolate, Handle<Script> script);
+        LocalIsolate* isolate, Handle<Script> script);
 
 namespace {
-bool NeedsContextInitialization(DeclarationScope* scope) {
-  return scope->NeedsContext() && !scope->is_script_scope() &&
-         !scope->is_module_scope();
-}
+    bool NeedsContextInitialization(DeclarationScope* scope) {
+        return scope->NeedsContext() && !scope->is_script_scope() &&
+               !scope->is_module_scope();
+    }
 }  // namespace
 
 void BytecodeGenerator::GenerateBytecode(uintptr_t stack_limit) {
-  InitializeAstVisitor(stack_limit);
+    InitializeAstVisitor(stack_limit);
 
-  // Initialize the incoming context.
-  ContextScope incoming_context(this, closure_scope());
+    // Initialize the incoming context.
+    ContextScope incoming_context(this, closure_scope());
 
-  // Initialize control scope.
-  ControlScopeForTopLevel control(this);
+    // Initialize control scope.
+    ControlScopeForTopLevel control(this);
 
-  RegisterAllocationScope register_scope(this);
+    RegisterAllocationScope register_scope(this);
 
-  AllocateTopLevelRegisters();
+    AllocateTopLevelRegisters();
 
-  builder()->EmitFunctionStartSourcePosition(
-      info()->literal()->start_position());
+    builder()->EmitFunctionStartSourcePosition(
+            info()->literal()->start_position());
 
-  if (info()->literal()->CanSuspend()) {
-    BuildGeneratorPrologue();
-  }
+    if (info()->literal()->CanSuspend()) {
+        BuildGeneratorPrologue();
+    }
 
-  if (NeedsContextInitialization(closure_scope())) {
-    // Push a new inner context scope for the function.
-    BuildNewLocalActivationContext();
-    ContextScope local_function_context(this, closure_scope());
-    BuildLocalActivationContextInitialization();
-    GenerateBytecodeBody();
-  } else {
-    GenerateBytecodeBody();
-  }
+    if (NeedsContextInitialization(closure_scope())) {
+        // Push a new inner context scope for the function.
+        BuildNewLocalActivationContext();
+        ContextScope local_function_context(this, closure_scope());
+        BuildLocalActivationContextInitialization();
+        GenerateBytecodeBody();
+    } else {
+        GenerateBytecodeBody();
+    }
 
-  // Check that we are not falling off the end.
-  DCHECK(builder()->RemainderOfBlockIsDead());
+    // Check that we are not falling off the end.
+    DCHECK(builder()->RemainderOfBlockIsDead());
 }
 
 void BytecodeGenerator::GenerateBytecodeBody() {
-  // Build the arguments object if it is used.
-  VisitArgumentsObject(closure_scope()->arguments());
-
-  // Build rest arguments array if it is used.
-  Variable* rest_parameter = closure_scope()->rest_parameter();
-  VisitRestArgumentsArray(rest_parameter);
-
-  // Build assignment to the function name or {.this_function}
-  // variables if used.
-  VisitThisFunctionVariable(closure_scope()->function_var());
-  VisitThisFunctionVariable(closure_scope()->this_function_var());
-
-  // Build assignment to {new.target} variable if it is used.
-  VisitNewTargetVariable(closure_scope()->new_target_var());
-
-  // Create a generator object if necessary and initialize the
-  // {.generator_object} variable.
-  FunctionLiteral* literal = info()->literal();
-  if (IsResumableFunction(literal->kind())) {
-    BuildGeneratorObjectVariableInitialization();
-  }
+    // Build the arguments object if it is used.
+    VisitArgumentsObject(closure_scope()->arguments());
 
-  // Emit tracing call if requested to do so.
-  if (v8_flags.trace) builder()->CallRuntime(Runtime::kTraceEnter);
+    // Build rest arguments array if it is used.
+    Variable* rest_parameter = closure_scope()->rest_parameter();
+    VisitRestArgumentsArray(rest_parameter);
 
-  // Increment the function-scope block coverage counter.
-  BuildIncrementBlockCoverageCounterIfEnabled(literal, SourceRangeKind::kBody);
+    // Build assignment to the function name or {.this_function}
+    // variables if used.
+    VisitThisFunctionVariable(closure_scope()->function_var());
+    VisitThisFunctionVariable(closure_scope()->this_function_var());
 
-  // Visit declarations within the function scope.
-  if (closure_scope()->is_script_scope()) {
-    VisitGlobalDeclarations(closure_scope()->declarations());
-  } else if (closure_scope()->is_module_scope()) {
-    VisitModuleDeclarations(closure_scope()->declarations());
-  } else {
-    VisitDeclarations(closure_scope()->declarations());
-  }
+    // Build assignment to {new.target} variable if it is used.
+    VisitNewTargetVariable(closure_scope()->new_target_var());
+
+    // Create a generator object if necessary and initialize the
+    // {.generator_object} variable.
+    FunctionLiteral* literal = info()->literal();
+    if (IsResumableFunction(literal->kind())) {
+        BuildGeneratorObjectVariableInitialization();
+    }
+
+    // Emit tracing call if requested to do so.
+    if (v8_flags.trace) builder()->CallRuntime(Runtime::kTraceEnter);
 
-  // Emit initializing assignments for module namespace imports (if any).
-  VisitModuleNamespaceImports();
+    // Increment the function-scope block coverage counter.
+    BuildIncrementBlockCoverageCounterIfEnabled(literal, SourceRangeKind::kBody);
 
-  // The derived constructor case is handled in VisitCallSuper.
-  if (IsBaseConstructor(function_kind())) {
-    if (literal->class_scope_has_private_brand()) {
-      ClassScope* scope = info()->scope()->outer_scope()->AsClassScope();
-      DCHECK_NOT_NULL(scope->brand());
-      BuildPrivateBrandInitialization(builder()->Receiver(), scope->brand());
+    // Visit declarations within the function scope.
+    if (closure_scope()->is_script_scope()) {
+        VisitGlobalDeclarations(closure_scope()->declarations());
+    } else if (closure_scope()->is_module_scope()) {
+        VisitModuleDeclarations(closure_scope()->declarations());
+    } else {
+        VisitDeclarations(closure_scope()->declarations());
     }
 
-    if (literal->requires_instance_members_initializer()) {
-      BuildInstanceMemberInitialization(Register::function_closure(),
-                                        builder()->Receiver());
+    // Emit initializing assignments for module namespace imports (if any).
+    VisitModuleNamespaceImports();
+
+    // The derived constructor case is handled in VisitCallSuper.
+    if (IsBaseConstructor(function_kind())) {
+        if (literal->class_scope_has_private_brand()) {
+            ClassScope* scope = info()->scope()->outer_scope()->AsClassScope();
+            DCHECK_NOT_NULL(scope->brand());
+            BuildPrivateBrandInitialization(builder()->Receiver(), scope->brand());
+        }
+
+        if (literal->requires_instance_members_initializer()) {
+            BuildInstanceMemberInitialization(Register::function_closure(),
+                                              builder()->Receiver());
+        }
     }
-  }
+    // xqg start
+    builder()->CallRuntime(Runtime::kTaintAnalysis_OnFunctionEnter);
+    // xqg end
 
-  // Visit statements in the function body.
-  VisitStatements(literal->body());
+    // Visit statements in the function body.
+    VisitStatements(literal->body());
 
-  // Emit an implicit return instruction in case control flow can fall off the
-  // end of the function without an explicit return being present on all paths.
-  if (!builder()->RemainderOfBlockIsDead()) {
-    builder()->LoadUndefined();
-    BuildReturn(literal->return_position());
-  }
+    // Emit an implicit return instruction in case control flow can fall off the
+    // end of the function without an explicit return being present on all paths.
+    if (!builder()->RemainderOfBlockIsDead()) {
+        builder()->LoadUndefined();
+        BuildReturn(literal->return_position());
+    }
 }
 
 void BytecodeGenerator::AllocateTopLevelRegisters() {
-  if (IsResumableFunction(info()->literal()->kind())) {
-    // Either directly use generator_object_var or allocate a new register for
-    // the incoming generator object.
-    Variable* generator_object_var = closure_scope()->generator_object_var();
-    if (generator_object_var->location() == VariableLocation::LOCAL) {
-      incoming_new_target_or_generator_ =
-          GetRegisterForLocalVariable(generator_object_var);
-    } else {
-      incoming_new_target_or_generator_ = register_allocator()->NewRegister();
-    }
-  } else if (closure_scope()->new_target_var()) {
-    // Either directly use new_target_var or allocate a new register for
-    // the incoming new target object.
-    Variable* new_target_var = closure_scope()->new_target_var();
-    if (new_target_var->location() == VariableLocation::LOCAL) {
-      incoming_new_target_or_generator_ =
-          GetRegisterForLocalVariable(new_target_var);
-    } else {
-      incoming_new_target_or_generator_ = register_allocator()->NewRegister();
+    if (IsResumableFunction(info()->literal()->kind())) {
+        // Either directly use generator_object_var or allocate a new register for
+        // the incoming generator object.
+        Variable* generator_object_var = closure_scope()->generator_object_var();
+        if (generator_object_var->location() == VariableLocation::LOCAL) {
+            incoming_new_target_or_generator_ =
+                    GetRegisterForLocalVariable(generator_object_var);
+        } else {
+            incoming_new_target_or_generator_ = register_allocator()->NewRegister();
+        }
+    } else if (closure_scope()->new_target_var()) {
+        // Either directly use new_target_var or allocate a new register for
+        // the incoming new target object.
+        Variable* new_target_var = closure_scope()->new_target_var();
+        if (new_target_var->location() == VariableLocation::LOCAL) {
+            incoming_new_target_or_generator_ =
+                    GetRegisterForLocalVariable(new_target_var);
+        } else {
+            incoming_new_target_or_generator_ = register_allocator()->NewRegister();
+        }
     }
-  }
 }
 
 void BytecodeGenerator::BuildGeneratorPrologue() {
-  DCHECK_GT(info()->literal()->suspend_count(), 0);
-  DCHECK(generator_object().is_valid());
-  generator_jump_table_ =
-      builder()->AllocateJumpTable(info()->literal()->suspend_count(), 0);
+    DCHECK_GT(info()->literal()->suspend_count(), 0);
+    DCHECK(generator_object().is_valid());
+    generator_jump_table_ =
+            builder()->AllocateJumpTable(info()->literal()->suspend_count(), 0);
 
-  // If the generator is not undefined, this is a resume, so perform state
-  // dispatch.
-  builder()->SwitchOnGeneratorState(generator_object(), generator_jump_table_);
+    // If the generator is not undefined, this is a resume, so perform state
+    // dispatch.
+    builder()->SwitchOnGeneratorState(generator_object(), generator_jump_table_);
 
-  // Otherwise, fall-through to the ordinary function prologue, after which we
-  // will run into the generator object creation and other extra code inserted
-  // by the parser.
+    // Otherwise, fall-through to the ordinary function prologue, after which we
+    // will run into the generator object creation and other extra code inserted
+    // by the parser.
 }
 
 void BytecodeGenerator::VisitBlock(Block* stmt) {
-  // Visit declarations and statements.
-  CurrentScope current_scope(this, stmt->scope());
-  if (stmt->scope() != nullptr && stmt->scope()->NeedsContext()) {
-    BuildNewLocalBlockContext(stmt->scope());
-    ContextScope scope(this, stmt->scope());
-    VisitBlockDeclarationsAndStatements(stmt);
-  } else {
-    VisitBlockDeclarationsAndStatements(stmt);
-  }
+    // Visit declarations and statements.
+    CurrentScope current_scope(this, stmt->scope());
+    if (stmt->scope() != nullptr && stmt->scope()->NeedsContext()) {
+        BuildNewLocalBlockContext(stmt->scope());
+        ContextScope scope(this, stmt->scope());
+        VisitBlockDeclarationsAndStatements(stmt);
+    } else {
+        VisitBlockDeclarationsAndStatements(stmt);
+    }
 }
 
 void BytecodeGenerator::VisitBlockDeclarationsAndStatements(Block* stmt) {
-  BlockBuilder block_builder(builder(), block_coverage_builder_, stmt);
-  ControlScopeForBreakable execution_control(this, stmt, &block_builder);
-  if (stmt->scope() != nullptr) {
-    VisitDeclarations(stmt->scope()->declarations());
-  }
-  VisitStatements(stmt->statements());
+    BlockBuilder block_builder(builder(), block_coverage_builder_, stmt);
+    ControlScopeForBreakable execution_control(this, stmt, &block_builder);
+    if (stmt->scope() != nullptr) {
+        VisitDeclarations(stmt->scope()->declarations());
+    }
+    VisitStatements(stmt->statements());
 }
 
 void BytecodeGenerator::VisitVariableDeclaration(VariableDeclaration* decl) {
-  Variable* variable = decl->var();
-  // Unused variables don't need to be visited.
-  if (!variable->is_used()) return;
-
-  switch (variable->location()) {
-    case VariableLocation::UNALLOCATED:
-    case VariableLocation::MODULE:
-      UNREACHABLE();
-    case VariableLocation::LOCAL:
-      if (variable->binding_needs_init()) {
-        Register destination(builder()->Local(variable->index()));
-        builder()->LoadTheHole().StoreAccumulatorInRegister(destination);
-      }
-      break;
-    case VariableLocation::PARAMETER:
-      if (variable->binding_needs_init()) {
-        Register destination(builder()->Parameter(variable->index()));
-        builder()->LoadTheHole().StoreAccumulatorInRegister(destination);
-      }
-      break;
-    case VariableLocation::REPL_GLOBAL:
-      // REPL let's are stored in script contexts. They get initialized
-      // with the hole the same way as normal context allocated variables.
-    case VariableLocation::CONTEXT:
-      if (variable->binding_needs_init()) {
-        DCHECK_EQ(0, execution_context()->ContextChainDepth(variable->scope()));
-        builder()->LoadTheHole().StoreContextSlot(execution_context()->reg(),
-                                                  variable->index(), 0);
-      }
-      break;
-    case VariableLocation::LOOKUP: {
-      DCHECK_EQ(VariableMode::kDynamic, variable->mode());
-      DCHECK(!variable->binding_needs_init());
-
-      Register name = register_allocator()->NewRegister();
-
-      builder()
-          ->LoadLiteral(variable->raw_name())
-          .StoreAccumulatorInRegister(name)
-          .CallRuntime(Runtime::kDeclareEvalVar, name);
-      break;
+    Variable* variable = decl->var();
+    // Unused variables don't need to be visited.
+    if (!variable->is_used()) return;
+
+    switch (variable->location()) {
+        case VariableLocation::UNALLOCATED:
+        case VariableLocation::MODULE:
+            UNREACHABLE();
+        case VariableLocation::LOCAL:
+            if (variable->binding_needs_init()) {
+                Register destination(builder()->Local(variable->index()));
+                builder()->LoadTheHole().StoreAccumulatorInRegister(destination);
+            }
+            break;
+        case VariableLocation::PARAMETER:
+            if (variable->binding_needs_init()) {
+                Register destination(builder()->Parameter(variable->index()));
+                builder()->LoadTheHole().StoreAccumulatorInRegister(destination);
+            }
+            break;
+        case VariableLocation::REPL_GLOBAL:
+            // REPL let's are stored in script contexts. They get initialized
+            // with the hole the same way as normal context allocated variables.
+        case VariableLocation::CONTEXT:
+            if (variable->binding_needs_init()) {
+                DCHECK_EQ(0, execution_context()->ContextChainDepth(variable->scope()));
+                builder()->LoadTheHole().StoreContextSlot(execution_context()->reg(),
+                                                          variable->index(), 0);
+            }
+            break;
+        case VariableLocation::LOOKUP: {
+            DCHECK_EQ(VariableMode::kDynamic, variable->mode());
+            DCHECK(!variable->binding_needs_init());
+
+            Register name = register_allocator()->NewRegister();
+
+            builder()
+                    ->LoadLiteral(variable->raw_name())
+                    .StoreAccumulatorInRegister(name)
+                    .CallRuntime(Runtime::kDeclareEvalVar, name);
+            break;
+        }
     }
-  }
 }
 
 void BytecodeGenerator::VisitFunctionDeclaration(FunctionDeclaration* decl) {
-  Variable* variable = decl->var();
-  DCHECK(variable->mode() == VariableMode::kLet ||
-         variable->mode() == VariableMode::kVar ||
-         variable->mode() == VariableMode::kDynamic);
-  // Unused variables don't need to be visited.
-  if (!variable->is_used()) return;
-
-  switch (variable->location()) {
-    case VariableLocation::UNALLOCATED:
-    case VariableLocation::MODULE:
-      UNREACHABLE();
-    case VariableLocation::PARAMETER:
-    case VariableLocation::LOCAL: {
-      VisitFunctionLiteral(decl->fun());
-      BuildVariableAssignment(variable, Token::INIT, HoleCheckMode::kElided);
-      break;
-    }
-    case VariableLocation::REPL_GLOBAL:
-    case VariableLocation::CONTEXT: {
-      DCHECK_EQ(0, execution_context()->ContextChainDepth(variable->scope()));
-      VisitFunctionLiteral(decl->fun());
-      builder()->StoreContextSlot(execution_context()->reg(), variable->index(),
-                                  0);
-      break;
-    }
-    case VariableLocation::LOOKUP: {
-      RegisterList args = register_allocator()->NewRegisterList(2);
-      builder()
-          ->LoadLiteral(variable->raw_name())
-          .StoreAccumulatorInRegister(args[0]);
-      VisitFunctionLiteral(decl->fun());
-      builder()->StoreAccumulatorInRegister(args[1]).CallRuntime(
-          Runtime::kDeclareEvalFunction, args);
-      break;
+    Variable* variable = decl->var();
+    DCHECK(variable->mode() == VariableMode::kLet ||
+           variable->mode() == VariableMode::kVar ||
+           variable->mode() == VariableMode::kDynamic);
+    // Unused variables don't need to be visited.
+    if (!variable->is_used()) return;
+
+    switch (variable->location()) {
+        case VariableLocation::UNALLOCATED:
+        case VariableLocation::MODULE:
+            UNREACHABLE();
+        case VariableLocation::PARAMETER:
+        case VariableLocation::LOCAL: {
+            VisitFunctionLiteral(decl->fun());
+            BuildVariableAssignment(variable, Token::INIT, HoleCheckMode::kElided);
+            break;
+        }
+        case VariableLocation::REPL_GLOBAL:
+        case VariableLocation::CONTEXT: {
+            DCHECK_EQ(0, execution_context()->ContextChainDepth(variable->scope()));
+            VisitFunctionLiteral(decl->fun());
+            builder()->StoreContextSlot(execution_context()->reg(), variable->index(),
+                                        0);
+            break;
+        }
+        case VariableLocation::LOOKUP: {
+            RegisterList args = register_allocator()->NewRegisterList(2);
+            builder()
+                    ->LoadLiteral(variable->raw_name())
+                    .StoreAccumulatorInRegister(args[0]);
+            VisitFunctionLiteral(decl->fun());
+            builder()->StoreAccumulatorInRegister(args[1]).CallRuntime(
+                    Runtime::kDeclareEvalFunction, args);
+            break;
+        }
     }
-  }
-  DCHECK_IMPLIES(
-      eager_inner_literals_ != nullptr && decl->fun()->ShouldEagerCompile(),
-      IsInEagerLiterals(decl->fun(), *eager_inner_literals_));
+    DCHECK_IMPLIES(
+            eager_inner_literals_ != nullptr && decl->fun()->ShouldEagerCompile(),
+            IsInEagerLiterals(decl->fun(), *eager_inner_literals_));
 }
 
 void BytecodeGenerator::VisitModuleNamespaceImports() {
-  if (!closure_scope()->is_module_scope()) return;
+    if (!closure_scope()->is_module_scope()) return;
 
-  RegisterAllocationScope register_scope(this);
-  Register module_request = register_allocator()->NewRegister();
+    RegisterAllocationScope register_scope(this);
+    Register module_request = register_allocator()->NewRegister();
 
-  SourceTextModuleDescriptor* descriptor =
-      closure_scope()->AsModuleScope()->module();
-  for (auto entry : descriptor->namespace_imports()) {
-    builder()
-        ->LoadLiteral(Smi::FromInt(entry->module_request))
-        .StoreAccumulatorInRegister(module_request)
-        .CallRuntime(Runtime::kGetModuleNamespace, module_request);
-    Variable* var = closure_scope()->LookupInModule(entry->local_name);
-    BuildVariableAssignment(var, Token::INIT, HoleCheckMode::kElided);
-  }
+    SourceTextModuleDescriptor* descriptor =
+            closure_scope()->AsModuleScope()->module();
+    for (auto entry : descriptor->namespace_imports()) {
+        builder()
+                ->LoadLiteral(Smi::FromInt(entry->module_request))
+                .StoreAccumulatorInRegister(module_request)
+                .CallRuntime(Runtime::kGetModuleNamespace, module_request);
+        Variable* var = closure_scope()->LookupInModule(entry->local_name);
+        BuildVariableAssignment(var, Token::INIT, HoleCheckMode::kElided);
+    }
 }
 
 void BytecodeGenerator::BuildDeclareCall(Runtime::FunctionId id) {
-  if (!top_level_builder()->has_top_level_declaration()) return;
-  DCHECK(!top_level_builder()->processed());
+    if (!top_level_builder()->has_top_level_declaration()) return;
+    DCHECK(!top_level_builder()->processed());
 
-  top_level_builder()->set_constant_pool_entry(
-      builder()->AllocateDeferredConstantPoolEntry());
+    top_level_builder()->set_constant_pool_entry(
+            builder()->AllocateDeferredConstantPoolEntry());
 
-  // Emit code to declare globals.
-  RegisterList args = register_allocator()->NewRegisterList(2);
-  builder()
-      ->LoadConstantPoolEntry(top_level_builder()->constant_pool_entry())
-      .StoreAccumulatorInRegister(args[0])
-      .MoveRegister(Register::function_closure(), args[1])
-      .CallRuntime(id, args);
+    // Emit code to declare globals.
+    RegisterList args = register_allocator()->NewRegisterList(2);
+    builder()
+            ->LoadConstantPoolEntry(top_level_builder()->constant_pool_entry())
+            .StoreAccumulatorInRegister(args[0])
+            .MoveRegister(Register::function_closure(), args[1])
+            .CallRuntime(id, args);
 
-  top_level_builder()->mark_processed();
+    top_level_builder()->mark_processed();
 }
 
 void BytecodeGenerator::VisitModuleDeclarations(Declaration::List* decls) {
-  RegisterAllocationScope register_scope(this);
-  for (Declaration* decl : *decls) {
-    Variable* var = decl->var();
-    if (!var->is_used()) continue;
-    if (var->location() == VariableLocation::MODULE) {
-      if (decl->IsFunctionDeclaration()) {
-        DCHECK(var->IsExport());
-        FunctionDeclaration* f = static_cast<FunctionDeclaration*>(decl);
-        AddToEagerLiteralsIfEager(f->fun());
-        top_level_builder()->record_module_function_declaration();
-      } else if (var->IsExport() && var->binding_needs_init()) {
-        DCHECK(decl->IsVariableDeclaration());
-        top_level_builder()->record_module_variable_declaration();
-      }
-    } else {
-      RegisterAllocationScope inner_register_scope(this);
-      Visit(decl);
+    RegisterAllocationScope register_scope(this);
+    for (Declaration* decl : *decls) {
+        Variable* var = decl->var();
+        if (!var->is_used()) continue;
+        if (var->location() == VariableLocation::MODULE) {
+            if (decl->IsFunctionDeclaration()) {
+                DCHECK(var->IsExport());
+                FunctionDeclaration* f = static_cast<FunctionDeclaration*>(decl);
+                AddToEagerLiteralsIfEager(f->fun());
+                top_level_builder()->record_module_function_declaration();
+            } else if (var->IsExport() && var->binding_needs_init()) {
+                DCHECK(decl->IsVariableDeclaration());
+                top_level_builder()->record_module_variable_declaration();
+            }
+        } else {
+            RegisterAllocationScope inner_register_scope(this);
+            Visit(decl);
+        }
     }
-  }
-  BuildDeclareCall(Runtime::kDeclareModuleExports);
+    BuildDeclareCall(Runtime::kDeclareModuleExports);
 }
 
 void BytecodeGenerator::VisitGlobalDeclarations(Declaration::List* decls) {
-  RegisterAllocationScope register_scope(this);
-  for (Declaration* decl : *decls) {
-    Variable* var = decl->var();
-    DCHECK(var->is_used());
-    if (var->location() == VariableLocation::UNALLOCATED) {
-      // var or function.
-      if (decl->IsFunctionDeclaration()) {
-        top_level_builder()->record_global_function_declaration();
-        FunctionDeclaration* f = static_cast<FunctionDeclaration*>(decl);
-        AddToEagerLiteralsIfEager(f->fun());
-      } else {
-        top_level_builder()->record_global_variable_declaration();
-      }
-    } else {
-      // let or const. Handled in NewScriptContext.
-      DCHECK(decl->IsVariableDeclaration());
-      DCHECK(IsLexicalVariableMode(var->mode()));
+    RegisterAllocationScope register_scope(this);
+    for (Declaration* decl : *decls) {
+        Variable* var = decl->var();
+        DCHECK(var->is_used());
+        if (var->location() == VariableLocation::UNALLOCATED) {
+            // var or function.
+            if (decl->IsFunctionDeclaration()) {
+                top_level_builder()->record_global_function_declaration();
+                FunctionDeclaration* f = static_cast<FunctionDeclaration*>(decl);
+                AddToEagerLiteralsIfEager(f->fun());
+            } else {
+                top_level_builder()->record_global_variable_declaration();
+            }
+        } else {
+            // let or const. Handled in NewScriptContext.
+            DCHECK(decl->IsVariableDeclaration());
+            DCHECK(IsLexicalVariableMode(var->mode()));
+        }
     }
-  }
 
-  BuildDeclareCall(Runtime::kDeclareGlobals);
+    BuildDeclareCall(Runtime::kDeclareGlobals);
 }
 
 void BytecodeGenerator::VisitDeclarations(Declaration::List* declarations) {
-  for (Declaration* decl : *declarations) {
-    RegisterAllocationScope register_scope(this);
-    Visit(decl);
-  }
+    for (Declaration* decl : *declarations) {
+        RegisterAllocationScope register_scope(this);
+        Visit(decl);
+    }
 }
 
 void BytecodeGenerator::VisitStatements(
-    const ZonePtrList<Statement>* statements) {
-  for (int i = 0; i < statements->length(); i++) {
-    // Allocate an outer register allocations scope for the statement.
-    RegisterAllocationScope allocation_scope(this);
-    Statement* stmt = statements->at(i);
-    Visit(stmt);
-    if (builder()->RemainderOfBlockIsDead()) break;
-  }
+        const ZonePtrList<Statement>* statements) {
+    for (int i = 0; i < statements->length(); i++) {
+        // Allocate an outer register allocations scope for the statement.
+        RegisterAllocationScope allocation_scope(this);
+        Statement* stmt = statements->at(i);
+        Visit(stmt);
+        if (builder()->RemainderOfBlockIsDead()) break;
+    }
 }
 
 void BytecodeGenerator::VisitExpressionStatement(ExpressionStatement* stmt) {
-  builder()->SetStatementPosition(stmt);
-  VisitForEffect(stmt->expression());
+    builder()->SetStatementPosition(stmt);
+    VisitForEffect(stmt->expression());
 }
 
 void BytecodeGenerator::VisitEmptyStatement(EmptyStatement* stmt) {}
 
 void BytecodeGenerator::VisitIfStatement(IfStatement* stmt) {
-  ConditionalControlFlowBuilder conditional_builder(
-      builder(), block_coverage_builder_, stmt);
-  builder()->SetStatementPosition(stmt);
-
-  if (stmt->condition()->ToBooleanIsTrue()) {
-    // Generate then block unconditionally as always true.
-    conditional_builder.Then();
-    Visit(stmt->then_statement());
-  } else if (stmt->condition()->ToBooleanIsFalse()) {
-    // Generate else block unconditionally if it exists.
-    if (stmt->HasElseStatement()) {
-      conditional_builder.Else();
-      Visit(stmt->else_statement());
-    }
-  } else {
-    // TODO(oth): If then statement is BreakStatement or
-    // ContinueStatement we can reduce number of generated
-    // jump/jump_ifs here. See BasicLoops test.
-    VisitForTest(stmt->condition(), conditional_builder.then_labels(),
-                 conditional_builder.else_labels(), TestFallthrough::kThen);
-
-    conditional_builder.Then();
-    Visit(stmt->then_statement());
-
-    if (stmt->HasElseStatement()) {
-      conditional_builder.JumpToEnd();
-      conditional_builder.Else();
-      Visit(stmt->else_statement());
+    ConditionalControlFlowBuilder conditional_builder(
+            builder(), block_coverage_builder_, stmt);
+    builder()->SetStatementPosition(stmt);
+
+    if (stmt->condition()->ToBooleanIsTrue()) {
+        // Generate then block unconditionally as always true.
+        conditional_builder.Then();
+        Visit(stmt->then_statement());
+    } else if (stmt->condition()->ToBooleanIsFalse()) {
+        // Generate else block unconditionally if it exists.
+        if (stmt->HasElseStatement()) {
+            conditional_builder.Else();
+            Visit(stmt->else_statement());
+        }
+    } else {
+        // TODO(oth): If then statement is BreakStatement or
+        // ContinueStatement we can reduce number of generated
+        // jump/jump_ifs here. See BasicLoops test.
+        VisitForTest(stmt->condition(), conditional_builder.then_labels(),
+                     conditional_builder.else_labels(), TestFallthrough::kThen);
+
+        conditional_builder.Then();
+        Visit(stmt->then_statement());
+
+        if (stmt->HasElseStatement()) {
+            conditional_builder.JumpToEnd();
+            conditional_builder.Else();
+            Visit(stmt->else_statement());
+        }
     }
-  }
 }
 
 void BytecodeGenerator::VisitSloppyBlockFunctionStatement(
-    SloppyBlockFunctionStatement* stmt) {
-  Visit(stmt->statement());
+        SloppyBlockFunctionStatement* stmt) {
+    Visit(stmt->statement());
 }
 
 void BytecodeGenerator::VisitContinueStatement(ContinueStatement* stmt) {
-  AllocateBlockCoverageSlotIfEnabled(stmt, SourceRangeKind::kContinuation);
-  builder()->SetStatementPosition(stmt);
-  execution_control()->Continue(stmt->target());
+    AllocateBlockCoverageSlotIfEnabled(stmt, SourceRangeKind::kContinuation);
+    builder()->SetStatementPosition(stmt);
+    execution_control()->Continue(stmt->target());
 }
 
 void BytecodeGenerator::VisitBreakStatement(BreakStatement* stmt) {
-  AllocateBlockCoverageSlotIfEnabled(stmt, SourceRangeKind::kContinuation);
-  builder()->SetStatementPosition(stmt);
-  execution_control()->Break(stmt->target());
+    AllocateBlockCoverageSlotIfEnabled(stmt, SourceRangeKind::kContinuation);
+    builder()->SetStatementPosition(stmt);
+    execution_control()->Break(stmt->target());
 }
 
 void BytecodeGenerator::VisitReturnStatement(ReturnStatement* stmt) {
-  AllocateBlockCoverageSlotIfEnabled(stmt, SourceRangeKind::kContinuation);
-  builder()->SetStatementPosition(stmt);
-  VisitForAccumulatorValue(stmt->expression());
-  int return_position = stmt->end_position();
-  if (return_position == ReturnStatement::kFunctionLiteralReturnPosition) {
-    return_position = info()->literal()->return_position();
-  }
-  if (stmt->is_async_return()) {
-    execution_control()->AsyncReturnAccumulator(return_position);
-  } else {
-    execution_control()->ReturnAccumulator(return_position);
-  }
+    AllocateBlockCoverageSlotIfEnabled(stmt, SourceRangeKind::kContinuation);
+    builder()->SetStatementPosition(stmt);
+    VisitForAccumulatorValue(stmt->expression());
+
+    // xqg start smi
+    {
+        Register temp1 = register_allocator()->NewRegister();
+        BytecodeLabel replace_smi_done;
+        builder()
+                ->JumpIfNotSmi(&replace_smi_done)
+                .StoreAccumulatorInRegister(temp1)
+                .CallRuntime(Runtime::kTaintAnalysis_ReplaceSmiResult, temp1)
+                .Bind(&replace_smi_done);
+
+        register_allocator()->ReleaseRegister(temp1);
+    } // xqg end smi
+
+    // xqg start return statement
+    int init_reg_index = register_allocator()->next_register_index();
+    RegisterList temp_args = register_allocator()->NewRegisterList(2);
+    Register acc_init = register_allocator()->NewRegister();
+    builder()->StoreAccumulatorInRegister(acc_init);
+
+    builder()->StoreAccumulatorInRegister(temp_args[0])
+            .LoadLiteral(Smi::FromInt(stmt->position()))
+            .StoreAccumulatorInRegister(temp_args[1])
+            .CallRuntime(Runtime::kTaintAnalysis_OnVisitReturnStatement, temp_args);
+
+    builder()->LoadAccumulatorWithRegister(acc_init);
+    register_allocator()->ReleaseRegisters(init_reg_index);
+    // xqg end return statement
+
+
+    int return_position = stmt->end_position();
+    if (return_position == ReturnStatement::kFunctionLiteralReturnPosition) {
+        return_position = info()->literal()->return_position();
+    }
+    if (stmt->is_async_return()) {
+        execution_control()->AsyncReturnAccumulator(return_position);
+    } else {
+        execution_control()->ReturnAccumulator(return_position);
+    }
 }
 
 void BytecodeGenerator::VisitWithStatement(WithStatement* stmt) {
-  builder()->SetStatementPosition(stmt);
-  VisitForAccumulatorValue(stmt->expression());
-  BuildNewLocalWithContext(stmt->scope());
-  VisitInScope(stmt->statement(), stmt->scope());
+    builder()->SetStatementPosition(stmt);
+    VisitForAccumulatorValue(stmt->expression());
+    BuildNewLocalWithContext(stmt->scope());
+    VisitInScope(stmt->statement(), stmt->scope());
 }
 
 namespace {
 
-bool IsSmiLiteralSwitchCaseValue(Expression* expr) {
-  if (expr->IsSmiLiteral() ||
-      (expr->IsLiteral() && expr->AsLiteral()->IsNumber() &&
-       expr->AsLiteral()->AsNumber() == 0.0)) {
-    return true;
+    bool IsSmiLiteralSwitchCaseValue(Expression* expr) {
+        if (expr->IsSmiLiteral() ||
+            (expr->IsLiteral() && expr->AsLiteral()->IsNumber() &&
+             expr->AsLiteral()->AsNumber() == 0.0)) {
+            return true;
 #ifdef DEBUG
-  } else if (expr->IsLiteral() && expr->AsLiteral()->IsNumber()) {
+            } else if (expr->IsLiteral() && expr->AsLiteral()->IsNumber()) {
     DCHECK(!IsSmiDouble(expr->AsLiteral()->AsNumber()));
 #endif
-  }
-  return false;
-}
+        }
+        return false;
+    }
 
 // Precondition: we called IsSmiLiteral to check this.
-inline int ReduceToSmiSwitchCaseValue(Expression* expr) {
-  if (V8_LIKELY(expr->IsSmiLiteral())) {
-    return expr->AsLiteral()->AsSmiLiteral().value();
-  } else {
-    // Only the zero case is possible otherwise.
-    DCHECK(expr->IsLiteral() && expr->AsLiteral()->IsNumber() &&
-           expr->AsLiteral()->AsNumber() == -0.0);
-    return 0;
-  }
-}
+    inline int ReduceToSmiSwitchCaseValue(Expression* expr) {
+        if (V8_LIKELY(expr->IsSmiLiteral())) {
+            return expr->AsLiteral()->AsSmiLiteral().value();
+        } else {
+            // Only the zero case is possible otherwise.
+            DCHECK(expr->IsLiteral() && expr->AsLiteral()->IsNumber() &&
+                   expr->AsLiteral()->AsNumber() == -0.0);
+            return 0;
+        }
+    }
 
 // Is the range of Smi's small enough relative to number of cases?
-inline bool IsSpreadAcceptable(int spread, int ncases) {
-  return spread < v8_flags.switch_table_spread_threshold * ncases;
-}
+    inline bool IsSpreadAcceptable(int spread, int ncases) {
+        return spread < v8_flags.switch_table_spread_threshold * ncases;
+    }
 
-struct SwitchInfo {
-  static const int kDefaultNotFound = -1;
+    struct SwitchInfo {
+        static const int kDefaultNotFound = -1;
 
-  std::map<int, CaseClause*> covered_cases;
-  int default_case;
+        std::map<int, CaseClause*> covered_cases;
+        int default_case;
 
-  SwitchInfo() { default_case = kDefaultNotFound; }
+        SwitchInfo() { default_case = kDefaultNotFound; }
 
-  bool DefaultExists() { return default_case != kDefaultNotFound; }
-  bool CaseExists(int j) {
-    return covered_cases.find(j) != covered_cases.end();
-  }
-  bool CaseExists(Expression* expr) {
-    return IsSmiLiteralSwitchCaseValue(expr)
-               ? CaseExists(ReduceToSmiSwitchCaseValue(expr))
-               : false;
-  }
-  CaseClause* GetClause(int j) { return covered_cases[j]; }
+        bool DefaultExists() { return default_case != kDefaultNotFound; }
+        bool CaseExists(int j) {
+            return covered_cases.find(j) != covered_cases.end();
+        }
+        bool CaseExists(Expression* expr) {
+            return IsSmiLiteralSwitchCaseValue(expr)
+                   ? CaseExists(ReduceToSmiSwitchCaseValue(expr))
+                   : false;
+        }
+        CaseClause* GetClause(int j) { return covered_cases[j]; }
 
-  bool IsDuplicate(CaseClause* clause) {
-    return IsSmiLiteralSwitchCaseValue(clause->label()) &&
-           CaseExists(clause->label()) &&
-           clause != GetClause(ReduceToSmiSwitchCaseValue(clause->label()));
-  }
-  int MinCase() {
-    return covered_cases.size() == 0 ? INT_MAX : covered_cases.begin()->first;
-  }
-  int MaxCase() {
-    return covered_cases.size() == 0 ? INT_MIN : covered_cases.rbegin()->first;
-  }
-  void Print() {
-    std::cout << "Covered_cases: " << '\n';
-    for (auto iter = covered_cases.begin(); iter != covered_cases.end();
-         ++iter) {
-      std::cout << iter->first << "->" << iter->second << '\n';
-    }
-    std::cout << "Default_case: " << default_case << '\n';
-  }
-};
+        bool IsDuplicate(CaseClause* clause) {
+            return IsSmiLiteralSwitchCaseValue(clause->label()) &&
+                   CaseExists(clause->label()) &&
+                   clause != GetClause(ReduceToSmiSwitchCaseValue(clause->label()));
+        }
+        int MinCase() {
+            return covered_cases.size() == 0 ? INT_MAX : covered_cases.begin()->first;
+        }
+        int MaxCase() {
+            return covered_cases.size() == 0 ? INT_MIN : covered_cases.rbegin()->first;
+        }
+        void Print() {
+            std::cout << "Covered_cases: " << '\n';
+            for (auto iter = covered_cases.begin(); iter != covered_cases.end();
+                 ++iter) {
+                std::cout << iter->first << "->" << iter->second << '\n';
+            }
+            std::cout << "Default_case: " << default_case << '\n';
+        }
+    };
 
 // Checks whether we should use a jump table to implement a switch operation.
-bool IsSwitchOptimizable(SwitchStatement* stmt, SwitchInfo* info) {
-  ZonePtrList<CaseClause>* cases = stmt->cases();
-
-  for (int i = 0; i < cases->length(); ++i) {
-    CaseClause* clause = cases->at(i);
-    if (clause->is_default()) {
-      continue;
-    } else if (!(clause->label()->IsLiteral())) {
-      // Don't consider Smi cases after a non-literal, because we
-      // need to evaluate the non-literal.
-      break;
-    } else if (IsSmiLiteralSwitchCaseValue(clause->label())) {
-      int value = ReduceToSmiSwitchCaseValue(clause->label());
-      info->covered_cases.insert({value, clause});
-    }
-  }
-
-  // GCC also jump-table optimizes switch statements with 6 cases or more.
-  if (static_cast<int>(info->covered_cases.size()) >=
-      v8_flags.switch_table_min_cases) {
-    // Due to case spread will be used as the size of jump-table,
-    // we need to check if it doesn't overflow by casting its
-    // min and max bounds to int64_t, and calculate if the difference is less
-    // than or equal to INT_MAX.
-    int64_t min = static_cast<int64_t>(info->MinCase());
-    int64_t max = static_cast<int64_t>(info->MaxCase());
-    int64_t spread = max - min + 1;
-
-    DCHECK_GT(spread, 0);
+    bool IsSwitchOptimizable(SwitchStatement* stmt, SwitchInfo* info) {
+        ZonePtrList<CaseClause>* cases = stmt->cases();
+
+        for (int i = 0; i < cases->length(); ++i) {
+            CaseClause* clause = cases->at(i);
+            if (clause->is_default()) {
+                continue;
+            } else if (!(clause->label()->IsLiteral())) {
+                // Don't consider Smi cases after a non-literal, because we
+                // need to evaluate the non-literal.
+                break;
+            } else if (IsSmiLiteralSwitchCaseValue(clause->label())) {
+                int value = ReduceToSmiSwitchCaseValue(clause->label());
+                info->covered_cases.insert({value, clause});
+            }
+        }
 
-    // Check if casted spread is acceptable and doesn't overflow.
-    if (spread <= INT_MAX &&
-        IsSpreadAcceptable(static_cast<int>(spread), cases->length())) {
-      return true;
+        // GCC also jump-table optimizes switch statements with 6 cases or more.
+        if (static_cast<int>(info->covered_cases.size()) >=
+            v8_flags.switch_table_min_cases) {
+            // Due to case spread will be used as the size of jump-table,
+            // we need to check if it doesn't overflow by casting its
+            // min and max bounds to int64_t, and calculate if the difference is less
+            // than or equal to INT_MAX.
+            int64_t min = static_cast<int64_t>(info->MinCase());
+            int64_t max = static_cast<int64_t>(info->MaxCase());
+            int64_t spread = max - min + 1;
+
+            DCHECK_GT(spread, 0);
+
+            // Check if casted spread is acceptable and doesn't overflow.
+            if (spread <= INT_MAX &&
+                IsSpreadAcceptable(static_cast<int>(spread), cases->length())) {
+                return true;
+            }
+        }
+        // Invariant- covered_cases has all cases and only cases that will go in the
+        // jump table.
+        info->covered_cases.clear();
+        return false;
     }
-  }
-  // Invariant- covered_cases has all cases and only cases that will go in the
-  // jump table.
-  info->covered_cases.clear();
-  return false;
-}
 
 }  // namespace
 
@@ -1975,394 +2035,394 @@ bool IsSwitchOptimizable(SwitchStatement* stmt, SwitchInfo* info) {
 //   <out = 19, break>
 
 void BytecodeGenerator::VisitSwitchStatement(SwitchStatement* stmt) {
-  // We need this scope because we visit for register values. We have to
-  // maintain a execution result scope where registers can be allocated.
-  ZonePtrList<CaseClause>* clauses = stmt->cases();
-
-  SwitchInfo info;
-  BytecodeJumpTable* jump_table = nullptr;
-  bool use_jump_table = IsSwitchOptimizable(stmt, &info);
-
-  // N_comp_cases is number of cases we will generate comparison jumps for.
-  // Note we ignore duplicate cases, since they are very unlikely.
-
-  int n_comp_cases = clauses->length();
-  if (use_jump_table) {
-    n_comp_cases -= static_cast<int>(info.covered_cases.size());
-    jump_table = builder()->AllocateJumpTable(
-        info.MaxCase() - info.MinCase() + 1, info.MinCase());
-  }
+    // We need this scope because we visit for register values. We have to
+    // maintain a execution result scope where registers can be allocated.
+    ZonePtrList<CaseClause>* clauses = stmt->cases();
 
-  // Are we still using any if-else bytecodes to evaluate the switch?
-  bool use_jumps = n_comp_cases != 0;
+    SwitchInfo info;
+    BytecodeJumpTable* jump_table = nullptr;
+    bool use_jump_table = IsSwitchOptimizable(stmt, &info);
 
-  SwitchBuilder switch_builder(builder(), block_coverage_builder_, stmt,
-                               n_comp_cases, jump_table);
-  ControlScopeForBreakable scope(this, stmt, &switch_builder);
-  builder()->SetStatementPosition(stmt);
+    // N_comp_cases is number of cases we will generate comparison jumps for.
+    // Note we ignore duplicate cases, since they are very unlikely.
 
-  VisitForAccumulatorValue(stmt->tag());
+    int n_comp_cases = clauses->length();
+    if (use_jump_table) {
+        n_comp_cases -= static_cast<int>(info.covered_cases.size());
+        jump_table = builder()->AllocateJumpTable(
+                info.MaxCase() - info.MinCase() + 1, info.MinCase());
+    }
 
-  if (use_jump_table) {
-    // Release temps so that they can be reused in clauses.
-    RegisterAllocationScope allocation_scope(this);
-    // This also fills empty slots in jump table.
-    Register r2 = register_allocator()->NewRegister();
+    // Are we still using any if-else bytecodes to evaluate the switch?
+    bool use_jumps = n_comp_cases != 0;
 
-    Register r1 = register_allocator()->NewRegister();
-    builder()->StoreAccumulatorInRegister(r1);
+    SwitchBuilder switch_builder(builder(), block_coverage_builder_, stmt,
+                                 n_comp_cases, jump_table);
+    ControlScopeForBreakable scope(this, stmt, &switch_builder);
+    builder()->SetStatementPosition(stmt);
 
-    builder()->CompareTypeOf(TestTypeOfFlags::LiteralFlag::kNumber);
-    switch_builder.JumpToFallThroughIfFalse();
-    builder()->LoadAccumulatorWithRegister(r1);
+    VisitForAccumulatorValue(stmt->tag());
 
-    // TODO(leszeks): Note these are duplicated range checks with the
-    // SwitchOnSmi handler for the most part.
+    if (use_jump_table) {
+        // Release temps so that they can be reused in clauses.
+        RegisterAllocationScope allocation_scope(this);
+        // This also fills empty slots in jump table.
+        Register r2 = register_allocator()->NewRegister();
 
-    builder()->LoadLiteral(Smi::kMinValue);
-    builder()->StoreAccumulatorInRegister(r2);
-    builder()->CompareOperation(
-        Token::Value::GTE, r1,
-        feedback_index(feedback_spec()->AddCompareICSlot()));
+        Register r1 = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(r1);
 
-    switch_builder.JumpToFallThroughIfFalse();
-    builder()->LoadAccumulatorWithRegister(r1);
+        builder()->CompareTypeOf(TestTypeOfFlags::LiteralFlag::kNumber);
+        switch_builder.JumpToFallThroughIfFalse();
+        builder()->LoadAccumulatorWithRegister(r1);
 
-    builder()->LoadLiteral(Smi::kMaxValue);
-    builder()->StoreAccumulatorInRegister(r2);
-    builder()->CompareOperation(
-        Token::Value::LTE, r1,
-        feedback_index(feedback_spec()->AddCompareICSlot()));
+        // TODO(leszeks): Note these are duplicated range checks with the
+        // SwitchOnSmi handler for the most part.
 
-    switch_builder.JumpToFallThroughIfFalse();
-    builder()->LoadAccumulatorWithRegister(r1);
+        builder()->LoadLiteral(Smi::kMinValue);
+        builder()->StoreAccumulatorInRegister(r2);
+        builder()->CompareOperation(
+                Token::Value::GTE, r1,
+                feedback_index(feedback_spec()->AddCompareICSlot()));
 
-    builder()->BinaryOperationSmiLiteral(
-        Token::Value::BIT_OR, Smi::FromInt(0),
-        feedback_index(feedback_spec()->AddBinaryOpICSlot()));
+        switch_builder.JumpToFallThroughIfFalse();
+        builder()->LoadAccumulatorWithRegister(r1);
 
-    builder()->StoreAccumulatorInRegister(r2);
-    builder()->CompareOperation(
-        Token::Value::EQ_STRICT, r1,
-        feedback_index(feedback_spec()->AddCompareICSlot()));
+        builder()->LoadLiteral(Smi::kMaxValue);
+        builder()->StoreAccumulatorInRegister(r2);
+        builder()->CompareOperation(
+                Token::Value::LTE, r1,
+                feedback_index(feedback_spec()->AddCompareICSlot()));
 
-    switch_builder.JumpToFallThroughIfFalse();
-    builder()->LoadAccumulatorWithRegister(r2);
+        switch_builder.JumpToFallThroughIfFalse();
+        builder()->LoadAccumulatorWithRegister(r1);
 
-    switch_builder.EmitJumpTableIfExists(info.MinCase(), info.MaxCase(),
-                                         info.covered_cases);
+        builder()->BinaryOperationSmiLiteral(
+                Token::Value::BIT_OR, Smi::FromInt(0),
+                feedback_index(feedback_spec()->AddBinaryOpICSlot()));
 
-    if (use_jumps) {
-      builder()->LoadAccumulatorWithRegister(r1);
+        builder()->StoreAccumulatorInRegister(r2);
+        builder()->CompareOperation(
+                Token::Value::EQ_STRICT, r1,
+                feedback_index(feedback_spec()->AddCompareICSlot()));
+
+        switch_builder.JumpToFallThroughIfFalse();
+        builder()->LoadAccumulatorWithRegister(r2);
+
+        switch_builder.EmitJumpTableIfExists(info.MinCase(), info.MaxCase(),
+                                             info.covered_cases);
+
+        if (use_jumps) {
+            builder()->LoadAccumulatorWithRegister(r1);
+        }
     }
-  }
 
-  int case_compare_ctr = 0;
+    int case_compare_ctr = 0;
 #ifdef DEBUG
-  std::unordered_map<int, int> case_ctr_checker;
+    std::unordered_map<int, int> case_ctr_checker;
 #endif
 
-  if (use_jumps) {
-    Register tag_holder = register_allocator()->NewRegister();
-    FeedbackSlot slot = clauses->length() > 0
+    if (use_jumps) {
+        Register tag_holder = register_allocator()->NewRegister();
+        FeedbackSlot slot = clauses->length() > 0
                             ? feedback_spec()->AddCompareICSlot()
                             : FeedbackSlot::Invalid();
-    builder()->StoreAccumulatorInRegister(tag_holder);
-
-    for (int i = 0; i < clauses->length(); ++i) {
-      CaseClause* clause = clauses->at(i);
-      if (clause->is_default()) {
-        info.default_case = i;
-      } else if (!info.CaseExists(clause->label())) {
-        // Perform label comparison as if via '===' with tag.
-        VisitForAccumulatorValue(clause->label());
-        builder()->CompareOperation(Token::Value::EQ_STRICT, tag_holder,
-                                    feedback_index(slot));
+        builder()->StoreAccumulatorInRegister(tag_holder);
+
+        for (int i = 0; i < clauses->length(); ++i) {
+            CaseClause* clause = clauses->at(i);
+            if (clause->is_default()) {
+                info.default_case = i;
+            } else if (!info.CaseExists(clause->label())) {
+                // Perform label comparison as if via '===' with tag.
+                VisitForAccumulatorValue(clause->label());
+                builder()->CompareOperation(Token::Value::EQ_STRICT, tag_holder,
+                                            feedback_index(slot));
 #ifdef DEBUG
-        case_ctr_checker[i] = case_compare_ctr;
+                case_ctr_checker[i] = case_compare_ctr;
 #endif
-        switch_builder.JumpToCaseIfTrue(ToBooleanMode::kAlreadyBoolean,
-                                        case_compare_ctr++);
-      }
+                switch_builder.JumpToCaseIfTrue(ToBooleanMode::kAlreadyBoolean,
+                                                case_compare_ctr++);
+            }
+        }
+        register_allocator()->ReleaseRegister(tag_holder);
     }
-    register_allocator()->ReleaseRegister(tag_holder);
-  }
 
-  // For fall-throughs after comparisons (or out-of-range/non-Smi's for jump
-  // tables).
-  if (info.DefaultExists()) {
-    switch_builder.JumpToDefault();
-  } else {
-    switch_builder.Break();
-  }
+    // For fall-throughs after comparisons (or out-of-range/non-Smi's for jump
+    // tables).
+    if (info.DefaultExists()) {
+        switch_builder.JumpToDefault();
+    } else {
+        switch_builder.Break();
+    }
 
-  case_compare_ctr = 0;
-  for (int i = 0; i < clauses->length(); ++i) {
-    CaseClause* clause = clauses->at(i);
-    if (i != info.default_case) {
-      if (!info.IsDuplicate(clause)) {
-        bool use_table = use_jump_table && info.CaseExists(clause->label());
-        if (!use_table) {
+    case_compare_ctr = 0;
+    for (int i = 0; i < clauses->length(); ++i) {
+        CaseClause* clause = clauses->at(i);
+        if (i != info.default_case) {
+            if (!info.IsDuplicate(clause)) {
+                bool use_table = use_jump_table && info.CaseExists(clause->label());
+                if (!use_table) {
 // Guarantee that we should generate compare/jump if no table.
 #ifdef DEBUG
-          DCHECK(case_ctr_checker[i] == case_compare_ctr);
+                    DCHECK(case_ctr_checker[i] == case_compare_ctr);
 #endif
-          switch_builder.BindCaseTargetForCompareJump(case_compare_ctr++,
-                                                      clause);
+                    switch_builder.BindCaseTargetForCompareJump(case_compare_ctr++,
+                                                                clause);
+                } else {
+                    // Use jump table if this is not a duplicate label.
+                    switch_builder.BindCaseTargetForJumpTable(
+                            ReduceToSmiSwitchCaseValue(clause->label()), clause);
+                }
+            }
         } else {
-          // Use jump table if this is not a duplicate label.
-          switch_builder.BindCaseTargetForJumpTable(
-              ReduceToSmiSwitchCaseValue(clause->label()), clause);
+            switch_builder.BindDefault(clause);
         }
-      }
-    } else {
-      switch_builder.BindDefault(clause);
+        // Regardless, generate code (in case of fall throughs).
+        VisitStatements(clause->statements());
     }
-    // Regardless, generate code (in case of fall throughs).
-    VisitStatements(clause->statements());
-  }
 }
 
 template <typename TryBodyFunc, typename CatchBodyFunc>
 void BytecodeGenerator::BuildTryCatch(
-    TryBodyFunc try_body_func, CatchBodyFunc catch_body_func,
-    HandlerTable::CatchPrediction catch_prediction,
-    TryCatchStatement* stmt_for_coverage) {
-  if (builder()->RemainderOfBlockIsDead()) return;
-
-  TryCatchBuilder try_control_builder(
-      builder(),
-      stmt_for_coverage == nullptr ? nullptr : block_coverage_builder_,
-      stmt_for_coverage, catch_prediction);
-
-  // Preserve the context in a dedicated register, so that it can be restored
-  // when the handler is entered by the stack-unwinding machinery.
-  // TODO(ignition): Be smarter about register allocation.
-  Register context = register_allocator()->NewRegister();
-  builder()->MoveRegister(Register::current_context(), context);
-
-  // Evaluate the try-block inside a control scope. This simulates a handler
-  // that is intercepting 'throw' control commands.
-  try_control_builder.BeginTry(context);
-  {
-    ControlScopeForTryCatch scope(this, &try_control_builder);
-    try_body_func();
-  }
-  try_control_builder.EndTry();
+        TryBodyFunc try_body_func, CatchBodyFunc catch_body_func,
+        HandlerTable::CatchPrediction catch_prediction,
+        TryCatchStatement* stmt_for_coverage) {
+    if (builder()->RemainderOfBlockIsDead()) return;
+
+    TryCatchBuilder try_control_builder(
+            builder(),
+            stmt_for_coverage == nullptr ? nullptr : block_coverage_builder_,
+            stmt_for_coverage, catch_prediction);
+
+    // Preserve the context in a dedicated register, so that it can be restored
+    // when the handler is entered by the stack-unwinding machinery.
+    // TODO(ignition): Be smarter about register allocation.
+    Register context = register_allocator()->NewRegister();
+    builder()->MoveRegister(Register::current_context(), context);
+
+    // Evaluate the try-block inside a control scope. This simulates a handler
+    // that is intercepting 'throw' control commands.
+    try_control_builder.BeginTry(context);
+    {
+        ControlScopeForTryCatch scope(this, &try_control_builder);
+        try_body_func();
+    }
+    try_control_builder.EndTry();
 
-  catch_body_func(context);
+    catch_body_func(context);
 
-  try_control_builder.EndCatch();
+    try_control_builder.EndCatch();
 }
 
 template <typename TryBodyFunc, typename FinallyBodyFunc>
 void BytecodeGenerator::BuildTryFinally(
-    TryBodyFunc try_body_func, FinallyBodyFunc finally_body_func,
-    HandlerTable::CatchPrediction catch_prediction,
-    TryFinallyStatement* stmt_for_coverage) {
-  if (builder()->RemainderOfBlockIsDead()) return;
-
-  // We can't know whether the finally block will override ("catch") an
-  // exception thrown in the try block, so we just adopt the outer prediction.
-  TryFinallyBuilder try_control_builder(
-      builder(),
-      stmt_for_coverage == nullptr ? nullptr : block_coverage_builder_,
-      stmt_for_coverage, catch_prediction);
-
-  // We keep a record of all paths that enter the finally-block to be able to
-  // dispatch to the correct continuation point after the statements in the
-  // finally-block have been evaluated.
-  //
-  // The try-finally construct can enter the finally-block in three ways:
-  // 1. By exiting the try-block normally, falling through at the end.
-  // 2. By exiting the try-block with a function-local control flow transfer
-  //    (i.e. through break/continue/return statements).
-  // 3. By exiting the try-block with a thrown exception.
-  //
-  // The result register semantics depend on how the block was entered:
-  //  - ReturnStatement: It represents the return value being returned.
-  //  - ThrowStatement: It represents the exception being thrown.
-  //  - BreakStatement/ContinueStatement: Undefined and not used.
-  //  - Falling through into finally-block: Undefined and not used.
-  Register token = register_allocator()->NewRegister();
-  Register result = register_allocator()->NewRegister();
-  ControlScope::DeferredCommands commands(this, token, result);
-
-  // Preserve the context in a dedicated register, so that it can be restored
-  // when the handler is entered by the stack-unwinding machinery.
-  // TODO(ignition): Be smarter about register allocation.
-  Register context = register_allocator()->NewRegister();
-  builder()->MoveRegister(Register::current_context(), context);
-
-  // Evaluate the try-block inside a control scope. This simulates a handler
-  // that is intercepting all control commands.
-  try_control_builder.BeginTry(context);
-  {
-    ControlScopeForTryFinally scope(this, &try_control_builder, &commands);
-    try_body_func();
-  }
-  try_control_builder.EndTry();
+        TryBodyFunc try_body_func, FinallyBodyFunc finally_body_func,
+        HandlerTable::CatchPrediction catch_prediction,
+        TryFinallyStatement* stmt_for_coverage) {
+    if (builder()->RemainderOfBlockIsDead()) return;
+
+    // We can't know whether the finally block will override ("catch") an
+    // exception thrown in the try block, so we just adopt the outer prediction.
+    TryFinallyBuilder try_control_builder(
+            builder(),
+            stmt_for_coverage == nullptr ? nullptr : block_coverage_builder_,
+            stmt_for_coverage, catch_prediction);
+
+    // We keep a record of all paths that enter the finally-block to be able to
+    // dispatch to the correct continuation point after the statements in the
+    // finally-block have been evaluated.
+    //
+    // The try-finally construct can enter the finally-block in three ways:
+    // 1. By exiting the try-block normally, falling through at the end.
+    // 2. By exiting the try-block with a function-local control flow transfer
+    //    (i.e. through break/continue/return statements).
+    // 3. By exiting the try-block with a thrown exception.
+    //
+    // The result register semantics depend on how the block was entered:
+    //  - ReturnStatement: It represents the return value being returned.
+    //  - ThrowStatement: It represents the exception being thrown.
+    //  - BreakStatement/ContinueStatement: Undefined and not used.
+    //  - Falling through into finally-block: Undefined and not used.
+    Register token = register_allocator()->NewRegister();
+    Register result = register_allocator()->NewRegister();
+    ControlScope::DeferredCommands commands(this, token, result);
+
+    // Preserve the context in a dedicated register, so that it can be restored
+    // when the handler is entered by the stack-unwinding machinery.
+    // TODO(ignition): Be smarter about register allocation.
+    Register context = register_allocator()->NewRegister();
+    builder()->MoveRegister(Register::current_context(), context);
 
-  // Record fall-through and exception cases.
-  commands.RecordFallThroughPath();
-  try_control_builder.LeaveTry();
-  try_control_builder.BeginHandler();
-  commands.RecordHandlerReThrowPath();
+    // Evaluate the try-block inside a control scope. This simulates a handler
+    // that is intercepting all control commands.
+    try_control_builder.BeginTry(context);
+    {
+        ControlScopeForTryFinally scope(this, &try_control_builder, &commands);
+        try_body_func();
+    }
+    try_control_builder.EndTry();
 
-  // Pending message object is saved on entry.
-  try_control_builder.BeginFinally();
-  Register message = context;  // Reuse register.
+    // Record fall-through and exception cases.
+    commands.RecordFallThroughPath();
+    try_control_builder.LeaveTry();
+    try_control_builder.BeginHandler();
+    commands.RecordHandlerReThrowPath();
 
-  // Clear message object as we enter the finally block.
-  builder()->LoadTheHole().SetPendingMessage().StoreAccumulatorInRegister(
-      message);
+    // Pending message object is saved on entry.
+    try_control_builder.BeginFinally();
+    Register message = context;  // Reuse register.
 
-  // Evaluate the finally-block.
-  finally_body_func(token);
-  try_control_builder.EndFinally();
+    // Clear message object as we enter the finally block.
+    builder()->LoadTheHole().SetPendingMessage().StoreAccumulatorInRegister(
+            message);
 
-  // Pending message object is restored on exit.
-  builder()->LoadAccumulatorWithRegister(message).SetPendingMessage();
+    // Evaluate the finally-block.
+    finally_body_func(token);
+    try_control_builder.EndFinally();
 
-  // Dynamic dispatch after the finally-block.
-  commands.ApplyDeferredCommands();
+    // Pending message object is restored on exit.
+    builder()->LoadAccumulatorWithRegister(message).SetPendingMessage();
+
+    // Dynamic dispatch after the finally-block.
+    commands.ApplyDeferredCommands();
 }
 
 void BytecodeGenerator::VisitIterationBody(IterationStatement* stmt,
                                            LoopBuilder* loop_builder) {
-  loop_builder->LoopBody();
-  ControlScopeForIteration execution_control(this, stmt, loop_builder);
-  Visit(stmt->body());
-  loop_builder->BindContinueTarget();
+    loop_builder->LoopBody();
+    ControlScopeForIteration execution_control(this, stmt, loop_builder);
+    Visit(stmt->body());
+    loop_builder->BindContinueTarget();
 }
 
 void BytecodeGenerator::VisitDoWhileStatement(DoWhileStatement* stmt) {
-  LoopBuilder loop_builder(builder(), block_coverage_builder_, stmt,
-                           feedback_spec());
-  if (stmt->cond()->ToBooleanIsFalse()) {
-    // Since we know that the condition is false, we don't create a loop.
-    // Therefore, we don't create a LoopScope (and thus we don't create a header
-    // and a JumpToHeader). However, we still need to iterate once through the
-    // body.
-    VisitIterationBody(stmt, &loop_builder);
-  } else if (stmt->cond()->ToBooleanIsTrue()) {
-    LoopScope loop_scope(this, &loop_builder);
-    VisitIterationBody(stmt, &loop_builder);
-  } else {
-    LoopScope loop_scope(this, &loop_builder);
-    VisitIterationBody(stmt, &loop_builder);
-    builder()->SetExpressionAsStatementPosition(stmt->cond());
-    BytecodeLabels loop_backbranch(zone());
-    VisitForTest(stmt->cond(), &loop_backbranch, loop_builder.break_labels(),
-                 TestFallthrough::kThen);
-    loop_backbranch.Bind(builder());
-  }
+    LoopBuilder loop_builder(builder(), block_coverage_builder_, stmt,
+                             feedback_spec());
+    if (stmt->cond()->ToBooleanIsFalse()) {
+        // Since we know that the condition is false, we don't create a loop.
+        // Therefore, we don't create a LoopScope (and thus we don't create a header
+        // and a JumpToHeader). However, we still need to iterate once through the
+        // body.
+        VisitIterationBody(stmt, &loop_builder);
+    } else if (stmt->cond()->ToBooleanIsTrue()) {
+        LoopScope loop_scope(this, &loop_builder);
+        VisitIterationBody(stmt, &loop_builder);
+    } else {
+        LoopScope loop_scope(this, &loop_builder);
+        VisitIterationBody(stmt, &loop_builder);
+        builder()->SetExpressionAsStatementPosition(stmt->cond());
+        BytecodeLabels loop_backbranch(zone());
+        VisitForTest(stmt->cond(), &loop_backbranch, loop_builder.break_labels(),
+                     TestFallthrough::kThen);
+        loop_backbranch.Bind(builder());
+    }
 }
 
 void BytecodeGenerator::VisitWhileStatement(WhileStatement* stmt) {
-  LoopBuilder loop_builder(builder(), block_coverage_builder_, stmt,
-                           feedback_spec());
+    LoopBuilder loop_builder(builder(), block_coverage_builder_, stmt,
+                             feedback_spec());
 
-  if (stmt->cond()->ToBooleanIsFalse()) {
-    // If the condition is false there is no need to generate the loop.
-    return;
-  }
+    if (stmt->cond()->ToBooleanIsFalse()) {
+        // If the condition is false there is no need to generate the loop.
+        return;
+    }
 
-  LoopScope loop_scope(this, &loop_builder);
-  if (!stmt->cond()->ToBooleanIsTrue()) {
-    builder()->SetExpressionAsStatementPosition(stmt->cond());
-    BytecodeLabels loop_body(zone());
-    VisitForTest(stmt->cond(), &loop_body, loop_builder.break_labels(),
-                 TestFallthrough::kThen);
-    loop_body.Bind(builder());
-  }
-  VisitIterationBody(stmt, &loop_builder);
+    LoopScope loop_scope(this, &loop_builder);
+    if (!stmt->cond()->ToBooleanIsTrue()) {
+        builder()->SetExpressionAsStatementPosition(stmt->cond());
+        BytecodeLabels loop_body(zone());
+        VisitForTest(stmt->cond(), &loop_body, loop_builder.break_labels(),
+                     TestFallthrough::kThen);
+        loop_body.Bind(builder());
+    }
+    VisitIterationBody(stmt, &loop_builder);
 }
 
 void BytecodeGenerator::VisitForStatement(ForStatement* stmt) {
-  if (stmt->init() != nullptr) {
-    Visit(stmt->init());
-  }
+    if (stmt->init() != nullptr) {
+        Visit(stmt->init());
+    }
 
-  LoopBuilder loop_builder(builder(), block_coverage_builder_, stmt,
-                           feedback_spec());
-  if (stmt->cond() && stmt->cond()->ToBooleanIsFalse()) {
-    // If the condition is known to be false there is no need to generate
-    // body, next or condition blocks. Init block should be generated.
-    return;
-  }
+    LoopBuilder loop_builder(builder(), block_coverage_builder_, stmt,
+                             feedback_spec());
+    if (stmt->cond() && stmt->cond()->ToBooleanIsFalse()) {
+        // If the condition is known to be false there is no need to generate
+        // body, next or condition blocks. Init block should be generated.
+        return;
+    }
 
-  LoopScope loop_scope(this, &loop_builder);
-  if (stmt->cond() && !stmt->cond()->ToBooleanIsTrue()) {
-    builder()->SetExpressionAsStatementPosition(stmt->cond());
-    BytecodeLabels loop_body(zone());
-    VisitForTest(stmt->cond(), &loop_body, loop_builder.break_labels(),
-                 TestFallthrough::kThen);
-    loop_body.Bind(builder());
-  }
-  VisitIterationBody(stmt, &loop_builder);
-  if (stmt->next() != nullptr) {
-    builder()->SetStatementPosition(stmt->next());
-    Visit(stmt->next());
-  }
+    LoopScope loop_scope(this, &loop_builder);
+    if (stmt->cond() && !stmt->cond()->ToBooleanIsTrue()) {
+        builder()->SetExpressionAsStatementPosition(stmt->cond());
+        BytecodeLabels loop_body(zone());
+        VisitForTest(stmt->cond(), &loop_body, loop_builder.break_labels(),
+                     TestFallthrough::kThen);
+        loop_body.Bind(builder());
+    }
+    VisitIterationBody(stmt, &loop_builder);
+    if (stmt->next() != nullptr) {
+        builder()->SetStatementPosition(stmt->next());
+        Visit(stmt->next());
+    }
 }
 
 void BytecodeGenerator::VisitForInStatement(ForInStatement* stmt) {
-  if (stmt->subject()->IsNullLiteral() ||
-      stmt->subject()->IsUndefinedLiteral()) {
-    // ForIn generates lots of code, skip if it wouldn't produce any effects.
-    return;
-  }
-
-  BytecodeLabel subject_undefined_label;
-  FeedbackSlot slot = feedback_spec()->AddForInSlot();
-
-  // Prepare the state for executing ForIn.
-  builder()->SetExpressionAsStatementPosition(stmt->subject());
-  VisitForAccumulatorValue(stmt->subject());
-  builder()->JumpIfUndefinedOrNull(&subject_undefined_label);
-  Register receiver = register_allocator()->NewRegister();
-  builder()->ToObject(receiver);
-
-  // Used as kRegTriple and kRegPair in ForInPrepare and ForInNext.
-  RegisterList triple = register_allocator()->NewRegisterList(3);
-  Register cache_length = triple[2];
-  builder()->ForInEnumerate(receiver);
-  builder()->ForInPrepare(triple, feedback_index(slot));
-
-  // Set up loop counter
-  Register index = register_allocator()->NewRegister();
-  builder()->LoadLiteral(Smi::zero());
-  builder()->StoreAccumulatorInRegister(index);
-
-  // The loop
-  {
-    LoopBuilder loop_builder(builder(), block_coverage_builder_, stmt,
-                             feedback_spec());
-    LoopScope loop_scope(this, &loop_builder);
-    builder()->SetExpressionAsStatementPosition(stmt->each());
-    builder()->ForInContinue(index, cache_length);
-    loop_builder.BreakIfFalse(ToBooleanMode::kAlreadyBoolean);
-    builder()->ForInNext(receiver, index, triple.Truncate(2),
-                         feedback_index(slot));
-    loop_builder.ContinueIfUndefined();
-
-    // Assign accumulator value to the 'each' target.
-    {
-      EffectResultScope scope(this);
-      // Make sure to preserve the accumulator across the PrepareAssignmentLhs
-      // call.
-      AssignmentLhsData lhs_data = PrepareAssignmentLhs(
-          stmt->each(), AccumulatorPreservingMode::kPreserve);
-      builder()->SetExpressionPosition(stmt->each());
-      BuildAssignment(lhs_data, Token::ASSIGN, LookupHoistingMode::kNormal);
+    if (stmt->subject()->IsNullLiteral() ||
+        stmt->subject()->IsUndefinedLiteral()) {
+        // ForIn generates lots of code, skip if it wouldn't produce any effects.
+        return;
     }
 
-    VisitIterationBody(stmt, &loop_builder);
-    builder()->ForInStep(index);
+    BytecodeLabel subject_undefined_label;
+    FeedbackSlot slot = feedback_spec()->AddForInSlot();
+
+    // Prepare the state for executing ForIn.
+    builder()->SetExpressionAsStatementPosition(stmt->subject());
+    VisitForAccumulatorValue(stmt->subject());
+    builder()->JumpIfUndefinedOrNull(&subject_undefined_label);
+    Register receiver = register_allocator()->NewRegister();
+    builder()->ToObject(receiver);
+
+    // Used as kRegTriple and kRegPair in ForInPrepare and ForInNext.
+    RegisterList triple = register_allocator()->NewRegisterList(3);
+    Register cache_length = triple[2];
+    builder()->ForInEnumerate(receiver);
+    builder()->ForInPrepare(triple, feedback_index(slot));
+
+    // Set up loop counter
+    Register index = register_allocator()->NewRegister();
+    builder()->LoadLiteral(Smi::zero());
     builder()->StoreAccumulatorInRegister(index);
-  }
-  builder()->Bind(&subject_undefined_label);
+
+    // The loop
+    {
+        LoopBuilder loop_builder(builder(), block_coverage_builder_, stmt,
+                                 feedback_spec());
+        LoopScope loop_scope(this, &loop_builder);
+        builder()->SetExpressionAsStatementPosition(stmt->each());
+        builder()->ForInContinue(index, cache_length);
+        loop_builder.BreakIfFalse(ToBooleanMode::kAlreadyBoolean);
+        builder()->ForInNext(receiver, index, triple.Truncate(2),
+                             feedback_index(slot));
+        loop_builder.ContinueIfUndefined();
+
+        // Assign accumulator value to the 'each' target.
+        {
+            EffectResultScope scope(this);
+            // Make sure to preserve the accumulator across the PrepareAssignmentLhs
+            // call.
+            AssignmentLhsData lhs_data = PrepareAssignmentLhs(
+                    stmt->each(), AccumulatorPreservingMode::kPreserve);
+            builder()->SetExpressionPosition(stmt->each());
+            BuildAssignment(lhs_data, Token::ASSIGN, LookupHoistingMode::kNormal);
+        }
+
+        VisitIterationBody(stmt, &loop_builder);
+        builder()->ForInStep(index);
+        builder()->StoreAccumulatorInRegister(index);
+    }
+    builder()->Bind(&subject_undefined_label);
 }
 
 // Desugar a for-of statement into an application of the iteration protocol.
@@ -2393,920 +2453,1028 @@ void BytecodeGenerator::VisitForInStatement(ForInStatement* stmt) {
 //   %FinalizeIteration(iterator, done, iteration_continuation)
 // }
 void BytecodeGenerator::VisitForOfStatement(ForOfStatement* stmt) {
-  EffectResultScope effect_scope(this);
-
-  builder()->SetExpressionAsStatementPosition(stmt->subject());
-  VisitForAccumulatorValue(stmt->subject());
-
-  // Store the iterator in a dedicated register so that it can be closed on
-  // exit, and the 'done' value in a dedicated register so that it can be
-  // changed and accessed independently of the iteration result.
-  IteratorRecord iterator = BuildGetIteratorRecord(stmt->type());
-  Register done = register_allocator()->NewRegister();
-  builder()->LoadFalse();
-  builder()->StoreAccumulatorInRegister(done);
-
-  BuildTryFinally(
-      // Try block.
-      [&]() {
-        LoopBuilder loop_builder(builder(), block_coverage_builder_, stmt,
-                                 feedback_spec());
-        LoopScope loop_scope(this, &loop_builder);
-
-        builder()->LoadTrue().StoreAccumulatorInRegister(done);
-
-        {
-          RegisterAllocationScope allocation_scope(this);
-          Register next_result = register_allocator()->NewRegister();
-
-          // Call the iterator's .next() method. Break from the loop if the
-          // `done` property is truthy, otherwise load the value from the
-          // iterator result and append the argument.
-          builder()->SetExpressionAsStatementPosition(stmt->each());
-          BuildIteratorNext(iterator, next_result);
-          builder()->LoadNamedProperty(
-              next_result, ast_string_constants()->done_string(),
-              feedback_index(feedback_spec()->AddLoadICSlot()));
-          loop_builder.BreakIfTrue(ToBooleanMode::kConvertToBoolean);
-
-          builder()
-              // value = value.value
-              ->LoadNamedProperty(
-                  next_result, ast_string_constants()->value_string(),
-                  feedback_index(feedback_spec()->AddLoadICSlot()));
-          // done = false, before the assignment to each happens, so that done
-          // is false if the assignment throws.
-          builder()
-              ->StoreAccumulatorInRegister(next_result)
-              .LoadFalse()
-              .StoreAccumulatorInRegister(done);
-
-          // Assign to the 'each' target.
-          AssignmentLhsData lhs_data = PrepareAssignmentLhs(stmt->each());
-          builder()->LoadAccumulatorWithRegister(next_result);
-          BuildAssignment(lhs_data, Token::ASSIGN, LookupHoistingMode::kNormal);
-        }
-
-        VisitIterationBody(stmt, &loop_builder);
-      },
-      // Finally block.
-      [&](Register iteration_continuation_token) {
-        // Finish the iteration in the finally block.
-        BuildFinalizeIteration(iterator, done, iteration_continuation_token);
-      },
-      HandlerTable::UNCAUGHT);
+    EffectResultScope effect_scope(this);
+
+    builder()->SetExpressionAsStatementPosition(stmt->subject());
+    VisitForAccumulatorValue(stmt->subject());
+
+    // Store the iterator in a dedicated register so that it can be closed on
+    // exit, and the 'done' value in a dedicated register so that it can be
+    // changed and accessed independently of the iteration result.
+    IteratorRecord iterator = BuildGetIteratorRecord(stmt->type());
+    Register done = register_allocator()->NewRegister();
+    builder()->LoadFalse();
+    builder()->StoreAccumulatorInRegister(done);
+
+    BuildTryFinally(
+            // Try block.
+            [&]() {
+                LoopBuilder loop_builder(builder(), block_coverage_builder_, stmt,
+                                         feedback_spec());
+                LoopScope loop_scope(this, &loop_builder);
+
+                builder()->LoadTrue().StoreAccumulatorInRegister(done);
+
+                {
+                    RegisterAllocationScope allocation_scope(this);
+                    Register next_result = register_allocator()->NewRegister();
+
+                    // Call the iterator's .next() method. Break from the loop if the
+                    // `done` property is truthy, otherwise load the value from the
+                    // iterator result and append the argument.
+                    builder()->SetExpressionAsStatementPosition(stmt->each());
+                    BuildIteratorNext(iterator, next_result);
+                    builder()->LoadNamedProperty(
+                            next_result, ast_string_constants()->done_string(),
+                            feedback_index(feedback_spec()->AddLoadICSlot()));
+                    loop_builder.BreakIfTrue(ToBooleanMode::kConvertToBoolean);
+
+                    builder()
+                            // value = value.value
+                            ->LoadNamedProperty(
+                                    next_result, ast_string_constants()->value_string(),
+                                    feedback_index(feedback_spec()->AddLoadICSlot()));
+                    // done = false, before the assignment to each happens, so that done
+                    // is false if the assignment throws.
+                    builder()
+                            ->StoreAccumulatorInRegister(next_result)
+                            .LoadFalse()
+                            .StoreAccumulatorInRegister(done);
+
+                    // Assign to the 'each' target.
+                    AssignmentLhsData lhs_data = PrepareAssignmentLhs(stmt->each());
+                    builder()->LoadAccumulatorWithRegister(next_result);
+                    BuildAssignment(lhs_data, Token::ASSIGN, LookupHoistingMode::kNormal);
+                }
+
+                VisitIterationBody(stmt, &loop_builder);
+            },
+            // Finally block.
+            [&](Register iteration_continuation_token) {
+                // Finish the iteration in the finally block.
+                BuildFinalizeIteration(iterator, done, iteration_continuation_token);
+            },
+            HandlerTable::UNCAUGHT);
 }
 
 void BytecodeGenerator::VisitTryCatchStatement(TryCatchStatement* stmt) {
-  // Update catch prediction tracking. The updated catch_prediction value lasts
-  // until the end of the try_block in the AST node, and does not apply to the
-  // catch_block.
-  HandlerTable::CatchPrediction outer_catch_prediction = catch_prediction();
-  set_catch_prediction(stmt->GetCatchPrediction(outer_catch_prediction));
-
-  BuildTryCatch(
-      // Try body.
-      [&]() {
-        Visit(stmt->try_block());
-        set_catch_prediction(outer_catch_prediction);
-      },
-      // Catch body.
-      [&](Register context) {
-        if (stmt->scope()) {
-          // Create a catch scope that binds the exception.
-          BuildNewLocalCatchContext(stmt->scope());
-          builder()->StoreAccumulatorInRegister(context);
-        }
-
-        // If requested, clear message object as we enter the catch block.
-        if (stmt->ShouldClearPendingException(outer_catch_prediction)) {
-          builder()->LoadTheHole().SetPendingMessage();
-        }
-
-        // Load the catch context into the accumulator.
-        builder()->LoadAccumulatorWithRegister(context);
-
-        // Evaluate the catch-block.
-        if (stmt->scope()) {
-          VisitInScope(stmt->catch_block(), stmt->scope());
-        } else {
-          VisitBlock(stmt->catch_block());
-        }
-      },
-      catch_prediction(), stmt);
+    // Update catch prediction tracking. The updated catch_prediction value lasts
+    // until the end of the try_block in the AST node, and does not apply to the
+    // catch_block.
+    HandlerTable::CatchPrediction outer_catch_prediction = catch_prediction();
+    set_catch_prediction(stmt->GetCatchPrediction(outer_catch_prediction));
+
+    BuildTryCatch(
+            // Try body.
+            [&]() {
+                Visit(stmt->try_block());
+                set_catch_prediction(outer_catch_prediction);
+            },
+            // Catch body.
+            [&](Register context) {
+                if (stmt->scope()) {
+                    // Create a catch scope that binds the exception.
+                    BuildNewLocalCatchContext(stmt->scope());
+                    builder()->StoreAccumulatorInRegister(context);
+                }
+
+                // If requested, clear message object as we enter the catch block.
+                if (stmt->ShouldClearPendingException(outer_catch_prediction)) {
+                    builder()->LoadTheHole().SetPendingMessage();
+                }
+
+                // Load the catch context into the accumulator.
+                builder()->LoadAccumulatorWithRegister(context);
+
+                // Evaluate the catch-block.
+                if (stmt->scope()) {
+                    VisitInScope(stmt->catch_block(), stmt->scope());
+                } else {
+                    VisitBlock(stmt->catch_block());
+                }
+            },
+            catch_prediction(), stmt);
 }
 
 void BytecodeGenerator::VisitTryFinallyStatement(TryFinallyStatement* stmt) {
-  BuildTryFinally(
-      // Try block.
-      [&]() { Visit(stmt->try_block()); },
-      // Finally block.
-      [&](Register body_continuation_token) { Visit(stmt->finally_block()); },
-      catch_prediction(), stmt);
+    BuildTryFinally(
+            // Try block.
+            [&]() { Visit(stmt->try_block()); },
+            // Finally block.
+            [&](Register body_continuation_token) { Visit(stmt->finally_block()); },
+            catch_prediction(), stmt);
 }
 
 void BytecodeGenerator::VisitDebuggerStatement(DebuggerStatement* stmt) {
-  builder()->SetStatementPosition(stmt);
-  builder()->Debugger();
+    builder()->SetStatementPosition(stmt);
+    builder()->Debugger();
 }
 
 void BytecodeGenerator::VisitFunctionLiteral(FunctionLiteral* expr) {
-  DCHECK_EQ(expr->scope()->outer_scope(), current_scope());
-  uint8_t flags = CreateClosureFlags::Encode(
-      expr->pretenure(), closure_scope()->is_function_scope(),
-      info()->flags().might_always_turbofan());
-  size_t entry = builder()->AllocateDeferredConstantPoolEntry();
-  builder()->CreateClosure(entry, GetCachedCreateClosureSlot(expr), flags);
-  function_literals_.push_back(std::make_pair(expr, entry));
-  AddToEagerLiteralsIfEager(expr);
+    DCHECK_EQ(expr->scope()->outer_scope(), current_scope());
+    uint8_t flags = CreateClosureFlags::Encode(
+            expr->pretenure(), closure_scope()->is_function_scope(),
+            info()->flags().might_always_turbofan());
+    size_t entry = builder()->AllocateDeferredConstantPoolEntry();
+    builder()->CreateClosure(entry, GetCachedCreateClosureSlot(expr), flags);
+    function_literals_.push_back(std::make_pair(expr, entry));
+    AddToEagerLiteralsIfEager(expr);
 }
 
 void BytecodeGenerator::AddToEagerLiteralsIfEager(FunctionLiteral* literal) {
-  // Only parallel compile when there's a script (not the case for source
-  // position collection).
-  if (!script_.is_null() && literal->should_parallel_compile()) {
-    // If we should normally be eagerly compiling this function, we must be here
-    // because of post_parallel_compile_tasks_for_eager_toplevel.
-    DCHECK_IMPLIES(
-        literal->ShouldEagerCompile(),
-        info()->flags().post_parallel_compile_tasks_for_eager_toplevel());
-    // There exists a lazy compile dispatcher.
-    DCHECK(info()->dispatcher());
-    // There exists a cloneable character stream.
-    DCHECK(info()->character_stream()->can_be_cloned_for_parallel_access());
-
-    UnparkedScope scope(local_isolate_);
-    // If there doesn't already exist a SharedFunctionInfo for this function,
-    // then create one and enqueue it. Otherwise, we're reparsing (e.g. for the
-    // debugger, source position collection, call printing, recompile after
-    // flushing, etc.) and don't want to over-compile.
-    Handle<SharedFunctionInfo> shared_info;
-    if (!Script::FindSharedFunctionInfo(script_, local_isolate_, literal)
-             .ToHandle(&shared_info)) {
-      shared_info =
-          Compiler::GetSharedFunctionInfo(literal, script_, local_isolate_);
-      info()->dispatcher()->Enqueue(local_isolate_, shared_info,
-                                    info()->character_stream()->Clone());
-    }
-  } else if (eager_inner_literals_ && literal->ShouldEagerCompile()) {
-    DCHECK(!IsInEagerLiterals(literal, *eager_inner_literals_));
-    DCHECK(!literal->should_parallel_compile());
-    eager_inner_literals_->push_back(literal);
-  }
+    // Only parallel compile when there's a script (not the case for source
+    // position collection).
+    if (!script_.is_null() && literal->should_parallel_compile()) {
+        // If we should normally be eagerly compiling this function, we must be here
+        // because of post_parallel_compile_tasks_for_eager_toplevel.
+        DCHECK_IMPLIES(
+                literal->ShouldEagerCompile(),
+                info()->flags().post_parallel_compile_tasks_for_eager_toplevel());
+        // There exists a lazy compile dispatcher.
+        DCHECK(info()->dispatcher());
+        // There exists a cloneable character stream.
+        DCHECK(info()->character_stream()->can_be_cloned_for_parallel_access());
+
+        UnparkedScope scope(local_isolate_);
+        // If there doesn't already exist a SharedFunctionInfo for this function,
+        // then create one and enqueue it. Otherwise, we're reparsing (e.g. for the
+        // debugger, source position collection, call printing, recompile after
+        // flushing, etc.) and don't want to over-compile.
+        Handle<SharedFunctionInfo> shared_info;
+        if (!Script::FindSharedFunctionInfo(script_, local_isolate_, literal)
+                .ToHandle(&shared_info)) {
+            shared_info =
+                    Compiler::GetSharedFunctionInfo(literal, script_, local_isolate_);
+            info()->dispatcher()->Enqueue(local_isolate_, shared_info,
+                                          info()->character_stream()->Clone());
+        }
+    } else if (eager_inner_literals_ && literal->ShouldEagerCompile()) {
+        DCHECK(!IsInEagerLiterals(literal, *eager_inner_literals_));
+        DCHECK(!literal->should_parallel_compile());
+        eager_inner_literals_->push_back(literal);
+    }
 }
 
 void BytecodeGenerator::BuildClassLiteral(ClassLiteral* expr, Register name) {
-  size_t class_boilerplate_entry =
-      builder()->AllocateDeferredConstantPoolEntry();
-  class_literals_.push_back(std::make_pair(expr, class_boilerplate_entry));
-
-  VisitDeclarations(expr->scope()->declarations());
-  Register class_constructor = register_allocator()->NewRegister();
-
-  // Create the class brand symbol and store it on the context during class
-  // evaluation. This will be stored in the instance later in the constructor.
-  // We do this early so that invalid access to private methods or accessors
-  // in computed property keys throw.
-  if (expr->scope()->brand() != nullptr) {
-    Register brand = register_allocator()->NewRegister();
-    const AstRawString* class_name =
-        expr->scope()->class_variable() != nullptr
-            ? expr->scope()->class_variable()->raw_name()
-            : ast_string_constants()->anonymous_string();
-    builder()
-        ->LoadLiteral(class_name)
-        .StoreAccumulatorInRegister(brand)
-        .CallRuntime(Runtime::kCreatePrivateBrandSymbol, brand);
-    register_allocator()->ReleaseRegister(brand);
+    size_t class_boilerplate_entry =
+            builder()->AllocateDeferredConstantPoolEntry();
+    class_literals_.push_back(std::make_pair(expr, class_boilerplate_entry));
+
+    VisitDeclarations(expr->scope()->declarations());
+    Register class_constructor = register_allocator()->NewRegister();
+
+    // Create the class brand symbol and store it on the context during class
+    // evaluation. This will be stored in the instance later in the constructor.
+    // We do this early so that invalid access to private methods or accessors
+    // in computed property keys throw.
+    if (expr->scope()->brand() != nullptr) {
+        Register brand = register_allocator()->NewRegister();
+        const AstRawString* class_name =
+                expr->scope()->class_variable() != nullptr
+                ? expr->scope()->class_variable()->raw_name()
+                : ast_string_constants()->anonymous_string();
+        builder()
+                ->LoadLiteral(class_name)
+                .StoreAccumulatorInRegister(brand)
+                .CallRuntime(Runtime::kCreatePrivateBrandSymbol, brand);
+        register_allocator()->ReleaseRegister(brand);
 
-    BuildVariableAssignment(expr->scope()->brand(), Token::INIT,
-                            HoleCheckMode::kElided);
-  }
-
-  AccessorTable<ClassLiteral::Property> private_accessors(zone());
-  for (int i = 0; i < expr->private_members()->length(); i++) {
-    ClassLiteral::Property* property = expr->private_members()->at(i);
-    DCHECK(property->is_private());
-    switch (property->kind()) {
-      case ClassLiteral::Property::FIELD: {
-        // Initialize the private field variables early.
-        // Create the private name symbols for fields during class
-        // evaluation and store them on the context. These will be
-        // used as keys later during instance or static initialization.
-        RegisterAllocationScope private_name_register_scope(this);
-        Register private_name = register_allocator()->NewRegister();
-        VisitForRegisterValue(property->key(), private_name);
-        builder()
-            ->LoadLiteral(property->key()->AsLiteral()->AsRawPropertyName())
-            .StoreAccumulatorInRegister(private_name)
-            .CallRuntime(Runtime::kCreatePrivateNameSymbol, private_name);
-        DCHECK_NOT_NULL(property->private_name_var());
-        BuildVariableAssignment(property->private_name_var(), Token::INIT,
-                                HoleCheckMode::kElided);
-        break;
-      }
-      case ClassLiteral::Property::METHOD: {
-        RegisterAllocationScope register_scope(this);
-        VisitForAccumulatorValue(property->value());
-        BuildVariableAssignment(property->private_name_var(), Token::INIT,
+        BuildVariableAssignment(expr->scope()->brand(), Token::INIT,
                                 HoleCheckMode::kElided);
-        break;
-      }
-      // Collect private accessors into a table to merge the creation of
-      // those closures later.
-      case ClassLiteral::Property::GETTER: {
-        Literal* key = property->key()->AsLiteral();
-        DCHECK_NULL(private_accessors.LookupOrInsert(key)->getter);
-        private_accessors.LookupOrInsert(key)->getter = property;
-        break;
-      }
-      case ClassLiteral::Property::SETTER: {
-        Literal* key = property->key()->AsLiteral();
-        DCHECK_NULL(private_accessors.LookupOrInsert(key)->setter);
-        private_accessors.LookupOrInsert(key)->setter = property;
-        break;
-      }
-      default:
-        UNREACHABLE();
     }
-  }
 
-  {
-    RegisterAllocationScope register_scope(this);
-    RegisterList args = register_allocator()->NewGrowableRegisterList();
+    AccessorTable<ClassLiteral::Property> private_accessors(zone());
+    for (int i = 0; i < expr->private_members()->length(); i++) {
+        ClassLiteral::Property* property = expr->private_members()->at(i);
+        DCHECK(property->is_private());
+        switch (property->kind()) {
+            case ClassLiteral::Property::FIELD: {
+                // Initialize the private field variables early.
+                // Create the private name symbols for fields during class
+                // evaluation and store them on the context. These will be
+                // used as keys later during instance or static initialization.
+                RegisterAllocationScope private_name_register_scope(this);
+                Register private_name = register_allocator()->NewRegister();
+                VisitForRegisterValue(property->key(), private_name);
+                builder()
+                        ->LoadLiteral(property->key()->AsLiteral()->AsRawPropertyName())
+                        .StoreAccumulatorInRegister(private_name)
+                        .CallRuntime(Runtime::kCreatePrivateNameSymbol, private_name);
+                DCHECK_NOT_NULL(property->private_name_var());
+                BuildVariableAssignment(property->private_name_var(), Token::INIT,
+                                        HoleCheckMode::kElided);
+                break;
+            }
+            case ClassLiteral::Property::METHOD: {
+                RegisterAllocationScope register_scope(this);
+                VisitForAccumulatorValue(property->value());
+                BuildVariableAssignment(property->private_name_var(), Token::INIT,
+                                        HoleCheckMode::kElided);
+                break;
+            }
+                // Collect private accessors into a table to merge the creation of
+                // those closures later.
+            case ClassLiteral::Property::GETTER: {
+                Literal* key = property->key()->AsLiteral();
+                DCHECK_NULL(private_accessors.LookupOrInsert(key)->getter);
+                private_accessors.LookupOrInsert(key)->getter = property;
+                break;
+            }
+            case ClassLiteral::Property::SETTER: {
+                Literal* key = property->key()->AsLiteral();
+                DCHECK_NULL(private_accessors.LookupOrInsert(key)->setter);
+                private_accessors.LookupOrInsert(key)->setter = property;
+                break;
+            }
+            default:
+                UNREACHABLE();
+        }
+    }
 
-    Register class_boilerplate = register_allocator()->GrowRegisterList(&args);
-    Register class_constructor_in_args =
-        register_allocator()->GrowRegisterList(&args);
-    Register super_class = register_allocator()->GrowRegisterList(&args);
-    DCHECK_EQ(ClassBoilerplate::kFirstDynamicArgumentIndex,
-              args.register_count());
+    {
+        RegisterAllocationScope register_scope(this);
+        RegisterList args = register_allocator()->NewGrowableRegisterList();
 
-    VisitForAccumulatorValueOrTheHole(expr->extends());
-    builder()->StoreAccumulatorInRegister(super_class);
+        Register class_boilerplate = register_allocator()->GrowRegisterList(&args);
+        Register class_constructor_in_args =
+                register_allocator()->GrowRegisterList(&args);
+        Register super_class = register_allocator()->GrowRegisterList(&args);
+        DCHECK_EQ(ClassBoilerplate::kFirstDynamicArgumentIndex,
+                  args.register_count());
 
-    VisitFunctionLiteral(expr->constructor());
-    builder()
-        ->StoreAccumulatorInRegister(class_constructor)
-        .MoveRegister(class_constructor, class_constructor_in_args)
-        .LoadConstantPoolEntry(class_boilerplate_entry)
-        .StoreAccumulatorInRegister(class_boilerplate);
-
-    // Create computed names and method values nodes to store into the literal.
-    for (int i = 0; i < expr->public_members()->length(); i++) {
-      ClassLiteral::Property* property = expr->public_members()->at(i);
-      if (property->is_computed_name()) {
-        Register key = register_allocator()->GrowRegisterList(&args);
-
-        builder()->SetExpressionAsStatementPosition(property->key());
-        BuildLoadPropertyKey(property, key);
-        if (property->is_static()) {
-          // The static prototype property is read only. We handle the non
-          // computed property name case in the parser. Since this is the only
-          // case where we need to check for an own read only property we
-          // special case this so we do not need to do this for every property.
-
-          FeedbackSlot slot = GetDummyCompareICSlot();
-          BytecodeLabel done;
-          builder()
-              ->LoadLiteral(ast_string_constants()->prototype_string())
-              .CompareOperation(Token::Value::EQ_STRICT, key,
-                                feedback_index(slot))
-              .JumpIfFalse(ToBooleanMode::kAlreadyBoolean, &done)
-              .CallRuntime(Runtime::kThrowStaticPrototypeError)
-              .Bind(&done);
-        }
-
-        if (property->kind() == ClassLiteral::Property::FIELD) {
-          DCHECK(!property->is_private());
-          // Initialize field's name variable with the computed name.
-          DCHECK_NOT_NULL(property->computed_name_var());
-          builder()->LoadAccumulatorWithRegister(key);
-          BuildVariableAssignment(property->computed_name_var(), Token::INIT,
-                                  HoleCheckMode::kElided);
-        }
-      }
-
-      DCHECK(!property->is_private());
-
-      if (property->kind() == ClassLiteral::Property::FIELD) {
-        // We don't compute field's value here, but instead do it in the
-        // initializer function.
-        continue;
-      }
-
-      Register value = register_allocator()->GrowRegisterList(&args);
-      VisitForRegisterValue(property->value(), value);
-    }
-
-    builder()->CallRuntime(Runtime::kDefineClass, args);
-  }
+        VisitForAccumulatorValueOrTheHole(expr->extends());
+        builder()->StoreAccumulatorInRegister(super_class);
 
-  // Assign to the home object variable. Accumulator already contains the
-  // prototype.
-  Variable* home_object_variable = expr->home_object();
-  if (home_object_variable != nullptr) {
-    DCHECK(home_object_variable->is_used());
-    DCHECK(home_object_variable->IsContextSlot());
-    BuildVariableAssignment(home_object_variable, Token::INIT,
-                            HoleCheckMode::kElided);
-  }
-  Variable* static_home_object_variable = expr->static_home_object();
-  if (static_home_object_variable != nullptr) {
-    DCHECK(static_home_object_variable->is_used());
-    DCHECK(static_home_object_variable->IsContextSlot());
-    builder()->LoadAccumulatorWithRegister(class_constructor);
-    BuildVariableAssignment(static_home_object_variable, Token::INIT,
-                            HoleCheckMode::kElided);
-  }
+        VisitFunctionLiteral(expr->constructor());
+        builder()
+                ->StoreAccumulatorInRegister(class_constructor)
+                .MoveRegister(class_constructor, class_constructor_in_args)
+                .LoadConstantPoolEntry(class_boilerplate_entry)
+                .StoreAccumulatorInRegister(class_boilerplate);
+
+        // Create computed names and method values nodes to store into the literal.
+        for (int i = 0; i < expr->public_members()->length(); i++) {
+            ClassLiteral::Property* property = expr->public_members()->at(i);
+            if (property->is_computed_name()) {
+                Register key = register_allocator()->GrowRegisterList(&args);
+
+                builder()->SetExpressionAsStatementPosition(property->key());
+                BuildLoadPropertyKey(property, key);
+                if (property->is_static()) {
+                    // The static prototype property is read only. We handle the non
+                    // computed property name case in the parser. Since this is the only
+                    // case where we need to check for an own read only property we
+                    // special case this so we do not need to do this for every property.
+
+                    FeedbackSlot slot = GetDummyCompareICSlot();
+                    BytecodeLabel done;
+                    builder()
+                            ->LoadLiteral(ast_string_constants()->prototype_string())
+                            .CompareOperation(Token::Value::EQ_STRICT, key,
+                                              feedback_index(slot))
+                            .JumpIfFalse(ToBooleanMode::kAlreadyBoolean, &done)
+                            .CallRuntime(Runtime::kThrowStaticPrototypeError)
+                            .Bind(&done);
+                }
+
+                if (property->kind() == ClassLiteral::Property::FIELD) {
+                    DCHECK(!property->is_private());
+                    // Initialize field's name variable with the computed name.
+                    DCHECK_NOT_NULL(property->computed_name_var());
+                    builder()->LoadAccumulatorWithRegister(key);
+                    BuildVariableAssignment(property->computed_name_var(), Token::INIT,
+                                            HoleCheckMode::kElided);
+                }
+            }
 
-  // Assign to class variable.
-  Variable* class_variable = expr->scope()->class_variable();
-  if (class_variable != nullptr && class_variable->is_used()) {
-    DCHECK(class_variable->IsStackLocal() || class_variable->IsContextSlot());
-    builder()->LoadAccumulatorWithRegister(class_constructor);
-    BuildVariableAssignment(class_variable, Token::INIT,
-                            HoleCheckMode::kElided);
-  }
+            DCHECK(!property->is_private());
 
-  // Define private accessors, using only a single call to the runtime for
-  // each pair of corresponding getters and setters, in the order the first
-  // component is declared.
-  for (auto accessors : private_accessors.ordered_accessors()) {
-    RegisterAllocationScope inner_register_scope(this);
-    RegisterList accessors_reg = register_allocator()->NewRegisterList(2);
-    ClassLiteral::Property* getter = accessors.second->getter;
-    ClassLiteral::Property* setter = accessors.second->setter;
-    VisitLiteralAccessor(getter, accessors_reg[0]);
-    VisitLiteralAccessor(setter, accessors_reg[1]);
-    builder()->CallRuntime(Runtime::kCreatePrivateAccessors, accessors_reg);
-    Variable* var = getter != nullptr ? getter->private_name_var()
-                                      : setter->private_name_var();
-    DCHECK_NOT_NULL(var);
-    BuildVariableAssignment(var, Token::INIT, HoleCheckMode::kElided);
-  }
+            if (property->kind() == ClassLiteral::Property::FIELD) {
+                // We don't compute field's value here, but instead do it in the
+                // initializer function.
+                continue;
+            }
 
-  if (expr->instance_members_initializer_function() != nullptr) {
-    Register initializer =
-        VisitForRegisterValue(expr->instance_members_initializer_function());
+            Register value = register_allocator()->GrowRegisterList(&args);
+            VisitForRegisterValue(property->value(), value);
+        }
 
-    FeedbackSlot slot = feedback_spec()->AddStoreICSlot(language_mode());
-    builder()
-        ->LoadAccumulatorWithRegister(initializer)
-        .StoreClassFieldsInitializer(class_constructor, feedback_index(slot))
-        .LoadAccumulatorWithRegister(class_constructor);
-  }
+        builder()->CallRuntime(Runtime::kDefineClass, args);
+    }
 
-  if (expr->static_initializer() != nullptr) {
-    // TODO(gsathya): This can be optimized away to be a part of the
-    // class boilerplate in the future. The name argument can be
-    // passed to the DefineClass runtime function and have it set
-    // there.
-    if (name.is_valid()) {
-      Register key = register_allocator()->NewRegister();
-      builder()
-          ->LoadLiteral(ast_string_constants()->name_string())
-          .StoreAccumulatorInRegister(key);
-
-      DefineKeyedOwnPropertyInLiteralFlags data_property_flags =
-          DefineKeyedOwnPropertyInLiteralFlag::kNoFlags;
-      FeedbackSlot slot =
-          feedback_spec()->AddDefineKeyedOwnPropertyInLiteralICSlot();
-      builder()
-          ->LoadAccumulatorWithRegister(name)
-          .DefineKeyedOwnPropertyInLiteral(class_constructor, key,
-                                           data_property_flags,
-                                           feedback_index(slot));
+    // Assign to the home object variable. Accumulator already contains the
+    // prototype.
+    Variable* home_object_variable = expr->home_object();
+    if (home_object_variable != nullptr) {
+        DCHECK(home_object_variable->is_used());
+        DCHECK(home_object_variable->IsContextSlot());
+        BuildVariableAssignment(home_object_variable, Token::INIT,
+                                HoleCheckMode::kElided);
+    }
+    Variable* static_home_object_variable = expr->static_home_object();
+    if (static_home_object_variable != nullptr) {
+        DCHECK(static_home_object_variable->is_used());
+        DCHECK(static_home_object_variable->IsContextSlot());
+        builder()->LoadAccumulatorWithRegister(class_constructor);
+        BuildVariableAssignment(static_home_object_variable, Token::INIT,
+                                HoleCheckMode::kElided);
     }
 
-    RegisterList args = register_allocator()->NewRegisterList(1);
-    Register initializer = VisitForRegisterValue(expr->static_initializer());
+    // Assign to class variable.
+    Variable* class_variable = expr->scope()->class_variable();
+    if (class_variable != nullptr && class_variable->is_used()) {
+        DCHECK(class_variable->IsStackLocal() || class_variable->IsContextSlot());
+        builder()->LoadAccumulatorWithRegister(class_constructor);
+        BuildVariableAssignment(class_variable, Token::INIT,
+                                HoleCheckMode::kElided);
+    }
 
-    builder()
-        ->MoveRegister(class_constructor, args[0])
-        .CallProperty(initializer, args,
-                      feedback_index(feedback_spec()->AddCallICSlot()));
-  }
-  builder()->LoadAccumulatorWithRegister(class_constructor);
+    // Define private accessors, using only a single call to the runtime for
+    // each pair of corresponding getters and setters, in the order the first
+    // component is declared.
+    for (auto accessors : private_accessors.ordered_accessors()) {
+        RegisterAllocationScope inner_register_scope(this);
+        RegisterList accessors_reg = register_allocator()->NewRegisterList(2);
+        ClassLiteral::Property* getter = accessors.second->getter;
+        ClassLiteral::Property* setter = accessors.second->setter;
+        VisitLiteralAccessor(getter, accessors_reg[0]);
+        VisitLiteralAccessor(setter, accessors_reg[1]);
+        builder()->CallRuntime(Runtime::kCreatePrivateAccessors, accessors_reg);
+        Variable* var = getter != nullptr ? getter->private_name_var()
+                                          : setter->private_name_var();
+        DCHECK_NOT_NULL(var);
+        BuildVariableAssignment(var, Token::INIT, HoleCheckMode::kElided);
+    }
+
+    if (expr->instance_members_initializer_function() != nullptr) {
+        Register initializer =
+                VisitForRegisterValue(expr->instance_members_initializer_function());
+
+        FeedbackSlot slot = feedback_spec()->AddStoreICSlot(language_mode());
+        builder()
+                ->LoadAccumulatorWithRegister(initializer)
+                .StoreClassFieldsInitializer(class_constructor, feedback_index(slot))
+                .LoadAccumulatorWithRegister(class_constructor);
+    }
+
+    if (expr->static_initializer() != nullptr) {
+        // TODO(gsathya): This can be optimized away to be a part of the
+        // class boilerplate in the future. The name argument can be
+        // passed to the DefineClass runtime function and have it set
+        // there.
+        if (name.is_valid()) {
+            Register key = register_allocator()->NewRegister();
+            builder()
+                    ->LoadLiteral(ast_string_constants()->name_string())
+                    .StoreAccumulatorInRegister(key);
+
+            DefineKeyedOwnPropertyInLiteralFlags data_property_flags =
+                    DefineKeyedOwnPropertyInLiteralFlag::kNoFlags;
+            FeedbackSlot slot =
+                    feedback_spec()->AddDefineKeyedOwnPropertyInLiteralICSlot();
+            builder()
+                    ->LoadAccumulatorWithRegister(name)
+                    .DefineKeyedOwnPropertyInLiteral(class_constructor, key,
+                                                     data_property_flags,
+                                                     feedback_index(slot));
+        }
+
+        RegisterList args = register_allocator()->NewRegisterList(1);
+        Register initializer = VisitForRegisterValue(expr->static_initializer());
+
+        builder()
+                ->MoveRegister(class_constructor, args[0])
+                .CallProperty(initializer, args,
+                              feedback_index(feedback_spec()->AddCallICSlot()));
+    }
+    builder()->LoadAccumulatorWithRegister(class_constructor);
 }
 
 void BytecodeGenerator::VisitClassLiteral(ClassLiteral* expr) {
-  VisitClassLiteral(expr, Register::invalid_value());
+    VisitClassLiteral(expr, Register::invalid_value());
 }
 
 void BytecodeGenerator::VisitClassLiteral(ClassLiteral* expr, Register name) {
-  CurrentScope current_scope(this, expr->scope());
-  DCHECK_NOT_NULL(expr->scope());
-  if (expr->scope()->NeedsContext()) {
-    // Make sure to associate the source position for the class
-    // after the block context is created. Otherwise we have a mismatch
-    // between the scope and the context, where we already are in a
-    // block context for the class, but not yet in the class scope. Only do
-    // this if the current source position is inside the class scope though.
-    // For example:
-    //  * `var x = class {};` will break on `class` which is inside
-    //    the class scope, so we expect the BlockContext to be pushed.
-    //
-    //  * `new class x {};` will break on `new` which is outside the
-    //    class scope, so we expect the BlockContext to not be pushed yet.
-    base::Optional<BytecodeSourceInfo> source_info =
-        builder()->MaybePopSourcePosition(expr->scope()->start_position());
-    BuildNewLocalBlockContext(expr->scope());
-    ContextScope scope(this, expr->scope());
-    if (source_info) builder()->PushSourcePosition(*source_info);
-    BuildClassLiteral(expr, name);
-  } else {
-    BuildClassLiteral(expr, name);
-  }
+    CurrentScope current_scope(this, expr->scope());
+    DCHECK_NOT_NULL(expr->scope());
+    if (expr->scope()->NeedsContext()) {
+        // Make sure to associate the source position for the class
+        // after the block context is created. Otherwise we have a mismatch
+        // between the scope and the context, where we already are in a
+        // block context for the class, but not yet in the class scope. Only do
+        // this if the current source position is inside the class scope though.
+        // For example:
+        //  * `var x = class {};` will break on `class` which is inside
+        //    the class scope, so we expect the BlockContext to be pushed.
+        //
+        //  * `new class x {};` will break on `new` which is outside the
+        //    class scope, so we expect the BlockContext to not be pushed yet.
+        base::Optional<BytecodeSourceInfo> source_info =
+                builder()->MaybePopSourcePosition(expr->scope()->start_position());
+        BuildNewLocalBlockContext(expr->scope());
+        ContextScope scope(this, expr->scope());
+        if (source_info) builder()->PushSourcePosition(*source_info);
+        BuildClassLiteral(expr, name);
+    } else {
+        BuildClassLiteral(expr, name);
+    }
 }
 
 void BytecodeGenerator::BuildClassProperty(ClassLiteral::Property* property) {
-  RegisterAllocationScope register_scope(this);
-  Register key;
-
-  // Private methods are not initialized in BuildClassProperty.
-  DCHECK_IMPLIES(property->is_private(),
-                 property->kind() == ClassLiteral::Property::FIELD);
-  builder()->SetExpressionPosition(property->key());
-
-  bool is_literal_store = property->key()->IsPropertyName() &&
-                          !property->is_computed_name() &&
-                          !property->is_private();
-
-  if (!is_literal_store) {
-    key = register_allocator()->NewRegister();
-    if (property->is_computed_name()) {
-      DCHECK_EQ(property->kind(), ClassLiteral::Property::FIELD);
-      DCHECK(!property->is_private());
-      Variable* var = property->computed_name_var();
-      DCHECK_NOT_NULL(var);
-      // The computed name is already evaluated and stored in a variable at
-      // class definition time.
-      BuildVariableLoad(var, HoleCheckMode::kElided);
-      builder()->StoreAccumulatorInRegister(key);
-    } else if (property->is_private()) {
-      Variable* private_name_var = property->private_name_var();
-      DCHECK_NOT_NULL(private_name_var);
-      BuildVariableLoad(private_name_var, HoleCheckMode::kElided);
-      builder()->StoreAccumulatorInRegister(key);
-    } else {
-      VisitForRegisterValue(property->key(), key);
+    RegisterAllocationScope register_scope(this);
+    Register key;
+
+    // Private methods are not initialized in BuildClassProperty.
+    DCHECK_IMPLIES(property->is_private(),
+                   property->kind() == ClassLiteral::Property::FIELD);
+    builder()->SetExpressionPosition(property->key());
+
+    bool is_literal_store = property->key()->IsPropertyName() &&
+                            !property->is_computed_name() &&
+                            !property->is_private();
+
+    if (!is_literal_store) {
+        key = register_allocator()->NewRegister();
+        if (property->is_computed_name()) {
+            DCHECK_EQ(property->kind(), ClassLiteral::Property::FIELD);
+            DCHECK(!property->is_private());
+            Variable* var = property->computed_name_var();
+            DCHECK_NOT_NULL(var);
+            // The computed name is already evaluated and stored in a variable at
+            // class definition time.
+            BuildVariableLoad(var, HoleCheckMode::kElided);
+            builder()->StoreAccumulatorInRegister(key);
+        } else if (property->is_private()) {
+            Variable* private_name_var = property->private_name_var();
+            DCHECK_NOT_NULL(private_name_var);
+            BuildVariableLoad(private_name_var, HoleCheckMode::kElided);
+            builder()->StoreAccumulatorInRegister(key);
+        } else {
+            VisitForRegisterValue(property->key(), key);
+        }
     }
-  }
 
-  builder()->SetExpressionAsStatementPosition(property->value());
-  VisitForAccumulatorValue(property->value());
-
-  if (is_literal_store) {
-    FeedbackSlot slot = feedback_spec()->AddDefineNamedOwnICSlot();
-    builder()->DefineNamedOwnProperty(
-        builder()->Receiver(),
-        property->key()->AsLiteral()->AsRawPropertyName(),
-        feedback_index(slot));
-  } else {
-    FeedbackSlot slot = feedback_spec()->AddDefineKeyedOwnICSlot();
-    builder()->DefineKeyedOwnProperty(builder()->Receiver(), key,
-                                      feedback_index(slot));
-  }
+    builder()->SetExpressionAsStatementPosition(property->value());
+    VisitForAccumulatorValue(property->value());
+
+    if (is_literal_store) {
+        FeedbackSlot slot = feedback_spec()->AddDefineNamedOwnICSlot();
+        builder()->DefineNamedOwnProperty(
+                builder()->Receiver(),
+                property->key()->AsLiteral()->AsRawPropertyName(),
+                feedback_index(slot));
+    } else {
+        FeedbackSlot slot = feedback_spec()->AddDefineKeyedOwnICSlot();
+        builder()->DefineKeyedOwnProperty(builder()->Receiver(), key,
+                                          feedback_index(slot));
+    }
 }
 
 void BytecodeGenerator::VisitInitializeClassMembersStatement(
-    InitializeClassMembersStatement* stmt) {
-  for (int i = 0; i < stmt->fields()->length(); i++) {
-    BuildClassProperty(stmt->fields()->at(i));
-  }
+        InitializeClassMembersStatement* stmt) {
+    for (int i = 0; i < stmt->fields()->length(); i++) {
+        BuildClassProperty(stmt->fields()->at(i));
+    }
 }
 
 void BytecodeGenerator::VisitInitializeClassStaticElementsStatement(
-    InitializeClassStaticElementsStatement* stmt) {
-  for (int i = 0; i < stmt->elements()->length(); i++) {
-    ClassLiteral::StaticElement* element = stmt->elements()->at(i);
-    switch (element->kind()) {
-      case ClassLiteral::StaticElement::PROPERTY:
-        BuildClassProperty(element->property());
-        break;
-      case ClassLiteral::StaticElement::STATIC_BLOCK:
-        VisitBlock(element->static_block());
-        break;
+        InitializeClassStaticElementsStatement* stmt) {
+    for (int i = 0; i < stmt->elements()->length(); i++) {
+        ClassLiteral::StaticElement* element = stmt->elements()->at(i);
+        switch (element->kind()) {
+            case ClassLiteral::StaticElement::PROPERTY:
+                BuildClassProperty(element->property());
+                break;
+            case ClassLiteral::StaticElement::STATIC_BLOCK:
+                VisitBlock(element->static_block());
+                break;
+        }
     }
-  }
 }
 
 void BytecodeGenerator::BuildInvalidPropertyAccess(MessageTemplate tmpl,
                                                    Property* property) {
-  RegisterAllocationScope register_scope(this);
-  const AstRawString* name = property->key()->AsVariableProxy()->raw_name();
-  RegisterList args = register_allocator()->NewRegisterList(2);
-  builder()
-      ->LoadLiteral(Smi::FromEnum(tmpl))
-      .StoreAccumulatorInRegister(args[0])
-      .LoadLiteral(name)
-      .StoreAccumulatorInRegister(args[1])
-      .CallRuntime(Runtime::kNewTypeError, args)
-      .Throw();
+    RegisterAllocationScope register_scope(this);
+    const AstRawString* name = property->key()->AsVariableProxy()->raw_name();
+    RegisterList args = register_allocator()->NewRegisterList(2);
+    builder()
+            ->LoadLiteral(Smi::FromEnum(tmpl))
+            .StoreAccumulatorInRegister(args[0])
+            .LoadLiteral(name)
+            .StoreAccumulatorInRegister(args[1])
+            .CallRuntime(Runtime::kNewTypeError, args)
+            .Throw();
 }
 
 void BytecodeGenerator::BuildPrivateBrandInitialization(Register receiver,
                                                         Variable* brand) {
-  BuildVariableLoad(brand, HoleCheckMode::kElided);
-  int depth = execution_context()->ContextChainDepth(brand->scope());
-  ContextScope* class_context = execution_context()->Previous(depth);
-  if (class_context) {
-    Register brand_reg = register_allocator()->NewRegister();
-    FeedbackSlot slot = feedback_spec()->AddDefineKeyedOwnICSlot();
-    builder()
-        ->StoreAccumulatorInRegister(brand_reg)
-        .LoadAccumulatorWithRegister(class_context->reg())
-        .DefineKeyedOwnProperty(receiver, brand_reg, feedback_index(slot));
-  } else {
-    // We are in the slow case where super() is called from a nested
-    // arrow function or a eval(), so the class scope context isn't
-    // tracked in a context register in the stack, and we have to
-    // walk the context chain from the runtime to find it.
-    DCHECK_NE(info()->literal()->scope()->outer_scope(), brand->scope());
-    RegisterList brand_args = register_allocator()->NewRegisterList(4);
-    builder()
-        ->StoreAccumulatorInRegister(brand_args[1])
-        .MoveRegister(receiver, brand_args[0])
-        .MoveRegister(execution_context()->reg(), brand_args[2])
-        .LoadLiteral(Smi::FromInt(depth))
-        .StoreAccumulatorInRegister(brand_args[3])
-        .CallRuntime(Runtime::kAddPrivateBrand, brand_args);
-  }
+    BuildVariableLoad(brand, HoleCheckMode::kElided);
+    int depth = execution_context()->ContextChainDepth(brand->scope());
+    ContextScope* class_context = execution_context()->Previous(depth);
+    if (class_context) {
+        Register brand_reg = register_allocator()->NewRegister();
+        FeedbackSlot slot = feedback_spec()->AddDefineKeyedOwnICSlot();
+        builder()
+                ->StoreAccumulatorInRegister(brand_reg)
+                .LoadAccumulatorWithRegister(class_context->reg())
+                .DefineKeyedOwnProperty(receiver, brand_reg, feedback_index(slot));
+    } else {
+        // We are in the slow case where super() is called from a nested
+        // arrow function or a eval(), so the class scope context isn't
+        // tracked in a context register in the stack, and we have to
+        // walk the context chain from the runtime to find it.
+        DCHECK_NE(info()->literal()->scope()->outer_scope(), brand->scope());
+        RegisterList brand_args = register_allocator()->NewRegisterList(4);
+        builder()
+                ->StoreAccumulatorInRegister(brand_args[1])
+                .MoveRegister(receiver, brand_args[0])
+                .MoveRegister(execution_context()->reg(), brand_args[2])
+                .LoadLiteral(Smi::FromInt(depth))
+                .StoreAccumulatorInRegister(brand_args[3])
+                .CallRuntime(Runtime::kAddPrivateBrand, brand_args);
+    }
 }
 
 void BytecodeGenerator::BuildInstanceMemberInitialization(Register constructor,
                                                           Register instance) {
-  RegisterList args = register_allocator()->NewRegisterList(1);
-  Register initializer = register_allocator()->NewRegister();
+    RegisterList args = register_allocator()->NewRegisterList(1);
+    Register initializer = register_allocator()->NewRegister();
 
-  FeedbackSlot slot = feedback_spec()->AddLoadICSlot();
-  BytecodeLabel done;
+    FeedbackSlot slot = feedback_spec()->AddLoadICSlot();
+    BytecodeLabel done;
 
-  builder()
-      ->LoadClassFieldsInitializer(constructor, feedback_index(slot))
-      // TODO(gsathya): This jump can be elided for the base
-      // constructor and derived constructor. This is only required
-      // when called from an arrow function.
-      .JumpIfUndefined(&done)
-      .StoreAccumulatorInRegister(initializer)
-      .MoveRegister(instance, args[0])
-      .CallProperty(initializer, args,
-                    feedback_index(feedback_spec()->AddCallICSlot()))
-      .Bind(&done);
+    builder()
+            ->LoadClassFieldsInitializer(constructor, feedback_index(slot))
+                    // TODO(gsathya): This jump can be elided for the base
+                    // constructor and derived constructor. This is only required
+                    // when called from an arrow function.
+            .JumpIfUndefined(&done)
+            .StoreAccumulatorInRegister(initializer)
+            .MoveRegister(instance, args[0])
+            .CallProperty(initializer, args,
+                          feedback_index(feedback_spec()->AddCallICSlot()))
+            .Bind(&done);
 }
 
 void BytecodeGenerator::VisitNativeFunctionLiteral(
-    NativeFunctionLiteral* expr) {
-  size_t entry = builder()->AllocateDeferredConstantPoolEntry();
-  int index = feedback_spec()->AddCreateClosureSlot();
-  uint8_t flags = CreateClosureFlags::Encode(false, false, false);
-  builder()->CreateClosure(entry, index, flags);
-  native_function_literals_.push_back(std::make_pair(expr, entry));
+        NativeFunctionLiteral* expr) {
+    size_t entry = builder()->AllocateDeferredConstantPoolEntry();
+    int index = feedback_spec()->AddCreateClosureSlot();
+    uint8_t flags = CreateClosureFlags::Encode(false, false, false);
+    builder()->CreateClosure(entry, index, flags);
+    native_function_literals_.push_back(std::make_pair(expr, entry));
 }
 
 void BytecodeGenerator::VisitConditional(Conditional* expr) {
-  ConditionalControlFlowBuilder conditional_builder(
-      builder(), block_coverage_builder_, expr);
-
-  if (expr->condition()->ToBooleanIsTrue()) {
-    // Generate then block unconditionally as always true.
-    conditional_builder.Then();
-    VisitForAccumulatorValue(expr->then_expression());
-  } else if (expr->condition()->ToBooleanIsFalse()) {
-    // Generate else block unconditionally if it exists.
-    conditional_builder.Else();
-    VisitForAccumulatorValue(expr->else_expression());
-  } else {
-    VisitForTest(expr->condition(), conditional_builder.then_labels(),
-                 conditional_builder.else_labels(), TestFallthrough::kThen);
-
-    conditional_builder.Then();
-    VisitForAccumulatorValue(expr->then_expression());
-    conditional_builder.JumpToEnd();
-
-    conditional_builder.Else();
-    VisitForAccumulatorValue(expr->else_expression());
-  }
+    ConditionalControlFlowBuilder conditional_builder(
+            builder(), block_coverage_builder_, expr);
+
+    if (expr->condition()->ToBooleanIsTrue()) {
+        // Generate then block unconditionally as always true.
+        conditional_builder.Then();
+        VisitForAccumulatorValue(expr->then_expression());
+    } else if (expr->condition()->ToBooleanIsFalse()) {
+        // Generate else block unconditionally if it exists.
+        conditional_builder.Else();
+        VisitForAccumulatorValue(expr->else_expression());
+    } else {
+        VisitForTest(expr->condition(), conditional_builder.then_labels(),
+                     conditional_builder.else_labels(), TestFallthrough::kThen);
+
+        conditional_builder.Then();
+        VisitForAccumulatorValue(expr->then_expression());
+        conditional_builder.JumpToEnd();
+
+        conditional_builder.Else();
+        VisitForAccumulatorValue(expr->else_expression());
+    }
 }
 
 void BytecodeGenerator::VisitLiteral(Literal* expr) {
-  if (execution_result()->IsEffect()) return;
-  switch (expr->type()) {
-    case Literal::kSmi:
-      builder()->LoadLiteral(expr->AsSmiLiteral());
-      break;
-    case Literal::kHeapNumber:
-      builder()->LoadLiteral(expr->AsNumber());
-      break;
-    case Literal::kUndefined:
-      builder()->LoadUndefined();
-      break;
-    case Literal::kBoolean:
-      builder()->LoadBoolean(expr->ToBooleanIsTrue());
-      execution_result()->SetResultIsBoolean();
-      break;
-    case Literal::kNull:
-      builder()->LoadNull();
-      break;
-    case Literal::kTheHole:
-      builder()->LoadTheHole();
-      break;
-    case Literal::kString:
-      builder()->LoadLiteral(expr->AsRawString());
-      execution_result()->SetResultIsString();
-      break;
-    case Literal::kBigInt:
-      builder()->LoadLiteral(expr->AsBigInt());
-      break;
-  }
+    if (execution_result()->IsEffect()) return;
+    switch (expr->type()) {
+        case Literal::kSmi:
+            builder()->LoadLiteral(expr->AsSmiLiteral());
+            break;
+        case Literal::kHeapNumber:
+            builder()->LoadLiteral(expr->AsNumber());
+            break;
+        case Literal::kUndefined:
+            builder()->LoadUndefined();
+            break;
+        case Literal::kBoolean:
+            builder()->LoadBoolean(expr->ToBooleanIsTrue());
+            execution_result()->SetResultIsBoolean();
+            break;
+        case Literal::kNull:
+            builder()->LoadNull();
+            break;
+        case Literal::kTheHole:
+            builder()->LoadTheHole();
+            break;
+        case Literal::kString:
+            builder()->LoadLiteral(expr->AsRawString());
+            execution_result()->SetResultIsString();
+            break;
+        case Literal::kBigInt:
+            builder()->LoadLiteral(expr->AsBigInt());
+            break;
+    }
 }
 
 void BytecodeGenerator::VisitRegExpLiteral(RegExpLiteral* expr) {
-  // Materialize a regular expression literal.
-  builder()->CreateRegExpLiteral(
-      expr->raw_pattern(), feedback_index(feedback_spec()->AddLiteralSlot()),
-      expr->flags());
+    // Materialize a regular expression literal.
+    builder()->CreateRegExpLiteral(
+            expr->raw_pattern(), feedback_index(feedback_spec()->AddLiteralSlot()),
+            expr->flags());
 }
 
 void BytecodeGenerator::BuildCreateObjectLiteral(Register literal,
                                                  uint8_t flags, size_t entry) {
-  // TODO(cbruni): Directly generate runtime call for literals we cannot
-  // optimize once the CreateShallowObjectLiteral stub is in sync with the TF
-  // optimizations.
-  int literal_index = feedback_index(feedback_spec()->AddLiteralSlot());
-  builder()
-      ->CreateObjectLiteral(entry, literal_index, flags)
-      .StoreAccumulatorInRegister(literal);
+    // TODO(cbruni): Directly generate runtime call for literals we cannot
+    // optimize once the CreateShallowObjectLiteral stub is in sync with the TF
+    // optimizations.
+    int literal_index = feedback_index(feedback_spec()->AddLiteralSlot());
+    builder()
+            ->CreateObjectLiteral(entry, literal_index, flags)
+            .StoreAccumulatorInRegister(literal);
 }
 
 void BytecodeGenerator::VisitObjectLiteral(ObjectLiteral* expr) {
-  expr->builder()->InitDepthAndFlags();
-
-  // Fast path for the empty object literal which doesn't need an
-  // AllocationSite.
-  if (expr->builder()->IsEmptyObjectLiteral()) {
-    DCHECK(expr->builder()->IsFastCloningSupported());
-    builder()->CreateEmptyObjectLiteral();
-    return;
-  }
+    expr->builder()->InitDepthAndFlags();
 
-  Variable* home_object = expr->home_object();
-  if (home_object != nullptr) {
-    DCHECK(home_object->is_used());
-    DCHECK(home_object->IsContextSlot());
-  }
-  MultipleEntryBlockContextScope object_literal_context_scope(
-      this, home_object ? home_object->scope() : nullptr);
-
-  // Deep-copy the literal boilerplate.
-  uint8_t flags = CreateObjectLiteralFlags::Encode(
-      expr->builder()->ComputeFlags(),
-      expr->builder()->IsFastCloningSupported());
-
-  Register literal = register_allocator()->NewRegister();
-
-  // Create literal object.
-  int property_index = 0;
-  bool clone_object_spread =
-      expr->properties()->first()->kind() == ObjectLiteral::Property::SPREAD;
-  if (clone_object_spread) {
-    // Avoid the slow path for spreads in the following common cases:
-    //   1) `let obj = { ...source }`
-    //   2) `let obj = { ...source, override: 1 }`
-    //   3) `let obj = { ...source, ...overrides }`
-    RegisterAllocationScope register_scope(this);
-    Expression* property = expr->properties()->first()->value();
-    Register from_value = VisitForRegisterValue(property);
-    int clone_index = feedback_index(feedback_spec()->AddCloneObjectSlot());
-    builder()->CloneObject(from_value, flags, clone_index);
-    builder()->StoreAccumulatorInRegister(literal);
-    property_index++;
-  } else {
-    size_t entry;
-    // If constant properties is an empty fixed array, use a cached empty fixed
-    // array to ensure it's only added to the constant pool once.
-    if (expr->builder()->properties_count() == 0) {
-      entry = builder()->EmptyObjectBoilerplateDescriptionConstantPoolEntry();
-    } else {
-      entry = builder()->AllocateDeferredConstantPoolEntry();
-      object_literals_.push_back(std::make_pair(expr->builder(), entry));
+    // Fast path for the empty object literal which doesn't need an
+    // AllocationSite.
+    if (expr->builder()->IsEmptyObjectLiteral()) {
+        DCHECK(expr->builder()->IsFastCloningSupported());
+        builder()->CreateEmptyObjectLiteral();
+        return;
     }
-    BuildCreateObjectLiteral(literal, flags, entry);
-  }
 
-  // Store computed values into the literal.
-  AccessorTable<ObjectLiteral::Property> accessor_table(zone());
-  for (; property_index < expr->properties()->length(); property_index++) {
-    ObjectLiteral::Property* property = expr->properties()->at(property_index);
-    if (property->is_computed_name()) break;
-    if (!clone_object_spread && property->IsCompileTimeValue()) continue;
-
-    RegisterAllocationScope inner_register_scope(this);
-    Literal* key = property->key()->AsLiteral();
-    switch (property->kind()) {
-      case ObjectLiteral::Property::SPREAD:
-        UNREACHABLE();
-      case ObjectLiteral::Property::CONSTANT:
-      case ObjectLiteral::Property::MATERIALIZED_LITERAL:
-        DCHECK(clone_object_spread || !property->value()->IsCompileTimeValue());
-        V8_FALLTHROUGH;
-      case ObjectLiteral::Property::COMPUTED: {
-        // It is safe to use [[Put]] here because the boilerplate already
-        // contains computed properties with an uninitialized value.
-        Register key_reg;
-        if (key->IsStringLiteral()) {
-          DCHECK(key->IsPropertyName());
-        } else {
-          key_reg = register_allocator()->NewRegister();
-          builder()->SetExpressionPosition(property->key());
-          VisitForRegisterValue(property->key(), key_reg);
-        }
-
-        object_literal_context_scope.SetEnteredIf(
-            property->value()->IsConciseMethodDefinition());
-        builder()->SetExpressionPosition(property->value());
-
-        if (property->emit_store()) {
-          VisitForAccumulatorValue(property->value());
-          if (key->IsStringLiteral()) {
-            FeedbackSlot slot = feedback_spec()->AddDefineNamedOwnICSlot();
-            builder()->DefineNamedOwnProperty(literal, key->AsRawPropertyName(),
-                                              feedback_index(slot));
-          } else {
-            FeedbackSlot slot = feedback_spec()->AddDefineKeyedOwnICSlot();
-            builder()->DefineKeyedOwnProperty(literal, key_reg,
-                                              feedback_index(slot));
-          }
+    Variable* home_object = expr->home_object();
+    if (home_object != nullptr) {
+        DCHECK(home_object->is_used());
+        DCHECK(home_object->IsContextSlot());
+    }
+    MultipleEntryBlockContextScope object_literal_context_scope(
+            this, home_object ? home_object->scope() : nullptr);
+
+    // Deep-copy the literal boilerplate.
+    uint8_t flags = CreateObjectLiteralFlags::Encode(
+            expr->builder()->ComputeFlags(),
+            expr->builder()->IsFastCloningSupported());
+
+    Register literal = register_allocator()->NewRegister();
+
+    // Create literal object.
+    int property_index = 0;
+    bool clone_object_spread =
+            expr->properties()->first()->kind() == ObjectLiteral::Property::SPREAD;
+    if (clone_object_spread) {
+        // Avoid the slow path for spreads in the following common cases:
+        //   1) `let obj = { ...source }`
+        //   2) `let obj = { ...source, override: 1 }`
+        //   3) `let obj = { ...source, ...overrides }`
+        RegisterAllocationScope register_scope(this);
+        Expression* property = expr->properties()->first()->value();
+        Register from_value = VisitForRegisterValue(property);
+        int clone_index = feedback_index(feedback_spec()->AddCloneObjectSlot());
+        builder()->CloneObject(from_value, flags, clone_index);
+        builder()->StoreAccumulatorInRegister(literal);
+        property_index++;
+    } else {
+        size_t entry;
+        // If constant properties is an empty fixed array, use a cached empty fixed
+        // array to ensure it's only added to the constant pool once.
+        if (expr->builder()->properties_count() == 0) {
+            entry = builder()->EmptyObjectBoilerplateDescriptionConstantPoolEntry();
         } else {
-          VisitForEffect(property->value());
-        }
-        break;
-      }
-      case ObjectLiteral::Property::PROTOTYPE: {
-        // __proto__:null is handled by CreateObjectLiteral.
-        if (property->IsNullPrototype()) break;
-        DCHECK(property->emit_store());
-        DCHECK(!property->NeedsSetFunctionName());
-        RegisterList args = register_allocator()->NewRegisterList(2);
-        builder()->MoveRegister(literal, args[0]);
-        object_literal_context_scope.SetEnteredIf(false);
-        builder()->SetExpressionPosition(property->value());
-        VisitForRegisterValue(property->value(), args[1]);
-        builder()->CallRuntime(Runtime::kInternalSetPrototype, args);
-        break;
-      }
-      case ObjectLiteral::Property::GETTER:
-        if (property->emit_store()) {
-          accessor_table.LookupOrInsert(key)->getter = property;
-        }
-        break;
-      case ObjectLiteral::Property::SETTER:
-        if (property->emit_store()) {
-          accessor_table.LookupOrInsert(key)->setter = property;
-        }
-        break;
+            entry = builder()->AllocateDeferredConstantPoolEntry();
+            object_literals_.push_back(std::make_pair(expr->builder(), entry));
+        }
+        BuildCreateObjectLiteral(literal, flags, entry);
+    }
+
+    // Store computed values into the literal.
+    AccessorTable<ObjectLiteral::Property> accessor_table(zone());
+    for (; property_index < expr->properties()->length(); property_index++) {
+        ObjectLiteral::Property* property = expr->properties()->at(property_index);
+        if (property->is_computed_name()) break;
+        if (!clone_object_spread && property->IsCompileTimeValue()) {
+            // xqg start object
+
+            // If it's compile time value, then it's probably constant that's
+            // handled in the ObjectLiteral creation code above. For now
+            // we don't replace such values if they are Smi, since constants are
+            // probably (?) not tainted in the first place.
+
+            int init_reg_index = register_allocator()->next_register_index();
+            RegisterList temp_args = register_allocator()->NewRegisterList(4);
+            Register acc_init = register_allocator()->NewRegister();
+            builder()->StoreAccumulatorInRegister(acc_init);
+            VisitForAccumulatorValue(property->value());
+
+            builder()->StoreAccumulatorInRegister(temp_args[0])
+                    .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                    .StoreAccumulatorInRegister(temp_args[1])
+                    .LoadLiteral(Smi::FromInt(expr->position()))
+                    .StoreAccumulatorInRegister(temp_args[2])
+                    .LoadLiteral(Smi::FromInt(property_index))
+                    .StoreAccumulatorInRegister(temp_args[3])
+                    .CallRuntime(Runtime::kTaintAnalysis_OnVisitObjectLiteral, temp_args);
+
+            builder()->LoadAccumulatorWithRegister(acc_init);
+            register_allocator()->ReleaseRegisters(init_reg_index);
+
+            // xqg end object
+            continue;
+        }
+
+        RegisterAllocationScope inner_register_scope(this);
+        Literal* key = property->key()->AsLiteral();
+        switch (property->kind()) {
+            case ObjectLiteral::Property::SPREAD:
+                UNREACHABLE();
+            case ObjectLiteral::Property::CONSTANT:
+            case ObjectLiteral::Property::MATERIALIZED_LITERAL:
+                DCHECK(clone_object_spread || !property->value()->IsCompileTimeValue());
+                V8_FALLTHROUGH;
+            case ObjectLiteral::Property::COMPUTED: {
+                // It is safe to use [[Put]] here because the boilerplate already
+                // contains computed properties with an uninitialized value.
+                Register key_reg;
+                if (key->IsStringLiteral()) {
+                    DCHECK(key->IsPropertyName());
+                } else {
+                    key_reg = register_allocator()->NewRegister();
+                    builder()->SetExpressionPosition(property->key());
+                    VisitForRegisterValue(property->key(), key_reg);
+                }
+
+                // xqg start
+                VisitForAccumulatorValue(property->value());
+                {
+                    Register temp1 = register_allocator()->NewRegister();
+                    BytecodeLabel replace_smi_done;
+                    builder()
+                            ->JumpIfNotSmi(&replace_smi_done)
+                            .StoreAccumulatorInRegister(temp1)
+                            .CallRuntime(Runtime::kTaintAnalysis_ReplaceSmiResult, temp1)
+                            .Bind(&replace_smi_done);
+
+                    register_allocator()->ReleaseRegister(temp1);
+                }
+                int init_reg_index = register_allocator()->next_register_index();
+                RegisterList temp_args = register_allocator()->NewRegisterList(4);
+                Register acc_init = register_allocator()->NewRegister();
+                builder()->StoreAccumulatorInRegister(acc_init);
+
+                builder()->StoreAccumulatorInRegister(temp_args[0])
+                        .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                        .StoreAccumulatorInRegister(temp_args[1])
+                        .LoadLiteral(Smi::FromInt(expr->position()))
+                        .StoreAccumulatorInRegister(temp_args[2])
+                        .LoadLiteral(Smi::FromInt(property_index))
+                        .StoreAccumulatorInRegister(temp_args[3])
+                        .CallRuntime(Runtime::kTaintAnalysis_OnVisitObjectLiteral, temp_args);
+
+                builder()->LoadAccumulatorWithRegister(acc_init);
+                register_allocator()->ReleaseRegisters(init_reg_index);
+                // xqg end object
+
+                object_literal_context_scope.SetEnteredIf(
+                        property->value()->IsConciseMethodDefinition());
+                builder()->SetExpressionPosition(property->value());
+
+                if (property->emit_store()) {
+                    // VisitForAccumulatorValue(property->value()); xqg comment
+                    if (key->IsStringLiteral()) {
+                        FeedbackSlot slot = feedback_spec()->AddDefineNamedOwnICSlot();
+                        builder()->DefineNamedOwnProperty(literal, key->AsRawPropertyName(),
+                                                          feedback_index(slot));
+                    } else {
+                        FeedbackSlot slot = feedback_spec()->AddDefineKeyedOwnICSlot();
+                        builder()->DefineKeyedOwnProperty(literal, key_reg,
+                                                          feedback_index(slot));
+                    }
+//        } else {
+//          VisitForEffect(property->value());
+                }
+                break;
+            }
+            case ObjectLiteral::Property::PROTOTYPE: {
+                // __proto__:null is handled by CreateObjectLiteral.
+                if (property->IsNullPrototype()) break;
+                DCHECK(property->emit_store());
+                DCHECK(!property->NeedsSetFunctionName());
+                RegisterList args = register_allocator()->NewRegisterList(2);
+                builder()->MoveRegister(literal, args[0]);
+                object_literal_context_scope.SetEnteredIf(false);
+                builder()->SetExpressionPosition(property->value());
+                VisitForRegisterValue(property->value(), args[1]);
+                builder()->CallRuntime(Runtime::kInternalSetPrototype, args);
+                break;
+            }
+            case ObjectLiteral::Property::GETTER:
+                if (property->emit_store()) {
+                    accessor_table.LookupOrInsert(key)->getter = property;
+                }
+                break;
+            case ObjectLiteral::Property::SETTER:
+                if (property->emit_store()) {
+                    accessor_table.LookupOrInsert(key)->setter = property;
+                }
+                break;
+        }
     }
-  }
 
     // Define accessors, using only a single call to the runtime for each pair
     // of corresponding getters and setters.
     object_literal_context_scope.SetEnteredIf(true);
     for (auto accessors : accessor_table.ordered_accessors()) {
-      RegisterAllocationScope inner_register_scope(this);
-      RegisterList args = register_allocator()->NewRegisterList(5);
-      builder()->MoveRegister(literal, args[0]);
-      VisitForRegisterValue(accessors.first, args[1]);
-      VisitLiteralAccessor(accessors.second->getter, args[2]);
-      VisitLiteralAccessor(accessors.second->setter, args[3]);
-      builder()
-          ->LoadLiteral(Smi::FromInt(NONE))
-          .StoreAccumulatorInRegister(args[4])
-          .CallRuntime(Runtime::kDefineAccessorPropertyUnchecked, args);
-    }
-
-  // Object literals have two parts. The "static" part on the left contains no
-  // computed property names, and so we can compute its map ahead of time; see
-  // Runtime_CreateObjectLiteralBoilerplate. The second "dynamic" part starts
-  // with the first computed property name and continues with all properties to
-  // its right. All the code from above initializes the static component of the
-  // object literal, and arranges for the map of the result to reflect the
-  // static order in which the keys appear. For the dynamic properties, we
-  // compile them into a series of "SetOwnProperty" runtime calls. This will
-  // preserve insertion order.
-  for (; property_index < expr->properties()->length(); property_index++) {
-    ObjectLiteral::Property* property = expr->properties()->at(property_index);
-    RegisterAllocationScope inner_register_scope(this);
-
-    bool should_be_in_object_literal_scope =
-        (property->value()->IsConciseMethodDefinition() ||
-         property->value()->IsAccessorFunctionDefinition());
-
-    if (property->IsPrototype()) {
-      // __proto__:null is handled by CreateObjectLiteral.
-      if (property->IsNullPrototype()) continue;
-      DCHECK(property->emit_store());
-      DCHECK(!property->NeedsSetFunctionName());
-      RegisterList args = register_allocator()->NewRegisterList(2);
-      builder()->MoveRegister(literal, args[0]);
-
-      DCHECK(!should_be_in_object_literal_scope);
-      object_literal_context_scope.SetEnteredIf(false);
-      builder()->SetExpressionPosition(property->value());
-      VisitForRegisterValue(property->value(), args[1]);
-      builder()->CallRuntime(Runtime::kInternalSetPrototype, args);
-      continue;
-    }
-
-    switch (property->kind()) {
-      case ObjectLiteral::Property::CONSTANT:
-      case ObjectLiteral::Property::COMPUTED:
-      case ObjectLiteral::Property::MATERIALIZED_LITERAL: {
-        // Computed property keys don't belong to the object literal scope (even
-        // if they're syntactically inside it).
-        if (property->is_computed_name()) {
-          object_literal_context_scope.SetEnteredIf(false);
-        }
-        Register key = register_allocator()->NewRegister();
-        BuildLoadPropertyKey(property, key);
-
-        object_literal_context_scope.SetEnteredIf(
-            should_be_in_object_literal_scope);
-        builder()->SetExpressionPosition(property->value());
-        Register value;
-
-        // Static class fields require the name property to be set on
-        // the class, meaning we can't wait until the
-        // DefineKeyedOwnPropertyInLiteral call later to set the name.
-        if (property->value()->IsClassLiteral() &&
-            property->value()->AsClassLiteral()->static_initializer() !=
-                nullptr) {
-          value = register_allocator()->NewRegister();
-          VisitClassLiteral(property->value()->AsClassLiteral(), key);
-          builder()->StoreAccumulatorInRegister(value);
-        } else {
-          value = VisitForRegisterValue(property->value());
-        }
+        RegisterAllocationScope inner_register_scope(this);
+        RegisterList args = register_allocator()->NewRegisterList(5);
+        builder()->MoveRegister(literal, args[0]);
+        VisitForRegisterValue(accessors.first, args[1]);
+        VisitLiteralAccessor(accessors.second->getter, args[2]);
+        VisitLiteralAccessor(accessors.second->setter, args[3]);
+        builder()
+                ->LoadLiteral(Smi::FromInt(NONE))
+                .StoreAccumulatorInRegister(args[4])
+                .CallRuntime(Runtime::kDefineAccessorPropertyUnchecked, args);
+    }
+
+    // Object literals have two parts. The "static" part on the left contains no
+    // computed property names, and so we can compute its map ahead of time; see
+    // Runtime_CreateObjectLiteralBoilerplate. The second "dynamic" part starts
+    // with the first computed property name and continues with all properties to
+    // its right. All the code from above initializes the static component of the
+    // object literal, and arranges for the map of the result to reflect the
+    // static order in which the keys appear. For the dynamic properties, we
+    // compile them into a series of "SetOwnProperty" runtime calls. This will
+    // preserve insertion order.
+    for (; property_index < expr->properties()->length(); property_index++) {
+        ObjectLiteral::Property* property = expr->properties()->at(property_index);
+        RegisterAllocationScope inner_register_scope(this);
 
-        DefineKeyedOwnPropertyInLiteralFlags data_property_flags =
-            DefineKeyedOwnPropertyInLiteralFlag::kNoFlags;
-        if (property->NeedsSetFunctionName()) {
-          data_property_flags |=
-              DefineKeyedOwnPropertyInLiteralFlag::kSetFunctionName;
+        bool should_be_in_object_literal_scope =
+                (property->value()->IsConciseMethodDefinition() ||
+                 property->value()->IsAccessorFunctionDefinition());
+
+        if (property->IsPrototype()) {
+            // __proto__:null is handled by CreateObjectLiteral.
+            if (property->IsNullPrototype()) continue;
+            DCHECK(property->emit_store());
+            DCHECK(!property->NeedsSetFunctionName());
+            RegisterList args = register_allocator()->NewRegisterList(2);
+            builder()->MoveRegister(literal, args[0]);
+
+            DCHECK(!should_be_in_object_literal_scope);
+            object_literal_context_scope.SetEnteredIf(false);
+            builder()->SetExpressionPosition(property->value());
+            VisitForRegisterValue(property->value(), args[1]);
+            builder()->CallRuntime(Runtime::kInternalSetPrototype, args);
+            continue;
         }
 
-        FeedbackSlot slot =
-            feedback_spec()->AddDefineKeyedOwnPropertyInLiteralICSlot();
-        builder()
-            ->LoadAccumulatorWithRegister(value)
-            .DefineKeyedOwnPropertyInLiteral(literal, key, data_property_flags,
-                                             feedback_index(slot));
-        break;
-      }
-      case ObjectLiteral::Property::GETTER:
-      case ObjectLiteral::Property::SETTER: {
-        // Computed property keys don't belong to the object literal scope (even
-        // if they're syntactically inside it).
-        if (property->is_computed_name()) {
-          object_literal_context_scope.SetEnteredIf(false);
+        switch (property->kind()) {
+            case ObjectLiteral::Property::CONSTANT:
+            case ObjectLiteral::Property::COMPUTED:
+            case ObjectLiteral::Property::MATERIALIZED_LITERAL: {
+                // Computed property keys don't belong to the object literal scope (even
+                // if they're syntactically inside it).
+                if (property->is_computed_name()) {
+                    object_literal_context_scope.SetEnteredIf(false);
+                }
+                Register key = register_allocator()->NewRegister();
+                BuildLoadPropertyKey(property, key);
+
+                object_literal_context_scope.SetEnteredIf(
+                        should_be_in_object_literal_scope);
+                builder()->SetExpressionPosition(property->value());
+                Register value;
+
+                // Static class fields require the name property to be set on
+                // the class, meaning we can't wait until the
+                // DefineKeyedOwnPropertyInLiteral call later to set the name.
+                if (property->value()->IsClassLiteral() &&
+                    property->value()->AsClassLiteral()->static_initializer() !=
+                    nullptr) {
+                    value = register_allocator()->NewRegister();
+                    VisitClassLiteral(property->value()->AsClassLiteral(), key);
+                    builder()->StoreAccumulatorInRegister(value);
+                } else {
+                    value = VisitForRegisterValue(property->value());
+                }
+
+                // xqg start object
+                {
+                    Register temp1 = register_allocator()->NewRegister();
+                    BytecodeLabel replace_smi_done;
+                    builder()
+                            ->JumpIfNotSmi(&replace_smi_done)
+                            .StoreAccumulatorInRegister(temp1)
+                            .CallRuntime(Runtime::kTaintAnalysis_ReplaceSmiResult, temp1)
+                            .Bind(&replace_smi_done);
+
+                    register_allocator()->ReleaseRegister(temp1);
+                }
+
+                int init_reg_index = register_allocator()->next_register_index();
+                RegisterList temp_args = register_allocator()->NewRegisterList(4);
+                Register acc_init = register_allocator()->NewRegister();
+                builder()->StoreAccumulatorInRegister(acc_init);
+
+                builder()->StoreAccumulatorInRegister(temp_args[0])
+                        .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                        .StoreAccumulatorInRegister(temp_args[1])
+                        .LoadLiteral(Smi::FromInt(expr->position()))
+                        .StoreAccumulatorInRegister(temp_args[2])
+                        .LoadLiteral(Smi::FromInt(property_index))
+                        .StoreAccumulatorInRegister(temp_args[3])
+                        .CallRuntime(Runtime::kTaintAnalysis_OnVisitObjectLiteral, temp_args);
+
+                builder()->LoadAccumulatorWithRegister(acc_init);
+                register_allocator()->ReleaseRegisters(init_reg_index);
+                // xqg end
+
+                DefineKeyedOwnPropertyInLiteralFlags data_property_flags =
+                        DefineKeyedOwnPropertyInLiteralFlag::kNoFlags;
+                if (property->NeedsSetFunctionName()) {
+                    data_property_flags |=
+                            DefineKeyedOwnPropertyInLiteralFlag::kSetFunctionName;
+                }
+
+                FeedbackSlot slot =
+                        feedback_spec()->AddDefineKeyedOwnPropertyInLiteralICSlot();
+                builder()
+                        ->LoadAccumulatorWithRegister(value)
+                        .DefineKeyedOwnPropertyInLiteral(literal, key, data_property_flags,
+                                                         feedback_index(slot));
+                break;
+            }
+            case ObjectLiteral::Property::GETTER:
+            case ObjectLiteral::Property::SETTER: {
+                // Computed property keys don't belong to the object literal scope (even
+                // if they're syntactically inside it).
+                if (property->is_computed_name()) {
+                    object_literal_context_scope.SetEnteredIf(false);
+                }
+                RegisterList args = register_allocator()->NewRegisterList(4);
+                builder()->MoveRegister(literal, args[0]);
+                BuildLoadPropertyKey(property, args[1]);
+
+                DCHECK(should_be_in_object_literal_scope);
+                object_literal_context_scope.SetEnteredIf(true);
+                builder()->SetExpressionPosition(property->value());
+                VisitForRegisterValue(property->value(), args[2]);
+                builder()
+                        ->LoadLiteral(Smi::FromInt(NONE))
+                        .StoreAccumulatorInRegister(args[3]);
+                Runtime::FunctionId function_id =
+                        property->kind() == ObjectLiteral::Property::GETTER
+                        ? Runtime::kDefineGetterPropertyUnchecked
+                        : Runtime::kDefineSetterPropertyUnchecked;
+                builder()->CallRuntime(function_id, args);
+                break;
+            }
+            case ObjectLiteral::Property::SPREAD: {
+                RegisterList args = register_allocator()->NewRegisterList(2);
+                builder()->MoveRegister(literal, args[0]);
+                builder()->SetExpressionPosition(property->value());
+                object_literal_context_scope.SetEnteredIf(false);
+                VisitForRegisterValue(property->value(), args[1]);
+                builder()->CallRuntime(Runtime::kInlineCopyDataProperties, args);
+
+                // xqg start, object spread, put this after copy thus target has values.
+                int init_reg_index = register_allocator()->next_register_index();
+                RegisterList temp_args = register_allocator()->NewRegisterList(4);
+                Register acc_init = register_allocator()->NewRegister();
+                builder()->StoreAccumulatorInRegister(acc_init);
+                builder()->MoveRegister(args[0], temp_args[0])
+                        .MoveRegister(args[1], temp_args[1])
+                        .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                        .StoreAccumulatorInRegister(temp_args[2])
+                        .LoadLiteral(Smi::FromInt(expr->position()))
+                        .StoreAccumulatorInRegister(temp_args[3])
+                        .CallRuntime(Runtime::kTaintAnalysis_OnVisitObjectLiteralSpread, temp_args);
+
+                builder()->LoadAccumulatorWithRegister(acc_init);
+                register_allocator()->ReleaseRegisters(init_reg_index);
+                // xqg end
+
+                break;
+            }
+            case ObjectLiteral::Property::PROTOTYPE:
+                UNREACHABLE();  // Handled specially above.
         }
-        RegisterList args = register_allocator()->NewRegisterList(4);
-        builder()->MoveRegister(literal, args[0]);
-        BuildLoadPropertyKey(property, args[1]);
+    }
 
-        DCHECK(should_be_in_object_literal_scope);
+    builder()->LoadAccumulatorWithRegister(literal);
+    if (home_object != nullptr) {
         object_literal_context_scope.SetEnteredIf(true);
-        builder()->SetExpressionPosition(property->value());
-        VisitForRegisterValue(property->value(), args[2]);
-        builder()
-            ->LoadLiteral(Smi::FromInt(NONE))
-            .StoreAccumulatorInRegister(args[3]);
-        Runtime::FunctionId function_id =
-            property->kind() == ObjectLiteral::Property::GETTER
-                ? Runtime::kDefineGetterPropertyUnchecked
-                : Runtime::kDefineSetterPropertyUnchecked;
-        builder()->CallRuntime(function_id, args);
-        break;
-      }
-      case ObjectLiteral::Property::SPREAD: {
-        RegisterList args = register_allocator()->NewRegisterList(2);
-        builder()->MoveRegister(literal, args[0]);
-        builder()->SetExpressionPosition(property->value());
-        object_literal_context_scope.SetEnteredIf(false);
-        VisitForRegisterValue(property->value(), args[1]);
-        builder()->CallRuntime(Runtime::kInlineCopyDataProperties, args);
-        break;
-      }
-      case ObjectLiteral::Property::PROTOTYPE:
-        UNREACHABLE();  // Handled specially above.
+        BuildVariableAssignment(home_object, Token::INIT, HoleCheckMode::kElided);
     }
-  }
-
-  builder()->LoadAccumulatorWithRegister(literal);
-  if (home_object != nullptr) {
-    object_literal_context_scope.SetEnteredIf(true);
-    BuildVariableAssignment(home_object, Token::INIT, HoleCheckMode::kElided);
-  }
 }
 
 // Fill an array with values from an iterator, starting at a given index. It is
@@ -3322,698 +3490,833 @@ void BytecodeGenerator::VisitObjectLiteral(ObjectLiteral* expr) {
 //   array[index++] = value
 // }
 void BytecodeGenerator::BuildFillArrayWithIterator(
-    IteratorRecord iterator, Register array, Register index, Register value,
-    FeedbackSlot next_value_slot, FeedbackSlot next_done_slot,
-    FeedbackSlot index_slot, FeedbackSlot element_slot) {
-  DCHECK(array.is_valid());
-  DCHECK(index.is_valid());
-  DCHECK(value.is_valid());
-
-  LoopBuilder loop_builder(builder(), nullptr, nullptr, feedback_spec());
-  LoopScope loop_scope(this, &loop_builder);
-
-  // Call the iterator's .next() method. Break from the loop if the `done`
-  // property is truthy, otherwise load the value from the iterator result and
-  // append the argument.
-  BuildIteratorNext(iterator, value);
-  builder()->LoadNamedProperty(
-      value, ast_string_constants()->done_string(),
-      feedback_index(feedback_spec()->AddLoadICSlot()));
-  loop_builder.BreakIfTrue(ToBooleanMode::kConvertToBoolean);
-
-  loop_builder.LoopBody();
-  builder()
-      // value = value.value
-      ->LoadNamedProperty(value, ast_string_constants()->value_string(),
-                          feedback_index(next_value_slot))
-      // array[index] = value
-      .StoreInArrayLiteral(array, index, feedback_index(element_slot))
-      // index++
-      .LoadAccumulatorWithRegister(index)
-      .UnaryOperation(Token::INC, feedback_index(index_slot))
-      .StoreAccumulatorInRegister(index);
-  loop_builder.BindContinueTarget();
+        IteratorRecord iterator, Register array, Register index, Register value,
+        FeedbackSlot next_value_slot, FeedbackSlot next_done_slot,
+        FeedbackSlot index_slot, FeedbackSlot element_slot) {
+    DCHECK(array.is_valid());
+    DCHECK(index.is_valid());
+    DCHECK(value.is_valid());
+
+    LoopBuilder loop_builder(builder(), nullptr, nullptr, feedback_spec());
+    LoopScope loop_scope(this, &loop_builder);
+
+    // Call the iterator's .next() method. Break from the loop if the `done`
+    // property is truthy, otherwise load the value from the iterator result and
+    // append the argument.
+    BuildIteratorNext(iterator, value);
+    builder()->LoadNamedProperty(
+            value, ast_string_constants()->done_string(),
+            feedback_index(feedback_spec()->AddLoadICSlot()));
+    loop_builder.BreakIfTrue(ToBooleanMode::kConvertToBoolean);
+
+    loop_builder.LoopBody();
+    builder()
+            // value = value.value
+            ->LoadNamedProperty(value, ast_string_constants()->value_string(),
+                                feedback_index(next_value_slot))
+                    // array[index] = value
+            .StoreInArrayLiteral(array, index, feedback_index(element_slot))
+                    // index++
+            .LoadAccumulatorWithRegister(index)
+            .UnaryOperation(Token::INC, feedback_index(index_slot))
+            .StoreAccumulatorInRegister(index);
+    loop_builder.BindContinueTarget();
 }
 
 void BytecodeGenerator::BuildCreateArrayLiteral(
-    const ZonePtrList<Expression>* elements, ArrayLiteral* expr) {
-  RegisterAllocationScope register_scope(this);
-  // Make this the first register allocated so that it has a chance of aliasing
-  // the next register allocated after returning from this function.
-  Register array = register_allocator()->NewRegister();
-  Register index = register_allocator()->NewRegister();
-  SharedFeedbackSlot element_slot(feedback_spec(),
-                                  FeedbackSlotKind::kStoreInArrayLiteral);
-  ZonePtrList<Expression>::const_iterator current = elements->begin();
-  ZonePtrList<Expression>::const_iterator end = elements->end();
-  bool is_empty = elements->is_empty();
-
-  if (!is_empty && (*current)->IsSpread()) {
-    // If we have a leading spread, use CreateArrayFromIterable to create
-    // an array from it and then add the remaining components to that array.
-    VisitForAccumulatorValue(*current);
-    builder()->SetExpressionPosition((*current)->AsSpread()->expression());
-    builder()->CreateArrayFromIterable().StoreAccumulatorInRegister(array);
-
-    if (++current != end) {
-      // If there are remaning elements, prepare the index register that is
-      // used for adding those elements. The next index is the length of the
-      // newly created array.
-      auto length = ast_string_constants()->length_string();
-      int length_load_slot = feedback_index(feedback_spec()->AddLoadICSlot());
-      builder()
-          ->LoadNamedProperty(array, length, length_load_slot)
-          .StoreAccumulatorInRegister(index);
-    }
-  } else {
-    // There are some elements before the first (if any) spread, and we can
-    // use a boilerplate when creating the initial array from those elements.
-
-    // First, allocate a constant pool entry for the boilerplate that will
-    // be created during finalization, and will contain all the constant
-    // elements before the first spread. This also handle the empty array case
-    // and one-shot optimization.
-
-    ArrayLiteralBoilerplateBuilder* array_literal_builder = nullptr;
-    if (expr != nullptr) {
-      array_literal_builder = expr->builder();
-    } else {
-      DCHECK(!elements->is_empty());
-
-      // get first_spread_index
-      int first_spread_index = -1;
-      for (auto iter = elements->begin(); iter != elements->end(); iter++) {
-        if ((*iter)->IsSpread()) {
-          first_spread_index = static_cast<int>(iter - elements->begin());
-          break;
-        }
-      }
-
-      array_literal_builder = zone()->New<ArrayLiteralBoilerplateBuilder>(
-          elements, first_spread_index);
-      array_literal_builder->InitDepthAndFlags();
-    }
-
-    DCHECK(array_literal_builder != nullptr);
-    uint8_t flags = CreateArrayLiteralFlags::Encode(
-        array_literal_builder->IsFastCloningSupported(),
-        array_literal_builder->ComputeFlags());
-    if (is_empty) {
-      // Empty array literal fast-path.
-      int literal_index = feedback_index(feedback_spec()->AddLiteralSlot());
-      DCHECK(array_literal_builder->IsFastCloningSupported());
-      builder()->CreateEmptyArrayLiteral(literal_index);
+        const ZonePtrList<Expression>* elements, ArrayLiteral* expr) {
+    RegisterAllocationScope register_scope(this);
+    // Make this the first register allocated so that it has a chance of aliasing
+    // the next register allocated after returning from this function.
+    Register array = register_allocator()->NewRegister();
+    Register index = register_allocator()->NewRegister();
+    SharedFeedbackSlot element_slot(feedback_spec(),
+                                    FeedbackSlotKind::kStoreInArrayLiteral);
+    ZonePtrList<Expression>::const_iterator current = elements->begin();
+    ZonePtrList<Expression>::const_iterator end = elements->end();
+    bool is_empty = elements->is_empty();
+
+    // xqg start
+    int spread_count = 0;
+    int spread_index = 0;
+    for (auto iter = elements->begin(); iter != elements->end(); iter++) {
+        if ((*iter)->IsSpread()) spread_count = spread_count + 1;
+    }
+    RegisterList spread_object_list;
+    if (spread_count > 0) {
+        spread_object_list = register_allocator()->NewRegisterList(spread_count);
+    }
+    // xqg end
+
+    if (!is_empty && (*current)->IsSpread()) {
+        // If we have a leading spread, use CreateArrayFromIterable to create
+        // an array from it and then add the remaining components to that array.
+        VisitForAccumulatorValue(*current);
+
+        // xqg start
+        builder()->StoreAccumulatorInRegister(spread_object_list[spread_index]);
+        spread_index = spread_index + 1;
+        // xqg end
+
+        builder()->SetExpressionPosition((*current)->AsSpread()->expression());
+        builder()->CreateArrayFromIterable().StoreAccumulatorInRegister(array);
+
+        if (++current != end) {
+            // If there are remaning elements, prepare the index register that is
+            // used for adding those elements. The next index is the length of the
+            // newly created array.
+            auto length = ast_string_constants()->length_string();
+            int length_load_slot = feedback_index(feedback_spec()->AddLoadICSlot());
+            builder()
+                    ->LoadNamedProperty(array, length, length_load_slot)
+                    .StoreAccumulatorInRegister(index);
+        }
     } else {
-      // Create array literal from boilerplate.
-      size_t entry = builder()->AllocateDeferredConstantPoolEntry();
-      array_literals_.push_back(std::make_pair(array_literal_builder, entry));
-      int literal_index = feedback_index(feedback_spec()->AddLiteralSlot());
-      builder()->CreateArrayLiteral(entry, literal_index, flags);
-    }
-    builder()->StoreAccumulatorInRegister(array);
-
-    ZonePtrList<Expression>::const_iterator first_spread_or_end =
-        array_literal_builder->first_spread_index() >= 0
-            ? current + array_literal_builder->first_spread_index()
-            : end;
-
-    // Insert the missing non-constant elements, up until the first spread
-    // index, into the initial array (the remaining elements will be inserted
-    // below).
-    DCHECK_EQ(current, elements->begin());
-    int array_index = 0;
-    for (; current != first_spread_or_end; ++current, array_index++) {
-      Expression* subexpr = *current;
-      DCHECK(!subexpr->IsSpread());
-      // Skip the constants.
-      if (subexpr->IsCompileTimeValue()) continue;
-
-      builder()
-          ->LoadLiteral(Smi::FromInt(array_index))
-          .StoreAccumulatorInRegister(index);
-      VisitForAccumulatorValue(subexpr);
-      builder()->StoreInArrayLiteral(array, index,
-                                     feedback_index(element_slot.Get()));
-    }
-
-    if (current != end) {
-      // If there are remaining elements, prepare the index register
-      // to store the next element, which comes from the first spread.
-      builder()
-          ->LoadLiteral(Smi::FromInt(array_index))
-          .StoreAccumulatorInRegister(index);
+        // There are some elements before the first (if any) spread, and we can
+        // use a boilerplate when creating the initial array from those elements.
+
+        // First, allocate a constant pool entry for the boilerplate that will
+        // be created during finalization, and will contain all the constant
+        // elements before the first spread. This also handle the empty array case
+        // and one-shot optimization.
+
+        ArrayLiteralBoilerplateBuilder* array_literal_builder = nullptr;
+        if (expr != nullptr) {
+            array_literal_builder = expr->builder();
+        } else {
+            DCHECK(!elements->is_empty());
+
+            // get first_spread_index
+            int first_spread_index = -1;
+            for (auto iter = elements->begin(); iter != elements->end(); iter++) {
+                if ((*iter)->IsSpread()) {
+                    first_spread_index = static_cast<int>(iter - elements->begin());
+                    break;
+                }
+            }
+
+            array_literal_builder = zone()->New<ArrayLiteralBoilerplateBuilder>(
+                    elements, first_spread_index);
+            array_literal_builder->InitDepthAndFlags();
+        }
+
+        DCHECK(array_literal_builder != nullptr);
+        uint8_t flags = CreateArrayLiteralFlags::Encode(
+                array_literal_builder->IsFastCloningSupported(),
+                array_literal_builder->ComputeFlags());
+        if (is_empty) {
+            // Empty array literal fast-path.
+            int literal_index = feedback_index(feedback_spec()->AddLiteralSlot());
+            DCHECK(array_literal_builder->IsFastCloningSupported());
+            builder()->CreateEmptyArrayLiteral(literal_index);
+        } else {
+            // Create array literal from boilerplate.
+            size_t entry = builder()->AllocateDeferredConstantPoolEntry();
+            array_literals_.push_back(std::make_pair(array_literal_builder, entry));
+            int literal_index = feedback_index(feedback_spec()->AddLiteralSlot());
+            builder()->CreateArrayLiteral(entry, literal_index, flags);
+        }
+        builder()->StoreAccumulatorInRegister(array);
+
+        ZonePtrList<Expression>::const_iterator first_spread_or_end =
+                array_literal_builder->first_spread_index() >= 0
+                ? current + array_literal_builder->first_spread_index()
+                : end;
+
+        // Insert the missing non-constant elements, up until the first spread
+        // index, into the initial array (the remaining elements will be inserted
+        // below).
+        DCHECK_EQ(current, elements->begin());
+        int array_index = 0;
+        for (; current != first_spread_or_end; ++current, array_index++) {
+            Expression* subexpr = *current;
+            DCHECK(!subexpr->IsSpread());
+            // Skip the constants.
+            if (subexpr->IsCompileTimeValue()) continue;
+
+            builder()
+                    ->LoadLiteral(Smi::FromInt(array_index))
+                    .StoreAccumulatorInRegister(index);
+            VisitForAccumulatorValue(subexpr);
+            builder()->StoreInArrayLiteral(array, index,
+                                           feedback_index(element_slot.Get()));
+        }
+
+        if (current != end) {
+            // If there are remaining elements, prepare the index register
+            // to store the next element, which comes from the first spread.
+            builder()
+                    ->LoadLiteral(Smi::FromInt(array_index))
+                    .StoreAccumulatorInRegister(index);
+        }
     }
-  }
 
-  // Now build insertions for the remaining elements from current to end.
-  SharedFeedbackSlot index_slot(feedback_spec(), FeedbackSlotKind::kBinaryOp);
-  SharedFeedbackSlot length_slot(
-      feedback_spec(), feedback_spec()->GetStoreICSlot(LanguageMode::kStrict));
-  for (; current != end; ++current) {
-    Expression* subexpr = *current;
-    if (subexpr->IsSpread()) {
-      RegisterAllocationScope scope(this);
-      builder()->SetExpressionPosition(subexpr->AsSpread()->expression());
-      VisitForAccumulatorValue(subexpr->AsSpread()->expression());
-      builder()->SetExpressionPosition(subexpr->AsSpread()->expression());
-      IteratorRecord iterator = BuildGetIteratorRecord(IteratorType::kNormal);
-
-      Register value = register_allocator()->NewRegister();
-      FeedbackSlot next_value_load_slot = feedback_spec()->AddLoadICSlot();
-      FeedbackSlot next_done_load_slot = feedback_spec()->AddLoadICSlot();
-      FeedbackSlot real_index_slot = index_slot.Get();
-      FeedbackSlot real_element_slot = element_slot.Get();
-      BuildFillArrayWithIterator(iterator, array, index, value,
-                                 next_value_load_slot, next_done_load_slot,
-                                 real_index_slot, real_element_slot);
-    } else if (!subexpr->IsTheHoleLiteral()) {
-      // literal[index++] = subexpr
-      VisitForAccumulatorValue(subexpr);
-      builder()
-          ->StoreInArrayLiteral(array, index,
-                                feedback_index(element_slot.Get()))
-          .LoadAccumulatorWithRegister(index);
-      // Only increase the index if we are not the last element.
-      if (current + 1 != end) {
-        builder()
-            ->UnaryOperation(Token::INC, feedback_index(index_slot.Get()))
-            .StoreAccumulatorInRegister(index);
-      }
-    } else {
-      // literal.length = ++index
-      // length_slot is only used when there are holes.
-      auto length = ast_string_constants()->length_string();
-      builder()
-          ->LoadAccumulatorWithRegister(index)
-          .UnaryOperation(Token::INC, feedback_index(index_slot.Get()))
-          .StoreAccumulatorInRegister(index)
-          .SetNamedProperty(array, length, feedback_index(length_slot.Get()),
-                            LanguageMode::kStrict);
+    // Now build insertions for the remaining elements from current to end.
+    SharedFeedbackSlot index_slot(feedback_spec(), FeedbackSlotKind::kBinaryOp);
+    SharedFeedbackSlot length_slot(
+            feedback_spec(), feedback_spec()->GetStoreICSlot(LanguageMode::kStrict));
+    for (; current != end; ++current) {
+        Expression* subexpr = *current;
+        if (subexpr->IsSpread()) {
+            RegisterAllocationScope scope(this);
+            builder()->SetExpressionPosition(subexpr->AsSpread()->expression());
+            VisitForAccumulatorValue(subexpr->AsSpread()->expression());
+            // xqg start
+            builder()->StoreAccumulatorInRegister(spread_object_list[spread_index]);
+            spread_index = spread_index + 1;
+            // xqg end
+            builder()->SetExpressionPosition(subexpr->AsSpread()->expression());
+            IteratorRecord iterator = BuildGetIteratorRecord(IteratorType::kNormal);
+
+            Register value = register_allocator()->NewRegister();
+            FeedbackSlot next_value_load_slot = feedback_spec()->AddLoadICSlot();
+            FeedbackSlot next_done_load_slot = feedback_spec()->AddLoadICSlot();
+            FeedbackSlot real_index_slot = index_slot.Get();
+            FeedbackSlot real_element_slot = element_slot.Get();
+            BuildFillArrayWithIterator(iterator, array, index, value,
+                                       next_value_load_slot, next_done_load_slot,
+                                       real_index_slot, real_element_slot);
+        } else if (!subexpr->IsTheHoleLiteral()) {
+            // literal[index++] = subexpr
+            VisitForAccumulatorValue(subexpr);
+            builder()
+                    ->StoreInArrayLiteral(array, index,
+                                          feedback_index(element_slot.Get()))
+                    .LoadAccumulatorWithRegister(index);
+            // Only increase the index if we are not the last element.
+            if (current + 1 != end) {
+                builder()
+                        ->UnaryOperation(Token::INC, feedback_index(index_slot.Get()))
+                        .StoreAccumulatorInRegister(index);
+            }
+        } else {
+            // literal.length = ++index
+            // length_slot is only used when there are holes.
+            auto length = ast_string_constants()->length_string();
+            builder()
+                    ->LoadAccumulatorWithRegister(index)
+                    .UnaryOperation(Token::INC, feedback_index(index_slot.Get()))
+                    .StoreAccumulatorInRegister(index)
+                    .SetNamedProperty(array, length, feedback_index(length_slot.Get()),
+                                      LanguageMode::kStrict);
+        }
     }
-  }
 
-  builder()->LoadAccumulatorWithRegister(array);
+    builder()->LoadAccumulatorWithRegister(array);
+
+    // xqg start
+    if (expr != nullptr){
+        int init_reg_index = register_allocator()->next_register_index();
+        RegisterList temp_args = register_allocator()->NewRegisterList(3 + spread_count);
+        Register acc_init = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(acc_init);
+
+        builder()->StoreAccumulatorInRegister(temp_args[0]);
+        builder()->LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                .StoreAccumulatorInRegister(temp_args[1]);
+        builder()->LoadLiteral(Smi::FromInt(expr->position()));
+        builder()->StoreAccumulatorInRegister(temp_args[2]);
+
+        for (int i = 0; i < spread_count; i++) {
+            builder()->LoadAccumulatorWithRegister(spread_object_list[i])
+                    .StoreAccumulatorInRegister(temp_args[3 + i]);
+        }
+        builder()->CallRuntime(Runtime::kTaintAnalysis_OnVisitArrayLiteral, temp_args);
+
+        builder()->LoadAccumulatorWithRegister(acc_init);
+        register_allocator()->ReleaseRegisters(init_reg_index);
+
+    }
+    // xqg end
 }
 
 void BytecodeGenerator::VisitArrayLiteral(ArrayLiteral* expr) {
-  expr->builder()->InitDepthAndFlags();
-  BuildCreateArrayLiteral(expr->values(), expr);
+    expr->builder()->InitDepthAndFlags();
+    BuildCreateArrayLiteral(expr->values(), expr);
 }
 
 void BytecodeGenerator::VisitVariableProxy(VariableProxy* proxy) {
-  builder()->SetExpressionPosition(proxy);
-  BuildVariableLoad(proxy->var(), proxy->hole_check_mode());
+    builder()->SetExpressionPosition(proxy);
+    // BuildVariableLoad(proxy->var(), proxy->hole_check_mode());
+    BuildVariableLoad(proxy, proxy->hole_check_mode()); // xqg
 }
 
 bool BytecodeGenerator::IsVariableInRegister(Variable* var, Register reg) {
-  BytecodeRegisterOptimizer* optimizer = builder()->GetRegisterOptimizer();
-  if (optimizer) {
-    return optimizer->IsVariableInRegister(var, reg);
-  }
-  return false;
+    BytecodeRegisterOptimizer* optimizer = builder()->GetRegisterOptimizer();
+    if (optimizer) {
+        return optimizer->IsVariableInRegister(var, reg);
+    }
+    return false;
 }
 
 void BytecodeGenerator::SetVariableInRegister(Variable* var, Register reg) {
-  BytecodeRegisterOptimizer* optimizer = builder()->GetRegisterOptimizer();
-  if (optimizer) {
-    optimizer->SetVariableInRegister(var, reg);
-  }
+    BytecodeRegisterOptimizer* optimizer = builder()->GetRegisterOptimizer();
+    if (optimizer) {
+        optimizer->SetVariableInRegister(var, reg);
+    }
+}
+
+// xqg start
+void BytecodeGenerator::BuildVariableLoad(VariableProxy* proxy,
+                                          HoleCheckMode hole_check_mode,
+                                          TypeofMode typeof_mode){
+
+    BuildVariableLoad(proxy->var(), hole_check_mode, typeof_mode);
+
+    // xqg visit proxy call load
+    {
+        int init_reg_index = register_allocator()->next_register_index();
+        RegisterList temp_args = register_allocator()->NewRegisterList(3);
+        Register acc_init = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(acc_init);
+
+        builder()->StoreAccumulatorInRegister(temp_args[0])
+                .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                .StoreAccumulatorInRegister(temp_args[1])
+                .LoadLiteral(Smi::FromInt(proxy->position()))
+                .StoreAccumulatorInRegister(temp_args[2])
+                .CallRuntime(Runtime::kTaintAnalysis_OnVisitVariableProxy, temp_args);
+
+        builder()->LoadAccumulatorWithRegister(acc_init);
+        register_allocator()->ReleaseRegisters(init_reg_index);
+    }
+    // xqg end
 }
+// xqg end
 
 void BytecodeGenerator::BuildVariableLoad(Variable* variable,
                                           HoleCheckMode hole_check_mode,
                                           TypeofMode typeof_mode) {
-  switch (variable->location()) {
-    case VariableLocation::LOCAL: {
-      Register source(builder()->Local(variable->index()));
-      // We need to load the variable into the accumulator, even when in a
-      // VisitForRegisterScope, in order to avoid register aliasing if
-      // subsequent expressions assign to the same variable.
-      builder()->LoadAccumulatorWithRegister(source);
-      if (hole_check_mode == HoleCheckMode::kRequired) {
-        BuildThrowIfHole(variable);
-      }
-      break;
-    }
-    case VariableLocation::PARAMETER: {
-      Register source;
-      if (variable->IsReceiver()) {
-        source = builder()->Receiver();
-      } else {
-        source = builder()->Parameter(variable->index());
-      }
-      // We need to load the variable into the accumulator, even when in a
-      // VisitForRegisterScope, in order to avoid register aliasing if
-      // subsequent expressions assign to the same variable.
-      builder()->LoadAccumulatorWithRegister(source);
-      if (hole_check_mode == HoleCheckMode::kRequired) {
-        BuildThrowIfHole(variable);
-      }
-      break;
-    }
-    case VariableLocation::UNALLOCATED: {
-      // The global identifier "undefined" is immutable. Everything
-      // else could be reassigned. For performance, we do a pointer comparison
-      // rather than checking if the raw_name is really "undefined".
-      if (variable->raw_name() == ast_string_constants()->undefined_string()) {
-        builder()->LoadUndefined();
-      } else {
-        FeedbackSlot slot = GetCachedLoadGlobalICSlot(typeof_mode, variable);
-        builder()->LoadGlobal(variable->raw_name(), feedback_index(slot),
-                              typeof_mode);
-      }
-      break;
-    }
-    case VariableLocation::CONTEXT: {
-      int depth = execution_context()->ContextChainDepth(variable->scope());
-      ContextScope* context = execution_context()->Previous(depth);
-      Register context_reg;
-      if (context) {
-        context_reg = context->reg();
-        depth = 0;
-      } else {
-        context_reg = execution_context()->reg();
-      }
-
-      BytecodeArrayBuilder::ContextSlotMutability immutable =
-          (variable->maybe_assigned() == kNotAssigned)
-              ? BytecodeArrayBuilder::kImmutableSlot
-              : BytecodeArrayBuilder::kMutableSlot;
-      Register acc = Register::virtual_accumulator();
-      if (immutable == BytecodeArrayBuilder::kImmutableSlot &&
-          IsVariableInRegister(variable, acc)) {
-        return;
-      }
+    switch (variable->location()) {
+        case VariableLocation::LOCAL: {
+            Register source(builder()->Local(variable->index()));
+            // We need to load the variable into the accumulator, even when in a
+            // VisitForRegisterScope, in order to avoid register aliasing if
+            // subsequent expressions assign to the same variable.
+            builder()->LoadAccumulatorWithRegister(source);
+            if (hole_check_mode == HoleCheckMode::kRequired) {
+                BuildThrowIfHole(variable);
+            }
+            break;
+        }
+        case VariableLocation::PARAMETER: {
+            Register source;
+            if (variable->IsReceiver()) {
+                source = builder()->Receiver();
+            } else {
+                source = builder()->Parameter(variable->index());
+            }
+            // We need to load the variable into the accumulator, even when in a
+            // VisitForRegisterScope, in order to avoid register aliasing if
+            // subsequent expressions assign to the same variable.
+            builder()->LoadAccumulatorWithRegister(source);
+            if (hole_check_mode == HoleCheckMode::kRequired) {
+                BuildThrowIfHole(variable);
+            }
+            break;
+        }
+        case VariableLocation::UNALLOCATED: {
+            // The global identifier "undefined" is immutable. Everything
+            // else could be reassigned. For performance, we do a pointer comparison
+            // rather than checking if the raw_name is really "undefined".
+            if (variable->raw_name() == ast_string_constants()->undefined_string()) {
+                builder()->LoadUndefined();
+            } else {
+                FeedbackSlot slot = GetCachedLoadGlobalICSlot(typeof_mode, variable);
+                builder()->LoadGlobal(variable->raw_name(), feedback_index(slot),
+                                      typeof_mode);
+            }
+            break;
+        }
+        case VariableLocation::CONTEXT: {
+            int depth = execution_context()->ContextChainDepth(variable->scope());
+            ContextScope* context = execution_context()->Previous(depth);
+            Register context_reg;
+            if (context) {
+                context_reg = context->reg();
+                depth = 0;
+            } else {
+                context_reg = execution_context()->reg();
+            }
 
-      builder()->LoadContextSlot(context_reg, variable->index(), depth,
-                                 immutable);
-      if (hole_check_mode == HoleCheckMode::kRequired) {
-        BuildThrowIfHole(variable);
-      }
-      if (immutable == BytecodeArrayBuilder::kImmutableSlot) {
-        SetVariableInRegister(variable, acc);
-      }
-      break;
-    }
-    case VariableLocation::LOOKUP: {
-      switch (variable->mode()) {
-        case VariableMode::kDynamicLocal: {
-          Variable* local_variable = variable->local_if_not_shadowed();
-          int depth =
-              execution_context()->ContextChainDepth(local_variable->scope());
-          builder()->LoadLookupContextSlot(variable->raw_name(), typeof_mode,
-                                           local_variable->index(), depth);
-          if (hole_check_mode == HoleCheckMode::kRequired) {
-            BuildThrowIfHole(variable);
-          }
-          break;
-        }
-        case VariableMode::kDynamicGlobal: {
-          int depth =
-              current_scope()->ContextChainLengthUntilOutermostSloppyEval();
-          // TODO(1008414): Add back caching here when bug is fixed properly.
-          FeedbackSlot slot = feedback_spec()->AddLoadGlobalICSlot(typeof_mode);
-
-          builder()->LoadLookupGlobalSlot(variable->raw_name(), typeof_mode,
-                                          feedback_index(slot), depth);
-          break;
+            BytecodeArrayBuilder::ContextSlotMutability immutable =
+                    (variable->maybe_assigned() == kNotAssigned)
+                    ? BytecodeArrayBuilder::kImmutableSlot
+                    : BytecodeArrayBuilder::kMutableSlot;
+            Register acc = Register::virtual_accumulator();
+            if (immutable == BytecodeArrayBuilder::kImmutableSlot &&
+                IsVariableInRegister(variable, acc)) {
+                return;
+            }
+
+            builder()->LoadContextSlot(context_reg, variable->index(), depth,
+                                       immutable);
+            if (hole_check_mode == HoleCheckMode::kRequired) {
+                BuildThrowIfHole(variable);
+            }
+            if (immutable == BytecodeArrayBuilder::kImmutableSlot) {
+                SetVariableInRegister(variable, acc);
+            }
+            break;
+        }
+        case VariableLocation::LOOKUP: {
+            switch (variable->mode()) {
+                case VariableMode::kDynamicLocal: {
+                    Variable* local_variable = variable->local_if_not_shadowed();
+                    int depth =
+                            execution_context()->ContextChainDepth(local_variable->scope());
+                    builder()->LoadLookupContextSlot(variable->raw_name(), typeof_mode,
+                                                     local_variable->index(), depth);
+                    if (hole_check_mode == HoleCheckMode::kRequired) {
+                        BuildThrowIfHole(variable);
+                    }
+                    break;
+                }
+                case VariableMode::kDynamicGlobal: {
+                    int depth =
+                            current_scope()->ContextChainLengthUntilOutermostSloppyEval();
+                    // TODO(1008414): Add back caching here when bug is fixed properly.
+                    FeedbackSlot slot = feedback_spec()->AddLoadGlobalICSlot(typeof_mode);
+
+                    builder()->LoadLookupGlobalSlot(variable->raw_name(), typeof_mode,
+                                                    feedback_index(slot), depth);
+                    break;
+                }
+                default:
+                    builder()->LoadLookupSlot(variable->raw_name(), typeof_mode);
+            }
+            break;
+        }
+        case VariableLocation::MODULE: {
+            int depth = execution_context()->ContextChainDepth(variable->scope());
+            builder()->LoadModuleVariable(variable->index(), depth);
+            if (hole_check_mode == HoleCheckMode::kRequired) {
+                BuildThrowIfHole(variable);
+            }
+            break;
+        }
+        case VariableLocation::REPL_GLOBAL: {
+            DCHECK(variable->IsReplGlobal());
+            FeedbackSlot slot = GetCachedLoadGlobalICSlot(typeof_mode, variable);
+            builder()->LoadGlobal(variable->raw_name(), feedback_index(slot),
+                                  typeof_mode);
+            break;
         }
-        default:
-          builder()->LoadLookupSlot(variable->raw_name(), typeof_mode);
-      }
-      break;
-    }
-    case VariableLocation::MODULE: {
-      int depth = execution_context()->ContextChainDepth(variable->scope());
-      builder()->LoadModuleVariable(variable->index(), depth);
-      if (hole_check_mode == HoleCheckMode::kRequired) {
-        BuildThrowIfHole(variable);
-      }
-      break;
-    }
-    case VariableLocation::REPL_GLOBAL: {
-      DCHECK(variable->IsReplGlobal());
-      FeedbackSlot slot = GetCachedLoadGlobalICSlot(typeof_mode, variable);
-      builder()->LoadGlobal(variable->raw_name(), feedback_index(slot),
-                            typeof_mode);
-      break;
     }
-  }
 }
 
+// xqg start
 void BytecodeGenerator::BuildVariableLoadForAccumulatorValue(
-    Variable* variable, HoleCheckMode hole_check_mode, TypeofMode typeof_mode) {
-  ValueResultScope accumulator_result(this);
-  BuildVariableLoad(variable, hole_check_mode, typeof_mode);
+        VariableProxy* proxy, HoleCheckMode hole_check_mode, TypeofMode typeof_mode) {
+    ValueResultScope accumulator_result(this);
+    BuildVariableLoad(proxy, hole_check_mode, typeof_mode);
 }
+// xqg end
 
-void BytecodeGenerator::BuildReturn(int source_position) {
-  if (v8_flags.trace) {
-    RegisterAllocationScope register_scope(this);
-    Register result = register_allocator()->NewRegister();
-    // Runtime returns {result} value, preserving accumulator.
-    builder()->StoreAccumulatorInRegister(result).CallRuntime(
-        Runtime::kTraceExit, result);
-  }
-  builder()->SetStatementPosition(source_position);
-  builder()->Return();
+void BytecodeGenerator::BuildVariableLoadForAccumulatorValue(
+        Variable* variable, HoleCheckMode hole_check_mode, TypeofMode typeof_mode) {
+    ValueResultScope accumulator_result(this);
+    BuildVariableLoad(variable, hole_check_mode, typeof_mode);
 }
 
-void BytecodeGenerator::BuildAsyncReturn(int source_position) {
-  RegisterAllocationScope register_scope(this);
+void BytecodeGenerator::BuildReturn(int source_position) {
+    // xqg start scope
 
-  if (IsAsyncGeneratorFunction(info()->literal()->kind())) {
-    RegisterList args = register_allocator()->NewRegisterList(3);
-    builder()
-        ->MoveRegister(generator_object(), args[0])  // generator
-        .StoreAccumulatorInRegister(args[1])         // value
-        .LoadTrue()
-        .StoreAccumulatorInRegister(args[2])  // done
-        .CallRuntime(Runtime::kInlineAsyncGeneratorResolve, args);
-  } else {
-    DCHECK(IsAsyncFunction(info()->literal()->kind()) ||
-           IsAsyncModule(info()->literal()->kind()));
-    RegisterList args = register_allocator()->NewRegisterList(2);
-    builder()
-        ->MoveRegister(generator_object(), args[0])  // generator
-        .StoreAccumulatorInRegister(args[1])         // value
-        .CallRuntime(Runtime::kInlineAsyncFunctionResolve, args);
-  }
+    Register temp_arg = register_allocator()->NewRegister();
+    Register acc_init = register_allocator()->NewRegister();
+    builder()->StoreAccumulatorInRegister(acc_init);
 
-  BuildReturn(source_position);
-}
+    builder()->LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+            .StoreAccumulatorInRegister(temp_arg)
+            .CallRuntime(Runtime::kTaintAnalysis_OnScopeExit, temp_arg);
+
+    builder()->LoadAccumulatorWithRegister(acc_init);
+
+    register_allocator()->ReleaseRegister(acc_init);
+    register_allocator()->ReleaseRegister(temp_arg);
+    // xqg end scope
+
+    if (v8_flags.trace) {
+        RegisterAllocationScope register_scope(this);
+        Register result = register_allocator()->NewRegister();
+        // Runtime returns {result} value, preserving accumulator.
+        builder()->StoreAccumulatorInRegister(result).CallRuntime(
+                Runtime::kTraceExit, result);
+    }
+    builder()->SetStatementPosition(source_position);
+    builder()->Return();
+}
+
+void BytecodeGenerator::BuildAsyncReturn(int source_position) {
+    RegisterAllocationScope register_scope(this);
+
+    if (IsAsyncGeneratorFunction(info()->literal()->kind())) {
+        RegisterList args = register_allocator()->NewRegisterList(3);
+        builder()
+                ->MoveRegister(generator_object(), args[0])  // generator
+                .StoreAccumulatorInRegister(args[1])         // value
+                .LoadTrue()
+                .StoreAccumulatorInRegister(args[2])  // done
+                .CallRuntime(Runtime::kInlineAsyncGeneratorResolve, args);
+    } else {
+        DCHECK(IsAsyncFunction(info()->literal()->kind()) ||
+               IsAsyncModule(info()->literal()->kind()));
+        RegisterList args = register_allocator()->NewRegisterList(2);
+        builder()
+                ->MoveRegister(generator_object(), args[0])  // generator
+                .StoreAccumulatorInRegister(args[1])         // value
+                .CallRuntime(Runtime::kInlineAsyncFunctionResolve, args);
+    }
+
+    BuildReturn(source_position);
+}
 
 void BytecodeGenerator::BuildReThrow() { builder()->ReThrow(); }
 
 void BytecodeGenerator::BuildThrowIfHole(Variable* variable) {
-  if (variable->is_this()) {
-    DCHECK(variable->mode() == VariableMode::kConst);
-    builder()->ThrowSuperNotCalledIfHole();
-  } else {
-    builder()->ThrowReferenceErrorIfHole(variable->raw_name());
-  }
+    if (variable->is_this()) {
+        DCHECK(variable->mode() == VariableMode::kConst);
+        builder()->ThrowSuperNotCalledIfHole();
+    } else {
+        builder()->ThrowReferenceErrorIfHole(variable->raw_name());
+    }
 }
 
 void BytecodeGenerator::BuildHoleCheckForVariableAssignment(Variable* variable,
                                                             Token::Value op) {
-  DCHECK(!IsPrivateMethodOrAccessorVariableMode(variable->mode()));
-  if (variable->is_this() && variable->mode() == VariableMode::kConst &&
-      op == Token::INIT) {
-    // Perform an initialization check for 'this'. 'this' variable is the
-    // only variable able to trigger bind operations outside the TDZ
-    // via 'super' calls.
-    builder()->ThrowSuperAlreadyCalledIfNotHole();
-  } else {
-    // Perform an initialization check for let/const declared variables.
-    // E.g. let x = (x = 20); is not allowed.
-    DCHECK(IsLexicalVariableMode(variable->mode()));
-    BuildThrowIfHole(variable);
-  }
+    DCHECK(!IsPrivateMethodOrAccessorVariableMode(variable->mode()));
+    if (variable->is_this() && variable->mode() == VariableMode::kConst &&
+        op == Token::INIT) {
+        // Perform an initialization check for 'this'. 'this' variable is the
+        // only variable able to trigger bind operations outside the TDZ
+        // via 'super' calls.
+        builder()->ThrowSuperAlreadyCalledIfNotHole();
+    } else {
+        // Perform an initialization check for let/const declared variables.
+        // E.g. let x = (x = 20); is not allowed.
+        DCHECK(IsLexicalVariableMode(variable->mode()));
+        BuildThrowIfHole(variable);
+    }
+}
+// xqg start
+void BytecodeGenerator::BuildVariableAssignment(
+        VariableProxy* proxy, Token::Value op, HoleCheckMode hole_check_mode,
+        LookupHoistingMode lookup_hoisting_mode){
+
+    {
+        Register temp1 = register_allocator()->NewRegister();
+        BytecodeLabel replace_smi_done;
+        builder()
+                ->JumpIfNotSmi(&replace_smi_done)
+                .StoreAccumulatorInRegister(temp1)
+                .CallRuntime(Runtime::kTaintAnalysis_ReplaceSmiResult, temp1)
+                .Bind(&replace_smi_done);
+
+        register_allocator()->ReleaseRegister(temp1);
+    }
+
+    BuildVariableAssignment(proxy->var(), op, hole_check_mode, lookup_hoisting_mode);
+
+    int init_reg_index = register_allocator()->next_register_index();
+    RegisterList temp_args = register_allocator()->NewRegisterList(3);
+    Register acc_init = register_allocator()->NewRegister();
+    builder()->StoreAccumulatorInRegister(acc_init);
+
+    builder()->StoreAccumulatorInRegister(temp_args[0])
+            .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+            .StoreAccumulatorInRegister(temp_args[1])
+            .LoadLiteral(Smi::FromInt(proxy->position()))
+            .StoreAccumulatorInRegister(temp_args[2])
+            .CallRuntime(Runtime::kTaintAnalysis_OnVisitVariableProxy, temp_args);
+
+    builder()->LoadAccumulatorWithRegister(acc_init);
+    register_allocator()->ReleaseRegisters(init_reg_index);
 }
+// xqg end
 
 void BytecodeGenerator::BuildVariableAssignment(
-    Variable* variable, Token::Value op, HoleCheckMode hole_check_mode,
-    LookupHoistingMode lookup_hoisting_mode) {
-  VariableMode mode = variable->mode();
-  RegisterAllocationScope assignment_register_scope(this);
-  BytecodeLabel end_label;
-  switch (variable->location()) {
-    case VariableLocation::PARAMETER:
-    case VariableLocation::LOCAL: {
-      Register destination;
-      if (VariableLocation::PARAMETER == variable->location()) {
-        if (variable->IsReceiver()) {
-          destination = builder()->Receiver();
-        } else {
-          destination = builder()->Parameter(variable->index());
+        Variable* variable, Token::Value op, HoleCheckMode hole_check_mode,
+        LookupHoistingMode lookup_hoisting_mode) {
+    VariableMode mode = variable->mode();
+    RegisterAllocationScope assignment_register_scope(this);
+    BytecodeLabel end_label;
+    switch (variable->location()) {
+        case VariableLocation::PARAMETER:
+        case VariableLocation::LOCAL: {
+            Register destination;
+            if (VariableLocation::PARAMETER == variable->location()) {
+                if (variable->IsReceiver()) {
+                    destination = builder()->Receiver();
+                } else {
+                    destination = builder()->Parameter(variable->index());
+                }
+            } else {
+                destination = builder()->Local(variable->index());
+            }
+
+            if (hole_check_mode == HoleCheckMode::kRequired) {
+                // Load destination to check for hole.
+                Register value_temp = register_allocator()->NewRegister();
+                builder()
+                        ->StoreAccumulatorInRegister(value_temp)
+                        .LoadAccumulatorWithRegister(destination);
+
+                BuildHoleCheckForVariableAssignment(variable, op);
+                builder()->LoadAccumulatorWithRegister(value_temp);
+            }
+
+            if (mode != VariableMode::kConst || op == Token::INIT) {
+                builder()->StoreAccumulatorInRegister(destination);
+            } else if (variable->throw_on_const_assignment(language_mode())) {
+                builder()->CallRuntime(Runtime::kThrowConstAssignError);
+            }
+            break;
+        }
+        case VariableLocation::UNALLOCATED: {
+            BuildStoreGlobal(variable);
+            break;
         }
-      } else {
-        destination = builder()->Local(variable->index());
-      }
+        case VariableLocation::CONTEXT: {
+            int depth = execution_context()->ContextChainDepth(variable->scope());
+            ContextScope* context = execution_context()->Previous(depth);
+            Register context_reg;
+
+            if (context) {
+                context_reg = context->reg();
+                depth = 0;
+            } else {
+                context_reg = execution_context()->reg();
+            }
 
-      if (hole_check_mode == HoleCheckMode::kRequired) {
-        // Load destination to check for hole.
-        Register value_temp = register_allocator()->NewRegister();
-        builder()
-            ->StoreAccumulatorInRegister(value_temp)
-            .LoadAccumulatorWithRegister(destination);
-
-        BuildHoleCheckForVariableAssignment(variable, op);
-        builder()->LoadAccumulatorWithRegister(value_temp);
-      }
-
-      if (mode != VariableMode::kConst || op == Token::INIT) {
-        builder()->StoreAccumulatorInRegister(destination);
-      } else if (variable->throw_on_const_assignment(language_mode())) {
-        builder()->CallRuntime(Runtime::kThrowConstAssignError);
-      }
-      break;
-    }
-    case VariableLocation::UNALLOCATED: {
-      BuildStoreGlobal(variable);
-      break;
-    }
-    case VariableLocation::CONTEXT: {
-      int depth = execution_context()->ContextChainDepth(variable->scope());
-      ContextScope* context = execution_context()->Previous(depth);
-      Register context_reg;
-
-      if (context) {
-        context_reg = context->reg();
-        depth = 0;
-      } else {
-        context_reg = execution_context()->reg();
-      }
-
-      if (hole_check_mode == HoleCheckMode::kRequired) {
-        // Load destination to check for hole.
-        Register value_temp = register_allocator()->NewRegister();
-        builder()
-            ->StoreAccumulatorInRegister(value_temp)
-            .LoadContextSlot(context_reg, variable->index(), depth,
-                             BytecodeArrayBuilder::kMutableSlot);
-
-        BuildHoleCheckForVariableAssignment(variable, op);
-        builder()->LoadAccumulatorWithRegister(value_temp);
-      }
-
-      if (mode != VariableMode::kConst || op == Token::INIT) {
-        builder()->StoreContextSlot(context_reg, variable->index(), depth);
-      } else if (variable->throw_on_const_assignment(language_mode())) {
-        builder()->CallRuntime(Runtime::kThrowConstAssignError);
-      }
-      break;
-    }
-    case VariableLocation::LOOKUP: {
-      builder()->StoreLookupSlot(variable->raw_name(), language_mode(),
-                                 lookup_hoisting_mode);
-      break;
-    }
-    case VariableLocation::MODULE: {
-      DCHECK(IsDeclaredVariableMode(mode));
-
-      if (mode == VariableMode::kConst && op != Token::INIT) {
-        builder()->CallRuntime(Runtime::kThrowConstAssignError);
-        break;
-      }
-
-      // If we don't throw above, we know that we're dealing with an
-      // export because imports are const and we do not generate initializing
-      // assignments for them.
-      DCHECK(variable->IsExport());
-
-      int depth = execution_context()->ContextChainDepth(variable->scope());
-      if (hole_check_mode == HoleCheckMode::kRequired) {
-        Register value_temp = register_allocator()->NewRegister();
-        builder()
-            ->StoreAccumulatorInRegister(value_temp)
-            .LoadModuleVariable(variable->index(), depth);
-        BuildHoleCheckForVariableAssignment(variable, op);
-        builder()->LoadAccumulatorWithRegister(value_temp);
-      }
-      builder()->StoreModuleVariable(variable->index(), depth);
-      break;
-    }
-    case VariableLocation::REPL_GLOBAL: {
-      // A let or const declaration like 'let x = 7' is effectively translated
-      // to:
-      //   <top of the script>:
-      //     ScriptContext.x = TheHole;
-      //   ...
-      //   <where the actual 'let' is>:
-      //     ScriptContextTable.x = 7; // no hole check
-      //
-      // The ScriptContext slot for 'x' that we store to here is not
-      // necessarily the ScriptContext of this script, but rather the
-      // first ScriptContext that has a slot for name 'x'.
-      DCHECK(variable->IsReplGlobal());
-      if (op == Token::INIT) {
-        RegisterList store_args = register_allocator()->NewRegisterList(2);
-        builder()
-            ->StoreAccumulatorInRegister(store_args[1])
-            .LoadLiteral(variable->raw_name())
-            .StoreAccumulatorInRegister(store_args[0]);
-        builder()->CallRuntime(
-            Runtime::kStoreGlobalNoHoleCheckForReplLetOrConst, store_args);
-      } else {
-        if (mode == VariableMode::kConst) {
-          builder()->CallRuntime(Runtime::kThrowConstAssignError);
-        } else {
-          BuildStoreGlobal(variable);
+            if (hole_check_mode == HoleCheckMode::kRequired) {
+                // Load destination to check for hole.
+                Register value_temp = register_allocator()->NewRegister();
+                builder()
+                        ->StoreAccumulatorInRegister(value_temp)
+                        .LoadContextSlot(context_reg, variable->index(), depth,
+                                         BytecodeArrayBuilder::kMutableSlot);
+
+                BuildHoleCheckForVariableAssignment(variable, op);
+                builder()->LoadAccumulatorWithRegister(value_temp);
+            }
+
+            if (mode != VariableMode::kConst || op == Token::INIT) {
+                builder()->StoreContextSlot(context_reg, variable->index(), depth);
+            } else if (variable->throw_on_const_assignment(language_mode())) {
+                builder()->CallRuntime(Runtime::kThrowConstAssignError);
+            }
+            break;
+        }
+        case VariableLocation::LOOKUP: {
+            builder()->StoreLookupSlot(variable->raw_name(), language_mode(),
+                                       lookup_hoisting_mode);
+            break;
+        }
+        case VariableLocation::MODULE: {
+            DCHECK(IsDeclaredVariableMode(mode));
+
+            if (mode == VariableMode::kConst && op != Token::INIT) {
+                builder()->CallRuntime(Runtime::kThrowConstAssignError);
+                break;
+            }
+
+            // If we don't throw above, we know that we're dealing with an
+            // export because imports are const and we do not generate initializing
+            // assignments for them.
+            DCHECK(variable->IsExport());
+
+            int depth = execution_context()->ContextChainDepth(variable->scope());
+            if (hole_check_mode == HoleCheckMode::kRequired) {
+                Register value_temp = register_allocator()->NewRegister();
+                builder()
+                        ->StoreAccumulatorInRegister(value_temp)
+                        .LoadModuleVariable(variable->index(), depth);
+                BuildHoleCheckForVariableAssignment(variable, op);
+                builder()->LoadAccumulatorWithRegister(value_temp);
+            }
+            builder()->StoreModuleVariable(variable->index(), depth);
+            break;
+        }
+        case VariableLocation::REPL_GLOBAL: {
+            // A let or const declaration like 'let x = 7' is effectively translated
+            // to:
+            //   <top of the script>:
+            //     ScriptContext.x = TheHole;
+            //   ...
+            //   <where the actual 'let' is>:
+            //     ScriptContextTable.x = 7; // no hole check
+            //
+            // The ScriptContext slot for 'x' that we store to here is not
+            // necessarily the ScriptContext of this script, but rather the
+            // first ScriptContext that has a slot for name 'x'.
+            DCHECK(variable->IsReplGlobal());
+            if (op == Token::INIT) {
+                RegisterList store_args = register_allocator()->NewRegisterList(2);
+                builder()
+                        ->StoreAccumulatorInRegister(store_args[1])
+                        .LoadLiteral(variable->raw_name())
+                        .StoreAccumulatorInRegister(store_args[0]);
+                builder()->CallRuntime(
+                        Runtime::kStoreGlobalNoHoleCheckForReplLetOrConst, store_args);
+            } else {
+                if (mode == VariableMode::kConst) {
+                    builder()->CallRuntime(Runtime::kThrowConstAssignError);
+                } else {
+                    BuildStoreGlobal(variable);
+                }
+            }
+            break;
         }
-      }
-      break;
     }
-  }
 }
 
 void BytecodeGenerator::BuildLoadNamedProperty(const Expression* object_expr,
                                                Register object,
                                                const AstRawString* name) {
-  FeedbackSlot slot = GetCachedLoadICSlot(object_expr, name);
-  builder()->LoadNamedProperty(object, name, feedback_index(slot));
+    FeedbackSlot slot = GetCachedLoadICSlot(object_expr, name);
+    builder()->LoadNamedProperty(object, name, feedback_index(slot));
 }
 
 void BytecodeGenerator::BuildSetNamedProperty(const Expression* object_expr,
                                               Register object,
                                               const AstRawString* name) {
-  Register value;
-  if (!execution_result()->IsEffect()) {
-    value = register_allocator()->NewRegister();
-    builder()->StoreAccumulatorInRegister(value);
-  }
+    Register value;
+    if (!execution_result()->IsEffect()) {
+        value = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(value);
+    }
 
-  FeedbackSlot slot = GetCachedStoreICSlot(object_expr, name);
-  builder()->SetNamedProperty(object, name, feedback_index(slot),
-                              language_mode());
+    FeedbackSlot slot = GetCachedStoreICSlot(object_expr, name);
+    builder()->SetNamedProperty(object, name, feedback_index(slot),
+                                language_mode());
 
-  if (!execution_result()->IsEffect()) {
-    builder()->LoadAccumulatorWithRegister(value);
-  }
+    if (!execution_result()->IsEffect()) {
+        builder()->LoadAccumulatorWithRegister(value);
+    }
 }
 
 void BytecodeGenerator::BuildStoreGlobal(Variable* variable) {
-  Register value;
-  if (!execution_result()->IsEffect()) {
-    value = register_allocator()->NewRegister();
-    builder()->StoreAccumulatorInRegister(value);
-  }
+    Register value;
+    if (!execution_result()->IsEffect()) {
+        value = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(value);
+    }
 
-  FeedbackSlot slot = GetCachedStoreGlobalICSlot(language_mode(), variable);
-  builder()->StoreGlobal(variable->raw_name(), feedback_index(slot));
+    FeedbackSlot slot = GetCachedStoreGlobalICSlot(language_mode(), variable);
+    builder()->StoreGlobal(variable->raw_name(), feedback_index(slot));
 
-  if (!execution_result()->IsEffect()) {
-    builder()->LoadAccumulatorWithRegister(value);
-  }
+    if (!execution_result()->IsEffect()) {
+        builder()->LoadAccumulatorWithRegister(value);
+    }
 }
 
 // static
 BytecodeGenerator::AssignmentLhsData
 BytecodeGenerator::AssignmentLhsData::NonProperty(Expression* expr) {
-  return AssignmentLhsData(NON_PROPERTY, expr, RegisterList(), Register(),
-                           Register(), nullptr, nullptr);
+    return AssignmentLhsData(NON_PROPERTY, expr, RegisterList(), Register(),
+                             Register(), nullptr, nullptr);
 }
 // static
 BytecodeGenerator::AssignmentLhsData
 BytecodeGenerator::AssignmentLhsData::NamedProperty(Expression* object_expr,
                                                     Register object,
                                                     const AstRawString* name) {
-  return AssignmentLhsData(NAMED_PROPERTY, nullptr, RegisterList(), object,
-                           Register(), object_expr, name);
+    return AssignmentLhsData(NAMED_PROPERTY, nullptr, RegisterList(), object,
+                             Register(), object_expr, name);
 }
 // static
 BytecodeGenerator::AssignmentLhsData
 BytecodeGenerator::AssignmentLhsData::KeyedProperty(Register object,
                                                     Register key) {
-  return AssignmentLhsData(KEYED_PROPERTY, nullptr, RegisterList(), object, key,
-                           nullptr, nullptr);
+    return AssignmentLhsData(KEYED_PROPERTY, nullptr, RegisterList(), object, key,
+                             nullptr, nullptr);
 }
 // static
 BytecodeGenerator::AssignmentLhsData
 BytecodeGenerator::AssignmentLhsData::NamedSuperProperty(
-    RegisterList super_property_args) {
-  return AssignmentLhsData(NAMED_SUPER_PROPERTY, nullptr, super_property_args,
-                           Register(), Register(), nullptr, nullptr);
+        RegisterList super_property_args) {
+    return AssignmentLhsData(NAMED_SUPER_PROPERTY, nullptr, super_property_args,
+                             Register(), Register(), nullptr, nullptr);
 }
 // static
 BytecodeGenerator::AssignmentLhsData
 BytecodeGenerator::AssignmentLhsData::PrivateMethodOrAccessor(
-    AssignType type, Property* property, Register object, Register key) {
-  return AssignmentLhsData(type, property, RegisterList(), object, key, nullptr,
-                           nullptr);
+        AssignType type, Property* property, Register object, Register key) {
+    return AssignmentLhsData(type, property, RegisterList(), object, key, nullptr,
+                             nullptr);
 }
 // static
 BytecodeGenerator::AssignmentLhsData
 BytecodeGenerator::AssignmentLhsData::KeyedSuperProperty(
-    RegisterList super_property_args) {
-  return AssignmentLhsData(KEYED_SUPER_PROPERTY, nullptr, super_property_args,
-                           Register(), Register(), nullptr, nullptr);
+        RegisterList super_property_args) {
+    return AssignmentLhsData(KEYED_SUPER_PROPERTY, nullptr, super_property_args,
+                             Register(), Register(), nullptr, nullptr);
 }
 
 BytecodeGenerator::AssignmentLhsData BytecodeGenerator::PrepareAssignmentLhs(
-    Expression* lhs, AccumulatorPreservingMode accumulator_preserving_mode) {
-  // Left-hand side can only be a property, a global or a variable slot.
-  Property* property = lhs->AsProperty();
-  AssignType assign_type = Property::GetAssignType(property);
-
-  // Evaluate LHS expression.
-  switch (assign_type) {
-    case NON_PROPERTY:
-      return AssignmentLhsData::NonProperty(lhs);
-    case NAMED_PROPERTY: {
-      AccumulatorPreservingScope scope(this, accumulator_preserving_mode);
-      Register object = VisitForRegisterValue(property->obj());
-      const AstRawString* name =
-          property->key()->AsLiteral()->AsRawPropertyName();
-      return AssignmentLhsData::NamedProperty(property->obj(), object, name);
-    }
-    case KEYED_PROPERTY: {
-      AccumulatorPreservingScope scope(this, accumulator_preserving_mode);
-      Register object = VisitForRegisterValue(property->obj());
-      Register key = VisitForRegisterValue(property->key());
-      return AssignmentLhsData::KeyedProperty(object, key);
-    }
-    case PRIVATE_METHOD:
-    case PRIVATE_GETTER_ONLY:
-    case PRIVATE_SETTER_ONLY:
-    case PRIVATE_GETTER_AND_SETTER: {
-      DCHECK(!property->IsSuperAccess());
-      AccumulatorPreservingScope scope(this, accumulator_preserving_mode);
-      Register object = VisitForRegisterValue(property->obj());
-      Register key = VisitForRegisterValue(property->key());
-      return AssignmentLhsData::PrivateMethodOrAccessor(assign_type, property,
-                                                        object, key);
-    }
-    case NAMED_SUPER_PROPERTY: {
-      AccumulatorPreservingScope scope(this, accumulator_preserving_mode);
-      RegisterList super_property_args =
-          register_allocator()->NewRegisterList(4);
-      BuildThisVariableLoad();
-      builder()->StoreAccumulatorInRegister(super_property_args[0]);
-      BuildVariableLoad(
-          property->obj()->AsSuperPropertyReference()->home_object()->var(),
-          HoleCheckMode::kElided);
-      builder()->StoreAccumulatorInRegister(super_property_args[1]);
-      builder()
-          ->LoadLiteral(property->key()->AsLiteral()->AsRawPropertyName())
-          .StoreAccumulatorInRegister(super_property_args[2]);
-      return AssignmentLhsData::NamedSuperProperty(super_property_args);
-    }
-    case KEYED_SUPER_PROPERTY: {
-      AccumulatorPreservingScope scope(this, accumulator_preserving_mode);
-      RegisterList super_property_args =
-          register_allocator()->NewRegisterList(4);
-      BuildThisVariableLoad();
-      builder()->StoreAccumulatorInRegister(super_property_args[0]);
-      BuildVariableLoad(
-          property->obj()->AsSuperPropertyReference()->home_object()->var(),
-          HoleCheckMode::kElided);
-      builder()->StoreAccumulatorInRegister(super_property_args[1]);
-      VisitForRegisterValue(property->key(), super_property_args[2]);
-      return AssignmentLhsData::KeyedSuperProperty(super_property_args);
+        Expression* lhs, AccumulatorPreservingMode accumulator_preserving_mode) {
+    // Left-hand side can only be a property, a global or a variable slot.
+    Property* property = lhs->AsProperty();
+    AssignType assign_type = Property::GetAssignType(property);
+
+    // Evaluate LHS expression.
+    switch (assign_type) {
+        case NON_PROPERTY:
+            return AssignmentLhsData::NonProperty(lhs);
+        case NAMED_PROPERTY: {
+            AccumulatorPreservingScope scope(this, accumulator_preserving_mode);
+            Register object = VisitForRegisterValue(property->obj());
+            const AstRawString* name =
+                    property->key()->AsLiteral()->AsRawPropertyName();
+            return AssignmentLhsData::NamedProperty(property->obj(), object, name);
+        }
+        case KEYED_PROPERTY: {
+            AccumulatorPreservingScope scope(this, accumulator_preserving_mode);
+            Register object = VisitForRegisterValue(property->obj());
+            Register key = VisitForRegisterValue(property->key());
+            return AssignmentLhsData::KeyedProperty(object, key);
+        }
+        case PRIVATE_METHOD:
+        case PRIVATE_GETTER_ONLY:
+        case PRIVATE_SETTER_ONLY:
+        case PRIVATE_GETTER_AND_SETTER: {
+            DCHECK(!property->IsSuperAccess());
+            AccumulatorPreservingScope scope(this, accumulator_preserving_mode);
+            Register object = VisitForRegisterValue(property->obj());
+            Register key = VisitForRegisterValue(property->key());
+            return AssignmentLhsData::PrivateMethodOrAccessor(assign_type, property,
+                                                              object, key);
+        }
+        case NAMED_SUPER_PROPERTY: {
+            AccumulatorPreservingScope scope(this, accumulator_preserving_mode);
+            RegisterList super_property_args =
+                    register_allocator()->NewRegisterList(4);
+            BuildThisVariableLoad();
+            builder()->StoreAccumulatorInRegister(super_property_args[0]);
+            BuildVariableLoad(
+                    property->obj()->AsSuperPropertyReference()->home_object()->var(),
+                    HoleCheckMode::kElided);
+            builder()->StoreAccumulatorInRegister(super_property_args[1]);
+            builder()
+                    ->LoadLiteral(property->key()->AsLiteral()->AsRawPropertyName())
+                    .StoreAccumulatorInRegister(super_property_args[2]);
+            return AssignmentLhsData::NamedSuperProperty(super_property_args);
+        }
+        case KEYED_SUPER_PROPERTY: {
+            AccumulatorPreservingScope scope(this, accumulator_preserving_mode);
+            RegisterList super_property_args =
+                    register_allocator()->NewRegisterList(4);
+            BuildThisVariableLoad();
+            builder()->StoreAccumulatorInRegister(super_property_args[0]);
+            BuildVariableLoad(
+                    property->obj()->AsSuperPropertyReference()->home_object()->var(),
+                    HoleCheckMode::kElided);
+            builder()->StoreAccumulatorInRegister(super_property_args[1]);
+            VisitForRegisterValue(property->key(), super_property_args[2]);
+            return AssignmentLhsData::KeyedSuperProperty(super_property_args);
+        }
     }
-  }
-  UNREACHABLE();
+    UNREACHABLE();
 }
 
 // Build the iteration finalizer called in the finally block of an iteration
@@ -4038,77 +4341,77 @@ BytecodeGenerator::AssignmentLhsData BytecodeGenerator::PrepareAssignmentLhs(
 //
 // For async iterators, iterator.close() becomes await iterator.close().
 void BytecodeGenerator::BuildFinalizeIteration(
-    IteratorRecord iterator, Register done,
-    Register iteration_continuation_token) {
-  RegisterAllocationScope register_scope(this);
-  BytecodeLabels iterator_is_done(zone());
-
-  // if (!done) {
-  builder()->LoadAccumulatorWithRegister(done).JumpIfTrue(
-      ToBooleanMode::kConvertToBoolean, iterator_is_done.New());
+        IteratorRecord iterator, Register done,
+        Register iteration_continuation_token) {
+    RegisterAllocationScope register_scope(this);
+    BytecodeLabels iterator_is_done(zone());
 
-  {
-    RegisterAllocationScope inner_register_scope(this);
-    BuildTryCatch(
-        // try {
-        //   let method = iterator.return
-        //   if (method !== null && method !== undefined) {
-        //     let return_val = method.call(iterator)
-        //     if (!%IsObject(return_val)) throw TypeError
-        //   }
-        // }
-        [&]() {
-          Register method = register_allocator()->NewRegister();
-          builder()
-              ->LoadNamedProperty(
-                  iterator.object(), ast_string_constants()->return_string(),
-                  feedback_index(feedback_spec()->AddLoadICSlot()))
-              .JumpIfUndefinedOrNull(iterator_is_done.New())
-              .StoreAccumulatorInRegister(method);
-
-          RegisterList args(iterator.object());
-          builder()->CallProperty(
-              method, args, feedback_index(feedback_spec()->AddCallICSlot()));
-          if (iterator.type() == IteratorType::kAsync) {
-            BuildAwait();
-          }
-          builder()->JumpIfJSReceiver(iterator_is_done.New());
-          {
-            // Throw this exception inside the try block so that it is
-            // suppressed by the iteration continuation if necessary.
-            RegisterAllocationScope register_scope(this);
-            Register return_result = register_allocator()->NewRegister();
-            builder()
-                ->StoreAccumulatorInRegister(return_result)
-                .CallRuntime(Runtime::kThrowIteratorResultNotAnObject,
-                             return_result);
-          }
-        },
-
-        // catch (e) {
-        //   if (iteration_continuation != RETHROW)
-        //     rethrow e
-        // }
-        [&](Register context) {
-          // Reuse context register to store the exception.
-          Register close_exception = context;
-          builder()->StoreAccumulatorInRegister(close_exception);
-
-          BytecodeLabel suppress_close_exception;
-          builder()
-              ->LoadLiteral(
-                  Smi::FromInt(ControlScope::DeferredCommands::kRethrowToken))
-              .CompareReference(iteration_continuation_token)
-              .JumpIfTrue(ToBooleanMode::kAlreadyBoolean,
-                          &suppress_close_exception)
-              .LoadAccumulatorWithRegister(close_exception)
-              .ReThrow()
-              .Bind(&suppress_close_exception);
-        },
-        HandlerTable::UNCAUGHT);
-  }
+    // if (!done) {
+    builder()->LoadAccumulatorWithRegister(done).JumpIfTrue(
+            ToBooleanMode::kConvertToBoolean, iterator_is_done.New());
 
-  iterator_is_done.Bind(builder());
+    {
+        RegisterAllocationScope inner_register_scope(this);
+        BuildTryCatch(
+                // try {
+                //   let method = iterator.return
+                //   if (method !== null && method !== undefined) {
+                //     let return_val = method.call(iterator)
+                //     if (!%IsObject(return_val)) throw TypeError
+                //   }
+                // }
+                [&]() {
+                    Register method = register_allocator()->NewRegister();
+                    builder()
+                            ->LoadNamedProperty(
+                                    iterator.object(), ast_string_constants()->return_string(),
+                                    feedback_index(feedback_spec()->AddLoadICSlot()))
+                            .JumpIfUndefinedOrNull(iterator_is_done.New())
+                            .StoreAccumulatorInRegister(method);
+
+                    RegisterList args(iterator.object());
+                    builder()->CallProperty(
+                            method, args, feedback_index(feedback_spec()->AddCallICSlot()));
+                    if (iterator.type() == IteratorType::kAsync) {
+                        BuildAwait();
+                    }
+                    builder()->JumpIfJSReceiver(iterator_is_done.New());
+                    {
+                        // Throw this exception inside the try block so that it is
+                        // suppressed by the iteration continuation if necessary.
+                        RegisterAllocationScope register_scope(this);
+                        Register return_result = register_allocator()->NewRegister();
+                        builder()
+                                ->StoreAccumulatorInRegister(return_result)
+                                .CallRuntime(Runtime::kThrowIteratorResultNotAnObject,
+                                             return_result);
+                    }
+                },
+
+                // catch (e) {
+                //   if (iteration_continuation != RETHROW)
+                //     rethrow e
+                // }
+                [&](Register context) {
+                    // Reuse context register to store the exception.
+                    Register close_exception = context;
+                    builder()->StoreAccumulatorInRegister(close_exception);
+
+                    BytecodeLabel suppress_close_exception;
+                    builder()
+                            ->LoadLiteral(
+                                    Smi::FromInt(ControlScope::DeferredCommands::kRethrowToken))
+                            .CompareReference(iteration_continuation_token)
+                            .JumpIfTrue(ToBooleanMode::kAlreadyBoolean,
+                                        &suppress_close_exception)
+                            .LoadAccumulatorWithRegister(close_exception)
+                            .ReThrow()
+                            .Bind(&suppress_close_exception);
+                },
+                HandlerTable::UNCAUGHT);
+    }
+
+    iterator_is_done.Bind(builder());
 }
 
 // Get the default value of a destructuring target. Will mutate the
@@ -4120,16 +4423,16 @@ void BytecodeGenerator::BuildFinalizeIteration(
 //   let {a = b} = c
 // returns b and mutates the input into a.
 Expression* BytecodeGenerator::GetDestructuringDefaultValue(
-    Expression** target) {
-  Expression* default_value = nullptr;
-  if ((*target)->IsAssignment()) {
-    Assignment* default_init = (*target)->AsAssignment();
-    DCHECK_EQ(default_init->op(), Token::ASSIGN);
-    default_value = default_init->value();
-    *target = default_init->target();
-    DCHECK((*target)->IsValidReferenceExpression() || (*target)->IsPattern());
-  }
-  return default_value;
+        Expression** target) {
+    Expression* default_value = nullptr;
+    if ((*target)->IsAssignment()) {
+        Assignment* default_init = (*target)->AsAssignment();
+        DCHECK_EQ(default_init->op(), Token::ASSIGN);
+        default_value = default_init->value();
+        *target = default_init->target();
+        DCHECK((*target)->IsValidReferenceExpression() || (*target)->IsPattern());
+    }
+    return default_value;
 }
 
 // Convert a destructuring assignment to an array literal into a sequence of
@@ -4171,157 +4474,157 @@ Expression* BytecodeGenerator::GetDestructuringDefaultValue(
 //   %FinalizeIteration(iterator, done, iteration_continuation)
 // }
 void BytecodeGenerator::BuildDestructuringArrayAssignment(
-    ArrayLiteral* pattern, Token::Value op,
-    LookupHoistingMode lookup_hoisting_mode) {
-  RegisterAllocationScope scope(this);
-
-  Register value = register_allocator()->NewRegister();
-  builder()->StoreAccumulatorInRegister(value);
-
-  // Store the iterator in a dedicated register so that it can be closed on
-  // exit, and the 'done' value in a dedicated register so that it can be
-  // changed and accessed independently of the iteration result.
-  IteratorRecord iterator = BuildGetIteratorRecord(IteratorType::kNormal);
-  Register done = register_allocator()->NewRegister();
-  builder()->LoadFalse();
-  builder()->StoreAccumulatorInRegister(done);
-
-  BuildTryFinally(
-      // Try block.
-      [&]() {
-        Register next_result = register_allocator()->NewRegister();
-        FeedbackSlot next_value_load_slot = feedback_spec()->AddLoadICSlot();
-        FeedbackSlot next_done_load_slot = feedback_spec()->AddLoadICSlot();
-
-        Spread* spread = nullptr;
-        for (Expression* target : *pattern->values()) {
-          if (target->IsSpread()) {
-            spread = target->AsSpread();
-            break;
-          }
-
-          Expression* default_value = GetDestructuringDefaultValue(&target);
-          builder()->SetExpressionPosition(target);
-
-          AssignmentLhsData lhs_data = PrepareAssignmentLhs(target);
-
-          // if (!done) {
-          //   // Make sure we are considered done if .next(), .done or .value
-          //   // fail.
-          //   done = true
-          //   var next_result = iterator.next()
-          //   var tmp_done = next_result.done
-          //   if (!tmp_done) {
-          //     value = next_result.value
-          //     done = false
-          //   }
-          // }
-          // if (done)
-          //   value = undefined
-          BytecodeLabels is_done(zone());
-
-          builder()->LoadAccumulatorWithRegister(done);
-          builder()->JumpIfTrue(ToBooleanMode::kConvertToBoolean,
-                                is_done.New());
-
-          builder()->LoadTrue().StoreAccumulatorInRegister(done);
-          BuildIteratorNext(iterator, next_result);
-          builder()
-              ->LoadNamedProperty(next_result,
-                                  ast_string_constants()->done_string(),
-                                  feedback_index(next_done_load_slot))
-              .JumpIfTrue(ToBooleanMode::kConvertToBoolean, is_done.New());
-
-          // Only do the assignment if this is not a hole (i.e. 'elided').
-          if (!target->IsTheHoleLiteral()) {
-            builder()
-                ->LoadNamedProperty(next_result,
-                                    ast_string_constants()->value_string(),
-                                    feedback_index(next_value_load_slot))
-                .StoreAccumulatorInRegister(next_result)
-                .LoadFalse()
-                .StoreAccumulatorInRegister(done)
-                .LoadAccumulatorWithRegister(next_result);
-
-            // [<pattern> = <init>] = <value>
-            //   becomes (roughly)
-            // temp = <value>.next();
-            // <pattern> = temp === undefined ? <init> : temp;
-            BytecodeLabel do_assignment;
-            if (default_value) {
-              builder()->JumpIfNotUndefined(&do_assignment);
-              // Since done == true => temp == undefined, jump directly to using
-              // the default value for that case.
-              is_done.Bind(builder());
-              VisitForAccumulatorValue(default_value);
-            } else {
-              builder()->Jump(&do_assignment);
-              is_done.Bind(builder());
-              builder()->LoadUndefined();
-            }
-            builder()->Bind(&do_assignment);
-
-            BuildAssignment(lhs_data, op, lookup_hoisting_mode);
-          } else {
-            builder()->LoadFalse().StoreAccumulatorInRegister(done);
-            DCHECK_EQ(lhs_data.assign_type(), NON_PROPERTY);
-            is_done.Bind(builder());
-          }
-        }
-
-        if (spread) {
-          RegisterAllocationScope scope(this);
-          BytecodeLabel is_done;
-
-          // A spread is turned into a loop over the remainer of the iterator.
-          Expression* target = spread->expression();
-          builder()->SetExpressionPosition(spread);
-
-          AssignmentLhsData lhs_data = PrepareAssignmentLhs(target);
-
-          // var array = [];
-          Register array = register_allocator()->NewRegister();
-          builder()->CreateEmptyArrayLiteral(
-              feedback_index(feedback_spec()->AddLiteralSlot()));
-          builder()->StoreAccumulatorInRegister(array);
-
-          // If done, jump to assigning empty array
-          builder()->LoadAccumulatorWithRegister(done);
-          builder()->JumpIfTrue(ToBooleanMode::kConvertToBoolean, &is_done);
-
-          // var index = 0;
-          Register index = register_allocator()->NewRegister();
-          builder()->LoadLiteral(Smi::zero());
-          builder()->StoreAccumulatorInRegister(index);
-
-          // Set done to true, since it's guaranteed to be true by the time the
-          // array fill completes.
-          builder()->LoadTrue().StoreAccumulatorInRegister(done);
-
-          // Fill the array with the iterator.
-          FeedbackSlot element_slot =
-              feedback_spec()->AddStoreInArrayLiteralICSlot();
-          FeedbackSlot index_slot = feedback_spec()->AddBinaryOpICSlot();
-          BuildFillArrayWithIterator(iterator, array, index, next_result,
-                                     next_value_load_slot, next_done_load_slot,
-                                     index_slot, element_slot);
-
-          builder()->Bind(&is_done);
-          // Assign the array to the LHS.
-          builder()->LoadAccumulatorWithRegister(array);
-          BuildAssignment(lhs_data, op, lookup_hoisting_mode);
-        }
-      },
-      // Finally block.
-      [&](Register iteration_continuation_token) {
-        // Finish the iteration in the finally block.
-        BuildFinalizeIteration(iterator, done, iteration_continuation_token);
-      },
-      HandlerTable::UNCAUGHT);
-
-  if (!execution_result()->IsEffect()) {
-    builder()->LoadAccumulatorWithRegister(value);
-  }
+        ArrayLiteral* pattern, Token::Value op,
+        LookupHoistingMode lookup_hoisting_mode) {
+    RegisterAllocationScope scope(this);
+
+    Register value = register_allocator()->NewRegister();
+    builder()->StoreAccumulatorInRegister(value);
+
+    // Store the iterator in a dedicated register so that it can be closed on
+    // exit, and the 'done' value in a dedicated register so that it can be
+    // changed and accessed independently of the iteration result.
+    IteratorRecord iterator = BuildGetIteratorRecord(IteratorType::kNormal);
+    Register done = register_allocator()->NewRegister();
+    builder()->LoadFalse();
+    builder()->StoreAccumulatorInRegister(done);
+
+    BuildTryFinally(
+            // Try block.
+            [&]() {
+                Register next_result = register_allocator()->NewRegister();
+                FeedbackSlot next_value_load_slot = feedback_spec()->AddLoadICSlot();
+                FeedbackSlot next_done_load_slot = feedback_spec()->AddLoadICSlot();
+
+                Spread* spread = nullptr;
+                for (Expression* target : *pattern->values()) {
+                    if (target->IsSpread()) {
+                        spread = target->AsSpread();
+                        break;
+                    }
+
+                    Expression* default_value = GetDestructuringDefaultValue(&target);
+                    builder()->SetExpressionPosition(target);
+
+                    AssignmentLhsData lhs_data = PrepareAssignmentLhs(target);
+
+                    // if (!done) {
+                    //   // Make sure we are considered done if .next(), .done or .value
+                    //   // fail.
+                    //   done = true
+                    //   var next_result = iterator.next()
+                    //   var tmp_done = next_result.done
+                    //   if (!tmp_done) {
+                    //     value = next_result.value
+                    //     done = false
+                    //   }
+                    // }
+                    // if (done)
+                    //   value = undefined
+                    BytecodeLabels is_done(zone());
+
+                    builder()->LoadAccumulatorWithRegister(done);
+                    builder()->JumpIfTrue(ToBooleanMode::kConvertToBoolean,
+                                          is_done.New());
+
+                    builder()->LoadTrue().StoreAccumulatorInRegister(done);
+                    BuildIteratorNext(iterator, next_result);
+                    builder()
+                            ->LoadNamedProperty(next_result,
+                                                ast_string_constants()->done_string(),
+                                                feedback_index(next_done_load_slot))
+                            .JumpIfTrue(ToBooleanMode::kConvertToBoolean, is_done.New());
+
+                    // Only do the assignment if this is not a hole (i.e. 'elided').
+                    if (!target->IsTheHoleLiteral()) {
+                        builder()
+                                ->LoadNamedProperty(next_result,
+                                                    ast_string_constants()->value_string(),
+                                                    feedback_index(next_value_load_slot))
+                                .StoreAccumulatorInRegister(next_result)
+                                .LoadFalse()
+                                .StoreAccumulatorInRegister(done)
+                                .LoadAccumulatorWithRegister(next_result);
+
+                        // [<pattern> = <init>] = <value>
+                        //   becomes (roughly)
+                        // temp = <value>.next();
+                        // <pattern> = temp === undefined ? <init> : temp;
+                        BytecodeLabel do_assignment;
+                        if (default_value) {
+                            builder()->JumpIfNotUndefined(&do_assignment);
+                            // Since done == true => temp == undefined, jump directly to using
+                            // the default value for that case.
+                            is_done.Bind(builder());
+                            VisitForAccumulatorValue(default_value);
+                        } else {
+                            builder()->Jump(&do_assignment);
+                            is_done.Bind(builder());
+                            builder()->LoadUndefined();
+                        }
+                        builder()->Bind(&do_assignment);
+
+                        BuildAssignment(lhs_data, op, lookup_hoisting_mode);
+                    } else {
+                        builder()->LoadFalse().StoreAccumulatorInRegister(done);
+                        DCHECK_EQ(lhs_data.assign_type(), NON_PROPERTY);
+                        is_done.Bind(builder());
+                    }
+                }
+
+                if (spread) {
+                    RegisterAllocationScope scope(this);
+                    BytecodeLabel is_done;
+
+                    // A spread is turned into a loop over the remainer of the iterator.
+                    Expression* target = spread->expression();
+                    builder()->SetExpressionPosition(spread);
+
+                    AssignmentLhsData lhs_data = PrepareAssignmentLhs(target);
+
+                    // var array = [];
+                    Register array = register_allocator()->NewRegister();
+                    builder()->CreateEmptyArrayLiteral(
+                            feedback_index(feedback_spec()->AddLiteralSlot()));
+                    builder()->StoreAccumulatorInRegister(array);
+
+                    // If done, jump to assigning empty array
+                    builder()->LoadAccumulatorWithRegister(done);
+                    builder()->JumpIfTrue(ToBooleanMode::kConvertToBoolean, &is_done);
+
+                    // var index = 0;
+                    Register index = register_allocator()->NewRegister();
+                    builder()->LoadLiteral(Smi::zero());
+                    builder()->StoreAccumulatorInRegister(index);
+
+                    // Set done to true, since it's guaranteed to be true by the time the
+                    // array fill completes.
+                    builder()->LoadTrue().StoreAccumulatorInRegister(done);
+
+                    // Fill the array with the iterator.
+                    FeedbackSlot element_slot =
+                            feedback_spec()->AddStoreInArrayLiteralICSlot();
+                    FeedbackSlot index_slot = feedback_spec()->AddBinaryOpICSlot();
+                    BuildFillArrayWithIterator(iterator, array, index, next_result,
+                                               next_value_load_slot, next_done_load_slot,
+                                               index_slot, element_slot);
+
+                    builder()->Bind(&is_done);
+                    // Assign the array to the LHS.
+                    builder()->LoadAccumulatorWithRegister(array);
+                    BuildAssignment(lhs_data, op, lookup_hoisting_mode);
+                }
+            },
+            // Finally block.
+            [&](Register iteration_continuation_token) {
+                // Finish the iteration in the finally block.
+                BuildFinalizeIteration(iterator, done, iteration_continuation_token);
+            },
+            HandlerTable::UNCAUGHT);
+
+    if (!execution_result()->IsEffect()) {
+        builder()->LoadAccumulatorWithRegister(value);
+    }
 }
 
 // Convert a destructuring assignment to an object literal into a sequence of
@@ -4344,437 +4647,501 @@ void BytecodeGenerator::BuildDestructuringArrayAssignment(
 // b.c =
 // %CopyDataPropertiesWithExcludedPropertiesOnStack.call(rest_runtime_callargs);
 void BytecodeGenerator::BuildDestructuringObjectAssignment(
-    ObjectLiteral* pattern, Token::Value op,
-    LookupHoistingMode lookup_hoisting_mode) {
-  RegisterAllocationScope register_scope(this);
-
-  // Store the assignment value in a register.
-  Register value;
-  RegisterList rest_runtime_callargs;
-  if (pattern->builder()->has_rest_property()) {
-    rest_runtime_callargs =
-        register_allocator()->NewRegisterList(pattern->properties()->length());
-    value = rest_runtime_callargs[0];
-  } else {
-    value = register_allocator()->NewRegister();
-  }
-  builder()->StoreAccumulatorInRegister(value);
-
-  // if (value === null || value === undefined)
-  //   throw new TypeError(kNonCoercible);
-  //
-  // Since the first property access on null/undefined will also trigger a
-  // TypeError, we can elide this check. The exception is when there are no
-  // properties and no rest property (this is an empty literal), or when the
-  // first property is a computed name and accessing it can have side effects.
-  //
-  // TODO(leszeks): Also eliminate this check if the value is known to be
-  // non-null (e.g. an object literal).
-  if (pattern->properties()->is_empty() ||
-      (pattern->properties()->at(0)->is_computed_name() &&
-       pattern->properties()->at(0)->kind() != ObjectLiteralProperty::SPREAD)) {
-    BytecodeLabel is_null_or_undefined, not_null_or_undefined;
-    builder()
-        ->JumpIfUndefinedOrNull(&is_null_or_undefined)
-        .Jump(&not_null_or_undefined);
+        ObjectLiteral* pattern, Token::Value op,
+        LookupHoistingMode lookup_hoisting_mode) {
+    RegisterAllocationScope register_scope(this);
 
-    {
-      builder()->Bind(&is_null_or_undefined);
-      builder()->SetExpressionPosition(pattern);
-      builder()->CallRuntime(Runtime::kThrowPatternAssignmentNonCoercible,
-                             value);
+    // Store the assignment value in a register.
+    Register value;
+    RegisterList rest_runtime_callargs;
+    if (pattern->builder()->has_rest_property()) {
+        rest_runtime_callargs =
+                register_allocator()->NewRegisterList(pattern->properties()->length());
+        value = rest_runtime_callargs[0];
+    } else {
+        value = register_allocator()->NewRegister();
     }
-    builder()->Bind(&not_null_or_undefined);
-  }
-
-  int i = 0;
-  for (ObjectLiteralProperty* pattern_property : *pattern->properties()) {
-    RegisterAllocationScope inner_register_scope(this);
+    builder()->StoreAccumulatorInRegister(value);
 
-    // The key of the pattern becomes the key into the RHS value, and the value
-    // of the pattern becomes the target of the assignment.
+    // if (value === null || value === undefined)
+    //   throw new TypeError(kNonCoercible);
     //
-    // e.g. { a: b } = o becomes b = o.a
-    Expression* pattern_key = pattern_property->key();
-    Expression* target = pattern_property->value();
-    Expression* default_value = GetDestructuringDefaultValue(&target);
-    builder()->SetExpressionPosition(target);
-
-    // Calculate this property's key into the assignment RHS value, additionally
-    // storing the key for rest_runtime_callargs if needed.
+    // Since the first property access on null/undefined will also trigger a
+    // TypeError, we can elide this check. The exception is when there are no
+    // properties and no rest property (this is an empty literal), or when the
+    // first property is a computed name and accessing it can have side effects.
     //
-    // The RHS is accessed using the key either by LoadNamedProperty (if
-    // value_name is valid) or by LoadKeyedProperty (otherwise).
-    const AstRawString* value_name = nullptr;
-    Register value_key;
-
-    if (pattern_property->kind() != ObjectLiteralProperty::Kind::SPREAD) {
-      if (pattern_key->IsPropertyName()) {
-        value_name = pattern_key->AsLiteral()->AsRawPropertyName();
-      }
-      if (pattern->builder()->has_rest_property() || !value_name) {
-        if (pattern->builder()->has_rest_property()) {
-          value_key = rest_runtime_callargs[i + 1];
-        } else {
-          value_key = register_allocator()->NewRegister();
-        }
-        if (pattern_property->is_computed_name()) {
-          // { [a()]: b().x } = c
-          // becomes
-          // var tmp = a()
-          // b().x = c[tmp]
-          DCHECK(!pattern_key->IsPropertyName() ||
-                 !pattern_key->IsNumberLiteral());
-          VisitForAccumulatorValue(pattern_key);
-          builder()->ToName(value_key);
-        } else {
-          // We only need the key for non-computed properties when it is numeric
-          // or is being saved for the rest_runtime_callargs.
-          DCHECK(pattern_key->IsNumberLiteral() ||
-                 (pattern->builder()->has_rest_property() &&
-                  pattern_key->IsPropertyName()));
-          VisitForRegisterValue(pattern_key, value_key);
-        }
-      }
-    }
-
-    AssignmentLhsData lhs_data = PrepareAssignmentLhs(target);
-
-    // Get the value from the RHS.
-    if (pattern_property->kind() == ObjectLiteralProperty::Kind::SPREAD) {
-      DCHECK_EQ(i, pattern->properties()->length() - 1);
-      DCHECK(!value_key.is_valid());
-      DCHECK_NULL(value_name);
-      builder()->CallRuntime(
-          Runtime::kInlineCopyDataPropertiesWithExcludedPropertiesOnStack,
-          rest_runtime_callargs);
-    } else if (value_name) {
-      builder()->LoadNamedProperty(
-          value, value_name, feedback_index(feedback_spec()->AddLoadICSlot()));
-    } else {
-      DCHECK(value_key.is_valid());
-      builder()->LoadAccumulatorWithRegister(value_key).LoadKeyedProperty(
-          value, feedback_index(feedback_spec()->AddKeyedLoadICSlot()));
-    }
+    // TODO(leszeks): Also eliminate this check if the value is known to be
+    // non-null (e.g. an object literal).
+    if (pattern->properties()->is_empty() ||
+        (pattern->properties()->at(0)->is_computed_name() &&
+         pattern->properties()->at(0)->kind() != ObjectLiteralProperty::SPREAD)) {
+        BytecodeLabel is_null_or_undefined, not_null_or_undefined;
+        builder()
+                ->JumpIfUndefinedOrNull(&is_null_or_undefined)
+                .Jump(&not_null_or_undefined);
 
-    // {<pattern> = <init>} = <value>
-    //   becomes
-    // temp = <value>;
-    // <pattern> = temp === undefined ? <init> : temp;
-    if (default_value) {
-      BytecodeLabel value_not_undefined;
-      builder()->JumpIfNotUndefined(&value_not_undefined);
-      VisitForAccumulatorValue(default_value);
-      builder()->Bind(&value_not_undefined);
+        {
+            builder()->Bind(&is_null_or_undefined);
+            builder()->SetExpressionPosition(pattern);
+            builder()->CallRuntime(Runtime::kThrowPatternAssignmentNonCoercible,
+                                   value);
+        }
+        builder()->Bind(&not_null_or_undefined);
     }
 
-    BuildAssignment(lhs_data, op, lookup_hoisting_mode);
+    int i = 0;
+    for (ObjectLiteralProperty* pattern_property : *pattern->properties()) {
+        RegisterAllocationScope inner_register_scope(this);
 
-    i++;
-  }
+        // The key of the pattern becomes the key into the RHS value, and the value
+        // of the pattern becomes the target of the assignment.
+        //
+        // e.g. { a: b } = o becomes b = o.a
+        Expression* pattern_key = pattern_property->key();
+        Expression* target = pattern_property->value();
+        Expression* default_value = GetDestructuringDefaultValue(&target);
+        builder()->SetExpressionPosition(target);
+
+        // Calculate this property's key into the assignment RHS value, additionally
+        // storing the key for rest_runtime_callargs if needed.
+        //
+        // The RHS is accessed using the key either by LoadNamedProperty (if
+        // value_name is valid) or by LoadKeyedProperty (otherwise).
+        const AstRawString* value_name = nullptr;
+        Register value_key;
+
+        if (pattern_property->kind() != ObjectLiteralProperty::Kind::SPREAD) {
+            if (pattern_key->IsPropertyName()) {
+                value_name = pattern_key->AsLiteral()->AsRawPropertyName();
+            }
+            if (pattern->builder()->has_rest_property() || !value_name) {
+                if (pattern->builder()->has_rest_property()) {
+                    value_key = rest_runtime_callargs[i + 1];
+                } else {
+                    value_key = register_allocator()->NewRegister();
+                }
+                if (pattern_property->is_computed_name()) {
+                    // { [a()]: b().x } = c
+                    // becomes
+                    // var tmp = a()
+                    // b().x = c[tmp]
+                    DCHECK(!pattern_key->IsPropertyName() ||
+                           !pattern_key->IsNumberLiteral());
+                    VisitForAccumulatorValue(pattern_key);
+                    builder()->ToName(value_key);
+                } else {
+                    // We only need the key for non-computed properties when it is numeric
+                    // or is being saved for the rest_runtime_callargs.
+                    DCHECK(pattern_key->IsNumberLiteral() ||
+                           (pattern->builder()->has_rest_property() &&
+                            pattern_key->IsPropertyName()));
+                    VisitForRegisterValue(pattern_key, value_key);
+                }
+            }
+        }
 
-  if (!execution_result()->IsEffect()) {
-    builder()->LoadAccumulatorWithRegister(value);
-  }
+        AssignmentLhsData lhs_data = PrepareAssignmentLhs(target);
+
+        // Get the value from the RHS.
+        if (pattern_property->kind() == ObjectLiteralProperty::Kind::SPREAD) {
+            DCHECK_EQ(i, pattern->properties()->length() - 1);
+            DCHECK(!value_key.is_valid());
+            DCHECK_NULL(value_name);
+            builder()->CallRuntime(
+                    Runtime::kInlineCopyDataPropertiesWithExcludedPropertiesOnStack,
+                    rest_runtime_callargs);
+        } else if (value_name) {
+            builder()->LoadNamedProperty(
+                    value, value_name, feedback_index(feedback_spec()->AddLoadICSlot()));
+        } else {
+            DCHECK(value_key.is_valid());
+            builder()->LoadAccumulatorWithRegister(value_key).LoadKeyedProperty(
+                    value, feedback_index(feedback_spec()->AddKeyedLoadICSlot()));
+        }
+
+        // {<pattern> = <init>} = <value>
+        //   becomes
+        // temp = <value>;
+        // <pattern> = temp === undefined ? <init> : temp;
+        if (default_value) {
+            BytecodeLabel value_not_undefined;
+            builder()->JumpIfNotUndefined(&value_not_undefined);
+            VisitForAccumulatorValue(default_value);
+            builder()->Bind(&value_not_undefined);
+        }
+
+        BuildAssignment(lhs_data, op, lookup_hoisting_mode);
+
+        i++;
+    }
+
+    if (!execution_result()->IsEffect()) {
+        builder()->LoadAccumulatorWithRegister(value);
+    }
 }
 
 void BytecodeGenerator::BuildAssignment(
-    const AssignmentLhsData& lhs_data, Token::Value op,
-    LookupHoistingMode lookup_hoisting_mode) {
-  // Assign the value to the LHS.
-  switch (lhs_data.assign_type()) {
-    case NON_PROPERTY: {
-      if (ObjectLiteral* pattern_as_object =
-              lhs_data.expr()->AsObjectLiteral()) {
-        // Split object literals into destructuring.
-        BuildDestructuringObjectAssignment(pattern_as_object, op,
-                                           lookup_hoisting_mode);
-      } else if (ArrayLiteral* pattern_as_array =
-                     lhs_data.expr()->AsArrayLiteral()) {
-        // Split object literals into destructuring.
-        BuildDestructuringArrayAssignment(pattern_as_array, op,
-                                          lookup_hoisting_mode);
-      } else {
-        DCHECK(lhs_data.expr()->IsVariableProxy());
-        VariableProxy* proxy = lhs_data.expr()->AsVariableProxy();
-        BuildVariableAssignment(proxy->var(), op, proxy->hole_check_mode(),
-                                lookup_hoisting_mode);
-      }
-      break;
-    }
-    case NAMED_PROPERTY: {
-      BuildSetNamedProperty(lhs_data.object_expr(), lhs_data.object(),
-                            lhs_data.name());
-      break;
-    }
-    case KEYED_PROPERTY: {
-      FeedbackSlot slot = feedback_spec()->AddKeyedStoreICSlot(language_mode());
-      Register value;
-      if (!execution_result()->IsEffect()) {
-        value = register_allocator()->NewRegister();
-        builder()->StoreAccumulatorInRegister(value);
-      }
-      builder()->SetKeyedProperty(lhs_data.object(), lhs_data.key(),
-                                  feedback_index(slot), language_mode());
-      if (!execution_result()->IsEffect()) {
-        builder()->LoadAccumulatorWithRegister(value);
-      }
-      break;
-    }
-    case NAMED_SUPER_PROPERTY: {
-      builder()
-          ->StoreAccumulatorInRegister(lhs_data.super_property_args()[3])
-          .CallRuntime(Runtime::kStoreToSuper, lhs_data.super_property_args());
-      break;
-    }
-    case KEYED_SUPER_PROPERTY: {
-      builder()
-          ->StoreAccumulatorInRegister(lhs_data.super_property_args()[3])
-          .CallRuntime(Runtime::kStoreKeyedToSuper,
-                       lhs_data.super_property_args());
-      break;
-    }
-    case PRIVATE_METHOD: {
-      Property* property = lhs_data.expr()->AsProperty();
-      BuildPrivateBrandCheck(property, lhs_data.object());
-      BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateMethodWrite,
-                                 lhs_data.expr()->AsProperty());
-      break;
-    }
-    case PRIVATE_GETTER_ONLY: {
-      Property* property = lhs_data.expr()->AsProperty();
-      BuildPrivateBrandCheck(property, lhs_data.object());
-      BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateSetterAccess,
-                                 lhs_data.expr()->AsProperty());
-      break;
-    }
-    case PRIVATE_SETTER_ONLY:
-    case PRIVATE_GETTER_AND_SETTER: {
-      Register value = register_allocator()->NewRegister();
-      builder()->StoreAccumulatorInRegister(value);
-      Property* property = lhs_data.expr()->AsProperty();
-      BuildPrivateBrandCheck(property, lhs_data.object());
-      BuildPrivateSetterAccess(lhs_data.object(), lhs_data.key(), value);
-      if (!execution_result()->IsEffect()) {
-        builder()->LoadAccumulatorWithRegister(value);
-      }
-      break;
+        const AssignmentLhsData& lhs_data, Token::Value op,
+        LookupHoistingMode lookup_hoisting_mode) {
+    // Assign the value to the LHS.
+    switch (lhs_data.assign_type()) {
+        case NON_PROPERTY: {
+            if (ObjectLiteral* pattern_as_object =
+                        lhs_data.expr()->AsObjectLiteral()) {
+                // Split object literals into destructuring.
+                BuildDestructuringObjectAssignment(pattern_as_object, op,
+                                                   lookup_hoisting_mode);
+            } else if (ArrayLiteral* pattern_as_array =
+                               lhs_data.expr()->AsArrayLiteral()) {
+                // Split object literals into destructuring.
+                BuildDestructuringArrayAssignment(pattern_as_array, op,
+                                                  lookup_hoisting_mode);
+            } else {
+                DCHECK(lhs_data.expr()->IsVariableProxy());
+                VariableProxy* proxy = lhs_data.expr()->AsVariableProxy();
+//        BuildVariableAssignment(proxy->var(), op, proxy->hole_check_mode(),
+//                                lookup_hoisting_mode);
+                BuildVariableAssignment(proxy, op, proxy->hole_check_mode(),
+                                        lookup_hoisting_mode); // xqg
+            }
+            break;
+        }
+        case NAMED_PROPERTY: {
+            BuildSetNamedProperty(lhs_data.object_expr(), lhs_data.object(),
+                                  lhs_data.name());
+            break;
+        }
+        case KEYED_PROPERTY: {
+            FeedbackSlot slot = feedback_spec()->AddKeyedStoreICSlot(language_mode());
+            Register value;
+            if (!execution_result()->IsEffect()) {
+                value = register_allocator()->NewRegister();
+                builder()->StoreAccumulatorInRegister(value);
+            }
+            builder()->SetKeyedProperty(lhs_data.object(), lhs_data.key(),
+                                        feedback_index(slot), language_mode());
+            if (!execution_result()->IsEffect()) {
+                builder()->LoadAccumulatorWithRegister(value);
+            }
+            break;
+        }
+        case NAMED_SUPER_PROPERTY: {
+            builder()
+                    ->StoreAccumulatorInRegister(lhs_data.super_property_args()[3])
+                    .CallRuntime(Runtime::kStoreToSuper, lhs_data.super_property_args());
+            break;
+        }
+        case KEYED_SUPER_PROPERTY: {
+            builder()
+                    ->StoreAccumulatorInRegister(lhs_data.super_property_args()[3])
+                    .CallRuntime(Runtime::kStoreKeyedToSuper,
+                                 lhs_data.super_property_args());
+            break;
+        }
+        case PRIVATE_METHOD: {
+            Property* property = lhs_data.expr()->AsProperty();
+            BuildPrivateBrandCheck(property, lhs_data.object());
+            BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateMethodWrite,
+                                       lhs_data.expr()->AsProperty());
+            break;
+        }
+        case PRIVATE_GETTER_ONLY: {
+            Property* property = lhs_data.expr()->AsProperty();
+            BuildPrivateBrandCheck(property, lhs_data.object());
+            BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateSetterAccess,
+                                       lhs_data.expr()->AsProperty());
+            break;
+        }
+        case PRIVATE_SETTER_ONLY:
+        case PRIVATE_GETTER_AND_SETTER: {
+            Register value = register_allocator()->NewRegister();
+            builder()->StoreAccumulatorInRegister(value);
+            Property* property = lhs_data.expr()->AsProperty();
+            BuildPrivateBrandCheck(property, lhs_data.object());
+            BuildPrivateSetterAccess(lhs_data.object(), lhs_data.key(), value);
+            if (!execution_result()->IsEffect()) {
+                builder()->LoadAccumulatorWithRegister(value);
+            }
+            break;
+        }
     }
-  }
 }
 
 void BytecodeGenerator::VisitAssignment(Assignment* expr) {
-  AssignmentLhsData lhs_data = PrepareAssignmentLhs(expr->target());
+    AssignmentLhsData lhs_data = PrepareAssignmentLhs(expr->target());
+
+    VisitForAccumulatorValue(expr->value());
+    // xqg start property
+    if (lhs_data.assign_type() != NON_PROPERTY){
+        {
+            Register temp1 = register_allocator()->NewRegister();
+            BytecodeLabel replace_smi_done;
+            builder()
+                    ->JumpIfNotSmi(&replace_smi_done)
+                    .StoreAccumulatorInRegister(temp1)
+                    .CallRuntime(Runtime::kTaintAnalysis_ReplaceSmiResult, temp1)
+                    .Bind(&replace_smi_done);
+
+            register_allocator()->ReleaseRegister(temp1);
+        }
 
-  VisitForAccumulatorValue(expr->value());
+        int init_reg_index = register_allocator()->next_register_index();
+        RegisterList temp_args = register_allocator()->NewRegisterList(3);
+        Register acc_init = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(acc_init);
 
-  builder()->SetExpressionPosition(expr);
-  BuildAssignment(lhs_data, expr->op(), expr->lookup_hoisting_mode());
+        builder()->StoreAccumulatorInRegister(temp_args[0])
+                .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                .StoreAccumulatorInRegister(temp_args[1])
+                .LoadLiteral(Smi::FromInt(expr->position()))
+                .StoreAccumulatorInRegister(temp_args[2])
+                .CallRuntime(Runtime::kTaintAnalysis_OnVisitProperty, temp_args);
+
+        builder()->LoadAccumulatorWithRegister(acc_init);
+        register_allocator()->ReleaseRegisters(init_reg_index);
+    }
+    // xqg end
+
+    builder()->SetExpressionPosition(expr);
+    BuildAssignment(lhs_data, expr->op(), expr->lookup_hoisting_mode());
 }
 
 void BytecodeGenerator::VisitCompoundAssignment(CompoundAssignment* expr) {
-  AssignmentLhsData lhs_data = PrepareAssignmentLhs(expr->target());
-
-  // Evaluate the value and potentially handle compound assignments by loading
-  // the left-hand side value and performing a binary operation.
-  switch (lhs_data.assign_type()) {
-    case NON_PROPERTY: {
-      VariableProxy* proxy = expr->target()->AsVariableProxy();
-      BuildVariableLoad(proxy->var(), proxy->hole_check_mode());
-      break;
-    }
-    case NAMED_PROPERTY: {
-      BuildLoadNamedProperty(lhs_data.object_expr(), lhs_data.object(),
-                             lhs_data.name());
-      break;
-    }
-    case KEYED_PROPERTY: {
-      FeedbackSlot slot = feedback_spec()->AddKeyedLoadICSlot();
-      builder()
-          ->LoadAccumulatorWithRegister(lhs_data.key())
-          .LoadKeyedProperty(lhs_data.object(), feedback_index(slot));
-      break;
-    }
-    case NAMED_SUPER_PROPERTY: {
-      builder()->CallRuntime(Runtime::kLoadFromSuper,
-                             lhs_data.super_property_args().Truncate(3));
-      break;
-    }
-    case KEYED_SUPER_PROPERTY: {
-      builder()->CallRuntime(Runtime::kLoadKeyedFromSuper,
-                             lhs_data.super_property_args().Truncate(3));
-      break;
-    }
-    // BuildAssignment() will throw an error about the private method being
-    // read-only.
-    case PRIVATE_METHOD: {
-      Property* property = lhs_data.expr()->AsProperty();
-      BuildPrivateBrandCheck(property, lhs_data.object());
-      builder()->LoadAccumulatorWithRegister(lhs_data.key());
-      break;
-    }
-    // For read-only properties, BuildAssignment() will throw an error about
-    // the missing setter.
-    case PRIVATE_GETTER_ONLY:
-    case PRIVATE_GETTER_AND_SETTER: {
-      Property* property = lhs_data.expr()->AsProperty();
-      BuildPrivateBrandCheck(property, lhs_data.object());
-      BuildPrivateGetterAccess(lhs_data.object(), lhs_data.key());
-      break;
-    }
-    case PRIVATE_SETTER_ONLY: {
-      // The property access is invalid, but if the brand check fails too, we
-      // need to return the error from the brand check.
-      Property* property = lhs_data.expr()->AsProperty();
-      BuildPrivateBrandCheck(property, lhs_data.object());
-      BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateGetterAccess,
-                                 lhs_data.expr()->AsProperty());
-      break;
+    AssignmentLhsData lhs_data = PrepareAssignmentLhs(expr->target());
+
+    // Evaluate the value and potentially handle compound assignments by loading
+    // the left-hand side value and performing a binary operation.
+    switch (lhs_data.assign_type()) {
+        case NON_PROPERTY: {
+            VariableProxy* proxy = expr->target()->AsVariableProxy();
+            // BuildVariableLoad(proxy->var(), proxy->hole_check_mode());
+            BuildVariableLoad(proxy, proxy->hole_check_mode()); // xqg
+            break;
+        }
+        case NAMED_PROPERTY: {
+            BuildLoadNamedProperty(lhs_data.object_expr(), lhs_data.object(),
+                                   lhs_data.name());
+            break;
+        }
+        case KEYED_PROPERTY: {
+            FeedbackSlot slot = feedback_spec()->AddKeyedLoadICSlot();
+            builder()
+                    ->LoadAccumulatorWithRegister(lhs_data.key())
+                    .LoadKeyedProperty(lhs_data.object(), feedback_index(slot));
+            break;
+        }
+        case NAMED_SUPER_PROPERTY: {
+            builder()->CallRuntime(Runtime::kLoadFromSuper,
+                                   lhs_data.super_property_args().Truncate(3));
+            break;
+        }
+        case KEYED_SUPER_PROPERTY: {
+            builder()->CallRuntime(Runtime::kLoadKeyedFromSuper,
+                                   lhs_data.super_property_args().Truncate(3));
+            break;
+        }
+            // BuildAssignment() will throw an error about the private method being
+            // read-only.
+        case PRIVATE_METHOD: {
+            Property* property = lhs_data.expr()->AsProperty();
+            BuildPrivateBrandCheck(property, lhs_data.object());
+            builder()->LoadAccumulatorWithRegister(lhs_data.key());
+            break;
+        }
+            // For read-only properties, BuildAssignment() will throw an error about
+            // the missing setter.
+        case PRIVATE_GETTER_ONLY:
+        case PRIVATE_GETTER_AND_SETTER: {
+            Property* property = lhs_data.expr()->AsProperty();
+            BuildPrivateBrandCheck(property, lhs_data.object());
+            BuildPrivateGetterAccess(lhs_data.object(), lhs_data.key());
+            break;
+        }
+        case PRIVATE_SETTER_ONLY: {
+            // The property access is invalid, but if the brand check fails too, we
+            // need to return the error from the brand check.
+            Property* property = lhs_data.expr()->AsProperty();
+            BuildPrivateBrandCheck(property, lhs_data.object());
+            BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateGetterAccess,
+                                       lhs_data.expr()->AsProperty());
+            break;
+        }
     }
-  }
 
-  BinaryOperation* binop = expr->binary_operation();
-  FeedbackSlot slot = feedback_spec()->AddBinaryOpICSlot();
-  BytecodeLabel short_circuit;
-  if (binop->op() == Token::NULLISH) {
-    BytecodeLabel nullish;
-    builder()
-        ->JumpIfUndefinedOrNull(&nullish)
-        .Jump(&short_circuit)
-        .Bind(&nullish);
-    VisitForAccumulatorValue(expr->value());
-  } else if (binop->op() == Token::OR) {
-    builder()->JumpIfTrue(ToBooleanMode::kConvertToBoolean, &short_circuit);
-    VisitForAccumulatorValue(expr->value());
-  } else if (binop->op() == Token::AND) {
-    builder()->JumpIfFalse(ToBooleanMode::kConvertToBoolean, &short_circuit);
-    VisitForAccumulatorValue(expr->value());
-  } else if (expr->value()->IsSmiLiteral()) {
-    builder()->BinaryOperationSmiLiteral(
-        binop->op(), expr->value()->AsLiteral()->AsSmiLiteral(),
-        feedback_index(slot));
-  } else {
-    Register old_value = register_allocator()->NewRegister();
-    builder()->StoreAccumulatorInRegister(old_value);
-    VisitForAccumulatorValue(expr->value());
-    builder()->BinaryOperation(binop->op(), old_value, feedback_index(slot));
-  }
-  builder()->SetExpressionPosition(expr);
+    BinaryOperation* binop = expr->binary_operation();
+    FeedbackSlot slot = feedback_spec()->AddBinaryOpICSlot();
+    BytecodeLabel short_circuit;
+    if (binop->op() == Token::NULLISH) {
+        BytecodeLabel nullish;
+        builder()
+                ->JumpIfUndefinedOrNull(&nullish)
+                .Jump(&short_circuit)
+                .Bind(&nullish);
+        VisitForAccumulatorValue(expr->value());
+    } else if (binop->op() == Token::OR) {
+        builder()->JumpIfTrue(ToBooleanMode::kConvertToBoolean, &short_circuit);
+        VisitForAccumulatorValue(expr->value());
+    } else if (binop->op() == Token::AND) {
+        builder()->JumpIfFalse(ToBooleanMode::kConvertToBoolean, &short_circuit);
+        VisitForAccumulatorValue(expr->value());
+    } else if (expr->value()->IsSmiLiteral()) {
+        builder()->BinaryOperationSmiLiteral(
+                binop->op(), expr->value()->AsLiteral()->AsSmiLiteral(),
+                feedback_index(slot));
+    } else {
+        Register old_value = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(old_value);
+        VisitForAccumulatorValue(expr->value());
+        builder()->BinaryOperation(binop->op(), old_value, feedback_index(slot));
+    }
+
+    // xqg start
+    if (lhs_data.assign_type() != NON_PROPERTY){
+        {
+            Register temp1 = register_allocator()->NewRegister();
+            BytecodeLabel replace_smi_done;
+            builder()
+                    ->JumpIfNotSmi(&replace_smi_done)
+                    .StoreAccumulatorInRegister(temp1)
+                    .CallRuntime(Runtime::kTaintAnalysis_ReplaceSmiResult, temp1)
+                    .Bind(&replace_smi_done);
+
+            register_allocator()->ReleaseRegister(temp1);
+        }
+        int init_reg_index = register_allocator()->next_register_index();
+        RegisterList temp_args = register_allocator()->NewRegisterList(3);
+        Register acc_init = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(acc_init);
+
+        builder()->StoreAccumulatorInRegister(temp_args[0])
+                .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                .StoreAccumulatorInRegister(temp_args[1])
+                .LoadLiteral(Smi::FromInt(expr->position()))
+                .StoreAccumulatorInRegister(temp_args[2])
+                .CallRuntime(Runtime::kTaintAnalysis_OnVisitProperty, temp_args);
+
+        builder()->LoadAccumulatorWithRegister(acc_init);
+        register_allocator()->ReleaseRegisters(init_reg_index);
+    }
+    // xqg end
+
+    builder()->SetExpressionPosition(expr);
 
-  BuildAssignment(lhs_data, expr->op(), expr->lookup_hoisting_mode());
-  builder()->Bind(&short_circuit);
+    BuildAssignment(lhs_data, expr->op(), expr->lookup_hoisting_mode());
+    builder()->Bind(&short_circuit);
 }
 
 // Suspends the generator to resume at the next suspend_id, with output stored
 // in the accumulator. When the generator is resumed, the sent value is loaded
 // in the accumulator.
 void BytecodeGenerator::BuildSuspendPoint(int position) {
-  // Because we eliminate jump targets in dead code, we also eliminate resumes
-  // when the suspend is not emitted because otherwise the below call to Bind
-  // would start a new basic block and the code would be considered alive.
-  if (builder()->RemainderOfBlockIsDead()) {
-    return;
-  }
-  const int suspend_id = suspend_count_++;
+    // Because we eliminate jump targets in dead code, we also eliminate resumes
+    // when the suspend is not emitted because otherwise the below call to Bind
+    // would start a new basic block and the code would be considered alive.
+    if (builder()->RemainderOfBlockIsDead()) {
+        return;
+    }
+    const int suspend_id = suspend_count_++;
 
-  RegisterList registers = register_allocator()->AllLiveRegisters();
+    RegisterList registers = register_allocator()->AllLiveRegisters();
 
-  // Save context, registers, and state. This bytecode then returns the value
-  // in the accumulator.
-  builder()->SetExpressionPosition(position);
-  builder()->SuspendGenerator(generator_object(), registers, suspend_id);
+    // Save context, registers, and state. This bytecode then returns the value
+    // in the accumulator.
+    builder()->SetExpressionPosition(position);
+    builder()->SuspendGenerator(generator_object(), registers, suspend_id);
 
-  // Upon resume, we continue here.
-  builder()->Bind(generator_jump_table_, suspend_id);
+    // Upon resume, we continue here.
+    builder()->Bind(generator_jump_table_, suspend_id);
 
-  // Clobbers all registers and sets the accumulator to the
-  // [[input_or_debug_pos]] slot of the generator object.
-  builder()->ResumeGenerator(generator_object(), registers);
+    // Clobbers all registers and sets the accumulator to the
+    // [[input_or_debug_pos]] slot of the generator object.
+    builder()->ResumeGenerator(generator_object(), registers);
 }
 
 void BytecodeGenerator::VisitYield(Yield* expr) {
-  builder()->SetExpressionPosition(expr);
-  VisitForAccumulatorValue(expr->expression());
-
-  // If this is not the first yield
-  if (suspend_count_ > 0) {
-    if (IsAsyncGeneratorFunction(function_kind())) {
-      // AsyncGenerator yields (with the exception of the initial yield)
-      // delegate work to the AsyncGeneratorYieldWithAwait stub, which Awaits
-      // the operand and on success, wraps the value in an IteratorResult.
-      //
-      // In the spec the Await is a separate operation, but they are combined
-      // here to reduce bytecode size.
-      RegisterAllocationScope register_scope(this);
-      RegisterList args = register_allocator()->NewRegisterList(3);
-      builder()
-          ->MoveRegister(generator_object(), args[0])  // generator
-          .StoreAccumulatorInRegister(args[1])         // value
-          .LoadBoolean(catch_prediction() != HandlerTable::ASYNC_AWAIT)
-          .StoreAccumulatorInRegister(args[2])  // is_caught
-          .CallRuntime(Runtime::kInlineAsyncGeneratorYieldWithAwait, args);
-    } else {
-      // Generator yields (with the exception of the initial yield) wrap the
-      // value into IteratorResult.
-      RegisterAllocationScope register_scope(this);
-      RegisterList args = register_allocator()->NewRegisterList(2);
-      builder()
-          ->StoreAccumulatorInRegister(args[0])  // value
-          .LoadFalse()
-          .StoreAccumulatorInRegister(args[1])  // done
-          .CallRuntime(Runtime::kInlineCreateIterResultObject, args);
-    }
-  }
+    builder()->SetExpressionPosition(expr);
+    VisitForAccumulatorValue(expr->expression());
 
-  BuildSuspendPoint(expr->position());
-  // At this point, the generator has been resumed, with the received value in
-  // the accumulator.
+    // If this is not the first yield
+    if (suspend_count_ > 0) {
+        if (IsAsyncGeneratorFunction(function_kind())) {
+            // AsyncGenerator yields (with the exception of the initial yield)
+            // delegate work to the AsyncGeneratorYieldWithAwait stub, which Awaits
+            // the operand and on success, wraps the value in an IteratorResult.
+            //
+            // In the spec the Await is a separate operation, but they are combined
+            // here to reduce bytecode size.
+            RegisterAllocationScope register_scope(this);
+            RegisterList args = register_allocator()->NewRegisterList(3);
+            builder()
+                    ->MoveRegister(generator_object(), args[0])  // generator
+                    .StoreAccumulatorInRegister(args[1])         // value
+                    .LoadBoolean(catch_prediction() != HandlerTable::ASYNC_AWAIT)
+                    .StoreAccumulatorInRegister(args[2])  // is_caught
+                    .CallRuntime(Runtime::kInlineAsyncGeneratorYieldWithAwait, args);
+        } else {
+            // Generator yields (with the exception of the initial yield) wrap the
+            // value into IteratorResult.
+            RegisterAllocationScope register_scope(this);
+            RegisterList args = register_allocator()->NewRegisterList(2);
+            builder()
+                    ->StoreAccumulatorInRegister(args[0])  // value
+                    .LoadFalse()
+                    .StoreAccumulatorInRegister(args[1])  // done
+                    .CallRuntime(Runtime::kInlineCreateIterResultObject, args);
+        }
+    }
 
-  // TODO(caitp): remove once yield* desugaring for async generators is handled
-  // in BytecodeGenerator.
-  if (expr->on_abrupt_resume() == Yield::kNoControl) {
-    DCHECK(IsAsyncGeneratorFunction(function_kind()));
-    return;
-  }
+    BuildSuspendPoint(expr->position());
+    // At this point, the generator has been resumed, with the received value in
+    // the accumulator.
 
-  Register input = register_allocator()->NewRegister();
-  builder()->StoreAccumulatorInRegister(input).CallRuntime(
-      Runtime::kInlineGeneratorGetResumeMode, generator_object());
+    // TODO(caitp): remove once yield* desugaring for async generators is handled
+    // in BytecodeGenerator.
+    if (expr->on_abrupt_resume() == Yield::kNoControl) {
+        DCHECK(IsAsyncGeneratorFunction(function_kind()));
+        return;
+    }
 
-  // Now dispatch on resume mode.
-  static_assert(JSGeneratorObject::kNext + 1 == JSGeneratorObject::kReturn);
-  BytecodeJumpTable* jump_table =
-      builder()->AllocateJumpTable(2, JSGeneratorObject::kNext);
+    Register input = register_allocator()->NewRegister();
+    builder()->StoreAccumulatorInRegister(input).CallRuntime(
+            Runtime::kInlineGeneratorGetResumeMode, generator_object());
 
-  builder()->SwitchOnSmiNoFeedback(jump_table);
+    // Now dispatch on resume mode.
+    static_assert(JSGeneratorObject::kNext + 1 == JSGeneratorObject::kReturn);
+    BytecodeJumpTable* jump_table =
+            builder()->AllocateJumpTable(2, JSGeneratorObject::kNext);
 
-  {
-    // Resume with throw (switch fallthrough).
-    // TODO(leszeks): Add a debug-only check that the accumulator is
-    // JSGeneratorObject::kThrow.
-    builder()->SetExpressionPosition(expr);
-    builder()->LoadAccumulatorWithRegister(input);
-    builder()->Throw();
-  }
+    builder()->SwitchOnSmiNoFeedback(jump_table);
 
-  {
-    // Resume with return.
-    builder()->Bind(jump_table, JSGeneratorObject::kReturn);
-    builder()->LoadAccumulatorWithRegister(input);
-    if (IsAsyncGeneratorFunction(function_kind())) {
-      execution_control()->AsyncReturnAccumulator(kNoSourcePosition);
-    } else {
-      execution_control()->ReturnAccumulator(kNoSourcePosition);
+    {
+        // Resume with throw (switch fallthrough).
+        // TODO(leszeks): Add a debug-only check that the accumulator is
+        // JSGeneratorObject::kThrow.
+        builder()->SetExpressionPosition(expr);
+        builder()->LoadAccumulatorWithRegister(input);
+        builder()->Throw();
     }
-  }
 
-  {
-    // Resume with next.
-    builder()->Bind(jump_table, JSGeneratorObject::kNext);
-    BuildIncrementBlockCoverageCounterIfEnabled(expr,
-                                                SourceRangeKind::kContinuation);
-    builder()->LoadAccumulatorWithRegister(input);
-  }
+    {
+        // Resume with return.
+        builder()->Bind(jump_table, JSGeneratorObject::kReturn);
+        builder()->LoadAccumulatorWithRegister(input);
+        if (IsAsyncGeneratorFunction(function_kind())) {
+            execution_control()->AsyncReturnAccumulator(kNoSourcePosition);
+        } else {
+            execution_control()->ReturnAccumulator(kNoSourcePosition);
+        }
+    }
+
+    {
+        // Resume with next.
+        builder()->Bind(jump_table, JSGeneratorObject::kNext);
+        BuildIncrementBlockCoverageCounterIfEnabled(expr,
+                                                    SourceRangeKind::kContinuation);
+        builder()->LoadAccumulatorWithRegister(input);
+    }
 }
 
 // Desugaring of (yield* iterable)
@@ -4842,1512 +5209,1673 @@ void BytecodeGenerator::VisitYield(Yield* expr) {
 //     output.value
 //   }
 void BytecodeGenerator::VisitYieldStar(YieldStar* expr) {
-  Register output = register_allocator()->NewRegister();
-  Register resume_mode = register_allocator()->NewRegister();
-  IteratorType iterator_type = IsAsyncGeneratorFunction(function_kind())
-                                   ? IteratorType::kAsync
-                                   : IteratorType::kNormal;
-
-  {
-    RegisterAllocationScope register_scope(this);
-    RegisterList iterator_and_input = register_allocator()->NewRegisterList(2);
-    VisitForAccumulatorValue(expr->expression());
-    IteratorRecord iterator = BuildGetIteratorRecord(
-        register_allocator()->NewRegister() /* next method */,
-        iterator_and_input[0], iterator_type);
-
-    Register input = iterator_and_input[1];
-    builder()->LoadUndefined().StoreAccumulatorInRegister(input);
-    builder()
-        ->LoadLiteral(Smi::FromInt(JSGeneratorObject::kNext))
-        .StoreAccumulatorInRegister(resume_mode);
+    Register output = register_allocator()->NewRegister();
+    Register resume_mode = register_allocator()->NewRegister();
+    IteratorType iterator_type = IsAsyncGeneratorFunction(function_kind())
+                                 ? IteratorType::kAsync
+                                 : IteratorType::kNormal;
 
     {
-      // This loop builder does not construct counters as the loop is not
-      // visible to the user, and we therefore neither pass the block coverage
-      // builder nor the expression.
-      //
-      // In addition to the normal suspend for yield*, a yield* in an async
-      // generator has 2 additional suspends:
-      //   - One for awaiting the iterator result of closing the generator when
-      //     resumed with a "throw" completion, and a throw method is not
-      //     present on the delegated iterator
-      //   - One for awaiting the iterator result yielded by the delegated
-      //     iterator
-
-      LoopBuilder loop_builder(builder(), nullptr, nullptr, feedback_spec());
-      LoopScope loop_scope(this, &loop_builder);
-
-      {
-        BytecodeLabels after_switch(zone());
-        BytecodeJumpTable* switch_jump_table =
-            builder()->AllocateJumpTable(2, 1);
-
+        RegisterAllocationScope register_scope(this);
+        RegisterList iterator_and_input = register_allocator()->NewRegisterList(2);
+        VisitForAccumulatorValue(expr->expression());
+        IteratorRecord iterator = BuildGetIteratorRecord(
+                register_allocator()->NewRegister() /* next method */,
+                iterator_and_input[0], iterator_type);
+
+        Register input = iterator_and_input[1];
+        builder()->LoadUndefined().StoreAccumulatorInRegister(input);
         builder()
-            ->LoadAccumulatorWithRegister(resume_mode)
-            .SwitchOnSmiNoFeedback(switch_jump_table);
+                ->LoadLiteral(Smi::FromInt(JSGeneratorObject::kNext))
+                .StoreAccumulatorInRegister(resume_mode);
 
-        // Fallthrough to default case.
-        // TODO(ignition): Add debug code to check that {resume_mode} really is
-        // {JSGeneratorObject::kNext} in this case.
-        static_assert(JSGeneratorObject::kNext == 0);
         {
-          FeedbackSlot slot = feedback_spec()->AddCallICSlot();
-          builder()->CallProperty(iterator.next(), iterator_and_input,
-                                  feedback_index(slot));
-          builder()->Jump(after_switch.New());
-        }
+            // This loop builder does not construct counters as the loop is not
+            // visible to the user, and we therefore neither pass the block coverage
+            // builder nor the expression.
+            //
+            // In addition to the normal suspend for yield*, a yield* in an async
+            // generator has 2 additional suspends:
+            //   - One for awaiting the iterator result of closing the generator when
+            //     resumed with a "throw" completion, and a throw method is not
+            //     present on the delegated iterator
+            //   - One for awaiting the iterator result yielded by the delegated
+            //     iterator
+
+            LoopBuilder loop_builder(builder(), nullptr, nullptr, feedback_spec());
+            LoopScope loop_scope(this, &loop_builder);
+
+            {
+                BytecodeLabels after_switch(zone());
+                BytecodeJumpTable* switch_jump_table =
+                        builder()->AllocateJumpTable(2, 1);
+
+                builder()
+                        ->LoadAccumulatorWithRegister(resume_mode)
+                        .SwitchOnSmiNoFeedback(switch_jump_table);
+
+                // Fallthrough to default case.
+                // TODO(ignition): Add debug code to check that {resume_mode} really is
+                // {JSGeneratorObject::kNext} in this case.
+                static_assert(JSGeneratorObject::kNext == 0);
+                {
+                    FeedbackSlot slot = feedback_spec()->AddCallICSlot();
+                    builder()->CallProperty(iterator.next(), iterator_and_input,
+                                            feedback_index(slot));
+                    builder()->Jump(after_switch.New());
+                }
+
+                static_assert(JSGeneratorObject::kReturn == 1);
+                builder()->Bind(switch_jump_table, JSGeneratorObject::kReturn);
+                {
+                    const AstRawString* return_string =
+                            ast_string_constants()->return_string();
+                    BytecodeLabels no_return_method(zone());
+
+                    BuildCallIteratorMethod(iterator.object(), return_string,
+                                            iterator_and_input, after_switch.New(),
+                                            &no_return_method);
+                    no_return_method.Bind(builder());
+                    builder()->LoadAccumulatorWithRegister(input);
+                    if (iterator_type == IteratorType::kAsync) {
+                        // Await input.
+                        BuildAwait(expr->position());
+                        execution_control()->AsyncReturnAccumulator(kNoSourcePosition);
+                    } else {
+                        execution_control()->ReturnAccumulator(kNoSourcePosition);
+                    }
+                }
+
+                static_assert(JSGeneratorObject::kThrow == 2);
+                builder()->Bind(switch_jump_table, JSGeneratorObject::kThrow);
+                {
+                    const AstRawString* throw_string =
+                            ast_string_constants()->throw_string();
+                    BytecodeLabels no_throw_method(zone());
+                    BuildCallIteratorMethod(iterator.object(), throw_string,
+                                            iterator_and_input, after_switch.New(),
+                                            &no_throw_method);
+
+                    // If there is no "throw" method, perform IteratorClose, and finally
+                    // throw a TypeError.
+                    no_throw_method.Bind(builder());
+                    BuildIteratorClose(iterator, expr);
+                    builder()->CallRuntime(Runtime::kThrowThrowMethodMissing);
+                }
+
+                after_switch.Bind(builder());
+            }
 
-        static_assert(JSGeneratorObject::kReturn == 1);
-        builder()->Bind(switch_jump_table, JSGeneratorObject::kReturn);
-        {
-          const AstRawString* return_string =
-              ast_string_constants()->return_string();
-          BytecodeLabels no_return_method(zone());
-
-          BuildCallIteratorMethod(iterator.object(), return_string,
-                                  iterator_and_input, after_switch.New(),
-                                  &no_return_method);
-          no_return_method.Bind(builder());
-          builder()->LoadAccumulatorWithRegister(input);
-          if (iterator_type == IteratorType::kAsync) {
-            // Await input.
-            BuildAwait(expr->position());
-            execution_control()->AsyncReturnAccumulator(kNoSourcePosition);
-          } else {
-            execution_control()->ReturnAccumulator(kNoSourcePosition);
-          }
-        }
+            if (iterator_type == IteratorType::kAsync) {
+                // Await the result of the method invocation.
+                BuildAwait(expr->position());
+            }
 
-        static_assert(JSGeneratorObject::kThrow == 2);
-        builder()->Bind(switch_jump_table, JSGeneratorObject::kThrow);
-        {
-          const AstRawString* throw_string =
-              ast_string_constants()->throw_string();
-          BytecodeLabels no_throw_method(zone());
-          BuildCallIteratorMethod(iterator.object(), throw_string,
-                                  iterator_and_input, after_switch.New(),
-                                  &no_throw_method);
+            // Check that output is an object.
+            BytecodeLabel check_if_done;
+            builder()
+                    ->StoreAccumulatorInRegister(output)
+                    .JumpIfJSReceiver(&check_if_done)
+                    .CallRuntime(Runtime::kThrowIteratorResultNotAnObject, output);
 
-          // If there is no "throw" method, perform IteratorClose, and finally
-          // throw a TypeError.
-          no_throw_method.Bind(builder());
-          BuildIteratorClose(iterator, expr);
-          builder()->CallRuntime(Runtime::kThrowThrowMethodMissing);
-        }
+            builder()->Bind(&check_if_done);
+            // Break once output.done is true.
+            builder()->LoadNamedProperty(
+                    output, ast_string_constants()->done_string(),
+                    feedback_index(feedback_spec()->AddLoadICSlot()));
 
-        after_switch.Bind(builder());
-      }
+            loop_builder.BreakIfTrue(ToBooleanMode::kConvertToBoolean);
 
-      if (iterator_type == IteratorType::kAsync) {
-        // Await the result of the method invocation.
-        BuildAwait(expr->position());
-      }
-
-      // Check that output is an object.
-      BytecodeLabel check_if_done;
-      builder()
-          ->StoreAccumulatorInRegister(output)
-          .JumpIfJSReceiver(&check_if_done)
-          .CallRuntime(Runtime::kThrowIteratorResultNotAnObject, output);
-
-      builder()->Bind(&check_if_done);
-      // Break once output.done is true.
-      builder()->LoadNamedProperty(
-          output, ast_string_constants()->done_string(),
-          feedback_index(feedback_spec()->AddLoadICSlot()));
-
-      loop_builder.BreakIfTrue(ToBooleanMode::kConvertToBoolean);
-
-      // Suspend the current generator.
-      if (iterator_type == IteratorType::kNormal) {
-        builder()->LoadAccumulatorWithRegister(output);
-      } else {
-        RegisterAllocationScope inner_register_scope(this);
-        DCHECK_EQ(iterator_type, IteratorType::kAsync);
-        // If generatorKind is async, perform
-        // AsyncGeneratorResolve(output.value, /* done = */ false), which will
-        // resolve the current AsyncGeneratorRequest's promise with
-        // output.value.
-        builder()->LoadNamedProperty(
-            output, ast_string_constants()->value_string(),
-            feedback_index(feedback_spec()->AddLoadICSlot()));
+            // Suspend the current generator.
+            if (iterator_type == IteratorType::kNormal) {
+                builder()->LoadAccumulatorWithRegister(output);
+            } else {
+                RegisterAllocationScope inner_register_scope(this);
+                DCHECK_EQ(iterator_type, IteratorType::kAsync);
+                // If generatorKind is async, perform
+                // AsyncGeneratorResolve(output.value, /* done = */ false), which will
+                // resolve the current AsyncGeneratorRequest's promise with
+                // output.value.
+                builder()->LoadNamedProperty(
+                        output, ast_string_constants()->value_string(),
+                        feedback_index(feedback_spec()->AddLoadICSlot()));
+
+                RegisterList args = register_allocator()->NewRegisterList(3);
+                builder()
+                        ->MoveRegister(generator_object(), args[0])  // generator
+                        .StoreAccumulatorInRegister(args[1])         // value
+                        .LoadFalse()
+                        .StoreAccumulatorInRegister(args[2])  // done
+                        .CallRuntime(Runtime::kInlineAsyncGeneratorResolve, args);
+            }
 
-        RegisterList args = register_allocator()->NewRegisterList(3);
-        builder()
-            ->MoveRegister(generator_object(), args[0])  // generator
-            .StoreAccumulatorInRegister(args[1])         // value
-            .LoadFalse()
-            .StoreAccumulatorInRegister(args[2])  // done
-            .CallRuntime(Runtime::kInlineAsyncGeneratorResolve, args);
-      }
-
-      BuildSuspendPoint(expr->position());
-      builder()->StoreAccumulatorInRegister(input);
-      builder()
-          ->CallRuntime(Runtime::kInlineGeneratorGetResumeMode,
-                        generator_object())
-          .StoreAccumulatorInRegister(resume_mode);
-
-      loop_builder.BindContinueTarget();
+            BuildSuspendPoint(expr->position());
+            builder()->StoreAccumulatorInRegister(input);
+            builder()
+                    ->CallRuntime(Runtime::kInlineGeneratorGetResumeMode,
+                                  generator_object())
+                    .StoreAccumulatorInRegister(resume_mode);
+
+            loop_builder.BindContinueTarget();
+        }
     }
-  }
 
-  // Decide if we trigger a return or if the yield* expression should just
-  // produce a value.
-  BytecodeLabel completion_is_output_value;
-  Register output_value = register_allocator()->NewRegister();
-  builder()
-      ->LoadNamedProperty(output, ast_string_constants()->value_string(),
-                          feedback_index(feedback_spec()->AddLoadICSlot()))
-      .StoreAccumulatorInRegister(output_value)
-      .LoadLiteral(Smi::FromInt(JSGeneratorObject::kReturn))
-      .CompareReference(resume_mode)
-      .JumpIfFalse(ToBooleanMode::kAlreadyBoolean, &completion_is_output_value)
-      .LoadAccumulatorWithRegister(output_value);
-  if (iterator_type == IteratorType::kAsync) {
-    execution_control()->AsyncReturnAccumulator(kNoSourcePosition);
-  } else {
-    execution_control()->ReturnAccumulator(kNoSourcePosition);
-  }
+    // Decide if we trigger a return or if the yield* expression should just
+    // produce a value.
+    BytecodeLabel completion_is_output_value;
+    Register output_value = register_allocator()->NewRegister();
+    builder()
+            ->LoadNamedProperty(output, ast_string_constants()->value_string(),
+                                feedback_index(feedback_spec()->AddLoadICSlot()))
+            .StoreAccumulatorInRegister(output_value)
+            .LoadLiteral(Smi::FromInt(JSGeneratorObject::kReturn))
+            .CompareReference(resume_mode)
+            .JumpIfFalse(ToBooleanMode::kAlreadyBoolean, &completion_is_output_value)
+            .LoadAccumulatorWithRegister(output_value);
+    if (iterator_type == IteratorType::kAsync) {
+        execution_control()->AsyncReturnAccumulator(kNoSourcePosition);
+    } else {
+        execution_control()->ReturnAccumulator(kNoSourcePosition);
+    }
 
-  builder()->Bind(&completion_is_output_value);
-  BuildIncrementBlockCoverageCounterIfEnabled(expr,
-                                              SourceRangeKind::kContinuation);
-  builder()->LoadAccumulatorWithRegister(output_value);
+    builder()->Bind(&completion_is_output_value);
+    BuildIncrementBlockCoverageCounterIfEnabled(expr,
+                                                SourceRangeKind::kContinuation);
+    builder()->LoadAccumulatorWithRegister(output_value);
 }
 
 void BytecodeGenerator::BuildAwait(int position) {
-  // Rather than HandlerTable::UNCAUGHT, async functions use
-  // HandlerTable::ASYNC_AWAIT to communicate that top-level exceptions are
-  // transformed into promise rejections. This is necessary to prevent emitting
-  // multiple debug events for the same uncaught exception. There is no point
-  // in the body of an async function where catch prediction is
-  // HandlerTable::UNCAUGHT.
-  DCHECK(catch_prediction() != HandlerTable::UNCAUGHT ||
-         info()->scope()->is_repl_mode_scope());
-
-  {
-    // Await(operand) and suspend.
-    RegisterAllocationScope register_scope(this);
+    // Rather than HandlerTable::UNCAUGHT, async functions use
+    // HandlerTable::ASYNC_AWAIT to communicate that top-level exceptions are
+    // transformed into promise rejections. This is necessary to prevent emitting
+    // multiple debug events for the same uncaught exception. There is no point
+    // in the body of an async function where catch prediction is
+    // HandlerTable::UNCAUGHT.
+    DCHECK(catch_prediction() != HandlerTable::UNCAUGHT ||
+           info()->scope()->is_repl_mode_scope());
 
-    Runtime::FunctionId await_intrinsic_id;
-    if (IsAsyncGeneratorFunction(function_kind())) {
-      await_intrinsic_id = catch_prediction() == HandlerTable::ASYNC_AWAIT
-                               ? Runtime::kInlineAsyncGeneratorAwaitUncaught
-                               : Runtime::kInlineAsyncGeneratorAwaitCaught;
-    } else {
-      await_intrinsic_id = catch_prediction() == HandlerTable::ASYNC_AWAIT
-                               ? Runtime::kInlineAsyncFunctionAwaitUncaught
-                               : Runtime::kInlineAsyncFunctionAwaitCaught;
-    }
-    RegisterList args = register_allocator()->NewRegisterList(2);
-    builder()
-        ->MoveRegister(generator_object(), args[0])
-        .StoreAccumulatorInRegister(args[1])
-        .CallRuntime(await_intrinsic_id, args);
-  }
+    {
+        // Await(operand) and suspend.
+        RegisterAllocationScope register_scope(this);
 
-  BuildSuspendPoint(position);
+        Runtime::FunctionId await_intrinsic_id;
+        if (IsAsyncGeneratorFunction(function_kind())) {
+            await_intrinsic_id = catch_prediction() == HandlerTable::ASYNC_AWAIT
+                                 ? Runtime::kInlineAsyncGeneratorAwaitUncaught
+                                 : Runtime::kInlineAsyncGeneratorAwaitCaught;
+        } else {
+            await_intrinsic_id = catch_prediction() == HandlerTable::ASYNC_AWAIT
+                                 ? Runtime::kInlineAsyncFunctionAwaitUncaught
+                                 : Runtime::kInlineAsyncFunctionAwaitCaught;
+        }
+        RegisterList args = register_allocator()->NewRegisterList(2);
+        builder()
+                ->MoveRegister(generator_object(), args[0])
+                .StoreAccumulatorInRegister(args[1])
+                .CallRuntime(await_intrinsic_id, args);
+    }
 
-  Register input = register_allocator()->NewRegister();
-  Register resume_mode = register_allocator()->NewRegister();
+    BuildSuspendPoint(position);
 
-  // Now dispatch on resume mode.
-  BytecodeLabel resume_next;
-  builder()
-      ->StoreAccumulatorInRegister(input)
-      .CallRuntime(Runtime::kInlineGeneratorGetResumeMode, generator_object())
-      .StoreAccumulatorInRegister(resume_mode)
-      .LoadLiteral(Smi::FromInt(JSGeneratorObject::kNext))
-      .CompareReference(resume_mode)
-      .JumpIfTrue(ToBooleanMode::kAlreadyBoolean, &resume_next);
+    Register input = register_allocator()->NewRegister();
+    Register resume_mode = register_allocator()->NewRegister();
 
-  // Resume with "throw" completion (rethrow the received value).
-  // TODO(leszeks): Add a debug-only check that the accumulator is
-  // JSGeneratorObject::kThrow.
-  builder()->LoadAccumulatorWithRegister(input).ReThrow();
+    // Now dispatch on resume mode.
+    BytecodeLabel resume_next;
+    builder()
+            ->StoreAccumulatorInRegister(input)
+            .CallRuntime(Runtime::kInlineGeneratorGetResumeMode, generator_object())
+            .StoreAccumulatorInRegister(resume_mode)
+            .LoadLiteral(Smi::FromInt(JSGeneratorObject::kNext))
+            .CompareReference(resume_mode)
+            .JumpIfTrue(ToBooleanMode::kAlreadyBoolean, &resume_next);
+
+    // Resume with "throw" completion (rethrow the received value).
+    // TODO(leszeks): Add a debug-only check that the accumulator is
+    // JSGeneratorObject::kThrow.
+    builder()->LoadAccumulatorWithRegister(input).ReThrow();
 
-  // Resume with next.
-  builder()->Bind(&resume_next);
-  builder()->LoadAccumulatorWithRegister(input);
+    // Resume with next.
+    builder()->Bind(&resume_next);
+    builder()->LoadAccumulatorWithRegister(input);
 }
 
 void BytecodeGenerator::VisitAwait(Await* expr) {
-  builder()->SetExpressionPosition(expr);
-  VisitForAccumulatorValue(expr->expression());
-  BuildAwait(expr->position());
-  BuildIncrementBlockCoverageCounterIfEnabled(expr,
-                                              SourceRangeKind::kContinuation);
+    builder()->SetExpressionPosition(expr);
+    VisitForAccumulatorValue(expr->expression());
+    BuildAwait(expr->position());
+    BuildIncrementBlockCoverageCounterIfEnabled(expr,
+                                                SourceRangeKind::kContinuation);
 }
 
 void BytecodeGenerator::VisitThrow(Throw* expr) {
-  AllocateBlockCoverageSlotIfEnabled(expr, SourceRangeKind::kContinuation);
-  VisitForAccumulatorValue(expr->exception());
-  builder()->SetExpressionPosition(expr);
-  builder()->Throw();
+    AllocateBlockCoverageSlotIfEnabled(expr, SourceRangeKind::kContinuation);
+    VisitForAccumulatorValue(expr->exception());
+    builder()->SetExpressionPosition(expr);
+    builder()->Throw();
 }
 
 void BytecodeGenerator::VisitPropertyLoad(Register obj, Property* property) {
-  if (property->is_optional_chain_link()) {
-    DCHECK_NOT_NULL(optional_chaining_null_labels_);
-    int right_range =
-        AllocateBlockCoverageSlotIfEnabled(property, SourceRangeKind::kRight);
-    builder()->LoadAccumulatorWithRegister(obj).JumpIfUndefinedOrNull(
-        optional_chaining_null_labels_->New());
-    BuildIncrementBlockCoverageCounterIfEnabled(right_range);
-  }
+    if (property->is_optional_chain_link()) {
+        DCHECK_NOT_NULL(optional_chaining_null_labels_);
+        int right_range =
+                AllocateBlockCoverageSlotIfEnabled(property, SourceRangeKind::kRight);
+        builder()->LoadAccumulatorWithRegister(obj).JumpIfUndefinedOrNull(
+                optional_chaining_null_labels_->New());
+        BuildIncrementBlockCoverageCounterIfEnabled(right_range);
+    }
 
-  AssignType property_kind = Property::GetAssignType(property);
-
-  switch (property_kind) {
-    case NON_PROPERTY:
-      UNREACHABLE();
-    case NAMED_PROPERTY: {
-      builder()->SetExpressionPosition(property);
-      const AstRawString* name =
-          property->key()->AsLiteral()->AsRawPropertyName();
-      BuildLoadNamedProperty(property->obj(), obj, name);
-      break;
-    }
-    case KEYED_PROPERTY: {
-      VisitForAccumulatorValue(property->key());
-      builder()->SetExpressionPosition(property);
-      builder()->LoadKeyedProperty(
-          obj, feedback_index(feedback_spec()->AddKeyedLoadICSlot()));
-      break;
-    }
-    case NAMED_SUPER_PROPERTY:
-      VisitNamedSuperPropertyLoad(property, Register::invalid_value());
-      break;
-    case KEYED_SUPER_PROPERTY:
-      VisitKeyedSuperPropertyLoad(property, Register::invalid_value());
-      break;
-    case PRIVATE_SETTER_ONLY: {
-      BuildPrivateBrandCheck(property, obj);
-      BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateGetterAccess,
-                                 property);
-      break;
-    }
-    case PRIVATE_GETTER_ONLY:
-    case PRIVATE_GETTER_AND_SETTER: {
-      Register key = VisitForRegisterValue(property->key());
-      BuildPrivateBrandCheck(property, obj);
-      BuildPrivateGetterAccess(obj, key);
-      break;
-    }
-    case PRIVATE_METHOD: {
-      BuildPrivateBrandCheck(property, obj);
-      // In the case of private methods, property->key() is the function to be
-      // loaded (stored in a context slot), so load this directly.
-      VisitForAccumulatorValue(property->key());
-      break;
+    AssignType property_kind = Property::GetAssignType(property);
+
+    switch (property_kind) {
+        case NON_PROPERTY:
+            UNREACHABLE();
+        case NAMED_PROPERTY: {
+            builder()->SetExpressionPosition(property);
+            const AstRawString* name =
+                    property->key()->AsLiteral()->AsRawPropertyName();
+            BuildLoadNamedProperty(property->obj(), obj, name);
+            break;
+        }
+        case KEYED_PROPERTY: {
+            VisitForAccumulatorValue(property->key());
+            builder()->SetExpressionPosition(property);
+            builder()->LoadKeyedProperty(
+                    obj, feedback_index(feedback_spec()->AddKeyedLoadICSlot()));
+            break;
+        }
+        case NAMED_SUPER_PROPERTY:
+            VisitNamedSuperPropertyLoad(property, Register::invalid_value());
+            break;
+        case KEYED_SUPER_PROPERTY:
+            VisitKeyedSuperPropertyLoad(property, Register::invalid_value());
+            break;
+        case PRIVATE_SETTER_ONLY: {
+            BuildPrivateBrandCheck(property, obj);
+            BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateGetterAccess,
+                                       property);
+            break;
+        }
+        case PRIVATE_GETTER_ONLY:
+        case PRIVATE_GETTER_AND_SETTER: {
+            Register key = VisitForRegisterValue(property->key());
+            BuildPrivateBrandCheck(property, obj);
+            BuildPrivateGetterAccess(obj, key);
+            break;
+        }
+        case PRIVATE_METHOD: {
+            BuildPrivateBrandCheck(property, obj);
+            // In the case of private methods, property->key() is the function to be
+            // loaded (stored in a context slot), so load this directly.
+            VisitForAccumulatorValue(property->key());
+            break;
+        }
     }
-  }
+    // xqg start property
+    int init_reg_index = register_allocator()->next_register_index();
+    RegisterList temp_args = register_allocator()->NewRegisterList(3);
+    Register acc_init = register_allocator()->NewRegister();
+    builder()->StoreAccumulatorInRegister(acc_init);
+
+    builder()->StoreAccumulatorInRegister(temp_args[0])
+            .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+            .StoreAccumulatorInRegister(temp_args[1])
+            .LoadLiteral(Smi::FromInt(property->position()))
+            .StoreAccumulatorInRegister(temp_args[2])
+            .CallRuntime(Runtime::kTaintAnalysis_OnVisitProperty, temp_args);
+
+    builder()->LoadAccumulatorWithRegister(acc_init);
+    register_allocator()->ReleaseRegisters(init_reg_index);
+    // xqg end property
 }
 
 void BytecodeGenerator::BuildPrivateGetterAccess(Register object,
                                                  Register accessor_pair) {
-  RegisterAllocationScope scope(this);
-  Register accessor = register_allocator()->NewRegister();
-  RegisterList args = register_allocator()->NewRegisterList(1);
+    RegisterAllocationScope scope(this);
+    Register accessor = register_allocator()->NewRegister();
+    RegisterList args = register_allocator()->NewRegisterList(1);
 
-  builder()
-      ->CallRuntime(Runtime::kLoadPrivateGetter, accessor_pair)
-      .StoreAccumulatorInRegister(accessor)
-      .MoveRegister(object, args[0])
-      .CallProperty(accessor, args,
-                    feedback_index(feedback_spec()->AddCallICSlot()));
+    builder()
+            ->CallRuntime(Runtime::kLoadPrivateGetter, accessor_pair)
+            .StoreAccumulatorInRegister(accessor)
+            .MoveRegister(object, args[0])
+            .CallProperty(accessor, args,
+                          feedback_index(feedback_spec()->AddCallICSlot()));
 }
 
 void BytecodeGenerator::BuildPrivateSetterAccess(Register object,
                                                  Register accessor_pair,
                                                  Register value) {
-  RegisterAllocationScope scope(this);
-  Register accessor = register_allocator()->NewRegister();
-  RegisterList args = register_allocator()->NewRegisterList(2);
+    RegisterAllocationScope scope(this);
+    Register accessor = register_allocator()->NewRegister();
+    RegisterList args = register_allocator()->NewRegisterList(2);
 
-  builder()
-      ->CallRuntime(Runtime::kLoadPrivateSetter, accessor_pair)
-      .StoreAccumulatorInRegister(accessor)
-      .MoveRegister(object, args[0])
-      .MoveRegister(value, args[1])
-      .CallProperty(accessor, args,
-                    feedback_index(feedback_spec()->AddCallICSlot()));
+    builder()
+            ->CallRuntime(Runtime::kLoadPrivateSetter, accessor_pair)
+            .StoreAccumulatorInRegister(accessor)
+            .MoveRegister(object, args[0])
+            .MoveRegister(value, args[1])
+            .CallProperty(accessor, args,
+                          feedback_index(feedback_spec()->AddCallICSlot()));
 }
 
 void BytecodeGenerator::BuildPrivateMethodIn(Variable* private_name,
                                              Expression* object_expression) {
-  DCHECK(IsPrivateMethodOrAccessorVariableMode(private_name->mode()));
-  ClassScope* scope = private_name->scope()->AsClassScope();
-  if (private_name->is_static()) {
-    // For static private methods, "#privatemethod in ..." only returns true for
-    // the class constructor.
-    if (scope->class_variable() == nullptr) {
-      // Can only happen via the debugger. See comment in
-      // BuildPrivateBrandCheck.
-      RegisterAllocationScope register_scope(this);
-      RegisterList args = register_allocator()->NewRegisterList(2);
-      builder()
-          ->LoadLiteral(Smi::FromEnum(
-              MessageTemplate::
-                  kInvalidUnusedPrivateStaticMethodAccessedByDebugger))
-          .StoreAccumulatorInRegister(args[0])
-          .LoadLiteral(private_name->raw_name())
-          .StoreAccumulatorInRegister(args[1])
-          .CallRuntime(Runtime::kNewError, args)
-          .Throw();
+    DCHECK(IsPrivateMethodOrAccessorVariableMode(private_name->mode()));
+    ClassScope* scope = private_name->scope()->AsClassScope();
+    if (private_name->is_static()) {
+        // For static private methods, "#privatemethod in ..." only returns true for
+        // the class constructor.
+        if (scope->class_variable() == nullptr) {
+            // Can only happen via the debugger. See comment in
+            // BuildPrivateBrandCheck.
+            RegisterAllocationScope register_scope(this);
+            RegisterList args = register_allocator()->NewRegisterList(2);
+            builder()
+                    ->LoadLiteral(Smi::FromEnum(
+                            MessageTemplate::
+                            kInvalidUnusedPrivateStaticMethodAccessedByDebugger))
+                    .StoreAccumulatorInRegister(args[0])
+                    .LoadLiteral(private_name->raw_name())
+                    .StoreAccumulatorInRegister(args[1])
+                    .CallRuntime(Runtime::kNewError, args)
+                    .Throw();
+        } else {
+            VisitForAccumulatorValue(object_expression);
+            Register object = register_allocator()->NewRegister();
+            builder()->StoreAccumulatorInRegister(object);
+
+            BytecodeLabel is_object;
+            builder()->JumpIfJSReceiver(&is_object);
+
+            RegisterList args = register_allocator()->NewRegisterList(3);
+            builder()
+                    ->StoreAccumulatorInRegister(args[2])
+                    .LoadLiteral(Smi::FromEnum(MessageTemplate::kInvalidInOperatorUse))
+                    .StoreAccumulatorInRegister(args[0])
+                    .LoadLiteral(private_name->raw_name())
+                    .StoreAccumulatorInRegister(args[1])
+                    .CallRuntime(Runtime::kNewTypeError, args)
+                    .Throw();
+
+            builder()->Bind(&is_object);
+            BuildVariableLoadForAccumulatorValue(scope->class_variable(),
+                                                 HoleCheckMode::kElided);
+            builder()->CompareReference(object);
+        }
     } else {
-      VisitForAccumulatorValue(object_expression);
-      Register object = register_allocator()->NewRegister();
-      builder()->StoreAccumulatorInRegister(object);
-
-      BytecodeLabel is_object;
-      builder()->JumpIfJSReceiver(&is_object);
-
-      RegisterList args = register_allocator()->NewRegisterList(3);
-      builder()
-          ->StoreAccumulatorInRegister(args[2])
-          .LoadLiteral(Smi::FromEnum(MessageTemplate::kInvalidInOperatorUse))
-          .StoreAccumulatorInRegister(args[0])
-          .LoadLiteral(private_name->raw_name())
-          .StoreAccumulatorInRegister(args[1])
-          .CallRuntime(Runtime::kNewTypeError, args)
-          .Throw();
-
-      builder()->Bind(&is_object);
-      BuildVariableLoadForAccumulatorValue(scope->class_variable(),
-                                           HoleCheckMode::kElided);
-      builder()->CompareReference(object);
-    }
-  } else {
-    BuildVariableLoadForAccumulatorValue(scope->brand(),
-                                         HoleCheckMode::kElided);
-    Register brand = register_allocator()->NewRegister();
-    builder()->StoreAccumulatorInRegister(brand);
-
-    VisitForAccumulatorValue(object_expression);
-    builder()->SetExpressionPosition(object_expression);
-
-    FeedbackSlot slot = feedback_spec()->AddKeyedHasICSlot();
-    builder()->CompareOperation(Token::IN, brand, feedback_index(slot));
-    execution_result()->SetResultIsBoolean();
-  }
+        BuildVariableLoadForAccumulatorValue(scope->brand(),
+                                             HoleCheckMode::kElided);
+        Register brand = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(brand);
+
+        VisitForAccumulatorValue(object_expression);
+        builder()->SetExpressionPosition(object_expression);
+
+        FeedbackSlot slot = feedback_spec()->AddKeyedHasICSlot();
+        builder()->CompareOperation(Token::IN, brand, feedback_index(slot));
+        execution_result()->SetResultIsBoolean();
+    }
 }
 
 void BytecodeGenerator::BuildPrivateBrandCheck(Property* property,
                                                Register object) {
-  Variable* private_name = property->key()->AsVariableProxy()->var();
-  DCHECK(IsPrivateMethodOrAccessorVariableMode(private_name->mode()));
-  ClassScope* scope = private_name->scope()->AsClassScope();
-  builder()->SetExpressionPosition(property);
-  if (private_name->is_static()) {
-    // For static private methods, the only valid receiver is the class.
-    // Load the class constructor.
-    if (scope->class_variable() == nullptr) {
-      // If the static private method has not been used used in source
-      // code (either explicitly or through the presence of eval), but is
-      // accessed by the debugger at runtime, reference to the class variable
-      // is not available since it was not be context-allocated. Therefore we
-      // can't build a branch check, and throw an ReferenceError as if the
-      // method was optimized away.
-      // TODO(joyee): get a reference to the class constructor through
-      // something other than scope->class_variable() in this scenario.
-      RegisterAllocationScope register_scope(this);
-      RegisterList args = register_allocator()->NewRegisterList(2);
-      builder()
-          ->LoadLiteral(Smi::FromEnum(
-              MessageTemplate::
-                  kInvalidUnusedPrivateStaticMethodAccessedByDebugger))
-          .StoreAccumulatorInRegister(args[0])
-          .LoadLiteral(private_name->raw_name())
-          .StoreAccumulatorInRegister(args[1])
-          .CallRuntime(Runtime::kNewError, args)
-          .Throw();
+    Variable* private_name = property->key()->AsVariableProxy()->var();
+    DCHECK(IsPrivateMethodOrAccessorVariableMode(private_name->mode()));
+    ClassScope* scope = private_name->scope()->AsClassScope();
+    builder()->SetExpressionPosition(property);
+    if (private_name->is_static()) {
+        // For static private methods, the only valid receiver is the class.
+        // Load the class constructor.
+        if (scope->class_variable() == nullptr) {
+            // If the static private method has not been used used in source
+            // code (either explicitly or through the presence of eval), but is
+            // accessed by the debugger at runtime, reference to the class variable
+            // is not available since it was not be context-allocated. Therefore we
+            // can't build a branch check, and throw an ReferenceError as if the
+            // method was optimized away.
+            // TODO(joyee): get a reference to the class constructor through
+            // something other than scope->class_variable() in this scenario.
+            RegisterAllocationScope register_scope(this);
+            RegisterList args = register_allocator()->NewRegisterList(2);
+            builder()
+                    ->LoadLiteral(Smi::FromEnum(
+                            MessageTemplate::
+                            kInvalidUnusedPrivateStaticMethodAccessedByDebugger))
+                    .StoreAccumulatorInRegister(args[0])
+                    .LoadLiteral(private_name->raw_name())
+                    .StoreAccumulatorInRegister(args[1])
+                    .CallRuntime(Runtime::kNewError, args)
+                    .Throw();
+        } else {
+            BuildVariableLoadForAccumulatorValue(scope->class_variable(),
+                                                 HoleCheckMode::kElided);
+            BytecodeLabel return_check;
+            builder()->CompareReference(object).JumpIfTrue(
+                    ToBooleanMode::kAlreadyBoolean, &return_check);
+            const AstRawString* name = scope->class_variable()->raw_name();
+            RegisterAllocationScope register_scope(this);
+            RegisterList args = register_allocator()->NewRegisterList(2);
+            builder()
+                    ->LoadLiteral(
+                            Smi::FromEnum(MessageTemplate::kInvalidPrivateBrandStatic))
+                    .StoreAccumulatorInRegister(args[0])
+                    .LoadLiteral(name)
+                    .StoreAccumulatorInRegister(args[1])
+                    .CallRuntime(Runtime::kNewTypeError, args)
+                    .Throw();
+            builder()->Bind(&return_check);
+        }
     } else {
-      BuildVariableLoadForAccumulatorValue(scope->class_variable(),
-                                           HoleCheckMode::kElided);
-      BytecodeLabel return_check;
-      builder()->CompareReference(object).JumpIfTrue(
-          ToBooleanMode::kAlreadyBoolean, &return_check);
-      const AstRawString* name = scope->class_variable()->raw_name();
-      RegisterAllocationScope register_scope(this);
-      RegisterList args = register_allocator()->NewRegisterList(2);
-      builder()
-          ->LoadLiteral(
-              Smi::FromEnum(MessageTemplate::kInvalidPrivateBrandStatic))
-          .StoreAccumulatorInRegister(args[0])
-          .LoadLiteral(name)
-          .StoreAccumulatorInRegister(args[1])
-          .CallRuntime(Runtime::kNewTypeError, args)
-          .Throw();
-      builder()->Bind(&return_check);
-    }
-  } else {
-    BuildVariableLoadForAccumulatorValue(scope->brand(),
-                                         HoleCheckMode::kElided);
-    builder()->LoadKeyedProperty(
-        object, feedback_index(feedback_spec()->AddKeyedLoadICSlot()));
-  }
+        BuildVariableLoadForAccumulatorValue(scope->brand(),
+                                             HoleCheckMode::kElided);
+        builder()->LoadKeyedProperty(
+                object, feedback_index(feedback_spec()->AddKeyedLoadICSlot()));
+    }
 }
 
 void BytecodeGenerator::VisitPropertyLoadForRegister(Register obj,
                                                      Property* expr,
                                                      Register destination) {
-  ValueResultScope result_scope(this);
-  VisitPropertyLoad(obj, expr);
-  builder()->StoreAccumulatorInRegister(destination);
+    ValueResultScope result_scope(this);
+    VisitPropertyLoad(obj, expr);
+    builder()->StoreAccumulatorInRegister(destination);
 }
 
 void BytecodeGenerator::VisitNamedSuperPropertyLoad(Property* property,
                                                     Register opt_receiver_out) {
-  RegisterAllocationScope register_scope(this);
-  if (v8_flags.super_ic) {
-    Register receiver = register_allocator()->NewRegister();
-    BuildThisVariableLoad();
-    builder()->StoreAccumulatorInRegister(receiver);
-    BuildVariableLoad(
-        property->obj()->AsSuperPropertyReference()->home_object()->var(),
-        HoleCheckMode::kElided);
-    builder()->SetExpressionPosition(property);
-    auto name = property->key()->AsLiteral()->AsRawPropertyName();
-    FeedbackSlot slot = GetCachedLoadSuperICSlot(name);
-    builder()->LoadNamedPropertyFromSuper(receiver, name, feedback_index(slot));
-    if (opt_receiver_out.is_valid()) {
-      builder()->MoveRegister(receiver, opt_receiver_out);
+    RegisterAllocationScope register_scope(this);
+    if (v8_flags.super_ic) {
+        Register receiver = register_allocator()->NewRegister();
+        BuildThisVariableLoad();
+        builder()->StoreAccumulatorInRegister(receiver);
+        BuildVariableLoad(
+                property->obj()->AsSuperPropertyReference()->home_object()->var(),
+                HoleCheckMode::kElided);
+        builder()->SetExpressionPosition(property);
+        auto name = property->key()->AsLiteral()->AsRawPropertyName();
+        FeedbackSlot slot = GetCachedLoadSuperICSlot(name);
+        builder()->LoadNamedPropertyFromSuper(receiver, name, feedback_index(slot));
+        if (opt_receiver_out.is_valid()) {
+            builder()->MoveRegister(receiver, opt_receiver_out);
+        }
+    } else {
+        RegisterList args = register_allocator()->NewRegisterList(3);
+        BuildThisVariableLoad();
+        builder()->StoreAccumulatorInRegister(args[0]);
+        BuildVariableLoad(
+                property->obj()->AsSuperPropertyReference()->home_object()->var(),
+                HoleCheckMode::kElided);
+        builder()->StoreAccumulatorInRegister(args[1]);
+        builder()->SetExpressionPosition(property);
+        builder()
+                ->LoadLiteral(property->key()->AsLiteral()->AsRawPropertyName())
+                .StoreAccumulatorInRegister(args[2])
+                .CallRuntime(Runtime::kLoadFromSuper, args);
+
+        if (opt_receiver_out.is_valid()) {
+            builder()->MoveRegister(args[0], opt_receiver_out);
+        }
     }
-  } else {
+}
+
+void BytecodeGenerator::VisitKeyedSuperPropertyLoad(Property* property,
+                                                    Register opt_receiver_out) {
+    RegisterAllocationScope register_scope(this);
     RegisterList args = register_allocator()->NewRegisterList(3);
     BuildThisVariableLoad();
     builder()->StoreAccumulatorInRegister(args[0]);
     BuildVariableLoad(
-        property->obj()->AsSuperPropertyReference()->home_object()->var(),
-        HoleCheckMode::kElided);
+            property->obj()->AsSuperPropertyReference()->home_object()->var(),
+            HoleCheckMode::kElided);
     builder()->StoreAccumulatorInRegister(args[1]);
+    VisitForRegisterValue(property->key(), args[2]);
+
     builder()->SetExpressionPosition(property);
-    builder()
-        ->LoadLiteral(property->key()->AsLiteral()->AsRawPropertyName())
-        .StoreAccumulatorInRegister(args[2])
-        .CallRuntime(Runtime::kLoadFromSuper, args);
+    builder()->CallRuntime(Runtime::kLoadKeyedFromSuper, args);
 
     if (opt_receiver_out.is_valid()) {
-      builder()->MoveRegister(args[0], opt_receiver_out);
+        builder()->MoveRegister(args[0], opt_receiver_out);
     }
-  }
-}
-
-void BytecodeGenerator::VisitKeyedSuperPropertyLoad(Property* property,
-                                                    Register opt_receiver_out) {
-  RegisterAllocationScope register_scope(this);
-  RegisterList args = register_allocator()->NewRegisterList(3);
-  BuildThisVariableLoad();
-  builder()->StoreAccumulatorInRegister(args[0]);
-  BuildVariableLoad(
-      property->obj()->AsSuperPropertyReference()->home_object()->var(),
-      HoleCheckMode::kElided);
-  builder()->StoreAccumulatorInRegister(args[1]);
-  VisitForRegisterValue(property->key(), args[2]);
-
-  builder()->SetExpressionPosition(property);
-  builder()->CallRuntime(Runtime::kLoadKeyedFromSuper, args);
-
-  if (opt_receiver_out.is_valid()) {
-    builder()->MoveRegister(args[0], opt_receiver_out);
-  }
 }
 
 template <typename ExpressionFunc>
 void BytecodeGenerator::BuildOptionalChain(ExpressionFunc expression_func) {
-  BytecodeLabel done;
-  OptionalChainNullLabelScope label_scope(this);
-  expression_func();
-  builder()->Jump(&done);
-  label_scope.labels()->Bind(builder());
-  builder()->LoadUndefined();
-  builder()->Bind(&done);
+    BytecodeLabel done;
+    OptionalChainNullLabelScope label_scope(this);
+    expression_func();
+    builder()->Jump(&done);
+    label_scope.labels()->Bind(builder());
+    builder()->LoadUndefined();
+    builder()->Bind(&done);
 }
 
 void BytecodeGenerator::VisitOptionalChain(OptionalChain* expr) {
-  BuildOptionalChain([&]() { VisitForAccumulatorValue(expr->expression()); });
+    BuildOptionalChain([&]() { VisitForAccumulatorValue(expr->expression()); });
 }
 
 void BytecodeGenerator::VisitProperty(Property* expr) {
-  AssignType property_kind = Property::GetAssignType(expr);
-  if (property_kind != NAMED_SUPER_PROPERTY &&
-      property_kind != KEYED_SUPER_PROPERTY) {
-    Register obj = VisitForRegisterValue(expr->obj());
-    VisitPropertyLoad(obj, expr);
-  } else {
-    VisitPropertyLoad(Register::invalid_value(), expr);
-  }
+    AssignType property_kind = Property::GetAssignType(expr);
+    if (property_kind != NAMED_SUPER_PROPERTY &&
+        property_kind != KEYED_SUPER_PROPERTY) {
+        Register obj = VisitForRegisterValue(expr->obj());
+        VisitPropertyLoad(obj, expr);
+    } else {
+        VisitPropertyLoad(Register::invalid_value(), expr);
+    }
 }
 
 void BytecodeGenerator::VisitArguments(const ZonePtrList<Expression>* args,
                                        RegisterList* arg_regs) {
-  // Visit arguments.
-  for (int i = 0; i < static_cast<int>(args->length()); i++) {
-    VisitAndPushIntoRegisterList(args->at(i), arg_regs);
-  }
+    // Visit arguments.
+    for (int i = 0; i < static_cast<int>(args->length()); i++) {
+        VisitAndPushIntoRegisterList(args->at(i), arg_regs);
+    }
 }
 
 void BytecodeGenerator::VisitCall(Call* expr) {
-  Expression* callee_expr = expr->expression();
-  Call::CallType call_type = expr->GetCallType();
+    Expression *callee_expr = expr->expression();
+    Call::CallType call_type = expr->GetCallType();
 
-  if (call_type == Call::SUPER_CALL) {
-    return VisitCallSuper(expr);
-  }
+    if (call_type == Call::SUPER_CALL) {
+        return VisitCallSuper(expr);
+    }
+
+    // We compile the call differently depending on the presence of spreads and
+    // their positions.
+    //
+    // If there is only one spread and it is the final argument, there is a
+    // special CallWithSpread bytecode.
+    //
+    // If there is a non-final spread, we rewrite calls like
+    //     callee(1, ...x, 2)
+    // to
+    //     %reflect_apply(callee, receiver, [1, ...x, 2])
+    const Call::SpreadPosition spread_position = expr->spread_position();
+
+    // xqg start
+    RegisterList temp_args = register_allocator()->NewRegisterList(3);
+    Register acc_init = register_allocator()->NewRegister();
+    // xqg end
+
+    // Grow the args list as we visit receiver / arguments to avoid allocating all
+    // the registers up-front. Otherwise these registers are unavailable during
+    // receiver / argument visiting and we can end up with memory leaks due to
+    // registers keeping objects alive.
+    RegisterList args = register_allocator()->NewGrowableRegisterList();
+
+    // The callee is the first register in args for ease of calling %reflect_apply
+    // if we have a non-final spread. For all other cases it is popped from args
+    // before emitting the call below.
+    Register callee = register_allocator()->GrowRegisterList(&args);
+
+    bool implicit_undefined_receiver = false;
+
+    // TODO(petermarshall): We have a lot of call bytecodes that are very similar,
+    // see if we can reduce the number by adding a separate argument which
+    // specifies the call type (e.g., property, spread, tailcall, etc.).
+
+    // Prepare the callee and the receiver to the function call. This depends on
+    // the semantics of the underlying call type.
+    switch (call_type) {
+        case Call::NAMED_PROPERTY_CALL:
+        case Call::KEYED_PROPERTY_CALL:
+        case Call::PRIVATE_CALL: {
+            Property *property = callee_expr->AsProperty();
+            VisitAndPushIntoRegisterList(property->obj(), &args);
+            VisitPropertyLoadForRegister(args.last_register(), property, callee);
+
+            // xqg start VisitProperty
+            builder()->StoreAccumulatorInRegister(acc_init);
+
+            builder()->StoreAccumulatorInRegister(temp_args[0])
+                    .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                    .StoreAccumulatorInRegister(temp_args[1])
+                    .LoadLiteral(Smi::FromInt(property->position()))
+                    .StoreAccumulatorInRegister(temp_args[2])
+                    .CallRuntime(Runtime::kTaintAnalysis_OnVisitProperty, temp_args);
+
+            builder()->LoadAccumulatorWithRegister(acc_init);
+            // xqg end VisitProperty
+            break;
+        }
+        case Call::GLOBAL_CALL: {
+            // Receiver is undefined for global calls.
+            if (spread_position == Call::kNoSpread) {
+                implicit_undefined_receiver = true;
+            } else {
+                // TODO(leszeks): There's no special bytecode for tail calls or spread
+                // calls with an undefined receiver, so just push undefined ourselves.
+                BuildPushUndefinedIntoRegisterList(&args);
+            }
+            // Load callee as a global variable.
+            VariableProxy *proxy = callee_expr->AsVariableProxy();
+//      BuildVariableLoadForAccumulatorValue(proxy->var(),
+//                                           proxy->hole_check_mode());
+            BuildVariableLoadForAccumulatorValue(proxy,
+                                                 proxy->hole_check_mode()); // xqg
+            builder()->StoreAccumulatorInRegister(callee);
+            break;
+        }
+        case Call::WITH_CALL: {
+            Register receiver = register_allocator()->GrowRegisterList(&args);
+            DCHECK(callee_expr->AsVariableProxy()->var()->IsLookupSlot());
+            {
+                RegisterAllocationScope inner_register_scope(this);
+                Register name = register_allocator()->NewRegister();
+
+                // Call %LoadLookupSlotForCall to get the callee and receiver.
+                RegisterList result_pair = register_allocator()->NewRegisterList(2);
+                Variable *variable = callee_expr->AsVariableProxy()->var();
+                builder()
+                        ->LoadLiteral(variable->raw_name())
+                        .StoreAccumulatorInRegister(name)
+                        .CallRuntimeForPair(Runtime::kLoadLookupSlotForCall, name,
+                                            result_pair)
+                        .MoveRegister(result_pair[0], callee)
+                        .MoveRegister(result_pair[1], receiver);
+            }
+            break;
+        }
+        case Call::OTHER_CALL: {
+            // Receiver is undefined for other calls.
+            if (spread_position == Call::kNoSpread) {
+                implicit_undefined_receiver = true;
+            } else {
+                // TODO(leszeks): There's no special bytecode for tail calls or spread
+                // calls with an undefined receiver, so just push undefined ourselves.
+                BuildPushUndefinedIntoRegisterList(&args);
+            }
+            VisitForRegisterValue(callee_expr, callee);
+            break;
+        }
+        case Call::NAMED_SUPER_PROPERTY_CALL: {
+            Register receiver = register_allocator()->GrowRegisterList(&args);
+            Property *property = callee_expr->AsProperty();
+            VisitNamedSuperPropertyLoad(property, receiver);
+            builder()->StoreAccumulatorInRegister(callee);
+            // xqg start property
+            builder()->StoreAccumulatorInRegister(acc_init);
+
+            builder()->StoreAccumulatorInRegister(temp_args[0])
+                    .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                    .StoreAccumulatorInRegister(temp_args[1])
+                    .LoadLiteral(Smi::FromInt(property->position()))
+                    .StoreAccumulatorInRegister(temp_args[2])
+                    .CallRuntime(Runtime::kTaintAnalysis_OnVisitProperty, temp_args);
+
+            builder()->LoadAccumulatorWithRegister(acc_init);
+            // xqg end property
+            break;
+        }
+        case Call::KEYED_SUPER_PROPERTY_CALL: {
+            Register receiver = register_allocator()->GrowRegisterList(&args);
+            Property *property = callee_expr->AsProperty();
+            VisitKeyedSuperPropertyLoad(property, receiver);
+            builder()->StoreAccumulatorInRegister(callee);
+            // xqg start property
+            builder()->StoreAccumulatorInRegister(acc_init);
+
+            builder()->StoreAccumulatorInRegister(temp_args[0])
+                    .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                    .StoreAccumulatorInRegister(temp_args[1])
+                    .LoadLiteral(Smi::FromInt(property->position()))
+                    .StoreAccumulatorInRegister(temp_args[2])
+                    .CallRuntime(Runtime::kTaintAnalysis_OnVisitProperty, temp_args);
+
+            builder()->LoadAccumulatorWithRegister(acc_init);
+            // xqg end property
+            break;
+        }
+        case Call::NAMED_OPTIONAL_CHAIN_PROPERTY_CALL:
+        case Call::KEYED_OPTIONAL_CHAIN_PROPERTY_CALL:
+        case Call::PRIVATE_OPTIONAL_CHAIN_CALL: {
+            OptionalChain *chain = callee_expr->AsOptionalChain();
+            Property *property = chain->expression()->AsProperty();
+            BuildOptionalChain([&]() {
+                VisitAndPushIntoRegisterList(property->obj(), &args);
+                VisitPropertyLoad(args.last_register(), property);
+            });
+            builder()->StoreAccumulatorInRegister(callee);
+            // xqg start property optional chain
+            builder()->StoreAccumulatorInRegister(acc_init);
+
+            builder()->StoreAccumulatorInRegister(temp_args[0])
+                    .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                    .StoreAccumulatorInRegister(temp_args[1])
+                    .LoadLiteral(Smi::FromInt(property->position()))
+                    .StoreAccumulatorInRegister(temp_args[2])
+                    .CallRuntime(Runtime::kTaintAnalysis_OnVisitPropertyOptionalChain, temp_args);
+
+            builder()->LoadAccumulatorWithRegister(acc_init);
+            // xqg end property optional chain
+            break;
+        }
+        case Call::SUPER_CALL:
+            UNREACHABLE();
+    }
 
-  // We compile the call differently depending on the presence of spreads and
-  // their positions.
-  //
-  // If there is only one spread and it is the final argument, there is a
-  // special CallWithSpread bytecode.
-  //
-  // If there is a non-final spread, we rewrite calls like
-  //     callee(1, ...x, 2)
-  // to
-  //     %reflect_apply(callee, receiver, [1, ...x, 2])
-  const Call::SpreadPosition spread_position = expr->spread_position();
-
-  // Grow the args list as we visit receiver / arguments to avoid allocating all
-  // the registers up-front. Otherwise these registers are unavailable during
-  // receiver / argument visiting and we can end up with memory leaks due to
-  // registers keeping objects alive.
-  RegisterList args = register_allocator()->NewGrowableRegisterList();
-
-  // The callee is the first register in args for ease of calling %reflect_apply
-  // if we have a non-final spread. For all other cases it is popped from args
-  // before emitting the call below.
-  Register callee = register_allocator()->GrowRegisterList(&args);
-
-  bool implicit_undefined_receiver = false;
-
-  // TODO(petermarshall): We have a lot of call bytecodes that are very similar,
-  // see if we can reduce the number by adding a separate argument which
-  // specifies the call type (e.g., property, spread, tailcall, etc.).
-
-  // Prepare the callee and the receiver to the function call. This depends on
-  // the semantics of the underlying call type.
-  switch (call_type) {
-    case Call::NAMED_PROPERTY_CALL:
-    case Call::KEYED_PROPERTY_CALL:
-    case Call::PRIVATE_CALL: {
-      Property* property = callee_expr->AsProperty();
-      VisitAndPushIntoRegisterList(property->obj(), &args);
-      VisitPropertyLoadForRegister(args.last_register(), property, callee);
-      break;
-    }
-    case Call::GLOBAL_CALL: {
-      // Receiver is undefined for global calls.
-      if (spread_position == Call::kNoSpread) {
-        implicit_undefined_receiver = true;
-      } else {
-        // TODO(leszeks): There's no special bytecode for tail calls or spread
-        // calls with an undefined receiver, so just push undefined ourselves.
-        BuildPushUndefinedIntoRegisterList(&args);
-      }
-      // Load callee as a global variable.
-      VariableProxy* proxy = callee_expr->AsVariableProxy();
-      BuildVariableLoadForAccumulatorValue(proxy->var(),
-                                           proxy->hole_check_mode());
-      builder()->StoreAccumulatorInRegister(callee);
-      break;
-    }
-    case Call::WITH_CALL: {
-      Register receiver = register_allocator()->GrowRegisterList(&args);
-      DCHECK(callee_expr->AsVariableProxy()->var()->IsLookupSlot());
-      {
+    if (expr->is_optional_chain_link()) {
+        DCHECK_NOT_NULL(optional_chaining_null_labels_);
+        int right_range =
+                AllocateBlockCoverageSlotIfEnabled(expr, SourceRangeKind::kRight);
+        builder()->LoadAccumulatorWithRegister(callee).JumpIfUndefinedOrNull(
+                optional_chaining_null_labels_->New());
+        BuildIncrementBlockCoverageCounterIfEnabled(right_range);
+    }
+
+    int receiver_arg_count = -1;
+    if (spread_position == Call::kHasNonFinalSpread) {
+        // If we're building %reflect_apply, build the array literal and put it in
+        // the 3rd argument.
+        DCHECK(!implicit_undefined_receiver);
+        DCHECK_EQ(args.register_count(), 2);
+        BuildCreateArrayLiteral(expr->arguments(), nullptr);
+        builder()->StoreAccumulatorInRegister(
+                register_allocator()->GrowRegisterList(&args));
+    } else {
+        // If we're not building %reflect_apply and don't need to build an array
+        // literal, pop the callee and evaluate all arguments to the function call
+        // and store in sequential args registers.
+        args = args.PopLeft();
+        VisitArguments(expr->arguments(), &args);
+        receiver_arg_count = implicit_undefined_receiver ? 0 : 1;
+        CHECK_EQ(receiver_arg_count + expr->arguments()->length(),
+                 args.register_count());
+    }
+
+    // Resolve callee for a potential direct eval call. This block will mutate the
+    // callee value.
+    if (expr->is_possibly_eval() && expr->arguments()->length() > 0) {
         RegisterAllocationScope inner_register_scope(this);
-        Register name = register_allocator()->NewRegister();
+        RegisterList runtime_call_args = register_allocator()->NewRegisterList(6);
+        // Set up arguments for ResolvePossiblyDirectEval by copying callee, source
+        // strings and function closure, and loading language and
+        // position.
+
+        // Move the first arg.
+        if (spread_position == Call::kHasNonFinalSpread) {
+            int feedback_slot_index =
+                    feedback_index(feedback_spec()->AddKeyedLoadICSlot());
+            Register args_array = args[2];
+            builder()
+                    ->LoadLiteral(Smi::FromInt(0))
+                    .LoadKeyedProperty(args_array, feedback_slot_index)
+                    .StoreAccumulatorInRegister(runtime_call_args[1]);
+        } else {
+            // FIXME(v8:5690): Support final spreads for eval.
+            DCHECK_GE(receiver_arg_count, 0);
+            builder()->MoveRegister(args[receiver_arg_count], runtime_call_args[1]);
+        }
 
-        // Call %LoadLookupSlotForCall to get the callee and receiver.
-        RegisterList result_pair = register_allocator()->NewRegisterList(2);
-        Variable* variable = callee_expr->AsVariableProxy()->var();
+        // xqg start
+        // TODO(xqg)
+        // xqg end
         builder()
-            ->LoadLiteral(variable->raw_name())
-            .StoreAccumulatorInRegister(name)
-            .CallRuntimeForPair(Runtime::kLoadLookupSlotForCall, name,
-                                result_pair)
-            .MoveRegister(result_pair[0], callee)
-            .MoveRegister(result_pair[1], receiver);
-      }
-      break;
-    }
-    case Call::OTHER_CALL: {
-      // Receiver is undefined for other calls.
-      if (spread_position == Call::kNoSpread) {
-        implicit_undefined_receiver = true;
-      } else {
-        // TODO(leszeks): There's no special bytecode for tail calls or spread
-        // calls with an undefined receiver, so just push undefined ourselves.
-        BuildPushUndefinedIntoRegisterList(&args);
-      }
-      VisitForRegisterValue(callee_expr, callee);
-      break;
-    }
-    case Call::NAMED_SUPER_PROPERTY_CALL: {
-      Register receiver = register_allocator()->GrowRegisterList(&args);
-      Property* property = callee_expr->AsProperty();
-      VisitNamedSuperPropertyLoad(property, receiver);
-      builder()->StoreAccumulatorInRegister(callee);
-      break;
-    }
-    case Call::KEYED_SUPER_PROPERTY_CALL: {
-      Register receiver = register_allocator()->GrowRegisterList(&args);
-      Property* property = callee_expr->AsProperty();
-      VisitKeyedSuperPropertyLoad(property, receiver);
-      builder()->StoreAccumulatorInRegister(callee);
-      break;
-    }
-    case Call::NAMED_OPTIONAL_CHAIN_PROPERTY_CALL:
-    case Call::KEYED_OPTIONAL_CHAIN_PROPERTY_CALL:
-    case Call::PRIVATE_OPTIONAL_CHAIN_CALL: {
-      OptionalChain* chain = callee_expr->AsOptionalChain();
-      Property* property = chain->expression()->AsProperty();
-      BuildOptionalChain([&]() {
-        VisitAndPushIntoRegisterList(property->obj(), &args);
-        VisitPropertyLoad(args.last_register(), property);
-      });
-      builder()->StoreAccumulatorInRegister(callee);
-      break;
-    }
-    case Call::SUPER_CALL:
-      UNREACHABLE();
-  }
+                ->MoveRegister(callee, runtime_call_args[0])
+                .MoveRegister(Register::function_closure(), runtime_call_args[2])
+                .LoadLiteral(Smi::FromEnum(language_mode()))
+                .StoreAccumulatorInRegister(runtime_call_args[3])
+                .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
+                .StoreAccumulatorInRegister(runtime_call_args[4])
+                .LoadLiteral(Smi::FromInt(expr->position()))
+                .StoreAccumulatorInRegister(runtime_call_args[5]);
+
+        // Call ResolvePossiblyDirectEval and modify the callee.
+        builder()
+                ->CallRuntime(Runtime::kResolvePossiblyDirectEval, runtime_call_args)
+                .StoreAccumulatorInRegister(callee);
+    }
+    // xqg start call arg
+    {
+        Register acc_init = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(acc_init);
 
-  if (expr->is_optional_chain_link()) {
-    DCHECK_NOT_NULL(optional_chaining_null_labels_);
-    int right_range =
-        AllocateBlockCoverageSlotIfEnabled(expr, SourceRangeKind::kRight);
-    builder()->LoadAccumulatorWithRegister(callee).JumpIfUndefinedOrNull(
-        optional_chaining_null_labels_->New());
-    BuildIncrementBlockCoverageCounterIfEnabled(right_range);
-  }
+        RegisterList temp_args = register_allocator()->NewGrowableRegisterList();
 
-  int receiver_arg_count = -1;
-  if (spread_position == Call::kHasNonFinalSpread) {
-    // If we're building %reflect_apply, build the array literal and put it in
-    // the 3rd argument.
-    DCHECK(!implicit_undefined_receiver);
-    DCHECK_EQ(args.register_count(), 2);
-    BuildCreateArrayLiteral(expr->arguments(), nullptr);
-    builder()->StoreAccumulatorInRegister(
-        register_allocator()->GrowRegisterList(&args));
-  } else {
-    // If we're not building %reflect_apply and don't need to build an array
-    // literal, pop the callee and evaluate all arguments to the function call
-    // and store in sequential args registers.
-    args = args.PopLeft();
-    VisitArguments(expr->arguments(), &args);
-    receiver_arg_count = implicit_undefined_receiver ? 0 : 1;
-    CHECK_EQ(receiver_arg_count + expr->arguments()->length(),
-             args.register_count());
-  }
+        Register in_callee = register_allocator()->GrowRegisterList(&temp_args);
+        builder()->LoadAccumulatorWithRegister(callee) // callee
+                .StoreAccumulatorInRegister(in_callee);
 
-  // Resolve callee for a potential direct eval call. This block will mutate the
-  // callee value.
-  if (expr->is_possibly_eval() && expr->arguments()->length() > 0) {
-    RegisterAllocationScope inner_register_scope(this);
-    RegisterList runtime_call_args = register_allocator()->NewRegisterList(6);
-    // Set up arguments for ResolvePossiblyDirectEval by copying callee, source
-    // strings and function closure, and loading language and
-    // position.
+        Register in_scope = register_allocator()->GrowRegisterList(&temp_args);
+        builder()->LoadLiteral(Smi::FromInt(current_scope()->start_position())) // scope start pos
+                .StoreAccumulatorInRegister(in_scope);
 
-    // Move the first arg.
-    if (spread_position == Call::kHasNonFinalSpread) {
-      int feedback_slot_index =
-          feedback_index(feedback_spec()->AddKeyedLoadICSlot());
-      Register args_array = args[2];
-      builder()
-          ->LoadLiteral(Smi::FromInt(0))
-          .LoadKeyedProperty(args_array, feedback_slot_index)
-          .StoreAccumulatorInRegister(runtime_call_args[1]);
+        Register in_exp = register_allocator()->GrowRegisterList(&temp_args);
+        builder()->LoadLiteral(Smi::FromInt(expr->position())) // expr pos
+                .StoreAccumulatorInRegister(in_exp);
+
+        if (spread_position == Call::kHasNonFinalSpread) {
+            Register in_argnum = register_allocator()->GrowRegisterList(&temp_args);
+            builder()->LoadLiteral(Smi::FromInt(-1)) // flag for non final spread
+                    .StoreAccumulatorInRegister(in_argnum);
+            DCHECK_EQ(args.register_count(), 3);
+            Register now = register_allocator()->GrowRegisterList(&temp_args);
+            builder()->LoadAccumulatorWithRegister(args[2])
+                    .StoreAccumulatorInRegister(now);
+
+        } else {
+            Register in_argnum = register_allocator()->GrowRegisterList(&temp_args);
+            builder()->LoadLiteral(Smi::FromInt(expr->arguments()->length())) //expr arg count
+                    .StoreAccumulatorInRegister(in_argnum);
+            CHECK_EQ(receiver_arg_count + expr->arguments()->length(),
+                     args.register_count());
+            for (int i = receiver_arg_count; i < args.register_count(); i++) {
+                Register now = register_allocator()->GrowRegisterList(&temp_args);
+                builder()->LoadAccumulatorWithRegister(args[i])
+                        .StoreAccumulatorInRegister(now);
+            }
+        }
+        builder()->CallRuntime(Runtime::kTaintAnalysis_OnVisitCallArguments, temp_args);
+        builder()->LoadAccumulatorWithRegister(acc_init);
+    }
+    // xqg end call args
+
+    builder()->SetExpressionPosition(expr);
+
+
+    if (spread_position == Call::kHasFinalSpread) {
+        DCHECK(!implicit_undefined_receiver);
+        builder()->CallWithSpread(callee, args,
+                                  feedback_index(feedback_spec()->AddCallICSlot()));
+    } else if (spread_position == Call::kHasNonFinalSpread) {
+        builder()->CallJSRuntime(Context::REFLECT_APPLY_INDEX, args);
+    } else if (call_type == Call::NAMED_PROPERTY_CALL ||
+               call_type == Call::KEYED_PROPERTY_CALL) {
+        DCHECK(!implicit_undefined_receiver);
+        builder()->CallProperty(callee, args,
+                                feedback_index(feedback_spec()->AddCallICSlot()));
+    } else if (implicit_undefined_receiver) {
+        builder()->CallUndefinedReceiver(
+                callee, args, feedback_index(feedback_spec()->AddCallICSlot()));
     } else {
-      // FIXME(v8:5690): Support final spreads for eval.
-      DCHECK_GE(receiver_arg_count, 0);
-      builder()->MoveRegister(args[receiver_arg_count], runtime_call_args[1]);
+        builder()->CallAnyReceiver(
+                callee, args, feedback_index(feedback_spec()->AddCallICSlot()));
     }
-    builder()
-        ->MoveRegister(callee, runtime_call_args[0])
-        .MoveRegister(Register::function_closure(), runtime_call_args[2])
-        .LoadLiteral(Smi::FromEnum(language_mode()))
-        .StoreAccumulatorInRegister(runtime_call_args[3])
-        .LoadLiteral(Smi::FromInt(current_scope()->start_position()))
-        .StoreAccumulatorInRegister(runtime_call_args[4])
-        .LoadLiteral(Smi::FromInt(expr->position()))
-        .StoreAccumulatorInRegister(runtime_call_args[5]);
-
-    // Call ResolvePossiblyDirectEval and modify the callee.
-    builder()
-        ->CallRuntime(Runtime::kResolvePossiblyDirectEval, runtime_call_args)
-        .StoreAccumulatorInRegister(callee);
-  }
 
-  builder()->SetExpressionPosition(expr);
+    // xqg start return from call
+    {
+        int init_reg_index = register_allocator()->next_register_index();
+        RegisterList temp_args = register_allocator()->NewRegisterList(2);
+        Register acc_init = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(acc_init);
 
-  if (spread_position == Call::kHasFinalSpread) {
-    DCHECK(!implicit_undefined_receiver);
-    builder()->CallWithSpread(callee, args,
-                              feedback_index(feedback_spec()->AddCallICSlot()));
-  } else if (spread_position == Call::kHasNonFinalSpread) {
-    builder()->CallJSRuntime(Context::REFLECT_APPLY_INDEX, args);
-  } else if (call_type == Call::NAMED_PROPERTY_CALL ||
-             call_type == Call::KEYED_PROPERTY_CALL) {
-    DCHECK(!implicit_undefined_receiver);
-    builder()->CallProperty(callee, args,
-                            feedback_index(feedback_spec()->AddCallICSlot()));
-  } else if (implicit_undefined_receiver) {
-    builder()->CallUndefinedReceiver(
-        callee, args, feedback_index(feedback_spec()->AddCallICSlot()));
-  } else {
-    builder()->CallAnyReceiver(
-        callee, args, feedback_index(feedback_spec()->AddCallICSlot()));
-  }
+        builder()->StoreAccumulatorInRegister(temp_args[0])
+                .LoadLiteral(Smi::FromInt(expr->position()))
+                .StoreAccumulatorInRegister(temp_args[1])
+                .CallRuntime(Runtime::kTaintAnalysis_OnReturnFromCall, temp_args);
+
+        builder()->LoadAccumulatorWithRegister(acc_init);
+        register_allocator()->ReleaseRegisters(init_reg_index);
+    }
+    // xqg end return from call
 }
 
 void BytecodeGenerator::VisitCallSuper(Call* expr) {
-  RegisterAllocationScope register_scope(this);
-  SuperCallReference* super = expr->expression()->AsSuperCallReference();
-  const ZonePtrList<Expression>* args = expr->arguments();
-
-  // We compile the super call differently depending on the presence of spreads
-  // and their positions.
-  //
-  // If there is only one spread and it is the final argument, there is a
-  // special ConstructWithSpread bytecode.
-  //
-  // It there is a non-final spread, we rewrite something like
-  //    super(1, ...x, 2)
-  // to
-  //    %reflect_construct(constructor, [1, ...x, 2], new_target)
-  //
-  // That is, we implement (non-last-arg) spreads in super calls via our
-  // mechanism for spreads in array literals.
-  const Call::SpreadPosition spread_position = expr->spread_position();
-
-  // Prepare the constructor to the super call.
-  Register this_function = VisitForRegisterValue(super->this_function_var());
-  // This register will initially hold the constructor, then afterward it will
-  // hold the instance -- the lifetimes of the two don't need to overlap, and
-  // this way FindNonDefaultConstructorOrConstruct can choose to write either
-  // the instance or the constructor into the same register.
-  Register constructor_then_instance = register_allocator()->NewRegister();
-
-  BytecodeLabel super_ctor_call_done;
-  bool omit_super_ctor = v8_flags.omit_default_ctors &&
-                         IsDerivedConstructor(info()->literal()->kind());
-
-  if (spread_position == Call::kHasNonFinalSpread) {
     RegisterAllocationScope register_scope(this);
-    RegisterList construct_args(constructor_then_instance);
-    const Register& constructor = constructor_then_instance;
-
-    // Generate the array containing all arguments.
-    BuildCreateArrayLiteral(args, nullptr);
-    Register args_array =
-        register_allocator()->GrowRegisterList(&construct_args);
-    builder()->StoreAccumulatorInRegister(args_array);
-
-    Register new_target =
-        register_allocator()->GrowRegisterList(&construct_args);
-    VisitForRegisterValue(super->new_target_var(), new_target);
-
-    if (omit_super_ctor) {
-      BuildSuperCallOptimization(this_function, new_target,
-                                 constructor_then_instance,
-                                 &super_ctor_call_done);
-    } else {
-      builder()
-          ->LoadAccumulatorWithRegister(this_function)
-          .GetSuperConstructor(constructor);
-    }
+    SuperCallReference* super = expr->expression()->AsSuperCallReference();
+    const ZonePtrList<Expression>* args = expr->arguments();
 
-    // Check if the constructor is in fact a constructor.
-    builder()->ThrowIfNotSuperConstructor(constructor);
+    // We compile the super call differently depending on the presence of spreads
+    // and their positions.
+    //
+    // If there is only one spread and it is the final argument, there is a
+    // special ConstructWithSpread bytecode.
+    //
+    // It there is a non-final spread, we rewrite something like
+    //    super(1, ...x, 2)
+    // to
+    //    %reflect_construct(constructor, [1, ...x, 2], new_target)
+    //
+    // That is, we implement (non-last-arg) spreads in super calls via our
+    // mechanism for spreads in array literals.
+    const Call::SpreadPosition spread_position = expr->spread_position();
+
+    // Prepare the constructor to the super call.
+    Register this_function = VisitForRegisterValue(super->this_function_var());
+    // This register will initially hold the constructor, then afterward it will
+    // hold the instance -- the lifetimes of the two don't need to overlap, and
+    // this way FindNonDefaultConstructorOrConstruct can choose to write either
+    // the instance or the constructor into the same register.
+    Register constructor_then_instance = register_allocator()->NewRegister();
+
+    BytecodeLabel super_ctor_call_done;
+    bool omit_super_ctor = v8_flags.omit_default_ctors &&
+                           IsDerivedConstructor(info()->literal()->kind());
 
-    // Now pass that array to %reflect_construct.
-    builder()->CallJSRuntime(Context::REFLECT_CONSTRUCT_INDEX, construct_args);
-  } else {
-    RegisterAllocationScope register_scope(this);
-    RegisterList args_regs = register_allocator()->NewGrowableRegisterList();
-    VisitArguments(args, &args_regs);
-
-    // The new target is loaded into the new_target register from the
-    // {new.target} variable.
-    Register new_target = register_allocator()->NewRegister();
-    VisitForRegisterValue(super->new_target_var(), new_target);
-
-    const Register& constructor = constructor_then_instance;
-    if (omit_super_ctor) {
-      BuildSuperCallOptimization(this_function, new_target,
-                                 constructor_then_instance,
-                                 &super_ctor_call_done);
+    if (spread_position == Call::kHasNonFinalSpread) {
+        RegisterAllocationScope register_scope(this);
+        RegisterList construct_args(constructor_then_instance);
+        const Register& constructor = constructor_then_instance;
+
+        // Generate the array containing all arguments.
+        BuildCreateArrayLiteral(args, nullptr);
+        Register args_array =
+                register_allocator()->GrowRegisterList(&construct_args);
+        builder()->StoreAccumulatorInRegister(args_array);
+
+        Register new_target =
+                register_allocator()->GrowRegisterList(&construct_args);
+        VisitForRegisterValue(super->new_target_var(), new_target);
+
+        if (omit_super_ctor) {
+            BuildSuperCallOptimization(this_function, new_target,
+                                       constructor_then_instance,
+                                       &super_ctor_call_done);
+        } else {
+            builder()
+                    ->LoadAccumulatorWithRegister(this_function)
+                    .GetSuperConstructor(constructor);
+        }
+
+        // Check if the constructor is in fact a constructor.
+        builder()->ThrowIfNotSuperConstructor(constructor);
+
+        // Now pass that array to %reflect_construct.
+        builder()->CallJSRuntime(Context::REFLECT_CONSTRUCT_INDEX, construct_args);
     } else {
-      builder()
-          ->LoadAccumulatorWithRegister(this_function)
-          .GetSuperConstructor(constructor);
-    }
+        RegisterAllocationScope register_scope(this);
+        RegisterList args_regs = register_allocator()->NewGrowableRegisterList();
+        VisitArguments(args, &args_regs);
+
+        // The new target is loaded into the new_target register from the
+        // {new.target} variable.
+        Register new_target = register_allocator()->NewRegister();
+        VisitForRegisterValue(super->new_target_var(), new_target);
+
+        const Register& constructor = constructor_then_instance;
+        if (omit_super_ctor) {
+            BuildSuperCallOptimization(this_function, new_target,
+                                       constructor_then_instance,
+                                       &super_ctor_call_done);
+        } else {
+            builder()
+                    ->LoadAccumulatorWithRegister(this_function)
+                    .GetSuperConstructor(constructor);
+        }
 
-    // Check if the constructor is in fact a constructor.
-    builder()->ThrowIfNotSuperConstructor(constructor);
-    builder()->LoadAccumulatorWithRegister(new_target);
-    builder()->SetExpressionPosition(expr);
+        // Check if the constructor is in fact a constructor.
+        builder()->ThrowIfNotSuperConstructor(constructor);
+        builder()->LoadAccumulatorWithRegister(new_target);
+        builder()->SetExpressionPosition(expr);
 
-    int feedback_slot_index = feedback_index(feedback_spec()->AddCallICSlot());
+        int feedback_slot_index = feedback_index(feedback_spec()->AddCallICSlot());
 
-    if (spread_position == Call::kHasFinalSpread) {
-      builder()->ConstructWithSpread(constructor, args_regs,
-                                     feedback_slot_index);
-    } else {
-      DCHECK_EQ(spread_position, Call::kNoSpread);
-      // Call construct.
-      // TODO(turbofan): For now we do gather feedback on super constructor
-      // calls, utilizing the existing machinery to inline the actual call
-      // target and the JSCreate for the implicit receiver allocation. This
-      // is not an ideal solution for super constructor calls, but it gets
-      // the job done for now. In the long run we might want to revisit this
-      // and come up with a better way.
-      builder()->Construct(constructor, args_regs, feedback_slot_index);
+        if (spread_position == Call::kHasFinalSpread) {
+            builder()->ConstructWithSpread(constructor, args_regs,
+                                           feedback_slot_index);
+        } else {
+            DCHECK_EQ(spread_position, Call::kNoSpread);
+            // Call construct.
+            // TODO(turbofan): For now we do gather feedback on super constructor
+            // calls, utilizing the existing machinery to inline the actual call
+            // target and the JSCreate for the implicit receiver allocation. This
+            // is not an ideal solution for super constructor calls, but it gets
+            // the job done for now. In the long run we might want to revisit this
+            // and come up with a better way.
+            builder()->Construct(constructor, args_regs, feedback_slot_index);
+        }
+    }
+
+    // From here onwards, constructor_then_instance will hold the instance.
+    const Register& instance = constructor_then_instance;
+    builder()->StoreAccumulatorInRegister(instance);
+    builder()->Bind(&super_ctor_call_done);
+
+    // Explicit calls to the super constructor using super() perform an
+    // implicit binding assignment to the 'this' variable.
+    //
+    // Default constructors don't need have to do the assignment because
+    // 'this' isn't accessed in default constructors.
+    if (!IsDefaultConstructor(info()->literal()->kind())) {
+        Variable* var = closure_scope()->GetReceiverScope()->receiver();
+        builder()->LoadAccumulatorWithRegister(instance);
+        BuildVariableAssignment(var, Token::INIT, HoleCheckMode::kRequired);
+    }
+
+    // The constructor scope always needs ScopeInfo, so we are certain that
+    // the first constructor scope found in the outer scope chain is the
+    // scope that we are looking for for this super() call.
+    // Note that this doesn't necessarily mean that the constructor needs
+    // a context, if it doesn't this would get handled specially in
+    // BuildPrivateBrandInitialization().
+    DeclarationScope* constructor_scope = info()->scope()->GetConstructorScope();
+
+    // We can rely on the class_scope_has_private_brand bit to tell if the
+    // constructor needs private brand initialization, and if that's
+    // the case we are certain that its outer class scope requires a context to
+    // keep the brand variable, so we can just get the brand variable
+    // from the outer scope.
+    if (constructor_scope->class_scope_has_private_brand()) {
+        DCHECK(constructor_scope->outer_scope()->is_class_scope());
+        ClassScope* class_scope = constructor_scope->outer_scope()->AsClassScope();
+        DCHECK_NOT_NULL(class_scope->brand());
+        Variable* brand = class_scope->brand();
+        BuildPrivateBrandInitialization(instance, brand);
+    }
+
+    // The derived constructor has the correct bit set always, so we
+    // don't emit code to load and call the initializer if not
+    // required.
+    //
+    // For the arrow function or eval case, we always emit code to load
+    // and call the initializer.
+    //
+    // TODO(gsathya): In the future, we could tag nested arrow functions
+    // or eval with the correct bit so that we do the load conditionally
+    // if required.
+    if (info()->literal()->requires_instance_members_initializer() ||
+        !IsDerivedConstructor(info()->literal()->kind())) {
+        BuildInstanceMemberInitialization(this_function, instance);
     }
-  }
 
-  // From here onwards, constructor_then_instance will hold the instance.
-  const Register& instance = constructor_then_instance;
-  builder()->StoreAccumulatorInRegister(instance);
-  builder()->Bind(&super_ctor_call_done);
-
-  // Explicit calls to the super constructor using super() perform an
-  // implicit binding assignment to the 'this' variable.
-  //
-  // Default constructors don't need have to do the assignment because
-  // 'this' isn't accessed in default constructors.
-  if (!IsDefaultConstructor(info()->literal()->kind())) {
-    Variable* var = closure_scope()->GetReceiverScope()->receiver();
     builder()->LoadAccumulatorWithRegister(instance);
-    BuildVariableAssignment(var, Token::INIT, HoleCheckMode::kRequired);
-  }
 
-  // The constructor scope always needs ScopeInfo, so we are certain that
-  // the first constructor scope found in the outer scope chain is the
-  // scope that we are looking for for this super() call.
-  // Note that this doesn't necessarily mean that the constructor needs
-  // a context, if it doesn't this would get handled specially in
-  // BuildPrivateBrandInitialization().
-  DeclarationScope* constructor_scope = info()->scope()->GetConstructorScope();
-
-  // We can rely on the class_scope_has_private_brand bit to tell if the
-  // constructor needs private brand initialization, and if that's
-  // the case we are certain that its outer class scope requires a context to
-  // keep the brand variable, so we can just get the brand variable
-  // from the outer scope.
-  if (constructor_scope->class_scope_has_private_brand()) {
-    DCHECK(constructor_scope->outer_scope()->is_class_scope());
-    ClassScope* class_scope = constructor_scope->outer_scope()->AsClassScope();
-    DCHECK_NOT_NULL(class_scope->brand());
-    Variable* brand = class_scope->brand();
-    BuildPrivateBrandInitialization(instance, brand);
-  }
+    // xqg start return from call
+    {
+        int init_reg_index = register_allocator()->next_register_index();
+        RegisterList temp_args = register_allocator()->NewRegisterList(2);
+        Register acc_init = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(acc_init);
 
-  // The derived constructor has the correct bit set always, so we
-  // don't emit code to load and call the initializer if not
-  // required.
-  //
-  // For the arrow function or eval case, we always emit code to load
-  // and call the initializer.
-  //
-  // TODO(gsathya): In the future, we could tag nested arrow functions
-  // or eval with the correct bit so that we do the load conditionally
-  // if required.
-  if (info()->literal()->requires_instance_members_initializer() ||
-      !IsDerivedConstructor(info()->literal()->kind())) {
-    BuildInstanceMemberInitialization(this_function, instance);
-  }
+        builder()->StoreAccumulatorInRegister(temp_args[0])
+                .LoadLiteral(Smi::FromInt(expr->position()))
+                .StoreAccumulatorInRegister(temp_args[1])
+                .CallRuntime(Runtime::kTaintAnalysis_OnReturnFromCall, temp_args);
 
-  builder()->LoadAccumulatorWithRegister(instance);
+        builder()->LoadAccumulatorWithRegister(acc_init);
+        register_allocator()->ReleaseRegisters(init_reg_index);
+    }
+    // xqg end return from call
 }
 
 void BytecodeGenerator::BuildSuperCallOptimization(
-    Register this_function, Register new_target,
-    Register constructor_then_instance, BytecodeLabel* super_ctor_call_done) {
-  DCHECK(v8_flags.omit_default_ctors);
-  RegisterList output = register_allocator()->NewRegisterList(2);
-  builder()->FindNonDefaultConstructorOrConstruct(this_function, new_target,
-                                                  output);
-  builder()->MoveRegister(output[1], constructor_then_instance);
-  builder()->LoadAccumulatorWithRegister(output[0]).JumpIfTrue(
-      ToBooleanMode::kAlreadyBoolean, super_ctor_call_done);
+        Register this_function, Register new_target,
+        Register constructor_then_instance, BytecodeLabel* super_ctor_call_done) {
+    DCHECK(v8_flags.omit_default_ctors);
+    RegisterList output = register_allocator()->NewRegisterList(2);
+    builder()->FindNonDefaultConstructorOrConstruct(this_function, new_target,
+                                                    output);
+    builder()->MoveRegister(output[1], constructor_then_instance);
+    builder()->LoadAccumulatorWithRegister(output[0]).JumpIfTrue(
+            ToBooleanMode::kAlreadyBoolean, super_ctor_call_done);
 }
 
 void BytecodeGenerator::VisitCallNew(CallNew* expr) {
-  RegisterList args = register_allocator()->NewGrowableRegisterList();
-
-  // Load the constructor. It's in the first register in args for ease of
-  // calling %reflect_construct if we have a non-final spread. For all other
-  // cases it is popped before emitting the construct below.
-  VisitAndPushIntoRegisterList(expr->expression(), &args);
-
-  // We compile the new differently depending on the presence of spreads and
-  // their positions.
-  //
-  // If there is only one spread and it is the final argument, there is a
-  // special ConstructWithSpread bytecode.
-  //
-  // If there is a non-final spread, we rewrite calls like
-  //     new ctor(1, ...x, 2)
-  // to
-  //     %reflect_construct(ctor, [1, ...x, 2])
-  const CallNew::SpreadPosition spread_position = expr->spread_position();
-
-  if (spread_position == CallNew::kHasNonFinalSpread) {
-    BuildCreateArrayLiteral(expr->arguments(), nullptr);
+    RegisterList args = register_allocator()->NewGrowableRegisterList();
+
+    // Load the constructor. It's in the first register in args for ease of
+    // calling %reflect_construct if we have a non-final spread. For all other
+    // cases it is popped before emitting the construct below.
+    VisitAndPushIntoRegisterList(expr->expression(), &args);
+
+    // We compile the new differently depending on the presence of spreads and
+    // their positions.
+    //
+    // If there is only one spread and it is the final argument, there is a
+    // special ConstructWithSpread bytecode.
+    //
+    // If there is a non-final spread, we rewrite calls like
+    //     new ctor(1, ...x, 2)
+    // to
+    //     %reflect_construct(ctor, [1, ...x, 2])
+    const CallNew::SpreadPosition spread_position = expr->spread_position();
+
+    if (spread_position == CallNew::kHasNonFinalSpread) {
+        BuildCreateArrayLiteral(expr->arguments(), nullptr);
+        builder()->SetExpressionPosition(expr);
+        builder()
+                ->StoreAccumulatorInRegister(
+                        register_allocator()->GrowRegisterList(&args))
+                .CallJSRuntime(Context::REFLECT_CONSTRUCT_INDEX, args);
+        return;
+    }
+
+    Register constructor = args.first_register();
+    args = args.PopLeft();
+    VisitArguments(expr->arguments(), &args);
+
+    // The accumulator holds new target which is the same as the
+    // constructor for CallNew.
     builder()->SetExpressionPosition(expr);
-    builder()
-        ->StoreAccumulatorInRegister(
-            register_allocator()->GrowRegisterList(&args))
-        .CallJSRuntime(Context::REFLECT_CONSTRUCT_INDEX, args);
-    return;
-  }
+    builder()->LoadAccumulatorWithRegister(constructor);
 
-  Register constructor = args.first_register();
-  args = args.PopLeft();
-  VisitArguments(expr->arguments(), &args);
-
-  // The accumulator holds new target which is the same as the
-  // constructor for CallNew.
-  builder()->SetExpressionPosition(expr);
-  builder()->LoadAccumulatorWithRegister(constructor);
-
-  int feedback_slot_index = feedback_index(feedback_spec()->AddCallICSlot());
-  if (spread_position == CallNew::kHasFinalSpread) {
-    builder()->ConstructWithSpread(constructor, args, feedback_slot_index);
-  } else {
-    DCHECK_EQ(spread_position, CallNew::kNoSpread);
-    builder()->Construct(constructor, args, feedback_slot_index);
-  }
+    int feedback_slot_index = feedback_index(feedback_spec()->AddCallICSlot());
+    if (spread_position == CallNew::kHasFinalSpread) {
+        builder()->ConstructWithSpread(constructor, args, feedback_slot_index);
+    } else {
+        DCHECK_EQ(spread_position, CallNew::kNoSpread);
+        builder()->Construct(constructor, args, feedback_slot_index);
+    }
 }
 
 void BytecodeGenerator::VisitCallRuntime(CallRuntime* expr) {
-  if (expr->is_jsruntime()) {
-    RegisterList args = register_allocator()->NewGrowableRegisterList();
-    VisitArguments(expr->arguments(), &args);
-    builder()->CallJSRuntime(expr->context_index(), args);
-  } else {
-    // Evaluate all arguments to the runtime call.
-    RegisterList args = register_allocator()->NewGrowableRegisterList();
-    VisitArguments(expr->arguments(), &args);
-    Runtime::FunctionId function_id = expr->function()->function_id;
-    builder()->CallRuntime(function_id, args);
-  }
+    if (expr->is_jsruntime()) {
+        RegisterList args = register_allocator()->NewGrowableRegisterList();
+        VisitArguments(expr->arguments(), &args);
+        builder()->CallJSRuntime(expr->context_index(), args);
+    } else {
+        // Evaluate all arguments to the runtime call.
+        RegisterList args = register_allocator()->NewGrowableRegisterList();
+        VisitArguments(expr->arguments(), &args);
+        Runtime::FunctionId function_id = expr->function()->function_id;
+        builder()->CallRuntime(function_id, args);
+    }
 }
 
 void BytecodeGenerator::VisitVoid(UnaryOperation* expr) {
-  VisitForEffect(expr->expression());
-  builder()->LoadUndefined();
+    VisitForEffect(expr->expression());
+    builder()->LoadUndefined();
 }
 
 void BytecodeGenerator::VisitForTypeOfValue(Expression* expr) {
-  if (expr->IsVariableProxy()) {
-    // Typeof does not throw a reference error on global variables, hence we
-    // perform a non-contextual load in case the operand is a variable proxy.
-    VariableProxy* proxy = expr->AsVariableProxy();
-    BuildVariableLoadForAccumulatorValue(proxy->var(), proxy->hole_check_mode(),
-                                         TypeofMode::kInside);
-  } else {
-    VisitForAccumulatorValue(expr);
-  }
+    if (expr->IsVariableProxy()) {
+        // Typeof does not throw a reference error on global variables, hence we
+        // perform a non-contextual load in case the operand is a variable proxy.
+        VariableProxy* proxy = expr->AsVariableProxy();
+//    BuildVariableLoadForAccumulatorValue(proxy->var(), proxy->hole_check_mode(),
+//                                         TypeofMode::kInside);
+        BuildVariableLoadForAccumulatorValue(proxy, proxy->hole_check_mode(),
+                                             TypeofMode::kInside); // xqg
+    } else {
+        VisitForAccumulatorValue(expr);
+    }
 }
 
 void BytecodeGenerator::VisitTypeOf(UnaryOperation* expr) {
-  VisitForTypeOfValue(expr->expression());
-  builder()->TypeOf();
+    VisitForTypeOfValue(expr->expression());
+    builder()->TypeOf();
 }
 
 void BytecodeGenerator::VisitNot(UnaryOperation* expr) {
-  if (execution_result()->IsEffect()) {
-    VisitForEffect(expr->expression());
-  } else if (execution_result()->IsTest()) {
-    // No actual logical negation happening, we just swap the control flow, by
-    // swapping the target labels and the fallthrough branch, and visit in the
-    // same test result context.
-    TestResultScope* test_result = execution_result()->AsTest();
-    test_result->InvertControlFlow();
-    VisitInSameTestExecutionScope(expr->expression());
-  } else {
-    TypeHint type_hint = VisitForAccumulatorValue(expr->expression());
-    builder()->LogicalNot(ToBooleanModeFromTypeHint(type_hint));
-    // Always returns a boolean value.
-    execution_result()->SetResultIsBoolean();
-  }
+    if (execution_result()->IsEffect()) {
+        VisitForEffect(expr->expression());
+    } else if (execution_result()->IsTest()) {
+        // No actual logical negation happening, we just swap the control flow, by
+        // swapping the target labels and the fallthrough branch, and visit in the
+        // same test result context.
+        TestResultScope* test_result = execution_result()->AsTest();
+        test_result->InvertControlFlow();
+        VisitInSameTestExecutionScope(expr->expression());
+    } else {
+        TypeHint type_hint = VisitForAccumulatorValue(expr->expression());
+        builder()->LogicalNot(ToBooleanModeFromTypeHint(type_hint));
+        // Always returns a boolean value.
+        execution_result()->SetResultIsBoolean();
+    }
 }
 
 void BytecodeGenerator::VisitUnaryOperation(UnaryOperation* expr) {
-  switch (expr->op()) {
-    case Token::Value::NOT:
-      VisitNot(expr);
-      break;
-    case Token::Value::TYPEOF:
-      VisitTypeOf(expr);
-      break;
-    case Token::Value::VOID:
-      VisitVoid(expr);
-      break;
-    case Token::Value::DELETE:
-      VisitDelete(expr);
-      break;
-    case Token::Value::ADD:
-    case Token::Value::SUB:
-    case Token::Value::BIT_NOT:
-      VisitForAccumulatorValue(expr->expression());
-      builder()->SetExpressionPosition(expr);
-      builder()->UnaryOperation(
-          expr->op(), feedback_index(feedback_spec()->AddBinaryOpICSlot()));
-      break;
-    default:
-      UNREACHABLE();
-  }
+    switch (expr->op()) {
+        case Token::Value::NOT:
+            VisitNot(expr);
+            break;
+        case Token::Value::TYPEOF:
+            VisitTypeOf(expr);
+            break;
+        case Token::Value::VOID:
+            VisitVoid(expr);
+            break;
+        case Token::Value::DELETE:
+            VisitDelete(expr);
+            break;
+        case Token::Value::ADD:
+        case Token::Value::SUB:
+        case Token::Value::BIT_NOT:
+            VisitForAccumulatorValue(expr->expression());
+            builder()->SetExpressionPosition(expr);
+            builder()->UnaryOperation(
+                    expr->op(), feedback_index(feedback_spec()->AddBinaryOpICSlot()));
+            break;
+        default:
+            UNREACHABLE();
+    }
 }
 
 void BytecodeGenerator::VisitDelete(UnaryOperation* unary) {
-  Expression* expr = unary->expression();
-  if (expr->IsProperty()) {
-    // Delete of an object property is allowed both in sloppy
-    // and strict modes.
-    Property* property = expr->AsProperty();
-    DCHECK(!property->IsPrivateReference());
-    Register object = VisitForRegisterValue(property->obj());
-    VisitForAccumulatorValue(property->key());
-    builder()->Delete(object, language_mode());
-  } else if (expr->IsOptionalChain()) {
-    Expression* expr_inner = expr->AsOptionalChain()->expression();
-    if (expr_inner->IsProperty()) {
-      Property* property = expr_inner->AsProperty();
-      DCHECK(!property->IsPrivateReference());
-      BytecodeLabel done;
-      OptionalChainNullLabelScope label_scope(this);
-      VisitForAccumulatorValue(property->obj());
-      if (property->is_optional_chain_link()) {
-        int right_range = AllocateBlockCoverageSlotIfEnabled(
-            property, SourceRangeKind::kRight);
-        builder()->JumpIfUndefinedOrNull(label_scope.labels()->New());
-        BuildIncrementBlockCoverageCounterIfEnabled(right_range);
-      }
-      Register object = register_allocator()->NewRegister();
-      builder()->StoreAccumulatorInRegister(object);
-      VisitForAccumulatorValue(property->key());
-      builder()->Delete(object, language_mode());
-      builder()->Jump(&done);
-      label_scope.labels()->Bind(builder());
-      builder()->LoadTrue();
-      builder()->Bind(&done);
+    Expression* expr = unary->expression();
+    if (expr->IsProperty()) {
+        // Delete of an object property is allowed both in sloppy
+        // and strict modes.
+        Property* property = expr->AsProperty();
+        DCHECK(!property->IsPrivateReference());
+        Register object = VisitForRegisterValue(property->obj());
+        VisitForAccumulatorValue(property->key());
+        builder()->Delete(object, language_mode());
+    } else if (expr->IsOptionalChain()) {
+        Expression* expr_inner = expr->AsOptionalChain()->expression();
+        if (expr_inner->IsProperty()) {
+            Property* property = expr_inner->AsProperty();
+            DCHECK(!property->IsPrivateReference());
+            BytecodeLabel done;
+            OptionalChainNullLabelScope label_scope(this);
+            VisitForAccumulatorValue(property->obj());
+            if (property->is_optional_chain_link()) {
+                int right_range = AllocateBlockCoverageSlotIfEnabled(
+                        property, SourceRangeKind::kRight);
+                builder()->JumpIfUndefinedOrNull(label_scope.labels()->New());
+                BuildIncrementBlockCoverageCounterIfEnabled(right_range);
+            }
+            Register object = register_allocator()->NewRegister();
+            builder()->StoreAccumulatorInRegister(object);
+            VisitForAccumulatorValue(property->key());
+            builder()->Delete(object, language_mode());
+            builder()->Jump(&done);
+            label_scope.labels()->Bind(builder());
+            builder()->LoadTrue();
+            builder()->Bind(&done);
+        } else {
+            VisitForEffect(expr);
+            builder()->LoadTrue();
+        }
+    } else if (expr->IsVariableProxy() &&
+               !expr->AsVariableProxy()->is_new_target()) {
+        // Delete of an unqualified identifier is allowed in sloppy mode but is
+        // not allowed in strict mode.
+        DCHECK(is_sloppy(language_mode()));
+        Variable* variable = expr->AsVariableProxy()->var();
+        switch (variable->location()) {
+            case VariableLocation::PARAMETER:
+            case VariableLocation::LOCAL:
+            case VariableLocation::CONTEXT:
+            case VariableLocation::REPL_GLOBAL: {
+                // Deleting local var/let/const, context variables, and arguments
+                // does not have any effect.
+                builder()->LoadFalse();
+                break;
+            }
+            case VariableLocation::UNALLOCATED:
+                // TODO(adamk): Falling through to the runtime results in correct
+                // behavior, but does unnecessary context-walking (since scope
+                // analysis has already proven that the variable doesn't exist in
+                // any non-global scope). Consider adding a DeleteGlobal bytecode
+                // that knows how to deal with ScriptContexts as well as global
+                // object properties.
+            case VariableLocation::LOOKUP: {
+                Register name_reg = register_allocator()->NewRegister();
+                builder()
+                        ->LoadLiteral(variable->raw_name())
+                        .StoreAccumulatorInRegister(name_reg)
+                        .CallRuntime(Runtime::kDeleteLookupSlot, name_reg);
+                break;
+            }
+            case VariableLocation::MODULE:
+                // Modules are always in strict mode and unqualified identifers are not
+                // allowed in strict mode.
+                UNREACHABLE();
+        }
     } else {
-      VisitForEffect(expr);
-      builder()->LoadTrue();
-    }
-  } else if (expr->IsVariableProxy() &&
-             !expr->AsVariableProxy()->is_new_target()) {
-    // Delete of an unqualified identifier is allowed in sloppy mode but is
-    // not allowed in strict mode.
-    DCHECK(is_sloppy(language_mode()));
-    Variable* variable = expr->AsVariableProxy()->var();
-    switch (variable->location()) {
-      case VariableLocation::PARAMETER:
-      case VariableLocation::LOCAL:
-      case VariableLocation::CONTEXT:
-      case VariableLocation::REPL_GLOBAL: {
-        // Deleting local var/let/const, context variables, and arguments
-        // does not have any effect.
-        builder()->LoadFalse();
-        break;
-      }
-      case VariableLocation::UNALLOCATED:
-      // TODO(adamk): Falling through to the runtime results in correct
-      // behavior, but does unnecessary context-walking (since scope
-      // analysis has already proven that the variable doesn't exist in
-      // any non-global scope). Consider adding a DeleteGlobal bytecode
-      // that knows how to deal with ScriptContexts as well as global
-      // object properties.
-      case VariableLocation::LOOKUP: {
-        Register name_reg = register_allocator()->NewRegister();
-        builder()
-            ->LoadLiteral(variable->raw_name())
-            .StoreAccumulatorInRegister(name_reg)
-            .CallRuntime(Runtime::kDeleteLookupSlot, name_reg);
-        break;
-      }
-      case VariableLocation::MODULE:
-        // Modules are always in strict mode and unqualified identifers are not
-        // allowed in strict mode.
-        UNREACHABLE();
-    }
-  } else {
-    // Delete of an unresolvable reference, new.target, and this returns true.
-    VisitForEffect(expr);
-    builder()->LoadTrue();
-  }
+        // Delete of an unresolvable reference, new.target, and this returns true.
+        VisitForEffect(expr);
+        builder()->LoadTrue();
+    }
 }
 
 void BytecodeGenerator::VisitCountOperation(CountOperation* expr) {
-  DCHECK(expr->expression()->IsValidReferenceExpression());
-
-  // Left-hand side can only be a property, a global or a variable slot.
-  Property* property = expr->expression()->AsProperty();
-  AssignType assign_type = Property::GetAssignType(property);
-
-  bool is_postfix = expr->is_postfix() && !execution_result()->IsEffect();
-
-  // Evaluate LHS expression and get old value.
-  Register object, key, old_value;
-  RegisterList super_property_args;
-  const AstRawString* name;
-  switch (assign_type) {
-    case NON_PROPERTY: {
-      VariableProxy* proxy = expr->expression()->AsVariableProxy();
-      BuildVariableLoadForAccumulatorValue(proxy->var(),
-                                           proxy->hole_check_mode());
-      break;
-    }
-    case NAMED_PROPERTY: {
-      object = VisitForRegisterValue(property->obj());
-      name = property->key()->AsLiteral()->AsRawPropertyName();
-      builder()->LoadNamedProperty(
-          object, name,
-          feedback_index(GetCachedLoadICSlot(property->obj(), name)));
-      break;
-    }
-    case KEYED_PROPERTY: {
-      object = VisitForRegisterValue(property->obj());
-      // Use visit for accumulator here since we need the key in the accumulator
-      // for the LoadKeyedProperty.
-      key = register_allocator()->NewRegister();
-      VisitForAccumulatorValue(property->key());
-      builder()->StoreAccumulatorInRegister(key).LoadKeyedProperty(
-          object, feedback_index(feedback_spec()->AddKeyedLoadICSlot()));
-      break;
-    }
-    case NAMED_SUPER_PROPERTY: {
-      super_property_args = register_allocator()->NewRegisterList(4);
-      RegisterList load_super_args = super_property_args.Truncate(3);
-      BuildThisVariableLoad();
-      builder()->StoreAccumulatorInRegister(load_super_args[0]);
-      BuildVariableLoad(
-          property->obj()->AsSuperPropertyReference()->home_object()->var(),
-          HoleCheckMode::kElided);
-      builder()->StoreAccumulatorInRegister(load_super_args[1]);
-      builder()
-          ->LoadLiteral(property->key()->AsLiteral()->AsRawPropertyName())
-          .StoreAccumulatorInRegister(load_super_args[2])
-          .CallRuntime(Runtime::kLoadFromSuper, load_super_args);
-      break;
-    }
-    case KEYED_SUPER_PROPERTY: {
-      super_property_args = register_allocator()->NewRegisterList(4);
-      RegisterList load_super_args = super_property_args.Truncate(3);
-      BuildThisVariableLoad();
-      builder()->StoreAccumulatorInRegister(load_super_args[0]);
-      BuildVariableLoad(
-          property->obj()->AsSuperPropertyReference()->home_object()->var(),
-          HoleCheckMode::kElided);
-      builder()->StoreAccumulatorInRegister(load_super_args[1]);
-      VisitForRegisterValue(property->key(), load_super_args[2]);
-      builder()->CallRuntime(Runtime::kLoadKeyedFromSuper, load_super_args);
-      break;
-    }
-    case PRIVATE_METHOD: {
-      object = VisitForRegisterValue(property->obj());
-      BuildPrivateBrandCheck(property, object);
-      BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateMethodWrite,
-                                 property);
-      return;
-    }
-    case PRIVATE_GETTER_ONLY: {
-      object = VisitForRegisterValue(property->obj());
-      BuildPrivateBrandCheck(property, object);
-      BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateSetterAccess,
-                                 property);
-      return;
-    }
-    case PRIVATE_SETTER_ONLY: {
-      object = VisitForRegisterValue(property->obj());
-      BuildPrivateBrandCheck(property, object);
-      BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateGetterAccess,
-                                 property);
-      return;
-    }
-    case PRIVATE_GETTER_AND_SETTER: {
-      object = VisitForRegisterValue(property->obj());
-      key = VisitForRegisterValue(property->key());
-      BuildPrivateBrandCheck(property, object);
-      BuildPrivateGetterAccess(object, key);
-      break;
+    DCHECK(expr->expression()->IsValidReferenceExpression());
+
+    // Left-hand side can only be a property, a global or a variable slot.
+    Property* property = expr->expression()->AsProperty();
+    AssignType assign_type = Property::GetAssignType(property);
+
+    bool is_postfix = expr->is_postfix() && !execution_result()->IsEffect();
+
+    // Evaluate LHS expression and get old value.
+    Register object, key, old_value;
+    RegisterList super_property_args;
+    const AstRawString* name;
+    switch (assign_type) {
+        case NON_PROPERTY: {
+            VariableProxy* proxy = expr->expression()->AsVariableProxy();
+//      BuildVariableLoadForAccumulatorValue(proxy->var(),
+//                                           proxy->hole_check_mode());
+            BuildVariableLoadForAccumulatorValue(proxy,
+                                                 proxy->hole_check_mode()); // xqg
+            break;
+        }
+        case NAMED_PROPERTY: {
+            object = VisitForRegisterValue(property->obj());
+            name = property->key()->AsLiteral()->AsRawPropertyName();
+            builder()->LoadNamedProperty(
+                    object, name,
+                    feedback_index(GetCachedLoadICSlot(property->obj(), name)));
+            break;
+        }
+        case KEYED_PROPERTY: {
+            object = VisitForRegisterValue(property->obj());
+            // Use visit for accumulator here since we need the key in the accumulator
+            // for the LoadKeyedProperty.
+            key = register_allocator()->NewRegister();
+            VisitForAccumulatorValue(property->key());
+            builder()->StoreAccumulatorInRegister(key).LoadKeyedProperty(
+                    object, feedback_index(feedback_spec()->AddKeyedLoadICSlot()));
+            break;
+        }
+        case NAMED_SUPER_PROPERTY: {
+            super_property_args = register_allocator()->NewRegisterList(4);
+            RegisterList load_super_args = super_property_args.Truncate(3);
+            BuildThisVariableLoad();
+            builder()->StoreAccumulatorInRegister(load_super_args[0]);
+            BuildVariableLoad(
+                    property->obj()->AsSuperPropertyReference()->home_object()->var(),
+                    HoleCheckMode::kElided);
+            builder()->StoreAccumulatorInRegister(load_super_args[1]);
+            builder()
+                    ->LoadLiteral(property->key()->AsLiteral()->AsRawPropertyName())
+                    .StoreAccumulatorInRegister(load_super_args[2])
+                    .CallRuntime(Runtime::kLoadFromSuper, load_super_args);
+            break;
+        }
+        case KEYED_SUPER_PROPERTY: {
+            super_property_args = register_allocator()->NewRegisterList(4);
+            RegisterList load_super_args = super_property_args.Truncate(3);
+            BuildThisVariableLoad();
+            builder()->StoreAccumulatorInRegister(load_super_args[0]);
+            BuildVariableLoad(
+                    property->obj()->AsSuperPropertyReference()->home_object()->var(),
+                    HoleCheckMode::kElided);
+            builder()->StoreAccumulatorInRegister(load_super_args[1]);
+            VisitForRegisterValue(property->key(), load_super_args[2]);
+            builder()->CallRuntime(Runtime::kLoadKeyedFromSuper, load_super_args);
+            break;
+        }
+        case PRIVATE_METHOD: {
+            object = VisitForRegisterValue(property->obj());
+            BuildPrivateBrandCheck(property, object);
+            BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateMethodWrite,
+                                       property);
+            return;
+        }
+        case PRIVATE_GETTER_ONLY: {
+            object = VisitForRegisterValue(property->obj());
+            BuildPrivateBrandCheck(property, object);
+            BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateSetterAccess,
+                                       property);
+            return;
+        }
+        case PRIVATE_SETTER_ONLY: {
+            object = VisitForRegisterValue(property->obj());
+            BuildPrivateBrandCheck(property, object);
+            BuildInvalidPropertyAccess(MessageTemplate::kInvalidPrivateGetterAccess,
+                                       property);
+            return;
+        }
+        case PRIVATE_GETTER_AND_SETTER: {
+            object = VisitForRegisterValue(property->obj());
+            key = VisitForRegisterValue(property->key());
+            BuildPrivateBrandCheck(property, object);
+            BuildPrivateGetterAccess(object, key);
+            break;
+        }
     }
-  }
-
-  // Save result for postfix expressions.
-  FeedbackSlot count_slot = feedback_spec()->AddBinaryOpICSlot();
-  if (is_postfix) {
-    old_value = register_allocator()->NewRegister();
-    // Convert old value into a number before saving it.
-    // TODO(ignition): Think about adding proper PostInc/PostDec bytecodes
-    // instead of this ToNumeric + Inc/Dec dance.
-    builder()
-        ->ToNumeric(feedback_index(count_slot))
-        .StoreAccumulatorInRegister(old_value);
-  }
 
-  // Perform +1/-1 operation.
-  builder()->UnaryOperation(expr->op(), feedback_index(count_slot));
-
-  // Store the value.
-  builder()->SetExpressionPosition(expr);
-  switch (assign_type) {
-    case NON_PROPERTY: {
-      VariableProxy* proxy = expr->expression()->AsVariableProxy();
-      BuildVariableAssignment(proxy->var(), expr->op(),
-                              proxy->hole_check_mode());
-      break;
-    }
-    case NAMED_PROPERTY: {
-      FeedbackSlot slot = GetCachedStoreICSlot(property->obj(), name);
-      Register value;
-      if (!execution_result()->IsEffect()) {
-        value = register_allocator()->NewRegister();
-        builder()->StoreAccumulatorInRegister(value);
-      }
-      builder()->SetNamedProperty(object, name, feedback_index(slot),
-                                  language_mode());
-      if (!execution_result()->IsEffect()) {
-        builder()->LoadAccumulatorWithRegister(value);
-      }
-      break;
+    // Save result for postfix expressions.
+    FeedbackSlot count_slot = feedback_spec()->AddBinaryOpICSlot();
+    if (is_postfix) {
+        old_value = register_allocator()->NewRegister();
+        // Convert old value into a number before saving it.
+        // TODO(ignition): Think about adding proper PostInc/PostDec bytecodes
+        // instead of this ToNumeric + Inc/Dec dance.
+        builder()
+                ->ToNumeric(feedback_index(count_slot))
+                .StoreAccumulatorInRegister(old_value);
     }
-    case KEYED_PROPERTY: {
-      FeedbackSlot slot = feedback_spec()->AddKeyedStoreICSlot(language_mode());
-      Register value;
-      if (!execution_result()->IsEffect()) {
-        value = register_allocator()->NewRegister();
-        builder()->StoreAccumulatorInRegister(value);
-      }
-      builder()->SetKeyedProperty(object, key, feedback_index(slot),
-                                  language_mode());
-      if (!execution_result()->IsEffect()) {
-        builder()->LoadAccumulatorWithRegister(value);
-      }
-      break;
-    }
-    case NAMED_SUPER_PROPERTY: {
-      builder()
-          ->StoreAccumulatorInRegister(super_property_args[3])
-          .CallRuntime(Runtime::kStoreToSuper, super_property_args);
-      break;
-    }
-    case KEYED_SUPER_PROPERTY: {
-      builder()
-          ->StoreAccumulatorInRegister(super_property_args[3])
-          .CallRuntime(Runtime::kStoreKeyedToSuper, super_property_args);
-      break;
-    }
-    case PRIVATE_SETTER_ONLY:
-    case PRIVATE_GETTER_ONLY:
-    case PRIVATE_METHOD: {
-      UNREACHABLE();
-    }
-    case PRIVATE_GETTER_AND_SETTER: {
-      Register value = register_allocator()->NewRegister();
-      builder()->StoreAccumulatorInRegister(value);
-      BuildPrivateSetterAccess(object, key, value);
-      if (!execution_result()->IsEffect()) {
-        builder()->LoadAccumulatorWithRegister(value);
-      }
-      break;
+
+    // Perform +1/-1 operation.
+    builder()->UnaryOperation(expr->op(), feedback_index(count_slot));
+
+    // Store the value.
+    builder()->SetExpressionPosition(expr);
+    switch (assign_type) {
+        case NON_PROPERTY: {
+            VariableProxy* proxy = expr->expression()->AsVariableProxy();
+//      BuildVariableAssignment(proxy->var(), expr->op(),
+//                              proxy->hole_check_mode());
+            BuildVariableAssignment(proxy, expr->op(),
+                                    proxy->hole_check_mode()); // xqg
+            break;
+        }
+        case NAMED_PROPERTY: {
+            FeedbackSlot slot = GetCachedStoreICSlot(property->obj(), name);
+            Register value;
+            if (!execution_result()->IsEffect()) {
+                value = register_allocator()->NewRegister();
+                builder()->StoreAccumulatorInRegister(value);
+            }
+            builder()->SetNamedProperty(object, name, feedback_index(slot),
+                                        language_mode());
+            if (!execution_result()->IsEffect()) {
+                builder()->LoadAccumulatorWithRegister(value);
+            }
+            break;
+        }
+        case KEYED_PROPERTY: {
+            FeedbackSlot slot = feedback_spec()->AddKeyedStoreICSlot(language_mode());
+            Register value;
+            if (!execution_result()->IsEffect()) {
+                value = register_allocator()->NewRegister();
+                builder()->StoreAccumulatorInRegister(value);
+            }
+            builder()->SetKeyedProperty(object, key, feedback_index(slot),
+                                        language_mode());
+            if (!execution_result()->IsEffect()) {
+                builder()->LoadAccumulatorWithRegister(value);
+            }
+            break;
+        }
+        case NAMED_SUPER_PROPERTY: {
+            builder()
+                    ->StoreAccumulatorInRegister(super_property_args[3])
+                    .CallRuntime(Runtime::kStoreToSuper, super_property_args);
+            break;
+        }
+        case KEYED_SUPER_PROPERTY: {
+            builder()
+                    ->StoreAccumulatorInRegister(super_property_args[3])
+                    .CallRuntime(Runtime::kStoreKeyedToSuper, super_property_args);
+            break;
+        }
+        case PRIVATE_SETTER_ONLY:
+        case PRIVATE_GETTER_ONLY:
+        case PRIVATE_METHOD: {
+            UNREACHABLE();
+        }
+        case PRIVATE_GETTER_AND_SETTER: {
+            Register value = register_allocator()->NewRegister();
+            builder()->StoreAccumulatorInRegister(value);
+            BuildPrivateSetterAccess(object, key, value);
+            if (!execution_result()->IsEffect()) {
+                builder()->LoadAccumulatorWithRegister(value);
+            }
+            break;
+        }
     }
-  }
 
-  // Restore old value for postfix expressions.
-  if (is_postfix) {
-    builder()->LoadAccumulatorWithRegister(old_value);
-  }
+    // Restore old value for postfix expressions.
+    if (is_postfix) {
+        builder()->LoadAccumulatorWithRegister(old_value);
+    }
 }
 
 void BytecodeGenerator::VisitBinaryOperation(BinaryOperation* binop) {
-  switch (binop->op()) {
-    case Token::COMMA:
-      VisitCommaExpression(binop);
-      break;
-    case Token::OR:
-      VisitLogicalOrExpression(binop);
-      break;
-    case Token::AND:
-      VisitLogicalAndExpression(binop);
-      break;
-    case Token::NULLISH:
-      VisitNullishExpression(binop);
-      break;
-    default:
-      VisitArithmeticExpression(binop);
-      break;
-  }
+    switch (binop->op()) {
+        case Token::COMMA:
+            VisitCommaExpression(binop);
+            break;
+        case Token::OR:
+            VisitLogicalOrExpression(binop);
+            break;
+        case Token::AND:
+            VisitLogicalAndExpression(binop);
+            break;
+        case Token::NULLISH:
+            VisitNullishExpression(binop);
+            break;
+        default:
+            VisitArithmeticExpression(binop);
+            break;
+    }
 }
 
 void BytecodeGenerator::VisitNaryOperation(NaryOperation* expr) {
-  switch (expr->op()) {
-    case Token::COMMA:
-      VisitNaryCommaExpression(expr);
-      break;
-    case Token::OR:
-      VisitNaryLogicalOrExpression(expr);
-      break;
-    case Token::AND:
-      VisitNaryLogicalAndExpression(expr);
-      break;
-    case Token::NULLISH:
-      VisitNaryNullishExpression(expr);
-      break;
-    default:
-      VisitNaryArithmeticExpression(expr);
-      break;
-  }
+    switch (expr->op()) {
+        case Token::COMMA:
+            VisitNaryCommaExpression(expr);
+            break;
+        case Token::OR:
+            VisitNaryLogicalOrExpression(expr);
+            break;
+        case Token::AND:
+            VisitNaryLogicalAndExpression(expr);
+            break;
+        case Token::NULLISH:
+            VisitNaryNullishExpression(expr);
+            break;
+        default:
+            VisitNaryArithmeticExpression(expr);
+            break;
+    }
 }
 
 void BytecodeGenerator::BuildLiteralCompareNil(
-    Token::Value op, BytecodeArrayBuilder::NilValue nil) {
-  if (execution_result()->IsTest()) {
-    TestResultScope* test_result = execution_result()->AsTest();
-    switch (test_result->fallthrough()) {
-      case TestFallthrough::kThen:
-        builder()->JumpIfNotNil(test_result->NewElseLabel(), op, nil);
-        break;
-      case TestFallthrough::kElse:
-        builder()->JumpIfNil(test_result->NewThenLabel(), op, nil);
-        break;
-      case TestFallthrough::kNone:
-        builder()
-            ->JumpIfNil(test_result->NewThenLabel(), op, nil)
-            .Jump(test_result->NewElseLabel());
+        Token::Value op, BytecodeArrayBuilder::NilValue nil) {
+    if (execution_result()->IsTest()) {
+        TestResultScope* test_result = execution_result()->AsTest();
+        switch (test_result->fallthrough()) {
+            case TestFallthrough::kThen:
+                builder()->JumpIfNotNil(test_result->NewElseLabel(), op, nil);
+                break;
+            case TestFallthrough::kElse:
+                builder()->JumpIfNil(test_result->NewThenLabel(), op, nil);
+                break;
+            case TestFallthrough::kNone:
+                builder()
+                        ->JumpIfNil(test_result->NewThenLabel(), op, nil)
+                        .Jump(test_result->NewElseLabel());
+        }
+        test_result->SetResultConsumedByTest();
+    } else {
+        builder()->CompareNil(op, nil);
     }
-    test_result->SetResultConsumedByTest();
-  } else {
-    builder()->CompareNil(op, nil);
-  }
 }
 
 void BytecodeGenerator::BuildLiteralStrictCompareBoolean(Literal* literal) {
-  DCHECK(literal->IsBooleanLiteral());
-  Register result = register_allocator()->NewRegister();
-  builder()->StoreAccumulatorInRegister(result);
-  builder()->LoadBoolean(literal->AsBooleanLiteral());
-  builder()->CompareReference(result);
+    DCHECK(literal->IsBooleanLiteral());
+    Register result = register_allocator()->NewRegister();
+    builder()->StoreAccumulatorInRegister(result);
+    builder()->LoadBoolean(literal->AsBooleanLiteral());
+    builder()->CompareReference(result);
 }
 
 void BytecodeGenerator::VisitCompareOperation(CompareOperation* expr) {
-  Expression* sub_expr;
-  Literal* literal;
-  if (expr->IsLiteralCompareTypeof(&sub_expr, &literal)) {
-    // Emit a fast literal comparion for expressions of the form:
-    // typeof(x) === 'string'.
-    VisitForTypeOfValue(sub_expr);
-    builder()->SetExpressionPosition(expr);
-    TestTypeOfFlags::LiteralFlag literal_flag =
-        TestTypeOfFlags::GetFlagForLiteral(ast_string_constants(), literal);
-    if (literal_flag == TestTypeOfFlags::LiteralFlag::kOther) {
-      builder()->LoadFalse();
+    Expression* sub_expr;
+    Literal* literal;
+    if (expr->IsLiteralCompareTypeof(&sub_expr, &literal)) {
+        // Emit a fast literal comparion for expressions of the form:
+        // typeof(x) === 'string'.
+        VisitForTypeOfValue(sub_expr);
+        builder()->SetExpressionPosition(expr);
+        TestTypeOfFlags::LiteralFlag literal_flag =
+                TestTypeOfFlags::GetFlagForLiteral(ast_string_constants(), literal);
+        if (literal_flag == TestTypeOfFlags::LiteralFlag::kOther) {
+            builder()->LoadFalse();
+        } else {
+            builder()->CompareTypeOf(literal_flag);
+        }
+    } else if (expr->IsLiteralStrictCompareBoolean(&sub_expr, &literal)) {
+        DCHECK(expr->op() == Token::EQ_STRICT);
+        VisitForAccumulatorValue(sub_expr);
+        builder()->SetExpressionPosition(expr);
+        BuildLiteralStrictCompareBoolean(literal);
+    } else if (expr->IsLiteralCompareUndefined(&sub_expr)) {
+        VisitForAccumulatorValue(sub_expr);
+        builder()->SetExpressionPosition(expr);
+        BuildLiteralCompareNil(expr->op(), BytecodeArrayBuilder::kUndefinedValue);
+    } else if (expr->IsLiteralCompareNull(&sub_expr)) {
+        VisitForAccumulatorValue(sub_expr);
+        builder()->SetExpressionPosition(expr);
+        BuildLiteralCompareNil(expr->op(), BytecodeArrayBuilder::kNullValue);
     } else {
-      builder()->CompareTypeOf(literal_flag);
-    }
-  } else if (expr->IsLiteralStrictCompareBoolean(&sub_expr, &literal)) {
-    DCHECK(expr->op() == Token::EQ_STRICT);
-    VisitForAccumulatorValue(sub_expr);
-    builder()->SetExpressionPosition(expr);
-    BuildLiteralStrictCompareBoolean(literal);
-  } else if (expr->IsLiteralCompareUndefined(&sub_expr)) {
-    VisitForAccumulatorValue(sub_expr);
-    builder()->SetExpressionPosition(expr);
-    BuildLiteralCompareNil(expr->op(), BytecodeArrayBuilder::kUndefinedValue);
-  } else if (expr->IsLiteralCompareNull(&sub_expr)) {
-    VisitForAccumulatorValue(sub_expr);
-    builder()->SetExpressionPosition(expr);
-    BuildLiteralCompareNil(expr->op(), BytecodeArrayBuilder::kNullValue);
-  } else {
-    if (expr->op() == Token::IN && expr->left()->IsPrivateName()) {
-      Variable* var = expr->left()->AsVariableProxy()->var();
-      if (IsPrivateMethodOrAccessorVariableMode(var->mode())) {
-        BuildPrivateMethodIn(var, expr->right());
-        return;
-      }
-      // For private fields, the code below does the right thing.
-    }
+        if (expr->op() == Token::IN && expr->left()->IsPrivateName()) {
+            Variable* var = expr->left()->AsVariableProxy()->var();
+            if (IsPrivateMethodOrAccessorVariableMode(var->mode())) {
+                BuildPrivateMethodIn(var, expr->right());
+                return;
+            }
+            // For private fields, the code below does the right thing.
+        }
 
-    Register lhs = VisitForRegisterValue(expr->left());
-    VisitForAccumulatorValue(expr->right());
-    builder()->SetExpressionPosition(expr);
-    FeedbackSlot slot;
-    if (expr->op() == Token::IN) {
-      slot = feedback_spec()->AddKeyedHasICSlot();
-    } else if (expr->op() == Token::INSTANCEOF) {
-      slot = feedback_spec()->AddInstanceOfSlot();
-    } else {
-      slot = feedback_spec()->AddCompareICSlot();
+        Register lhs = VisitForRegisterValue(expr->left());
+        VisitForAccumulatorValue(expr->right());
+        builder()->SetExpressionPosition(expr);
+        FeedbackSlot slot;
+        if (expr->op() == Token::IN) {
+            slot = feedback_spec()->AddKeyedHasICSlot();
+        } else if (expr->op() == Token::INSTANCEOF) {
+            slot = feedback_spec()->AddInstanceOfSlot();
+        } else {
+            slot = feedback_spec()->AddCompareICSlot();
+        }
+        builder()->CompareOperation(expr->op(), lhs, feedback_index(slot));
     }
-    builder()->CompareOperation(expr->op(), lhs, feedback_index(slot));
-  }
-  // Always returns a boolean value.
-  execution_result()->SetResultIsBoolean();
+    // Always returns a boolean value.
+    execution_result()->SetResultIsBoolean();
 }
 
 void BytecodeGenerator::VisitArithmeticExpression(BinaryOperation* expr) {
-  FeedbackSlot slot = feedback_spec()->AddBinaryOpICSlot();
-  Expression* subexpr;
-  Smi literal;
-  if (expr->IsSmiLiteralOperation(&subexpr, &literal)) {
-    TypeHint type_hint = VisitForAccumulatorValue(subexpr);
-    builder()->SetExpressionPosition(expr);
-    builder()->BinaryOperationSmiLiteral(expr->op(), literal,
-                                         feedback_index(slot));
-    if (expr->op() == Token::ADD && type_hint == TypeHint::kString) {
-      execution_result()->SetResultIsString();
-    }
-  } else {
-    TypeHint lhs_type = VisitForAccumulatorValue(expr->left());
-    Register lhs = register_allocator()->NewRegister();
-    builder()->StoreAccumulatorInRegister(lhs);
-    TypeHint rhs_type = VisitForAccumulatorValue(expr->right());
-    if (expr->op() == Token::ADD &&
-        (lhs_type == TypeHint::kString || rhs_type == TypeHint::kString)) {
-      execution_result()->SetResultIsString();
-    }
+    FeedbackSlot slot = feedback_spec()->AddBinaryOpICSlot();
+    Expression* subexpr;
+    Smi literal;
+    if (expr->IsSmiLiteralOperation(&subexpr, &literal)) {
+        TypeHint type_hint = VisitForAccumulatorValue(subexpr);
+        builder()->SetExpressionPosition(expr);
+        builder()->BinaryOperationSmiLiteral(expr->op(), literal,
+                                             feedback_index(slot));
+        if (expr->op() == Token::ADD && type_hint == TypeHint::kString) {
+            execution_result()->SetResultIsString();
+        }
+    } else {
+        TypeHint lhs_type = VisitForAccumulatorValue(expr->left());
+        Register lhs = register_allocator()->NewRegister();
+        builder()->StoreAccumulatorInRegister(lhs);
+        TypeHint rhs_type = VisitForAccumulatorValue(expr->right());
+        if (expr->op() == Token::ADD &&
+            (lhs_type == TypeHint::kString || rhs_type == TypeHint::kString)) {
+            execution_result()->SetResultIsString();
+        }
 
-    builder()->SetExpressionPosition(expr);
-    builder()->BinaryOperation(expr->op(), lhs, feedback_index(slot));
-  }
+        builder()->SetExpressionPosition(expr);
+        builder()->BinaryOperation(expr->op(), lhs, feedback_index(slot));
+    }
 }
 
 void BytecodeGenerator::VisitNaryArithmeticExpression(NaryOperation* expr) {
-  // TODO(leszeks): Add support for lhs smi in commutative ops.
-  TypeHint type_hint = VisitForAccumulatorValue(expr->first());
+    // TODO(leszeks): Add support for lhs smi in commutative ops.
+    TypeHint type_hint = VisitForAccumulatorValue(expr->first());
 
-  for (size_t i = 0; i < expr->subsequent_length(); ++i) {
-    RegisterAllocationScope register_scope(this);
-    if (expr->subsequent(i)->IsSmiLiteral()) {
-      builder()->SetExpressionPosition(expr->subsequent_op_position(i));
-      builder()->BinaryOperationSmiLiteral(
-          expr->op(), expr->subsequent(i)->AsLiteral()->AsSmiLiteral(),
-          feedback_index(feedback_spec()->AddBinaryOpICSlot()));
-    } else {
-      Register lhs = register_allocator()->NewRegister();
-      builder()->StoreAccumulatorInRegister(lhs);
-      TypeHint rhs_hint = VisitForAccumulatorValue(expr->subsequent(i));
-      if (rhs_hint == TypeHint::kString) type_hint = TypeHint::kString;
-      builder()->SetExpressionPosition(expr->subsequent_op_position(i));
-      builder()->BinaryOperation(
-          expr->op(), lhs,
-          feedback_index(feedback_spec()->AddBinaryOpICSlot()));
+    for (size_t i = 0; i < expr->subsequent_length(); ++i) {
+        RegisterAllocationScope register_scope(this);
+        if (expr->subsequent(i)->IsSmiLiteral()) {
+            builder()->SetExpressionPosition(expr->subsequent_op_position(i));
+            builder()->BinaryOperationSmiLiteral(
+                    expr->op(), expr->subsequent(i)->AsLiteral()->AsSmiLiteral(),
+                    feedback_index(feedback_spec()->AddBinaryOpICSlot()));
+        } else {
+            Register lhs = register_allocator()->NewRegister();
+            builder()->StoreAccumulatorInRegister(lhs);
+            TypeHint rhs_hint = VisitForAccumulatorValue(expr->subsequent(i));
+            if (rhs_hint == TypeHint::kString) type_hint = TypeHint::kString;
+            builder()->SetExpressionPosition(expr->subsequent_op_position(i));
+            builder()->BinaryOperation(
+                    expr->op(), lhs,
+                    feedback_index(feedback_spec()->AddBinaryOpICSlot()));
+        }
     }
-  }
 
-  if (type_hint == TypeHint::kString && expr->op() == Token::ADD) {
-    // If any operand of an ADD is a String, a String is produced.
-    execution_result()->SetResultIsString();
-  }
+    if (type_hint == TypeHint::kString && expr->op() == Token::ADD) {
+        // If any operand of an ADD is a String, a String is produced.
+        execution_result()->SetResultIsString();
+    }
 }
 
 // Note: the actual spreading is performed by the surrounding expression's
@@ -6355,120 +6883,120 @@ void BytecodeGenerator::VisitNaryArithmeticExpression(NaryOperation* expr) {
 void BytecodeGenerator::VisitSpread(Spread* expr) { Visit(expr->expression()); }
 
 void BytecodeGenerator::VisitEmptyParentheses(EmptyParentheses* expr) {
-  UNREACHABLE();
+    UNREACHABLE();
 }
 
 void BytecodeGenerator::VisitImportCallExpression(ImportCallExpression* expr) {
-  const int register_count = expr->import_assertions() ? 3 : 2;
-  RegisterList args = register_allocator()->NewRegisterList(register_count);
-  VisitForRegisterValue(expr->specifier(), args[1]);
-  if (expr->import_assertions()) {
-    VisitForRegisterValue(expr->import_assertions(), args[2]);
-  }
-  builder()
-      ->MoveRegister(Register::function_closure(), args[0])
-      .CallRuntime(Runtime::kDynamicImportCall, args);
+    const int register_count = expr->import_assertions() ? 3 : 2;
+    RegisterList args = register_allocator()->NewRegisterList(register_count);
+    VisitForRegisterValue(expr->specifier(), args[1]);
+    if (expr->import_assertions()) {
+        VisitForRegisterValue(expr->import_assertions(), args[2]);
+    }
+    builder()
+            ->MoveRegister(Register::function_closure(), args[0])
+            .CallRuntime(Runtime::kDynamicImportCall, args);
 }
 
 void BytecodeGenerator::BuildGetIterator(IteratorType hint) {
-  if (hint == IteratorType::kAsync) {
-    RegisterAllocationScope scope(this);
-
-    Register obj = register_allocator()->NewRegister();
-    Register method = register_allocator()->NewRegister();
-
-    // Set method to GetMethod(obj, @@asyncIterator)
-    builder()->StoreAccumulatorInRegister(obj).LoadAsyncIteratorProperty(
-        obj, feedback_index(feedback_spec()->AddLoadICSlot()));
+    if (hint == IteratorType::kAsync) {
+        RegisterAllocationScope scope(this);
 
-    BytecodeLabel async_iterator_undefined, done;
-    builder()->JumpIfUndefinedOrNull(&async_iterator_undefined);
+        Register obj = register_allocator()->NewRegister();
+        Register method = register_allocator()->NewRegister();
 
-    // Let iterator be Call(method, obj)
-    builder()->StoreAccumulatorInRegister(method).CallProperty(
-        method, RegisterList(obj),
-        feedback_index(feedback_spec()->AddCallICSlot()));
+        // Set method to GetMethod(obj, @@asyncIterator)
+        builder()->StoreAccumulatorInRegister(obj).LoadAsyncIteratorProperty(
+                obj, feedback_index(feedback_spec()->AddLoadICSlot()));
 
-    // If Type(iterator) is not Object, throw a TypeError exception.
-    builder()->JumpIfJSReceiver(&done);
-    builder()->CallRuntime(Runtime::kThrowSymbolAsyncIteratorInvalid);
+        BytecodeLabel async_iterator_undefined, done;
+        builder()->JumpIfUndefinedOrNull(&async_iterator_undefined);
 
-    builder()->Bind(&async_iterator_undefined);
-    // If method is undefined,
-    //     Let syncMethod be GetMethod(obj, @@iterator)
-    builder()
-        ->LoadIteratorProperty(obj,
-                               feedback_index(feedback_spec()->AddLoadICSlot()))
-        .StoreAccumulatorInRegister(method);
+        // Let iterator be Call(method, obj)
+        builder()->StoreAccumulatorInRegister(method).CallProperty(
+                method, RegisterList(obj),
+                feedback_index(feedback_spec()->AddCallICSlot()));
 
-    //     Let syncIterator be Call(syncMethod, obj)
-    builder()->CallProperty(method, RegisterList(obj),
-                            feedback_index(feedback_spec()->AddCallICSlot()));
+        // If Type(iterator) is not Object, throw a TypeError exception.
+        builder()->JumpIfJSReceiver(&done);
+        builder()->CallRuntime(Runtime::kThrowSymbolAsyncIteratorInvalid);
 
-    // Return CreateAsyncFromSyncIterator(syncIterator)
-    // alias `method` register as it's no longer used
-    Register sync_iter = method;
-    builder()->StoreAccumulatorInRegister(sync_iter).CallRuntime(
-        Runtime::kInlineCreateAsyncFromSyncIterator, sync_iter);
+        builder()->Bind(&async_iterator_undefined);
+        // If method is undefined,
+        //     Let syncMethod be GetMethod(obj, @@iterator)
+        builder()
+                ->LoadIteratorProperty(obj,
+                                       feedback_index(feedback_spec()->AddLoadICSlot()))
+                .StoreAccumulatorInRegister(method);
 
-    builder()->Bind(&done);
-  } else {
-    {
-      RegisterAllocationScope scope(this);
+        //     Let syncIterator be Call(syncMethod, obj)
+        builder()->CallProperty(method, RegisterList(obj),
+                                feedback_index(feedback_spec()->AddCallICSlot()));
 
-      Register obj = register_allocator()->NewRegister();
-      int load_feedback_index =
-          feedback_index(feedback_spec()->AddLoadICSlot());
-      int call_feedback_index =
-          feedback_index(feedback_spec()->AddCallICSlot());
+        // Return CreateAsyncFromSyncIterator(syncIterator)
+        // alias `method` register as it's no longer used
+        Register sync_iter = method;
+        builder()->StoreAccumulatorInRegister(sync_iter).CallRuntime(
+                Runtime::kInlineCreateAsyncFromSyncIterator, sync_iter);
 
-      // Let method be GetMethod(obj, @@iterator) and
-      // iterator be Call(method, obj). If iterator is
-      // not JSReceiver, then throw TypeError.
-      builder()->StoreAccumulatorInRegister(obj).GetIterator(
-          obj, load_feedback_index, call_feedback_index);
+        builder()->Bind(&done);
+    } else {
+        {
+            RegisterAllocationScope scope(this);
+
+            Register obj = register_allocator()->NewRegister();
+            int load_feedback_index =
+                    feedback_index(feedback_spec()->AddLoadICSlot());
+            int call_feedback_index =
+                    feedback_index(feedback_spec()->AddCallICSlot());
+
+            // Let method be GetMethod(obj, @@iterator) and
+            // iterator be Call(method, obj). If iterator is
+            // not JSReceiver, then throw TypeError.
+            builder()->StoreAccumulatorInRegister(obj).GetIterator(
+                    obj, load_feedback_index, call_feedback_index);
+        }
     }
-  }
 }
 
 // Returns an IteratorRecord which is valid for the lifetime of the current
 // register_allocation_scope.
 BytecodeGenerator::IteratorRecord BytecodeGenerator::BuildGetIteratorRecord(
-    Register next, Register object, IteratorType hint) {
-  DCHECK(next.is_valid() && object.is_valid());
-  BuildGetIterator(hint);
+        Register next, Register object, IteratorType hint) {
+    DCHECK(next.is_valid() && object.is_valid());
+    BuildGetIterator(hint);
 
-  builder()
-      ->StoreAccumulatorInRegister(object)
-      .LoadNamedProperty(object, ast_string_constants()->next_string(),
-                         feedback_index(feedback_spec()->AddLoadICSlot()))
-      .StoreAccumulatorInRegister(next);
-  return IteratorRecord(object, next, hint);
+    builder()
+            ->StoreAccumulatorInRegister(object)
+            .LoadNamedProperty(object, ast_string_constants()->next_string(),
+                               feedback_index(feedback_spec()->AddLoadICSlot()))
+            .StoreAccumulatorInRegister(next);
+    return IteratorRecord(object, next, hint);
 }
 
 BytecodeGenerator::IteratorRecord BytecodeGenerator::BuildGetIteratorRecord(
-    IteratorType hint) {
-  Register next = register_allocator()->NewRegister();
-  Register object = register_allocator()->NewRegister();
-  return BuildGetIteratorRecord(next, object, hint);
+        IteratorType hint) {
+    Register next = register_allocator()->NewRegister();
+    Register object = register_allocator()->NewRegister();
+    return BuildGetIteratorRecord(next, object, hint);
 }
 
 void BytecodeGenerator::BuildIteratorNext(const IteratorRecord& iterator,
                                           Register next_result) {
-  DCHECK(next_result.is_valid());
-  builder()->CallProperty(iterator.next(), RegisterList(iterator.object()),
-                          feedback_index(feedback_spec()->AddCallICSlot()));
+    DCHECK(next_result.is_valid());
+    builder()->CallProperty(iterator.next(), RegisterList(iterator.object()),
+                            feedback_index(feedback_spec()->AddCallICSlot()));
 
-  if (iterator.type() == IteratorType::kAsync) {
-    BuildAwait();
-  }
+    if (iterator.type() == IteratorType::kAsync) {
+        BuildAwait();
+    }
 
-  BytecodeLabel is_object;
-  builder()
-      ->StoreAccumulatorInRegister(next_result)
-      .JumpIfJSReceiver(&is_object)
-      .CallRuntime(Runtime::kThrowIteratorResultNotAnObject, next_result)
-      .Bind(&is_object);
+    BytecodeLabel is_object;
+    builder()
+            ->StoreAccumulatorInRegister(next_result)
+            .JumpIfJSReceiver(&is_object)
+            .CallRuntime(Runtime::kThrowIteratorResultNotAnObject, next_result)
+            .Bind(&is_object);
 }
 
 void BytecodeGenerator::BuildCallIteratorMethod(Register iterator,
@@ -6476,731 +7004,731 @@ void BytecodeGenerator::BuildCallIteratorMethod(Register iterator,
                                                 RegisterList receiver_and_args,
                                                 BytecodeLabel* if_called,
                                                 BytecodeLabels* if_notcalled) {
-  RegisterAllocationScope register_scope(this);
+    RegisterAllocationScope register_scope(this);
 
-  Register method = register_allocator()->NewRegister();
-  FeedbackSlot slot = feedback_spec()->AddLoadICSlot();
-  builder()
-      ->LoadNamedProperty(iterator, method_name, feedback_index(slot))
-      .JumpIfUndefinedOrNull(if_notcalled->New())
-      .StoreAccumulatorInRegister(method)
-      .CallProperty(method, receiver_and_args,
-                    feedback_index(feedback_spec()->AddCallICSlot()))
-      .Jump(if_called);
+    Register method = register_allocator()->NewRegister();
+    FeedbackSlot slot = feedback_spec()->AddLoadICSlot();
+    builder()
+            ->LoadNamedProperty(iterator, method_name, feedback_index(slot))
+            .JumpIfUndefinedOrNull(if_notcalled->New())
+            .StoreAccumulatorInRegister(method)
+            .CallProperty(method, receiver_and_args,
+                          feedback_index(feedback_spec()->AddCallICSlot()))
+            .Jump(if_called);
 }
 
 void BytecodeGenerator::BuildIteratorClose(const IteratorRecord& iterator,
                                            Expression* expr) {
-  RegisterAllocationScope register_scope(this);
-  BytecodeLabels done(zone());
-  BytecodeLabel if_called;
-  RegisterList args = RegisterList(iterator.object());
-  BuildCallIteratorMethod(iterator.object(),
-                          ast_string_constants()->return_string(), args,
-                          &if_called, &done);
-  builder()->Bind(&if_called);
-
-  if (iterator.type() == IteratorType::kAsync) {
-    DCHECK_NOT_NULL(expr);
-    BuildAwait(expr->position());
-  }
+    RegisterAllocationScope register_scope(this);
+    BytecodeLabels done(zone());
+    BytecodeLabel if_called;
+    RegisterList args = RegisterList(iterator.object());
+    BuildCallIteratorMethod(iterator.object(),
+                            ast_string_constants()->return_string(), args,
+                            &if_called, &done);
+    builder()->Bind(&if_called);
+
+    if (iterator.type() == IteratorType::kAsync) {
+        DCHECK_NOT_NULL(expr);
+        BuildAwait(expr->position());
+    }
 
-  builder()->JumpIfJSReceiver(done.New());
-  {
-    RegisterAllocationScope inner_register_scope(this);
-    Register return_result = register_allocator()->NewRegister();
-    builder()
-        ->StoreAccumulatorInRegister(return_result)
-        .CallRuntime(Runtime::kThrowIteratorResultNotAnObject, return_result);
-  }
+    builder()->JumpIfJSReceiver(done.New());
+    {
+        RegisterAllocationScope inner_register_scope(this);
+        Register return_result = register_allocator()->NewRegister();
+        builder()
+                ->StoreAccumulatorInRegister(return_result)
+                .CallRuntime(Runtime::kThrowIteratorResultNotAnObject, return_result);
+    }
 
-  done.Bind(builder());
+    done.Bind(builder());
 }
 
 void BytecodeGenerator::VisitGetTemplateObject(GetTemplateObject* expr) {
-  builder()->SetExpressionPosition(expr);
-  size_t entry = builder()->AllocateDeferredConstantPoolEntry();
-  template_objects_.push_back(std::make_pair(expr, entry));
-  FeedbackSlot literal_slot = feedback_spec()->AddLiteralSlot();
-  builder()->GetTemplateObject(entry, feedback_index(literal_slot));
+    builder()->SetExpressionPosition(expr);
+    size_t entry = builder()->AllocateDeferredConstantPoolEntry();
+    template_objects_.push_back(std::make_pair(expr, entry));
+    FeedbackSlot literal_slot = feedback_spec()->AddLiteralSlot();
+    builder()->GetTemplateObject(entry, feedback_index(literal_slot));
 }
 
 void BytecodeGenerator::VisitTemplateLiteral(TemplateLiteral* expr) {
-  const ZonePtrList<const AstRawString>& parts = *expr->string_parts();
-  const ZonePtrList<Expression>& substitutions = *expr->substitutions();
-  // Template strings with no substitutions are turned into StringLiterals.
-  DCHECK_GT(substitutions.length(), 0);
-  DCHECK_EQ(parts.length(), substitutions.length() + 1);
-
-  // Generate string concatenation
-  // TODO(caitp): Don't generate feedback slot if it's not used --- introduce
-  // a simple, concise, reusable mechanism to lazily create reusable slots.
-  FeedbackSlot slot = feedback_spec()->AddBinaryOpICSlot();
-  Register last_part = register_allocator()->NewRegister();
-  bool last_part_valid = false;
-
-  builder()->SetExpressionPosition(expr);
-  for (int i = 0; i < substitutions.length(); ++i) {
-    if (i != 0) {
-      builder()->StoreAccumulatorInRegister(last_part);
-      last_part_valid = true;
-    }
-
-    if (!parts[i]->IsEmpty()) {
-      builder()->LoadLiteral(parts[i]);
-      if (last_part_valid) {
-        builder()->BinaryOperation(Token::ADD, last_part, feedback_index(slot));
-      }
-      builder()->StoreAccumulatorInRegister(last_part);
-      last_part_valid = true;
-    }
+    const ZonePtrList<const AstRawString>& parts = *expr->string_parts();
+    const ZonePtrList<Expression>& substitutions = *expr->substitutions();
+    // Template strings with no substitutions are turned into StringLiterals.
+    DCHECK_GT(substitutions.length(), 0);
+    DCHECK_EQ(parts.length(), substitutions.length() + 1);
+
+    // Generate string concatenation
+    // TODO(caitp): Don't generate feedback slot if it's not used --- introduce
+    // a simple, concise, reusable mechanism to lazily create reusable slots.
+    FeedbackSlot slot = feedback_spec()->AddBinaryOpICSlot();
+    Register last_part = register_allocator()->NewRegister();
+    bool last_part_valid = false;
 
-    TypeHint type_hint = VisitForAccumulatorValue(substitutions[i]);
-    if (type_hint != TypeHint::kString) {
-      builder()->ToString();
-    }
-    if (last_part_valid) {
-      builder()->BinaryOperation(Token::ADD, last_part, feedback_index(slot));
+    builder()->SetExpressionPosition(expr);
+    for (int i = 0; i < substitutions.length(); ++i) {
+        if (i != 0) {
+            builder()->StoreAccumulatorInRegister(last_part);
+            last_part_valid = true;
+        }
+
+        if (!parts[i]->IsEmpty()) {
+            builder()->LoadLiteral(parts[i]);
+            if (last_part_valid) {
+                builder()->BinaryOperation(Token::ADD, last_part, feedback_index(slot));
+            }
+            builder()->StoreAccumulatorInRegister(last_part);
+            last_part_valid = true;
+        }
+
+        TypeHint type_hint = VisitForAccumulatorValue(substitutions[i]);
+        if (type_hint != TypeHint::kString) {
+            builder()->ToString();
+        }
+        if (last_part_valid) {
+            builder()->BinaryOperation(Token::ADD, last_part, feedback_index(slot));
+        }
+        last_part_valid = false;
     }
-    last_part_valid = false;
-  }
 
-  if (!parts.last()->IsEmpty()) {
-    builder()->StoreAccumulatorInRegister(last_part);
-    builder()->LoadLiteral(parts.last());
-    builder()->BinaryOperation(Token::ADD, last_part, feedback_index(slot));
-  }
+    if (!parts.last()->IsEmpty()) {
+        builder()->StoreAccumulatorInRegister(last_part);
+        builder()->LoadLiteral(parts.last());
+        builder()->BinaryOperation(Token::ADD, last_part, feedback_index(slot));
+    }
 }
 
 void BytecodeGenerator::BuildThisVariableLoad() {
-  DeclarationScope* receiver_scope = closure_scope()->GetReceiverScope();
-  Variable* var = receiver_scope->receiver();
-  // TODO(littledan): implement 'this' hole check elimination.
-  HoleCheckMode hole_check_mode =
-      IsDerivedConstructor(receiver_scope->function_kind())
-          ? HoleCheckMode::kRequired
-          : HoleCheckMode::kElided;
-  BuildVariableLoad(var, hole_check_mode);
+    DeclarationScope* receiver_scope = closure_scope()->GetReceiverScope();
+    Variable* var = receiver_scope->receiver();
+    // TODO(littledan): implement 'this' hole check elimination.
+    HoleCheckMode hole_check_mode =
+            IsDerivedConstructor(receiver_scope->function_kind())
+            ? HoleCheckMode::kRequired
+            : HoleCheckMode::kElided;
+    BuildVariableLoad(var, hole_check_mode);
 }
 
 void BytecodeGenerator::VisitThisExpression(ThisExpression* expr) {
-  BuildThisVariableLoad();
+    BuildThisVariableLoad();
 }
 
 void BytecodeGenerator::VisitSuperCallReference(SuperCallReference* expr) {
-  // Handled by VisitCall().
-  UNREACHABLE();
+    // Handled by VisitCall().
+    UNREACHABLE();
 }
 
 void BytecodeGenerator::VisitSuperPropertyReference(
-    SuperPropertyReference* expr) {
-  builder()->CallRuntime(Runtime::kThrowUnsupportedSuperError);
+        SuperPropertyReference* expr) {
+    builder()->CallRuntime(Runtime::kThrowUnsupportedSuperError);
 }
 
 void BytecodeGenerator::VisitCommaExpression(BinaryOperation* binop) {
-  VisitForEffect(binop->left());
-  builder()->SetExpressionAsStatementPosition(binop->right());
-  Visit(binop->right());
+    VisitForEffect(binop->left());
+    builder()->SetExpressionAsStatementPosition(binop->right());
+    Visit(binop->right());
 }
 
 void BytecodeGenerator::VisitNaryCommaExpression(NaryOperation* expr) {
-  DCHECK_GT(expr->subsequent_length(), 0);
+    DCHECK_GT(expr->subsequent_length(), 0);
 
-  VisitForEffect(expr->first());
-  for (size_t i = 0; i < expr->subsequent_length() - 1; ++i) {
-    builder()->SetExpressionAsStatementPosition(expr->subsequent(i));
-    VisitForEffect(expr->subsequent(i));
-  }
-  builder()->SetExpressionAsStatementPosition(
-      expr->subsequent(expr->subsequent_length() - 1));
-  Visit(expr->subsequent(expr->subsequent_length() - 1));
+    VisitForEffect(expr->first());
+    for (size_t i = 0; i < expr->subsequent_length() - 1; ++i) {
+        builder()->SetExpressionAsStatementPosition(expr->subsequent(i));
+        VisitForEffect(expr->subsequent(i));
+    }
+    builder()->SetExpressionAsStatementPosition(
+            expr->subsequent(expr->subsequent_length() - 1));
+    Visit(expr->subsequent(expr->subsequent_length() - 1));
 }
 
 void BytecodeGenerator::VisitLogicalTestSubExpression(
-    Token::Value token, Expression* expr, BytecodeLabels* then_labels,
-    BytecodeLabels* else_labels, int coverage_slot) {
-  DCHECK(token == Token::OR || token == Token::AND || token == Token::NULLISH);
-
-  BytecodeLabels test_next(zone());
-  if (token == Token::OR) {
-    VisitForTest(expr, then_labels, &test_next, TestFallthrough::kElse);
-  } else if (token == Token::AND) {
-    VisitForTest(expr, &test_next, else_labels, TestFallthrough::kThen);
-  } else {
-    DCHECK_EQ(Token::NULLISH, token);
-    VisitForNullishTest(expr, then_labels, &test_next, else_labels);
-  }
-  test_next.Bind(builder());
+        Token::Value token, Expression* expr, BytecodeLabels* then_labels,
+        BytecodeLabels* else_labels, int coverage_slot) {
+    DCHECK(token == Token::OR || token == Token::AND || token == Token::NULLISH);
+
+    BytecodeLabels test_next(zone());
+    if (token == Token::OR) {
+        VisitForTest(expr, then_labels, &test_next, TestFallthrough::kElse);
+    } else if (token == Token::AND) {
+        VisitForTest(expr, &test_next, else_labels, TestFallthrough::kThen);
+    } else {
+        DCHECK_EQ(Token::NULLISH, token);
+        VisitForNullishTest(expr, then_labels, &test_next, else_labels);
+    }
+    test_next.Bind(builder());
 
-  BuildIncrementBlockCoverageCounterIfEnabled(coverage_slot);
+    BuildIncrementBlockCoverageCounterIfEnabled(coverage_slot);
 }
 
 void BytecodeGenerator::VisitLogicalTest(Token::Value token, Expression* left,
                                          Expression* right,
                                          int right_coverage_slot) {
-  DCHECK(token == Token::OR || token == Token::AND || token == Token::NULLISH);
-  TestResultScope* test_result = execution_result()->AsTest();
-  BytecodeLabels* then_labels = test_result->then_labels();
-  BytecodeLabels* else_labels = test_result->else_labels();
-  TestFallthrough fallthrough = test_result->fallthrough();
+    DCHECK(token == Token::OR || token == Token::AND || token == Token::NULLISH);
+    TestResultScope* test_result = execution_result()->AsTest();
+    BytecodeLabels* then_labels = test_result->then_labels();
+    BytecodeLabels* else_labels = test_result->else_labels();
+    TestFallthrough fallthrough = test_result->fallthrough();
 
-  VisitLogicalTestSubExpression(token, left, then_labels, else_labels,
-                                right_coverage_slot);
-  // The last test has the same then, else and fallthrough as the parent test.
-  VisitForTest(right, then_labels, else_labels, fallthrough);
+    VisitLogicalTestSubExpression(token, left, then_labels, else_labels,
+                                  right_coverage_slot);
+    // The last test has the same then, else and fallthrough as the parent test.
+    VisitForTest(right, then_labels, else_labels, fallthrough);
 }
 
 void BytecodeGenerator::VisitNaryLogicalTest(
-    Token::Value token, NaryOperation* expr,
-    const NaryCodeCoverageSlots* coverage_slots) {
-  DCHECK(token == Token::OR || token == Token::AND || token == Token::NULLISH);
-  DCHECK_GT(expr->subsequent_length(), 0);
-
-  TestResultScope* test_result = execution_result()->AsTest();
-  BytecodeLabels* then_labels = test_result->then_labels();
-  BytecodeLabels* else_labels = test_result->else_labels();
-  TestFallthrough fallthrough = test_result->fallthrough();
-
-  VisitLogicalTestSubExpression(token, expr->first(), then_labels, else_labels,
-                                coverage_slots->GetSlotFor(0));
-  for (size_t i = 0; i < expr->subsequent_length() - 1; ++i) {
-    VisitLogicalTestSubExpression(token, expr->subsequent(i), then_labels,
-                                  else_labels,
-                                  coverage_slots->GetSlotFor(i + 1));
-  }
-  // The last test has the same then, else and fallthrough as the parent test.
-  VisitForTest(expr->subsequent(expr->subsequent_length() - 1), then_labels,
-               else_labels, fallthrough);
+        Token::Value token, NaryOperation* expr,
+        const NaryCodeCoverageSlots* coverage_slots) {
+    DCHECK(token == Token::OR || token == Token::AND || token == Token::NULLISH);
+    DCHECK_GT(expr->subsequent_length(), 0);
+
+    TestResultScope* test_result = execution_result()->AsTest();
+    BytecodeLabels* then_labels = test_result->then_labels();
+    BytecodeLabels* else_labels = test_result->else_labels();
+    TestFallthrough fallthrough = test_result->fallthrough();
+
+    VisitLogicalTestSubExpression(token, expr->first(), then_labels, else_labels,
+                                  coverage_slots->GetSlotFor(0));
+    for (size_t i = 0; i < expr->subsequent_length() - 1; ++i) {
+        VisitLogicalTestSubExpression(token, expr->subsequent(i), then_labels,
+                                      else_labels,
+                                      coverage_slots->GetSlotFor(i + 1));
+    }
+    // The last test has the same then, else and fallthrough as the parent test.
+    VisitForTest(expr->subsequent(expr->subsequent_length() - 1), then_labels,
+                 else_labels, fallthrough);
 }
 
 bool BytecodeGenerator::VisitLogicalOrSubExpression(Expression* expr,
                                                     BytecodeLabels* end_labels,
                                                     int coverage_slot) {
-  if (expr->ToBooleanIsTrue()) {
-    VisitForAccumulatorValue(expr);
-    end_labels->Bind(builder());
-    return true;
-  } else if (!expr->ToBooleanIsFalse()) {
-    TypeHint type_hint = VisitForAccumulatorValue(expr);
-    builder()->JumpIfTrue(ToBooleanModeFromTypeHint(type_hint),
-                          end_labels->New());
-  }
+    if (expr->ToBooleanIsTrue()) {
+        VisitForAccumulatorValue(expr);
+        end_labels->Bind(builder());
+        return true;
+    } else if (!expr->ToBooleanIsFalse()) {
+        TypeHint type_hint = VisitForAccumulatorValue(expr);
+        builder()->JumpIfTrue(ToBooleanModeFromTypeHint(type_hint),
+                              end_labels->New());
+    }
 
-  BuildIncrementBlockCoverageCounterIfEnabled(coverage_slot);
+    BuildIncrementBlockCoverageCounterIfEnabled(coverage_slot);
 
-  return false;
+    return false;
 }
 
 bool BytecodeGenerator::VisitLogicalAndSubExpression(Expression* expr,
                                                      BytecodeLabels* end_labels,
                                                      int coverage_slot) {
-  if (expr->ToBooleanIsFalse()) {
-    VisitForAccumulatorValue(expr);
-    end_labels->Bind(builder());
-    return true;
-  } else if (!expr->ToBooleanIsTrue()) {
-    TypeHint type_hint = VisitForAccumulatorValue(expr);
-    builder()->JumpIfFalse(ToBooleanModeFromTypeHint(type_hint),
-                           end_labels->New());
-  }
+    if (expr->ToBooleanIsFalse()) {
+        VisitForAccumulatorValue(expr);
+        end_labels->Bind(builder());
+        return true;
+    } else if (!expr->ToBooleanIsTrue()) {
+        TypeHint type_hint = VisitForAccumulatorValue(expr);
+        builder()->JumpIfFalse(ToBooleanModeFromTypeHint(type_hint),
+                               end_labels->New());
+    }
 
-  BuildIncrementBlockCoverageCounterIfEnabled(coverage_slot);
+    BuildIncrementBlockCoverageCounterIfEnabled(coverage_slot);
 
-  return false;
+    return false;
 }
 
 bool BytecodeGenerator::VisitNullishSubExpression(Expression* expr,
                                                   BytecodeLabels* end_labels,
                                                   int coverage_slot) {
-  if (expr->IsLiteralButNotNullOrUndefined()) {
-    VisitForAccumulatorValue(expr);
-    end_labels->Bind(builder());
-    return true;
-  } else if (!expr->IsNullOrUndefinedLiteral()) {
-    VisitForAccumulatorValue(expr);
-    BytecodeLabel is_null_or_undefined;
-    builder()
-        ->JumpIfUndefinedOrNull(&is_null_or_undefined)
-        .Jump(end_labels->New());
-    builder()->Bind(&is_null_or_undefined);
-  }
+    if (expr->IsLiteralButNotNullOrUndefined()) {
+        VisitForAccumulatorValue(expr);
+        end_labels->Bind(builder());
+        return true;
+    } else if (!expr->IsNullOrUndefinedLiteral()) {
+        VisitForAccumulatorValue(expr);
+        BytecodeLabel is_null_or_undefined;
+        builder()
+                ->JumpIfUndefinedOrNull(&is_null_or_undefined)
+                .Jump(end_labels->New());
+        builder()->Bind(&is_null_or_undefined);
+    }
 
-  BuildIncrementBlockCoverageCounterIfEnabled(coverage_slot);
+    BuildIncrementBlockCoverageCounterIfEnabled(coverage_slot);
 
-  return false;
+    return false;
 }
 
 void BytecodeGenerator::VisitLogicalOrExpression(BinaryOperation* binop) {
-  Expression* left = binop->left();
-  Expression* right = binop->right();
-
-  int right_coverage_slot =
-      AllocateBlockCoverageSlotIfEnabled(binop, SourceRangeKind::kRight);
-
-  if (execution_result()->IsTest()) {
-    TestResultScope* test_result = execution_result()->AsTest();
-    if (left->ToBooleanIsTrue()) {
-      builder()->Jump(test_result->NewThenLabel());
-    } else if (left->ToBooleanIsFalse() && right->ToBooleanIsFalse()) {
-      BuildIncrementBlockCoverageCounterIfEnabled(right_coverage_slot);
-      builder()->Jump(test_result->NewElseLabel());
+    Expression* left = binop->left();
+    Expression* right = binop->right();
+
+    int right_coverage_slot =
+            AllocateBlockCoverageSlotIfEnabled(binop, SourceRangeKind::kRight);
+
+    if (execution_result()->IsTest()) {
+        TestResultScope* test_result = execution_result()->AsTest();
+        if (left->ToBooleanIsTrue()) {
+            builder()->Jump(test_result->NewThenLabel());
+        } else if (left->ToBooleanIsFalse() && right->ToBooleanIsFalse()) {
+            BuildIncrementBlockCoverageCounterIfEnabled(right_coverage_slot);
+            builder()->Jump(test_result->NewElseLabel());
+        } else {
+            VisitLogicalTest(Token::OR, left, right, right_coverage_slot);
+        }
+        test_result->SetResultConsumedByTest();
     } else {
-      VisitLogicalTest(Token::OR, left, right, right_coverage_slot);
-    }
-    test_result->SetResultConsumedByTest();
-  } else {
-    BytecodeLabels end_labels(zone());
-    if (VisitLogicalOrSubExpression(left, &end_labels, right_coverage_slot)) {
-      return;
+        BytecodeLabels end_labels(zone());
+        if (VisitLogicalOrSubExpression(left, &end_labels, right_coverage_slot)) {
+            return;
+        }
+        VisitForAccumulatorValue(right);
+        end_labels.Bind(builder());
     }
-    VisitForAccumulatorValue(right);
-    end_labels.Bind(builder());
-  }
 }
 
 void BytecodeGenerator::VisitNaryLogicalOrExpression(NaryOperation* expr) {
-  Expression* first = expr->first();
-  DCHECK_GT(expr->subsequent_length(), 0);
+    Expression* first = expr->first();
+    DCHECK_GT(expr->subsequent_length(), 0);
 
-  NaryCodeCoverageSlots coverage_slots(this, expr);
+    NaryCodeCoverageSlots coverage_slots(this, expr);
 
-  if (execution_result()->IsTest()) {
-    TestResultScope* test_result = execution_result()->AsTest();
-    if (first->ToBooleanIsTrue()) {
-      builder()->Jump(test_result->NewThenLabel());
+    if (execution_result()->IsTest()) {
+        TestResultScope* test_result = execution_result()->AsTest();
+        if (first->ToBooleanIsTrue()) {
+            builder()->Jump(test_result->NewThenLabel());
+        } else {
+            VisitNaryLogicalTest(Token::OR, expr, &coverage_slots);
+        }
+        test_result->SetResultConsumedByTest();
     } else {
-      VisitNaryLogicalTest(Token::OR, expr, &coverage_slots);
-    }
-    test_result->SetResultConsumedByTest();
-  } else {
-    BytecodeLabels end_labels(zone());
-    if (VisitLogicalOrSubExpression(first, &end_labels,
-                                    coverage_slots.GetSlotFor(0))) {
-      return;
-    }
-    for (size_t i = 0; i < expr->subsequent_length() - 1; ++i) {
-      if (VisitLogicalOrSubExpression(expr->subsequent(i), &end_labels,
-                                      coverage_slots.GetSlotFor(i + 1))) {
-        return;
-      }
+        BytecodeLabels end_labels(zone());
+        if (VisitLogicalOrSubExpression(first, &end_labels,
+                                        coverage_slots.GetSlotFor(0))) {
+            return;
+        }
+        for (size_t i = 0; i < expr->subsequent_length() - 1; ++i) {
+            if (VisitLogicalOrSubExpression(expr->subsequent(i), &end_labels,
+                                            coverage_slots.GetSlotFor(i + 1))) {
+                return;
+            }
+        }
+        // We have to visit the last value even if it's true, because we need its
+        // actual value.
+        VisitForAccumulatorValue(expr->subsequent(expr->subsequent_length() - 1));
+        end_labels.Bind(builder());
     }
-    // We have to visit the last value even if it's true, because we need its
-    // actual value.
-    VisitForAccumulatorValue(expr->subsequent(expr->subsequent_length() - 1));
-    end_labels.Bind(builder());
-  }
 }
 
 void BytecodeGenerator::VisitLogicalAndExpression(BinaryOperation* binop) {
-  Expression* left = binop->left();
-  Expression* right = binop->right();
-
-  int right_coverage_slot =
-      AllocateBlockCoverageSlotIfEnabled(binop, SourceRangeKind::kRight);
-
-  if (execution_result()->IsTest()) {
-    TestResultScope* test_result = execution_result()->AsTest();
-    if (left->ToBooleanIsFalse()) {
-      builder()->Jump(test_result->NewElseLabel());
-    } else if (left->ToBooleanIsTrue() && right->ToBooleanIsTrue()) {
-      BuildIncrementBlockCoverageCounterIfEnabled(right_coverage_slot);
-      builder()->Jump(test_result->NewThenLabel());
+    Expression* left = binop->left();
+    Expression* right = binop->right();
+
+    int right_coverage_slot =
+            AllocateBlockCoverageSlotIfEnabled(binop, SourceRangeKind::kRight);
+
+    if (execution_result()->IsTest()) {
+        TestResultScope* test_result = execution_result()->AsTest();
+        if (left->ToBooleanIsFalse()) {
+            builder()->Jump(test_result->NewElseLabel());
+        } else if (left->ToBooleanIsTrue() && right->ToBooleanIsTrue()) {
+            BuildIncrementBlockCoverageCounterIfEnabled(right_coverage_slot);
+            builder()->Jump(test_result->NewThenLabel());
+        } else {
+            VisitLogicalTest(Token::AND, left, right, right_coverage_slot);
+        }
+        test_result->SetResultConsumedByTest();
     } else {
-      VisitLogicalTest(Token::AND, left, right, right_coverage_slot);
-    }
-    test_result->SetResultConsumedByTest();
-  } else {
-    BytecodeLabels end_labels(zone());
-    if (VisitLogicalAndSubExpression(left, &end_labels, right_coverage_slot)) {
-      return;
+        BytecodeLabels end_labels(zone());
+        if (VisitLogicalAndSubExpression(left, &end_labels, right_coverage_slot)) {
+            return;
+        }
+        VisitForAccumulatorValue(right);
+        end_labels.Bind(builder());
     }
-    VisitForAccumulatorValue(right);
-    end_labels.Bind(builder());
-  }
 }
 
 void BytecodeGenerator::VisitNaryLogicalAndExpression(NaryOperation* expr) {
-  Expression* first = expr->first();
-  DCHECK_GT(expr->subsequent_length(), 0);
+    Expression* first = expr->first();
+    DCHECK_GT(expr->subsequent_length(), 0);
 
-  NaryCodeCoverageSlots coverage_slots(this, expr);
+    NaryCodeCoverageSlots coverage_slots(this, expr);
 
-  if (execution_result()->IsTest()) {
-    TestResultScope* test_result = execution_result()->AsTest();
-    if (first->ToBooleanIsFalse()) {
-      builder()->Jump(test_result->NewElseLabel());
+    if (execution_result()->IsTest()) {
+        TestResultScope* test_result = execution_result()->AsTest();
+        if (first->ToBooleanIsFalse()) {
+            builder()->Jump(test_result->NewElseLabel());
+        } else {
+            VisitNaryLogicalTest(Token::AND, expr, &coverage_slots);
+        }
+        test_result->SetResultConsumedByTest();
     } else {
-      VisitNaryLogicalTest(Token::AND, expr, &coverage_slots);
-    }
-    test_result->SetResultConsumedByTest();
-  } else {
-    BytecodeLabels end_labels(zone());
-    if (VisitLogicalAndSubExpression(first, &end_labels,
-                                     coverage_slots.GetSlotFor(0))) {
-      return;
-    }
-    for (size_t i = 0; i < expr->subsequent_length() - 1; ++i) {
-      if (VisitLogicalAndSubExpression(expr->subsequent(i), &end_labels,
-                                       coverage_slots.GetSlotFor(i + 1))) {
-        return;
-      }
+        BytecodeLabels end_labels(zone());
+        if (VisitLogicalAndSubExpression(first, &end_labels,
+                                         coverage_slots.GetSlotFor(0))) {
+            return;
+        }
+        for (size_t i = 0; i < expr->subsequent_length() - 1; ++i) {
+            if (VisitLogicalAndSubExpression(expr->subsequent(i), &end_labels,
+                                             coverage_slots.GetSlotFor(i + 1))) {
+                return;
+            }
+        }
+        // We have to visit the last value even if it's false, because we need its
+        // actual value.
+        VisitForAccumulatorValue(expr->subsequent(expr->subsequent_length() - 1));
+        end_labels.Bind(builder());
     }
-    // We have to visit the last value even if it's false, because we need its
-    // actual value.
-    VisitForAccumulatorValue(expr->subsequent(expr->subsequent_length() - 1));
-    end_labels.Bind(builder());
-  }
 }
 
 void BytecodeGenerator::VisitNullishExpression(BinaryOperation* binop) {
-  Expression* left = binop->left();
-  Expression* right = binop->right();
-
-  int right_coverage_slot =
-      AllocateBlockCoverageSlotIfEnabled(binop, SourceRangeKind::kRight);
-
-  if (execution_result()->IsTest()) {
-    TestResultScope* test_result = execution_result()->AsTest();
-    if (left->IsLiteralButNotNullOrUndefined() && left->ToBooleanIsTrue()) {
-      builder()->Jump(test_result->NewThenLabel());
-    } else if (left->IsNullOrUndefinedLiteral() &&
-               right->IsNullOrUndefinedLiteral()) {
-      BuildIncrementBlockCoverageCounterIfEnabled(right_coverage_slot);
-      builder()->Jump(test_result->NewElseLabel());
+    Expression* left = binop->left();
+    Expression* right = binop->right();
+
+    int right_coverage_slot =
+            AllocateBlockCoverageSlotIfEnabled(binop, SourceRangeKind::kRight);
+
+    if (execution_result()->IsTest()) {
+        TestResultScope* test_result = execution_result()->AsTest();
+        if (left->IsLiteralButNotNullOrUndefined() && left->ToBooleanIsTrue()) {
+            builder()->Jump(test_result->NewThenLabel());
+        } else if (left->IsNullOrUndefinedLiteral() &&
+                   right->IsNullOrUndefinedLiteral()) {
+            BuildIncrementBlockCoverageCounterIfEnabled(right_coverage_slot);
+            builder()->Jump(test_result->NewElseLabel());
+        } else {
+            VisitLogicalTest(Token::NULLISH, left, right, right_coverage_slot);
+        }
+        test_result->SetResultConsumedByTest();
     } else {
-      VisitLogicalTest(Token::NULLISH, left, right, right_coverage_slot);
-    }
-    test_result->SetResultConsumedByTest();
-  } else {
-    BytecodeLabels end_labels(zone());
-    if (VisitNullishSubExpression(left, &end_labels, right_coverage_slot)) {
-      return;
+        BytecodeLabels end_labels(zone());
+        if (VisitNullishSubExpression(left, &end_labels, right_coverage_slot)) {
+            return;
+        }
+        VisitForAccumulatorValue(right);
+        end_labels.Bind(builder());
     }
-    VisitForAccumulatorValue(right);
-    end_labels.Bind(builder());
-  }
 }
 
 void BytecodeGenerator::VisitNaryNullishExpression(NaryOperation* expr) {
-  Expression* first = expr->first();
-  DCHECK_GT(expr->subsequent_length(), 0);
+    Expression* first = expr->first();
+    DCHECK_GT(expr->subsequent_length(), 0);
 
-  NaryCodeCoverageSlots coverage_slots(this, expr);
+    NaryCodeCoverageSlots coverage_slots(this, expr);
 
-  if (execution_result()->IsTest()) {
-    TestResultScope* test_result = execution_result()->AsTest();
-    if (first->IsLiteralButNotNullOrUndefined() && first->ToBooleanIsTrue()) {
-      builder()->Jump(test_result->NewThenLabel());
+    if (execution_result()->IsTest()) {
+        TestResultScope* test_result = execution_result()->AsTest();
+        if (first->IsLiteralButNotNullOrUndefined() && first->ToBooleanIsTrue()) {
+            builder()->Jump(test_result->NewThenLabel());
+        } else {
+            VisitNaryLogicalTest(Token::NULLISH, expr, &coverage_slots);
+        }
+        test_result->SetResultConsumedByTest();
     } else {
-      VisitNaryLogicalTest(Token::NULLISH, expr, &coverage_slots);
-    }
-    test_result->SetResultConsumedByTest();
-  } else {
-    BytecodeLabels end_labels(zone());
-    if (VisitNullishSubExpression(first, &end_labels,
-                                  coverage_slots.GetSlotFor(0))) {
-      return;
-    }
-    for (size_t i = 0; i < expr->subsequent_length() - 1; ++i) {
-      if (VisitNullishSubExpression(expr->subsequent(i), &end_labels,
-                                    coverage_slots.GetSlotFor(i + 1))) {
-        return;
-      }
+        BytecodeLabels end_labels(zone());
+        if (VisitNullishSubExpression(first, &end_labels,
+                                      coverage_slots.GetSlotFor(0))) {
+            return;
+        }
+        for (size_t i = 0; i < expr->subsequent_length() - 1; ++i) {
+            if (VisitNullishSubExpression(expr->subsequent(i), &end_labels,
+                                          coverage_slots.GetSlotFor(i + 1))) {
+                return;
+            }
+        }
+        // We have to visit the last value even if it's nullish, because we need its
+        // actual value.
+        VisitForAccumulatorValue(expr->subsequent(expr->subsequent_length() - 1));
+        end_labels.Bind(builder());
     }
-    // We have to visit the last value even if it's nullish, because we need its
-    // actual value.
-    VisitForAccumulatorValue(expr->subsequent(expr->subsequent_length() - 1));
-    end_labels.Bind(builder());
-  }
 }
 
 void BytecodeGenerator::BuildNewLocalActivationContext() {
-  ValueResultScope value_execution_result(this);
-  Scope* scope = closure_scope();
-  DCHECK_EQ(current_scope(), closure_scope());
-
-  // Create the appropriate context.
-  DCHECK(scope->is_function_scope() || scope->is_eval_scope());
-  int slot_count = scope->num_heap_slots() - Context::MIN_CONTEXT_SLOTS;
-  if (slot_count <= ConstructorBuiltins::MaximumFunctionContextSlots()) {
-    switch (scope->scope_type()) {
-      case EVAL_SCOPE:
-        builder()->CreateEvalContext(scope, slot_count);
-        break;
-      case FUNCTION_SCOPE:
-        builder()->CreateFunctionContext(scope, slot_count);
-        break;
-      default:
-        UNREACHABLE();
-    }
-  } else {
-    Register arg = register_allocator()->NewRegister();
-    builder()->LoadLiteral(scope).StoreAccumulatorInRegister(arg).CallRuntime(
-        Runtime::kNewFunctionContext, arg);
-    register_allocator()->ReleaseRegister(arg);
-  }
+    ValueResultScope value_execution_result(this);
+    Scope* scope = closure_scope();
+    DCHECK_EQ(current_scope(), closure_scope());
+
+    // Create the appropriate context.
+    DCHECK(scope->is_function_scope() || scope->is_eval_scope());
+    int slot_count = scope->num_heap_slots() - Context::MIN_CONTEXT_SLOTS;
+    if (slot_count <= ConstructorBuiltins::MaximumFunctionContextSlots()) {
+        switch (scope->scope_type()) {
+            case EVAL_SCOPE:
+                builder()->CreateEvalContext(scope, slot_count);
+                break;
+            case FUNCTION_SCOPE:
+                builder()->CreateFunctionContext(scope, slot_count);
+                break;
+            default:
+                UNREACHABLE();
+        }
+    } else {
+        Register arg = register_allocator()->NewRegister();
+        builder()->LoadLiteral(scope).StoreAccumulatorInRegister(arg).CallRuntime(
+                Runtime::kNewFunctionContext, arg);
+        register_allocator()->ReleaseRegister(arg);
+    }
 }
 
 void BytecodeGenerator::BuildLocalActivationContextInitialization() {
-  DeclarationScope* scope = closure_scope();
-
-  if (scope->has_this_declaration() && scope->receiver()->IsContextSlot()) {
-    Variable* variable = scope->receiver();
-    Register receiver(builder()->Receiver());
-    // Context variable (at bottom of the context chain).
-    DCHECK_EQ(0, scope->ContextChainLength(variable->scope()));
-    builder()->LoadAccumulatorWithRegister(receiver).StoreContextSlot(
-        execution_context()->reg(), variable->index(), 0);
-  }
+    DeclarationScope* scope = closure_scope();
 
-  // Copy parameters into context if necessary.
-  int num_parameters = scope->num_parameters();
-  for (int i = 0; i < num_parameters; i++) {
-    Variable* variable = scope->parameter(i);
-    if (!variable->IsContextSlot()) continue;
-
-    Register parameter(builder()->Parameter(i));
-    // Context variable (at bottom of the context chain).
-    DCHECK_EQ(0, scope->ContextChainLength(variable->scope()));
-    builder()->LoadAccumulatorWithRegister(parameter).StoreContextSlot(
-        execution_context()->reg(), variable->index(), 0);
-  }
+    if (scope->has_this_declaration() && scope->receiver()->IsContextSlot()) {
+        Variable* variable = scope->receiver();
+        Register receiver(builder()->Receiver());
+        // Context variable (at bottom of the context chain).
+        DCHECK_EQ(0, scope->ContextChainLength(variable->scope()));
+        builder()->LoadAccumulatorWithRegister(receiver).StoreContextSlot(
+                execution_context()->reg(), variable->index(), 0);
+    }
+
+    // Copy parameters into context if necessary.
+    int num_parameters = scope->num_parameters();
+    for (int i = 0; i < num_parameters; i++) {
+        Variable* variable = scope->parameter(i);
+        if (!variable->IsContextSlot()) continue;
+
+        Register parameter(builder()->Parameter(i));
+        // Context variable (at bottom of the context chain).
+        DCHECK_EQ(0, scope->ContextChainLength(variable->scope()));
+        builder()->LoadAccumulatorWithRegister(parameter).StoreContextSlot(
+                execution_context()->reg(), variable->index(), 0);
+    }
 }
 
 void BytecodeGenerator::BuildNewLocalBlockContext(Scope* scope) {
-  ValueResultScope value_execution_result(this);
-  DCHECK(scope->is_block_scope());
+    ValueResultScope value_execution_result(this);
+    DCHECK(scope->is_block_scope());
 
-  builder()->CreateBlockContext(scope);
+    builder()->CreateBlockContext(scope);
 }
 
 void BytecodeGenerator::BuildNewLocalWithContext(Scope* scope) {
-  ValueResultScope value_execution_result(this);
+    ValueResultScope value_execution_result(this);
 
-  Register extension_object = register_allocator()->NewRegister();
+    Register extension_object = register_allocator()->NewRegister();
 
-  builder()->ToObject(extension_object);
-  builder()->CreateWithContext(extension_object, scope);
+    builder()->ToObject(extension_object);
+    builder()->CreateWithContext(extension_object, scope);
 
-  register_allocator()->ReleaseRegister(extension_object);
+    register_allocator()->ReleaseRegister(extension_object);
 }
 
 void BytecodeGenerator::BuildNewLocalCatchContext(Scope* scope) {
-  ValueResultScope value_execution_result(this);
-  DCHECK(scope->catch_variable()->IsContextSlot());
+    ValueResultScope value_execution_result(this);
+    DCHECK(scope->catch_variable()->IsContextSlot());
 
-  Register exception = register_allocator()->NewRegister();
-  builder()->StoreAccumulatorInRegister(exception);
-  builder()->CreateCatchContext(exception, scope);
-  register_allocator()->ReleaseRegister(exception);
+    Register exception = register_allocator()->NewRegister();
+    builder()->StoreAccumulatorInRegister(exception);
+    builder()->CreateCatchContext(exception, scope);
+    register_allocator()->ReleaseRegister(exception);
 }
 
 void BytecodeGenerator::VisitLiteralAccessor(LiteralProperty* property,
                                              Register value_out) {
-  if (property == nullptr) {
-    builder()->LoadNull().StoreAccumulatorInRegister(value_out);
-  } else {
-    VisitForRegisterValue(property->value(), value_out);
-  }
+    if (property == nullptr) {
+        builder()->LoadNull().StoreAccumulatorInRegister(value_out);
+    } else {
+        VisitForRegisterValue(property->value(), value_out);
+    }
 }
 
 void BytecodeGenerator::VisitArgumentsObject(Variable* variable) {
-  if (variable == nullptr) return;
+    if (variable == nullptr) return;
 
-  DCHECK(variable->IsContextSlot() || variable->IsStackAllocated());
+    DCHECK(variable->IsContextSlot() || variable->IsStackAllocated());
 
-  // Allocate and initialize a new arguments object and assign to the
-  // {arguments} variable.
-  builder()->CreateArguments(closure_scope()->GetArgumentsType());
-  BuildVariableAssignment(variable, Token::ASSIGN, HoleCheckMode::kElided);
+    // Allocate and initialize a new arguments object and assign to the
+    // {arguments} variable.
+    builder()->CreateArguments(closure_scope()->GetArgumentsType());
+    BuildVariableAssignment(variable, Token::ASSIGN, HoleCheckMode::kElided);
 }
 
 void BytecodeGenerator::VisitRestArgumentsArray(Variable* rest) {
-  if (rest == nullptr) return;
+    if (rest == nullptr) return;
 
-  // Allocate and initialize a new rest parameter and assign to the {rest}
-  // variable.
-  builder()->CreateArguments(CreateArgumentsType::kRestParameter);
-  DCHECK(rest->IsContextSlot() || rest->IsStackAllocated());
-  BuildVariableAssignment(rest, Token::ASSIGN, HoleCheckMode::kElided);
+    // Allocate and initialize a new rest parameter and assign to the {rest}
+    // variable.
+    builder()->CreateArguments(CreateArgumentsType::kRestParameter);
+    DCHECK(rest->IsContextSlot() || rest->IsStackAllocated());
+    BuildVariableAssignment(rest, Token::ASSIGN, HoleCheckMode::kElided);
 }
 
 void BytecodeGenerator::VisitThisFunctionVariable(Variable* variable) {
-  if (variable == nullptr) return;
+    if (variable == nullptr) return;
 
-  // Store the closure we were called with in the given variable.
-  builder()->LoadAccumulatorWithRegister(Register::function_closure());
-  BuildVariableAssignment(variable, Token::INIT, HoleCheckMode::kElided);
+    // Store the closure we were called with in the given variable.
+    builder()->LoadAccumulatorWithRegister(Register::function_closure());
+    BuildVariableAssignment(variable, Token::INIT, HoleCheckMode::kElided);
 }
 
 void BytecodeGenerator::VisitNewTargetVariable(Variable* variable) {
-  if (variable == nullptr) return;
-
-  // The generator resume trampoline abuses the new.target register
-  // to pass in the generator object.  In ordinary calls, new.target is always
-  // undefined because generator functions are non-constructible, so don't
-  // assign anything to the new.target variable.
-  if (IsResumableFunction(info()->literal()->kind())) return;
-
-  if (variable->location() == VariableLocation::LOCAL) {
-    // The new.target register was already assigned by entry trampoline.
-    DCHECK_EQ(incoming_new_target_or_generator_.index(),
-              GetRegisterForLocalVariable(variable).index());
-    return;
-  }
+    if (variable == nullptr) return;
+
+    // The generator resume trampoline abuses the new.target register
+    // to pass in the generator object.  In ordinary calls, new.target is always
+    // undefined because generator functions are non-constructible, so don't
+    // assign anything to the new.target variable.
+    if (IsResumableFunction(info()->literal()->kind())) return;
+
+    if (variable->location() == VariableLocation::LOCAL) {
+        // The new.target register was already assigned by entry trampoline.
+        DCHECK_EQ(incoming_new_target_or_generator_.index(),
+                  GetRegisterForLocalVariable(variable).index());
+        return;
+    }
 
-  // Store the new target we were called with in the given variable.
-  builder()->LoadAccumulatorWithRegister(incoming_new_target_or_generator_);
-  BuildVariableAssignment(variable, Token::INIT, HoleCheckMode::kElided);
+    // Store the new target we were called with in the given variable.
+    builder()->LoadAccumulatorWithRegister(incoming_new_target_or_generator_);
+    BuildVariableAssignment(variable, Token::INIT, HoleCheckMode::kElided);
 }
 
 void BytecodeGenerator::BuildGeneratorObjectVariableInitialization() {
-  DCHECK(IsResumableFunction(info()->literal()->kind()));
-
-  Variable* generator_object_var = closure_scope()->generator_object_var();
-  RegisterAllocationScope register_scope(this);
-  RegisterList args = register_allocator()->NewRegisterList(2);
-  Runtime::FunctionId function_id =
-      ((IsAsyncFunction(info()->literal()->kind()) &&
-        !IsAsyncGeneratorFunction(info()->literal()->kind())) ||
-       IsAsyncModule(info()->literal()->kind()))
-          ? Runtime::kInlineAsyncFunctionEnter
-          : Runtime::kInlineCreateJSGeneratorObject;
-  builder()
-      ->MoveRegister(Register::function_closure(), args[0])
-      .MoveRegister(builder()->Receiver(), args[1])
-      .CallRuntime(function_id, args)
-      .StoreAccumulatorInRegister(generator_object());
-
-  if (generator_object_var->location() == VariableLocation::LOCAL) {
-    // The generator object register is already set to the variable's local
-    // register.
-    DCHECK_EQ(generator_object().index(),
-              GetRegisterForLocalVariable(generator_object_var).index());
-  } else {
-    BuildVariableAssignment(generator_object_var, Token::INIT,
-                            HoleCheckMode::kElided);
-  }
+    DCHECK(IsResumableFunction(info()->literal()->kind()));
+
+    Variable* generator_object_var = closure_scope()->generator_object_var();
+    RegisterAllocationScope register_scope(this);
+    RegisterList args = register_allocator()->NewRegisterList(2);
+    Runtime::FunctionId function_id =
+            ((IsAsyncFunction(info()->literal()->kind()) &&
+              !IsAsyncGeneratorFunction(info()->literal()->kind())) ||
+             IsAsyncModule(info()->literal()->kind()))
+            ? Runtime::kInlineAsyncFunctionEnter
+            : Runtime::kInlineCreateJSGeneratorObject;
+    builder()
+            ->MoveRegister(Register::function_closure(), args[0])
+            .MoveRegister(builder()->Receiver(), args[1])
+            .CallRuntime(function_id, args)
+            .StoreAccumulatorInRegister(generator_object());
+
+    if (generator_object_var->location() == VariableLocation::LOCAL) {
+        // The generator object register is already set to the variable's local
+        // register.
+        DCHECK_EQ(generator_object().index(),
+                  GetRegisterForLocalVariable(generator_object_var).index());
+    } else {
+        BuildVariableAssignment(generator_object_var, Token::INIT,
+                                HoleCheckMode::kElided);
+    }
 }
 
 void BytecodeGenerator::BuildPushUndefinedIntoRegisterList(
-    RegisterList* reg_list) {
-  Register reg = register_allocator()->GrowRegisterList(reg_list);
-  builder()->LoadUndefined().StoreAccumulatorInRegister(reg);
+        RegisterList* reg_list) {
+    Register reg = register_allocator()->GrowRegisterList(reg_list);
+    builder()->LoadUndefined().StoreAccumulatorInRegister(reg);
 }
 
 void BytecodeGenerator::BuildLoadPropertyKey(LiteralProperty* property,
                                              Register out_reg) {
-  if (property->key()->IsStringLiteral()) {
-    builder()
-        ->LoadLiteral(property->key()->AsLiteral()->AsRawString())
-        .StoreAccumulatorInRegister(out_reg);
-  } else {
-    VisitForAccumulatorValue(property->key());
-    builder()->ToName(out_reg);
-  }
+    if (property->key()->IsStringLiteral()) {
+        builder()
+                ->LoadLiteral(property->key()->AsLiteral()->AsRawString())
+                .StoreAccumulatorInRegister(out_reg);
+    } else {
+        VisitForAccumulatorValue(property->key());
+        builder()->ToName(out_reg);
+    }
 }
 
 int BytecodeGenerator::AllocateBlockCoverageSlotIfEnabled(
-    AstNode* node, SourceRangeKind kind) {
-  return (block_coverage_builder_ == nullptr)
-             ? BlockCoverageBuilder::kNoCoverageArraySlot
-             : block_coverage_builder_->AllocateBlockCoverageSlot(node, kind);
+        AstNode* node, SourceRangeKind kind) {
+    return (block_coverage_builder_ == nullptr)
+           ? BlockCoverageBuilder::kNoCoverageArraySlot
+           : block_coverage_builder_->AllocateBlockCoverageSlot(node, kind);
 }
 
 int BytecodeGenerator::AllocateNaryBlockCoverageSlotIfEnabled(
-    NaryOperation* node, size_t index) {
-  return (block_coverage_builder_ == nullptr)
-             ? BlockCoverageBuilder::kNoCoverageArraySlot
-             : block_coverage_builder_->AllocateNaryBlockCoverageSlot(node,
-                                                                      index);
+        NaryOperation* node, size_t index) {
+    return (block_coverage_builder_ == nullptr)
+           ? BlockCoverageBuilder::kNoCoverageArraySlot
+           : block_coverage_builder_->AllocateNaryBlockCoverageSlot(node,
+                                                                    index);
 }
 
 void BytecodeGenerator::BuildIncrementBlockCoverageCounterIfEnabled(
-    AstNode* node, SourceRangeKind kind) {
-  if (block_coverage_builder_ == nullptr) return;
-  block_coverage_builder_->IncrementBlockCounter(node, kind);
+        AstNode* node, SourceRangeKind kind) {
+    if (block_coverage_builder_ == nullptr) return;
+    block_coverage_builder_->IncrementBlockCounter(node, kind);
 }
 
 void BytecodeGenerator::BuildIncrementBlockCoverageCounterIfEnabled(
-    int coverage_array_slot) {
-  if (block_coverage_builder_ != nullptr) {
-    block_coverage_builder_->IncrementBlockCounter(coverage_array_slot);
-  }
+        int coverage_array_slot) {
+    if (block_coverage_builder_ != nullptr) {
+        block_coverage_builder_->IncrementBlockCounter(coverage_array_slot);
+    }
 }
 
 // Visits the expression |expr| and places the result in the accumulator.
 BytecodeGenerator::TypeHint BytecodeGenerator::VisitForAccumulatorValue(
-    Expression* expr) {
-  ValueResultScope accumulator_scope(this);
-  Visit(expr);
-  return accumulator_scope.type_hint();
+        Expression* expr) {
+    ValueResultScope accumulator_scope(this);
+    Visit(expr);
+    return accumulator_scope.type_hint();
 }
 
 void BytecodeGenerator::VisitForAccumulatorValueOrTheHole(Expression* expr) {
-  if (expr == nullptr) {
-    builder()->LoadTheHole();
-  } else {
-    VisitForAccumulatorValue(expr);
-  }
+    if (expr == nullptr) {
+        builder()->LoadTheHole();
+    } else {
+        VisitForAccumulatorValue(expr);
+    }
 }
 
 // Visits the expression |expr| and discards the result.
 void BytecodeGenerator::VisitForEffect(Expression* expr) {
-  EffectResultScope effect_scope(this);
-  Visit(expr);
+    EffectResultScope effect_scope(this);
+    Visit(expr);
 }
 
 // Visits the expression |expr| and returns the register containing
 // the expression result.
 Register BytecodeGenerator::VisitForRegisterValue(Expression* expr) {
-  VisitForAccumulatorValue(expr);
-  Register result = register_allocator()->NewRegister();
-  builder()->StoreAccumulatorInRegister(result);
-  return result;
+    VisitForAccumulatorValue(expr);
+    Register result = register_allocator()->NewRegister();
+    builder()->StoreAccumulatorInRegister(result);
+    return result;
 }
 
 // Visits the expression |expr| and stores the expression result in
 // |destination|.
 void BytecodeGenerator::VisitForRegisterValue(Expression* expr,
                                               Register destination) {
-  ValueResultScope register_scope(this);
-  Visit(expr);
-  builder()->StoreAccumulatorInRegister(destination);
+    ValueResultScope register_scope(this);
+    Visit(expr);
+    builder()->StoreAccumulatorInRegister(destination);
 }
 
 // Visits the expression |expr| and pushes the result into a new register
 // added to the end of |reg_list|.
 void BytecodeGenerator::VisitAndPushIntoRegisterList(Expression* expr,
                                                      RegisterList* reg_list) {
-  {
-    ValueResultScope register_scope(this);
-    Visit(expr);
-  }
-  // Grow the register list after visiting the expression to avoid reserving
-  // the register across the expression evaluation, which could cause memory
-  // leaks for deep expressions due to dead objects being kept alive by pointers
-  // in registers.
-  Register destination = register_allocator()->GrowRegisterList(reg_list);
-  builder()->StoreAccumulatorInRegister(destination);
+    {
+        ValueResultScope register_scope(this);
+        Visit(expr);
+    }
+    // Grow the register list after visiting the expression to avoid reserving
+    // the register across the expression evaluation, which could cause memory
+    // leaks for deep expressions due to dead objects being kept alive by pointers
+    // in registers.
+    Register destination = register_allocator()->GrowRegisterList(reg_list);
+    builder()->StoreAccumulatorInRegister(destination);
 }
 
 void BytecodeGenerator::BuildTest(ToBooleanMode mode,
                                   BytecodeLabels* then_labels,
                                   BytecodeLabels* else_labels,
                                   TestFallthrough fallthrough) {
-  switch (fallthrough) {
-    case TestFallthrough::kThen:
-      builder()->JumpIfFalse(mode, else_labels->New());
-      break;
-    case TestFallthrough::kElse:
-      builder()->JumpIfTrue(mode, then_labels->New());
-      break;
-    case TestFallthrough::kNone:
-      builder()->JumpIfTrue(mode, then_labels->New());
-      builder()->Jump(else_labels->New());
-      break;
-  }
+    switch (fallthrough) {
+        case TestFallthrough::kThen:
+            builder()->JumpIfFalse(mode, else_labels->New());
+            break;
+        case TestFallthrough::kElse:
+            builder()->JumpIfTrue(mode, then_labels->New());
+            break;
+        case TestFallthrough::kNone:
+            builder()->JumpIfTrue(mode, then_labels->New());
+            builder()->Jump(else_labels->New());
+            break;
+    }
 }
 
 // Visits the expression |expr| for testing its boolean value and jumping to the
@@ -7209,26 +7737,26 @@ void BytecodeGenerator::VisitForTest(Expression* expr,
                                      BytecodeLabels* then_labels,
                                      BytecodeLabels* else_labels,
                                      TestFallthrough fallthrough) {
-  bool result_consumed;
-  TypeHint type_hint;
-  {
-    // To make sure that all temporary registers are returned before generating
-    // jumps below, we ensure that the result scope is deleted before doing so.
-    // Dead registers might be materialized otherwise.
-    TestResultScope test_result(this, then_labels, else_labels, fallthrough);
-    Visit(expr);
-    result_consumed = test_result.result_consumed_by_test();
-    type_hint = test_result.type_hint();
-    // Labels and fallthrough might have been mutated, so update based on
-    // TestResultScope.
-    then_labels = test_result.then_labels();
-    else_labels = test_result.else_labels();
-    fallthrough = test_result.fallthrough();
-  }
-  if (!result_consumed) {
-    BuildTest(ToBooleanModeFromTypeHint(type_hint), then_labels, else_labels,
-              fallthrough);
-  }
+    bool result_consumed;
+    TypeHint type_hint;
+    {
+        // To make sure that all temporary registers are returned before generating
+        // jumps below, we ensure that the result scope is deleted before doing so.
+        // Dead registers might be materialized otherwise.
+        TestResultScope test_result(this, then_labels, else_labels, fallthrough);
+        Visit(expr);
+        result_consumed = test_result.result_consumed_by_test();
+        type_hint = test_result.type_hint();
+        // Labels and fallthrough might have been mutated, so update based on
+        // TestResultScope.
+        then_labels = test_result.then_labels();
+        else_labels = test_result.else_labels();
+        fallthrough = test_result.fallthrough();
+    }
+    if (!result_consumed) {
+        BuildTest(ToBooleanModeFromTypeHint(type_hint), then_labels, else_labels,
+                  fallthrough);
+    }
 }
 
 // Visits the expression |expr| for testing its nullish value and jumping to the
@@ -7237,175 +7765,175 @@ void BytecodeGenerator::VisitForNullishTest(Expression* expr,
                                             BytecodeLabels* then_labels,
                                             BytecodeLabels* test_next_labels,
                                             BytecodeLabels* else_labels) {
-  // Nullish short circuits on undefined or null, otherwise we fall back to
-  // BuildTest with no fallthrough.
-  // TODO(joshualitt): We should do this in a TestResultScope.
-  TypeHint type_hint = VisitForAccumulatorValue(expr);
-  ToBooleanMode mode = ToBooleanModeFromTypeHint(type_hint);
-
-  // Skip the nullish shortcircuit if we already have a boolean.
-  if (mode != ToBooleanMode::kAlreadyBoolean) {
-    builder()->JumpIfUndefinedOrNull(test_next_labels->New());
-  }
-  BuildTest(mode, then_labels, else_labels, TestFallthrough::kNone);
+    // Nullish short circuits on undefined or null, otherwise we fall back to
+    // BuildTest with no fallthrough.
+    // TODO(joshualitt): We should do this in a TestResultScope.
+    TypeHint type_hint = VisitForAccumulatorValue(expr);
+    ToBooleanMode mode = ToBooleanModeFromTypeHint(type_hint);
+
+    // Skip the nullish shortcircuit if we already have a boolean.
+    if (mode != ToBooleanMode::kAlreadyBoolean) {
+        builder()->JumpIfUndefinedOrNull(test_next_labels->New());
+    }
+    BuildTest(mode, then_labels, else_labels, TestFallthrough::kNone);
 }
 
 void BytecodeGenerator::VisitInSameTestExecutionScope(Expression* expr) {
-  DCHECK(execution_result()->IsTest());
-  {
-    RegisterAllocationScope reg_scope(this);
-    Visit(expr);
-  }
-  if (!execution_result()->AsTest()->result_consumed_by_test()) {
-    TestResultScope* result_scope = execution_result()->AsTest();
-    BuildTest(ToBooleanModeFromTypeHint(result_scope->type_hint()),
-              result_scope->then_labels(), result_scope->else_labels(),
-              result_scope->fallthrough());
-    result_scope->SetResultConsumedByTest();
-  }
+    DCHECK(execution_result()->IsTest());
+    {
+        RegisterAllocationScope reg_scope(this);
+        Visit(expr);
+    }
+    if (!execution_result()->AsTest()->result_consumed_by_test()) {
+        TestResultScope* result_scope = execution_result()->AsTest();
+        BuildTest(ToBooleanModeFromTypeHint(result_scope->type_hint()),
+                  result_scope->then_labels(), result_scope->else_labels(),
+                  result_scope->fallthrough());
+        result_scope->SetResultConsumedByTest();
+    }
 }
 
 void BytecodeGenerator::VisitInScope(Statement* stmt, Scope* scope) {
-  DCHECK(scope->declarations()->is_empty());
-  CurrentScope current_scope(this, scope);
-  ContextScope context_scope(this, scope);
-  Visit(stmt);
+    DCHECK(scope->declarations()->is_empty());
+    CurrentScope current_scope(this, scope);
+    ContextScope context_scope(this, scope);
+    Visit(stmt);
 }
 
 Register BytecodeGenerator::GetRegisterForLocalVariable(Variable* variable) {
-  DCHECK_EQ(VariableLocation::LOCAL, variable->location());
-  return builder()->Local(variable->index());
+    DCHECK_EQ(VariableLocation::LOCAL, variable->location());
+    return builder()->Local(variable->index());
 }
 
 FunctionKind BytecodeGenerator::function_kind() const {
-  return info()->literal()->kind();
+    return info()->literal()->kind();
 }
 
 LanguageMode BytecodeGenerator::language_mode() const {
-  return current_scope()->language_mode();
+    return current_scope()->language_mode();
 }
 
 Register BytecodeGenerator::generator_object() const {
-  DCHECK(IsResumableFunction(info()->literal()->kind()));
-  return incoming_new_target_or_generator_;
+    DCHECK(IsResumableFunction(info()->literal()->kind()));
+    return incoming_new_target_or_generator_;
 }
 
 FeedbackVectorSpec* BytecodeGenerator::feedback_spec() {
-  return info()->feedback_vector_spec();
+    return info()->feedback_vector_spec();
 }
 
 int BytecodeGenerator::feedback_index(FeedbackSlot slot) const {
-  DCHECK(!slot.IsInvalid());
-  return FeedbackVector::GetIndex(slot);
+    DCHECK(!slot.IsInvalid());
+    return FeedbackVector::GetIndex(slot);
 }
 
 FeedbackSlot BytecodeGenerator::GetCachedLoadGlobalICSlot(
-    TypeofMode typeof_mode, Variable* variable) {
-  FeedbackSlotCache::SlotKind slot_kind =
-      typeof_mode == TypeofMode::kInside
-          ? FeedbackSlotCache::SlotKind::kLoadGlobalInsideTypeof
-          : FeedbackSlotCache::SlotKind::kLoadGlobalNotInsideTypeof;
-  FeedbackSlot slot(feedback_slot_cache()->Get(slot_kind, variable));
-  if (!slot.IsInvalid()) {
+        TypeofMode typeof_mode, Variable* variable) {
+    FeedbackSlotCache::SlotKind slot_kind =
+            typeof_mode == TypeofMode::kInside
+            ? FeedbackSlotCache::SlotKind::kLoadGlobalInsideTypeof
+            : FeedbackSlotCache::SlotKind::kLoadGlobalNotInsideTypeof;
+    FeedbackSlot slot(feedback_slot_cache()->Get(slot_kind, variable));
+    if (!slot.IsInvalid()) {
+        return slot;
+    }
+    slot = feedback_spec()->AddLoadGlobalICSlot(typeof_mode);
+    feedback_slot_cache()->Put(slot_kind, variable, feedback_index(slot));
     return slot;
-  }
-  slot = feedback_spec()->AddLoadGlobalICSlot(typeof_mode);
-  feedback_slot_cache()->Put(slot_kind, variable, feedback_index(slot));
-  return slot;
 }
 
 FeedbackSlot BytecodeGenerator::GetCachedStoreGlobalICSlot(
-    LanguageMode language_mode, Variable* variable) {
-  FeedbackSlotCache::SlotKind slot_kind =
-      is_strict(language_mode)
-          ? FeedbackSlotCache::SlotKind::kStoreGlobalStrict
-          : FeedbackSlotCache::SlotKind::kStoreGlobalSloppy;
-  FeedbackSlot slot(feedback_slot_cache()->Get(slot_kind, variable));
-  if (!slot.IsInvalid()) {
+        LanguageMode language_mode, Variable* variable) {
+    FeedbackSlotCache::SlotKind slot_kind =
+            is_strict(language_mode)
+            ? FeedbackSlotCache::SlotKind::kStoreGlobalStrict
+            : FeedbackSlotCache::SlotKind::kStoreGlobalSloppy;
+    FeedbackSlot slot(feedback_slot_cache()->Get(slot_kind, variable));
+    if (!slot.IsInvalid()) {
+        return slot;
+    }
+    slot = feedback_spec()->AddStoreGlobalICSlot(language_mode);
+    feedback_slot_cache()->Put(slot_kind, variable, feedback_index(slot));
     return slot;
-  }
-  slot = feedback_spec()->AddStoreGlobalICSlot(language_mode);
-  feedback_slot_cache()->Put(slot_kind, variable, feedback_index(slot));
-  return slot;
 }
 
 FeedbackSlot BytecodeGenerator::GetCachedLoadICSlot(const Expression* expr,
                                                     const AstRawString* name) {
-  DCHECK(!expr->IsSuperPropertyReference());
-  if (!v8_flags.ignition_share_named_property_feedback) {
-    return feedback_spec()->AddLoadICSlot();
-  }
-  FeedbackSlotCache::SlotKind slot_kind =
-      FeedbackSlotCache::SlotKind::kLoadProperty;
-  if (!expr->IsVariableProxy()) {
-    return feedback_spec()->AddLoadICSlot();
-  }
-  const VariableProxy* proxy = expr->AsVariableProxy();
-  FeedbackSlot slot(
-      feedback_slot_cache()->Get(slot_kind, proxy->var()->index(), name));
-  if (!slot.IsInvalid()) {
+    DCHECK(!expr->IsSuperPropertyReference());
+    if (!v8_flags.ignition_share_named_property_feedback) {
+        return feedback_spec()->AddLoadICSlot();
+    }
+    FeedbackSlotCache::SlotKind slot_kind =
+            FeedbackSlotCache::SlotKind::kLoadProperty;
+    if (!expr->IsVariableProxy()) {
+        return feedback_spec()->AddLoadICSlot();
+    }
+    const VariableProxy* proxy = expr->AsVariableProxy();
+    FeedbackSlot slot(
+            feedback_slot_cache()->Get(slot_kind, proxy->var()->index(), name));
+    if (!slot.IsInvalid()) {
+        return slot;
+    }
+    slot = feedback_spec()->AddLoadICSlot();
+    feedback_slot_cache()->Put(slot_kind, proxy->var()->index(), name,
+                               feedback_index(slot));
     return slot;
-  }
-  slot = feedback_spec()->AddLoadICSlot();
-  feedback_slot_cache()->Put(slot_kind, proxy->var()->index(), name,
-                             feedback_index(slot));
-  return slot;
 }
 
 FeedbackSlot BytecodeGenerator::GetCachedLoadSuperICSlot(
-    const AstRawString* name) {
-  if (!v8_flags.ignition_share_named_property_feedback) {
-    return feedback_spec()->AddLoadICSlot();
-  }
-  FeedbackSlotCache::SlotKind slot_kind =
-      FeedbackSlotCache::SlotKind::kLoadSuperProperty;
+        const AstRawString* name) {
+    if (!v8_flags.ignition_share_named_property_feedback) {
+        return feedback_spec()->AddLoadICSlot();
+    }
+    FeedbackSlotCache::SlotKind slot_kind =
+            FeedbackSlotCache::SlotKind::kLoadSuperProperty;
 
-  FeedbackSlot slot(feedback_slot_cache()->Get(slot_kind, name));
-  if (!slot.IsInvalid()) {
+    FeedbackSlot slot(feedback_slot_cache()->Get(slot_kind, name));
+    if (!slot.IsInvalid()) {
+        return slot;
+    }
+    slot = feedback_spec()->AddLoadICSlot();
+    feedback_slot_cache()->Put(slot_kind, name, feedback_index(slot));
     return slot;
-  }
-  slot = feedback_spec()->AddLoadICSlot();
-  feedback_slot_cache()->Put(slot_kind, name, feedback_index(slot));
-  return slot;
 }
 
 FeedbackSlot BytecodeGenerator::GetCachedStoreICSlot(const Expression* expr,
                                                      const AstRawString* name) {
-  if (!v8_flags.ignition_share_named_property_feedback) {
-    return feedback_spec()->AddStoreICSlot(language_mode());
-  }
-  FeedbackSlotCache::SlotKind slot_kind =
-      is_strict(language_mode()) ? FeedbackSlotCache::SlotKind::kSetNamedStrict
-                                 : FeedbackSlotCache::SlotKind::kSetNamedSloppy;
-  if (!expr->IsVariableProxy()) {
-    return feedback_spec()->AddStoreICSlot(language_mode());
-  }
-  const VariableProxy* proxy = expr->AsVariableProxy();
-  FeedbackSlot slot(
-      feedback_slot_cache()->Get(slot_kind, proxy->var()->index(), name));
-  if (!slot.IsInvalid()) {
+    if (!v8_flags.ignition_share_named_property_feedback) {
+        return feedback_spec()->AddStoreICSlot(language_mode());
+    }
+    FeedbackSlotCache::SlotKind slot_kind =
+            is_strict(language_mode()) ? FeedbackSlotCache::SlotKind::kSetNamedStrict
+                                       : FeedbackSlotCache::SlotKind::kSetNamedSloppy;
+    if (!expr->IsVariableProxy()) {
+        return feedback_spec()->AddStoreICSlot(language_mode());
+    }
+    const VariableProxy* proxy = expr->AsVariableProxy();
+    FeedbackSlot slot(
+            feedback_slot_cache()->Get(slot_kind, proxy->var()->index(), name));
+    if (!slot.IsInvalid()) {
+        return slot;
+    }
+    slot = feedback_spec()->AddStoreICSlot(language_mode());
+    feedback_slot_cache()->Put(slot_kind, proxy->var()->index(), name,
+                               feedback_index(slot));
     return slot;
-  }
-  slot = feedback_spec()->AddStoreICSlot(language_mode());
-  feedback_slot_cache()->Put(slot_kind, proxy->var()->index(), name,
-                             feedback_index(slot));
-  return slot;
 }
 
 int BytecodeGenerator::GetCachedCreateClosureSlot(FunctionLiteral* literal) {
-  FeedbackSlotCache::SlotKind slot_kind =
-      FeedbackSlotCache::SlotKind::kClosureFeedbackCell;
-  int index = feedback_slot_cache()->Get(slot_kind, literal);
-  if (index != -1) {
+    FeedbackSlotCache::SlotKind slot_kind =
+            FeedbackSlotCache::SlotKind::kClosureFeedbackCell;
+    int index = feedback_slot_cache()->Get(slot_kind, literal);
+    if (index != -1) {
+        return index;
+    }
+    index = feedback_spec()->AddCreateClosureSlot();
+    feedback_slot_cache()->Put(slot_kind, literal, index);
     return index;
-  }
-  index = feedback_spec()->AddCreateClosureSlot();
-  feedback_slot_cache()->Put(slot_kind, literal, index);
-  return index;
 }
 
 FeedbackSlot BytecodeGenerator::GetDummyCompareICSlot() {
-  return dummy_feedback_slot_.Get();
+    return dummy_feedback_slot_.Get();
 }
 
 }  // namespace interpreter
diff --git a/src/interpreter/bytecode-generator.h b/src/interpreter/bytecode-generator.h
index 63174d44fcb..8857fb48400 100644
--- a/src/interpreter/bytecode-generator.h
+++ b/src/interpreter/bytecode-generator.h
@@ -259,12 +259,31 @@ class BytecodeGenerator final : public AstVisitor<BytecodeGenerator> {
 
   void BuildVariableLoad(Variable* variable, HoleCheckMode hole_check_mode,
                          TypeofMode typeof_mode = TypeofMode::kNotInside);
+
+  // xqg start
+  void BuildVariableLoad(VariableProxy* proxy, HoleCheckMode hole_check_mode,
+                         TypeofMode typeof_mode = TypeofMode::kNotInside);
+  // xqg end
   void BuildVariableLoadForAccumulatorValue(
       Variable* variable, HoleCheckMode hole_check_mode,
       TypeofMode typeof_mode = TypeofMode::kNotInside);
+
+  // xqg start
+  void BuildVariableLoadForAccumulatorValue(
+                VariableProxy* proxy, HoleCheckMode hole_check_mode,
+                TypeofMode typeof_mode = TypeofMode::kNotInside);
+  // xqg end
+
   void BuildVariableAssignment(
       Variable* variable, Token::Value op, HoleCheckMode hole_check_mode,
       LookupHoistingMode lookup_hoisting_mode = LookupHoistingMode::kNormal);
+
+  // xqg start
+  void BuildVariableAssignment(
+          VariableProxy* proxy, Token::Value op, HoleCheckMode hole_check_mode,
+          LookupHoistingMode lookup_hoisting_mode = LookupHoistingMode::kNormal);
+  // xqg end
+
   void BuildLiteralCompareNil(Token::Value compare_op,
                               BytecodeArrayBuilder::NilValue nil);
   void BuildLiteralStrictCompareBoolean(Literal* literal);
diff --git a/src/interpreter/bytecodes.h b/src/interpreter/bytecodes.h
index 3919daeb203..4eb3d92b34a 100644
--- a/src/interpreter/bytecodes.h
+++ b/src/interpreter/bytecodes.h
@@ -379,6 +379,7 @@ namespace interpreter {
   V(JumpIfFalse, ImplicitRegisterUse::kReadAccumulator, OperandType::kUImm)    \
   V(JumpIfNull, ImplicitRegisterUse::kReadAccumulator, OperandType::kUImm)     \
   V(JumpIfNotNull, ImplicitRegisterUse::kReadAccumulator, OperandType::kUImm)  \
+  V(JumpIfNotSmi, ImplicitRegisterUse::kReadAccumulator, OperandType::kUImm)   \
   V(JumpIfUndefined, ImplicitRegisterUse::kReadAccumulator,                    \
     OperandType::kUImm)                                                        \
   V(JumpIfNotUndefined, ImplicitRegisterUse::kReadAccumulator,                 \
diff --git a/src/interpreter/interpreter-generator.cc b/src/interpreter/interpreter-generator.cc
index 82f053300c3..eb6dd7fd9a7 100644
--- a/src/interpreter/interpreter-generator.cc
+++ b/src/interpreter/interpreter-generator.cc
@@ -2107,6 +2107,27 @@ IGNITION_HANDLER(JumpIfUndefinedOrNullConstant, InterpreterAssembler) {
   Jump(relative_jump);
 }
 
+// xqg start
+// JumpIfNotSmi <imm>
+//
+// Jump by the number of bytes represented by an immediate operand if the object
+// referenced by the accumulator is not a Smi.
+IGNITION_HANDLER(JumpIfNotSmi, InterpreterAssembler) {
+    TNode<Object> accumulator = GetAccumulator();
+
+    Label if_notobject(this), if_notsmi(this);
+    Branch(TaggedIsSmi(accumulator), &if_notobject, &if_notsmi);
+
+    BIND(&if_notsmi);
+    TNode<IntPtrT> relative_jump = Signed(BytecodeOperandUImmWord(0));
+    Jump(relative_jump);
+
+    BIND(&if_notobject);
+    Dispatch();
+}
+// xqg end
+
+
 // JumpIfJSReceiver <imm>
 //
 // Jump by the number of bytes represented by an immediate operand if the object
diff --git a/src/objects/hash-table-inl.h b/src/objects/hash-table-inl.h
index 7ba51aa1301..46a366829f7 100644
--- a/src/objects/hash-table-inl.h
+++ b/src/objects/hash-table-inl.h
@@ -45,6 +45,13 @@ EphemeronHashTable::EphemeronHashTable(Address ptr)
   SLOW_DCHECK(IsEphemeronHashTable());
 }
 
+// xqg start
+ObjectPointerHashTable::ObjectPointerHashTable(Address ptr)
+    : ObjectHashTableBase<ObjectPointerHashTable, ObjectPointerHashTableShape>(ptr) {
+    SLOW_DCHECK(IsObjectPointerHashTable());
+}
+// xqg end
+
 ObjectHashSet::ObjectHashSet(Address ptr)
     : HashTable<ObjectHashSet, ObjectHashSetShape>(ptr) {
   SLOW_DCHECK(IsObjectHashSet());
@@ -58,6 +65,7 @@ NameToIndexHashTable::NameToIndexHashTable(Address ptr)
 CAST_ACCESSOR(ObjectHashTable)
 CAST_ACCESSOR(RegisteredSymbolTable)
 CAST_ACCESSOR(EphemeronHashTable)
+CAST_ACCESSOR(ObjectPointerHashTable) // xqg
 CAST_ACCESSOR(ObjectHashSet)
 CAST_ACCESSOR(NameToIndexHashTable)
 
@@ -282,6 +290,14 @@ bool ObjectHashTableShape::IsMatch(Handle<Object> key, Object other) {
   return key->SameValue(other);
 }
 
+// xqg start
+bool ObjectPointerHashTableShape::IsMatch(Handle<Object> key, Object other) {
+    if (key.is_null())
+        return false;
+    return (*key).ptr() == other.ptr();
+}
+// xqg end
+
 bool RegisteredSymbolTableShape::IsMatch(Handle<String> key, Object value) {
   DCHECK(value.IsString());
   return key->Equals(String::cast(value));
diff --git a/src/objects/hash-table.h b/src/objects/hash-table.h
index a77d7e8aa4b..7b6eacef572 100644
--- a/src/objects/hash-table.h
+++ b/src/objects/hash-table.h
@@ -221,6 +221,7 @@ class EXPORT_TEMPLATE_DECLARE(V8_EXPORT_PRIVATE) HashTable
 
  protected:
   friend class ObjectHashTable;
+  friend class ObjectPointerHashTable; // xqg
 
   template <typename IsolateT>
   V8_WARN_UNUSED_RESULT static Handle<Derived> NewInternal(
@@ -335,7 +336,7 @@ class EXPORT_TEMPLATE_DECLARE(V8_EXPORT_PRIVATE) ObjectHashTableBase
   Object Lookup(Handle<Object> key);
   Object Lookup(Handle<Object> key, int32_t hash);
   Object Lookup(PtrComprCageBase cage_base, Handle<Object> key, int32_t hash);
-
+  
   // Returns the value at entry.
   Object ValueAt(InternalIndex entry);
 
@@ -391,6 +392,32 @@ class V8_EXPORT_PRIVATE ObjectHashTable
 
 EXTERN_DECLARE_OBJECT_BASE_HASH_TABLE(EphemeronHashTable, ObjectHashTableShape)
 
+// xqg start
+
+// Same as ObjectHashTableShape, except match is determined
+// by pointer identity.
+class ObjectPointerHashTableShape : public ObjectHashTableShape {
+public:
+    static inline bool IsMatch(Handle<Object> key, Object other);
+};
+
+EXTERN_DECLARE_OBJECT_BASE_HASH_TABLE(ObjectPointerHashTable, ObjectPointerHashTableShape)
+
+class V8_EXPORT_PRIVATE ObjectPointerHashTable
+: public ObjectHashTableBase<ObjectPointerHashTable, ObjectPointerHashTableShape> {
+public:
+DECL_CAST(ObjectPointerHashTable)
+DECL_PRINTER(ObjectPointerHashTable)
+
+protected:
+friend class MarkCompactCollector;
+
+OBJECT_CONSTRUCTORS(
+        ObjectPointerHashTable,
+        ObjectHashTableBase<ObjectPointerHashTable, ObjectPointerHashTableShape>);
+};
+// xqg end
+
 // EphemeronHashTable is similar to ObjectHashTable but gets special treatment
 // by the GC. The GC treats its entries as ephemerons: both key and value are
 // weak references, however if the key is strongly reachable its corresponding
diff --git a/src/objects/js-collection.h b/src/objects/js-collection.h
index 8de079e69cf..7b6c02843e7 100644
--- a/src/objects/js-collection.h
+++ b/src/objects/js-collection.h
@@ -89,12 +89,14 @@ class JSMapIterator
 class JSWeakCollection
     : public TorqueGeneratedJSWeakCollection<JSWeakCollection, JSObject> {
  public:
-  static void Initialize(Handle<JSWeakCollection> collection, Isolate* isolate);
+  // xqg start
+  static void Initialize(Handle<JSWeakCollection> collection, Isolate* isolate, bool is_pointer_map=false);
   V8_EXPORT_PRIVATE static void Set(Handle<JSWeakCollection> collection,
                                     Handle<Object> key, Handle<Object> value,
-                                    int32_t hash);
+                                    int32_t hash, bool is_pointer_map=false);
   static bool Delete(Handle<JSWeakCollection> collection, Handle<Object> key,
-                     int32_t hash);
+                     int32_t hash, bool is_pointer_map=false);
+  // xqg end
   static Handle<JSArray> GetEntries(Handle<JSWeakCollection> holder,
                                     int max_entries);
 
diff --git a/src/objects/js-promise.h b/src/objects/js-promise.h
index ffaaab60265..220262ddb79 100644
--- a/src/objects/js-promise.h
+++ b/src/objects/js-promise.h
@@ -57,13 +57,17 @@ class JSPromise
 
   // ES section #sec-fulfillpromise
   V8_EXPORT_PRIVATE static Handle<Object> Fulfill(Handle<JSPromise> promise,
-                                                  Handle<Object> value);
+                                                  Handle<Object> value, bool is_tainted=false,
+            std::vector<Handle<Object>> tainted_objs=std::vector<Handle<Object>>(),
+    const std::string& from=std::string());
   // ES section #sec-rejectpromise
   static Handle<Object> Reject(Handle<JSPromise> promise, Handle<Object> reason,
                                bool debug_event = true);
   // ES section #sec-promise-resolve-functions
   V8_WARN_UNUSED_RESULT static MaybeHandle<Object> Resolve(
-      Handle<JSPromise> promise, Handle<Object> resolution);
+      Handle<JSPromise> promise, Handle<Object> resolution, bool is_tainted=false,
+            std::vector<Handle<Object>> tainted_objs=std::vector<Handle<Object>>(),
+    const std::string& from=std::string());
 
   // Dispatched behavior.
   DECL_PRINTER(JSPromise)
@@ -84,7 +88,9 @@ class JSPromise
   static Handle<Object> TriggerPromiseReactions(Isolate* isolate,
                                                 Handle<Object> reactions,
                                                 Handle<Object> argument,
-                                                PromiseReaction::Type type);
+                                                PromiseReaction::Type type, bool is_tainted=false,
+                                                std::vector<Handle<Object>> tainted_objs=std::vector<Handle<Object>>(),
+                                                const std::string& from=std::string());
 
   TQ_OBJECT_CONSTRUCTORS(JSPromise)
 };
diff --git a/src/objects/object-list-macros.h b/src/objects/object-list-macros.h
index 368dd540092..5e8f4b0e5d7 100644
--- a/src/objects/object-list-macros.h
+++ b/src/objects/object-list-macros.h
@@ -106,6 +106,7 @@ class ZoneForwardList;
   V(DescriptorArray)                            \
   V(EmbedderDataArray)                          \
   V(EphemeronHashTable)                         \
+  V(ObjectPointerHashTable)                     \
   V(ExternalOneByteString)                      \
   V(ExternalString)                             \
   V(ExternalTwoByteString)                      \
diff --git a/src/objects/objects-inl.h b/src/objects/objects-inl.h
index 025c87dbf31..f4e63b71b05 100644
--- a/src/objects/objects-inl.h
+++ b/src/objects/objects-inl.h
@@ -1116,6 +1116,7 @@ MaybeHandle<Object> Object::GetPropertyOrElement(Handle<Object> receiver,
   return GetProperty(&it);
 }
 
+
 // static
 Object Object::GetSimpleHash(Object object) {
   DisallowGarbageCollection no_gc;
@@ -1153,15 +1154,40 @@ Object Object::GetSimpleHash(Object object) {
     uint32_t hash = ScopeInfo::cast(object).Hash();
     return Smi::FromInt(hash & Smi::kMaxValue);
   }
-  DCHECK(object.IsJSReceiver());
+  // DCHECK(object.IsJSReceiver()); xqg
   return object;
 }
 
+
 Object Object::GetHash() {
   DisallowGarbageCollection no_gc;
   Object hash = GetSimpleHash(*this);
   if (hash.IsSmi()) return hash;
 
+  // xqg start
+  if (!IsJSReceiver()) {
+        // Do NOT use pointer hash here, since GC can change the memory
+        // address of an object.
+        if (this->IsJSFunction()) {
+            uint32_t hash = ComputeSeededHash(JSFunction::cast(*this).shared().SourceSize(), kZeroHashSeed);
+            return Smi::FromInt(hash & Smi::kMaxValue);
+        }
+        else if (this->IsSharedFunctionInfo()) {
+            uint32_t hash = ComputeSeededHash(SharedFunctionInfo::cast(*this).SourceSize(), kZeroHashSeed);
+            return Smi::FromInt(hash & Smi::kMaxValue);
+        }
+        else if (this->IsContext()) {
+            JSGlobalObject global_object = Context::cast(*this).global_object();
+            CHECK(global_object.IsJSGlobalObject());
+            Isolate *isolate = global_object.GetIsolate();
+            return global_object.GetOrCreateHash(isolate);
+        }
+        else {
+            return Smi::FromInt(Smi::kMaxValue);
+        }
+  }
+  // xqg end
+
   DCHECK(IsJSReceiver());
   JSReceiver receiver = JSReceiver::cast(*this);
   return receiver.GetIdentityHash();
diff --git a/src/objects/objects.cc b/src/objects/objects.cc
index c15ac8656ad..ba0b2ac7511 100644
--- a/src/objects/objects.cc
+++ b/src/objects/objects.cc
@@ -129,6 +129,11 @@
 #include "src/utils/utils-inl.h"
 #include "src/zone/zone.h"
 
+// xqg start
+#include "src/json/json-parser.h"
+#include "src/json/json-stringifier.h"
+// xqg end
+
 #if V8_ENABLE_WEBASSEMBLY
 #include "src/wasm/wasm-objects.h"
 #endif  // V8_ENABLE_WEBASSEMBLY
@@ -1607,6 +1612,30 @@ Smi Object::GetOrCreateHash(Isolate* isolate) {
   Object hash = Object::GetSimpleHash(*this);
   if (hash.IsSmi()) return Smi::cast(hash);
 
+  // xqg start
+  if (!IsJSReceiver()) {
+        // Do NOT use pointer hash here, since GC can change the memory
+        // address of an object.
+        if (this->IsJSFunction()) {
+            uint32_t hash = ComputeSeededHash(JSFunction::cast(*this).shared().SourceSize(), kZeroHashSeed);
+            return Smi::FromInt(hash & Smi::kMaxValue);
+        }
+        else if (this->IsSharedFunctionInfo()) {
+            uint32_t hash = ComputeSeededHash(SharedFunctionInfo::cast(*this).SourceSize(), kZeroHashSeed);
+            return Smi::FromInt(hash & Smi::kMaxValue);
+        }
+        else if (this->IsContext()) {
+            JSGlobalObject global_object = Context::cast(*this).global_object();
+            CHECK(global_object.IsJSGlobalObject());
+            Isolate *isolate = global_object.GetIsolate();
+            return global_object.GetOrCreateHash(isolate);
+        }
+        else {
+            return Smi::FromInt(Smi::kMaxValue);
+        }
+    }
+  // xqg end
+
   DCHECK(IsJSReceiver());
   return JSReceiver::cast(*this).GetOrCreateIdentityHash(isolate);
 }
@@ -1645,6 +1674,233 @@ bool Object::SameValueZero(Object other) {
   return false;
 }
 
+// xqg start
+MaybeHandle<Object> Object::GetAllPropagationPaths(Isolate* isolate){
+    std::vector<void*> visited;
+
+    Handle <Object> obj = Handle <Object>(*this, isolate);
+    Handle <JSObject> report = isolate->factory()->NewJSObject(isolate->object_function()); // should init
+
+    if (DoGetAllPropagationPaths(isolate, obj, report, visited)){}
+
+    Handle <Object> report_json;
+    ASSIGN_RETURN_ON_EXCEPTION(isolate, report_json,
+                                   JsonStringify(isolate, report, isolate->factory()->undefined_value(),
+                                                 isolate->factory()->undefined_value()), Object);
+
+    return report_json;
+}
+
+bool Object::DoGetAllPropagationPaths(Isolate* isolate, Handle<Object>obj, Handle<JSObject>& report,
+                                      std::vector<void*>& visited){
+    if (obj.is_null() || *obj == ReadOnlyRoots(isolate).undefined_value()) return false;
+
+    Handle<String> obj_report = obj->getPropagationPaths(isolate);
+    Handle<Name> key_tainted = Handle<Name>::cast(isolate->factory()->NewStringFromAsciiChecked("tainted"));
+    Handle<Name> key_details = Handle<Name>::cast(isolate->factory()->NewStringFromAsciiChecked("details"));
+    Handle<Name> key_recursive = Handle<Name>::cast(isolate->factory()->NewStringFromAsciiChecked("recursive"));
+
+    // report["details"] = obj_report;
+    Maybe<bool> res_create = JSReceiver::CreateDataProperty(isolate, report, key_details, obj_report, Just(kDontThrow));
+    if (!res_create.FromJust()) return false;
+
+    // report["tainted"] = obj.isTainted();
+    bool tainted = false;
+    if (isolate->IsV8ObjectTainted(obj)) tainted = true;
+    res_create = JSReceiver::CreateDataProperty(isolate, report, key_tainted, isolate->factory()->ToBoolean(tainted), Just(kDontThrow));
+    if (!res_create.FromJust()) return false;
+
+    // report["recursive"] = {};
+    Handle<JSObject> val_recursive = isolate->factory()->NewJSObject(isolate->object_function());
+    res_create = JSReceiver::CreateDataProperty(isolate, report, key_recursive, val_recursive, Just(kDontThrow));
+    if (!res_create.FromJust()) return false;
+
+    visited.push_back(reinterpret_cast<void*>(obj->ptr()));
+    if (obj->IsString()) return false; // Don't recurse into array indices.
+    if (!obj->IsJSReceiver()) return false;
+
+    Handle<JSReceiver> receiver;
+    ASSIGN_RETURN_ON_EXCEPTION_VALUE(isolate, receiver, Object::ToObject(isolate, obj), false);
+
+    Handle<FixedArray> keys;
+    ASSIGN_RETURN_ON_EXCEPTION_VALUE(isolate, keys,
+                                     KeyAccumulator::GetKeys(isolate, receiver, KeyCollectionMode::kOwnOnly,
+                                                             ALL_PROPERTIES,
+                                                             GetKeysConversion::kKeepNumbers), false);
+    Handle<FixedArray> str_keys;
+    ASSIGN_RETURN_ON_EXCEPTION_VALUE(
+            isolate, str_keys,
+            KeyAccumulator::GetKeys(isolate, receiver, KeyCollectionMode::kOwnOnly,
+                                    ALL_PROPERTIES,
+                                    GetKeysConversion::kConvertToString), false);
+    for (int i = 0; i < keys->length(); ++i) {
+        Handle<Object> key = FixedArray::get(*keys, i, isolate);
+        Handle<Object> str_key = FixedArray::get(*str_keys, i, isolate);
+        Handle<Object> value;
+        ASSIGN_RETURN_ON_EXCEPTION_VALUE(
+                isolate, value, Runtime::GetObjectProperty(isolate, receiver, key), false);
+        bool include = false;
+        for (size_t j = 0; j < visited.size(); ++j){
+//            Object other = Object(reinterpret_cast<Address>(visited.at(j)));
+            if (visited.at(j) == reinterpret_cast<void*>(value->ptr())){
+                include = true;
+                break;
+            }
+        }
+        if (include == false){
+            Handle<JSObject> val_recursive_next = isolate->factory()->NewJSObject(isolate->object_function());
+            Maybe<bool> res_final = Nothing<bool>();
+            if (key->IsName())
+                res_final = JSReceiver::CreateDataProperty(isolate, val_recursive, Handle<Name>::cast(key),
+                                                           val_recursive_next, Just(kDontThrow));
+            else
+                res_final = JSReceiver::CreateDataProperty(isolate, val_recursive,Handle<Name>::cast(str_key),
+                                                           val_recursive_next, Just(kDontThrow));
+            if (!res_final.FromJust()) return false;
+
+            if (value->DoGetAllPropagationPaths(isolate, value, val_recursive_next, visited)){}
+        }
+    }
+    return true;
+}
+
+Handle<String> Object::getPropagationPaths(Isolate* isolate){
+    Handle <Object> obj = Handle <Object>(*this, isolate);
+    if (!isolate->IsV8ObjectTainted(obj))
+        return isolate->factory()->empty_string();
+    return isolate->GetPropagationPaths(obj);
+}
+
+bool Object::ContainsTaintedValue(Isolate* isolate){
+    std::vector<void*> visited;
+    i::OFStream os(stdout);
+    return this->ContainsTaintedValueRecursive(isolate, visited);
+}
+
+bool Object::ContainsTaintedValueRecursive(Isolate* isolate, std::vector<void*>& visited){
+    Handle <Object> obj = Handle <Object>(*this, isolate);
+    i::OFStream os(stdout);
+    bool show = false;
+    if (isolate->IsV8ObjectTainted(obj)) {
+        return true;
+    }
+    if (obj->IsSmi()) return false; // should not be Smi.
+    if (obj->IsNull() || obj->IsUndefined()) return false;
+    visited.push_back(reinterpret_cast<void*>(obj->ptr()));
+
+    if (obj->IsString())
+        return false; // Don't recurse into array indices.
+    if (obj->IsJSArrayBuffer()) {
+        if (show) os << "object is arraybuffer, obj = " << obj <<"\n";
+        return false; // Don't recurse into array indices.
+    }
+    if (obj->IsJSArrayBufferView()){
+        if (show) {
+            os << "object is IsJSArrayBufferView, obj = " << obj <<"\n";
+            if (obj->IsJSTypedArray()){
+                os << "inside object is IsJSTypedArray, obj = " << obj <<"\n";
+                os << JSTypedArray::cast(*obj).GetBuffer()<<"\n";
+                os << JSTypedArray::cast(*obj).GetBuffer()<<"\n";
+            }
+        }
+        return false;
+    }
+    if ( obj->IsJSTypedArray()){
+        if (show) os << "object is IsJSTypedArray, obj = " << obj <<"\n";
+        return false;
+    }
+    if (!obj->IsJSReceiver()) return false;
+
+    if (show) os << "not return, obj="<<obj<<"\n";
+
+    Handle<JSReceiver> receiver;
+    ASSIGN_RETURN_ON_EXCEPTION_VALUE(isolate, receiver, Object::ToObject(isolate, obj), false);
+
+    Handle<FixedArray> keys;
+    ASSIGN_RETURN_ON_EXCEPTION_VALUE(
+            isolate, keys,
+            KeyAccumulator::GetKeys(isolate, receiver, KeyCollectionMode::kOwnOnly,
+                                    ALL_PROPERTIES, GetKeysConversion::kKeepNumbers), false);
+    if (show){
+        os << "obj="<<obj<<",length="<<keys->length()<<"\n";
+    }
+    for (int i = 0; i < keys->length(); ++i) {
+        Handle<Object> key = FixedArray::get(*keys, i, isolate);
+        Handle<Object> value;
+        ASSIGN_RETURN_ON_EXCEPTION_VALUE(
+                isolate, value, Runtime::GetObjectProperty(isolate, receiver, key), false);
+        bool include = false;
+        for (size_t j = 0; j < visited.size(); ++j){
+            if (visited.at(j) == reinterpret_cast<void*>(value->ptr())){
+                include = true;
+                break;
+            }
+        }
+        if (include == false && value->ContainsTaintedValueRecursive(isolate, visited))
+            return true;
+    }
+    return false;
+}
+
+void Object::SetTaintForAll(Isolate* isolate, Handle<JSFunction> func,
+                               const std::string& from){
+
+    std::vector<void*> visited; // Cycle avoidance.
+
+    this->DoSetTaintForAll(isolate, func, from, visited);
+}
+
+void Object::DoSetTaintForAll(Isolate* isolate, Handle<JSFunction> func,
+                               const std::string& from, std::vector<void*>& visited){
+    i::OFStream os(stdout);
+    Handle <Object> obj = Handle <Object>(*this, isolate);
+    if (obj->IsNull() || obj->IsUndefined()) return;
+    if (obj->IsSmi()){
+        // TODO: Replace Smi.
+    }
+//    os << "Enter DoSetTaintForAll, obj="<<obj<<"\n";
+    isolate->SetTaintForV8Object(obj);
+    isolate->SetV8ObjectAsTaintSource(obj, func, from);
+    visited.push_back(reinterpret_cast<void*>(obj->ptr()));
+
+    if (obj->IsString() || obj->IsStringWrapper()) return;
+    if (obj->IsJSArrayBuffer() || obj->IsJSArrayBufferView() || obj->IsJSTypedArray()) return;
+    if (!obj->IsJSReceiver()) return;
+
+    Handle<JSReceiver> receiver;
+    if (!Object::ToObject(isolate, obj).ToHandle(&receiver)){
+        DCHECK(isolate->has_pending_exception());
+        return;
+    }
+    Handle<FixedArray> keys;
+    if (!KeyAccumulator::GetKeys(isolate, receiver, KeyCollectionMode::kOwnOnly,
+                                  ALL_PROPERTIES, GetKeysConversion::kKeepNumbers).ToHandle(&keys)){
+        DCHECK(isolate->has_pending_exception());
+        return;
+    }
+
+    for (int i = 0; i < keys->length(); ++i) {
+        Handle<Object> key = FixedArray::get(*keys, i, isolate);
+        Handle<Object> value;
+        if (!Runtime::GetObjectProperty(isolate, receiver, key).ToHandle(&value)){
+            DCHECK(isolate->has_pending_exception());
+            return;
+        }
+        bool include = false;
+        for (size_t j = 0; j < visited.size(); ++j){
+//            Object other = Object(reinterpret_cast<Address>(visited.at(j)));
+            if (visited.at(j) == reinterpret_cast<void*>(value->ptr())){
+                include = true;
+                break;
+            }
+        }
+        if (include == false)
+            value->DoSetTaintForAll(isolate, func, from, visited);
+    }
+}
+
+// xqg end
+
 MaybeHandle<Object> Object::ArraySpeciesConstructor(
     Isolate* isolate, Handle<Object> original_array) {
   Handle<Object> default_species = isolate->array_function();
@@ -5464,7 +5720,9 @@ void JSPromise::set_async_task_id(int id) {
 
 // static
 Handle<Object> JSPromise::Fulfill(Handle<JSPromise> promise,
-                                  Handle<Object> value) {
+                                  Handle<Object> value, bool is_tainted,
+                                  std::vector<Handle<Object>> tainted_objs,
+                                  const std::string& from) {
   Isolate* const isolate = promise->GetIsolate();
 
 #ifdef V8_ENABLE_JAVASCRIPT_PROMISE_HOOKS
@@ -5491,7 +5749,7 @@ Handle<Object> JSPromise::Fulfill(Handle<JSPromise> promise,
 
   // 7. Return TriggerPromiseReactions(reactions, value).
   return TriggerPromiseReactions(isolate, reactions, value,
-                                 PromiseReaction::kFulfill);
+                                 PromiseReaction::kFulfill, is_tainted, tainted_objs, from);
 }
 
 static void MoveMessageToPromise(Isolate* isolate, Handle<JSPromise> promise) {
@@ -5549,7 +5807,10 @@ Handle<Object> JSPromise::Reject(Handle<JSPromise> promise,
 // https://tc39.es/ecma262/#sec-promise-resolve-functions
 // static
 MaybeHandle<Object> JSPromise::Resolve(Handle<JSPromise> promise,
-                                       Handle<Object> resolution) {
+                                       Handle<Object> resolution,
+                                       bool is_tainted,
+                                       std::vector<Handle<Object>> tainted_objs,
+                                       const std::string& from) { // xqg
   Isolate* const isolate = promise->GetIsolate();
   DCHECK(
       !reinterpret_cast<v8::Isolate*>(isolate)->GetCurrentContext().IsEmpty());
@@ -5569,7 +5830,7 @@ MaybeHandle<Object> JSPromise::Resolve(Handle<JSPromise> promise,
   // 8. If Type(resolution) is not Object, then
   if (!resolution->IsJSReceiver()) {
     // a. Return FulfillPromise(promise, resolution).
-    return Fulfill(promise, resolution);
+    return Fulfill(promise, resolution, is_tainted, tainted_objs, from); // xqg
   }
 
   // 9. Let then be Get(resolution, "then").
@@ -5613,7 +5874,7 @@ MaybeHandle<Object> JSPromise::Resolve(Handle<JSPromise> promise,
   // 12. If IsCallable(thenAction) is false, then
   if (!then_action->IsCallable()) {
     // a. Return FulfillPromise(promise, resolution).
-    return Fulfill(promise, resolution);
+    return Fulfill(promise, resolution, is_tainted, tainted_objs, from);
   }
 
   // 13. Let job be NewPromiseResolveThenableJob(promise, resolution,
@@ -5646,7 +5907,10 @@ MaybeHandle<Object> JSPromise::Resolve(Handle<JSPromise> promise,
 Handle<Object> JSPromise::TriggerPromiseReactions(Isolate* isolate,
                                                   Handle<Object> reactions,
                                                   Handle<Object> argument,
-                                                  PromiseReaction::Type type) {
+                                                  PromiseReaction::Type type,
+                                                  bool is_tainted,
+                                                  std::vector<Handle<Object>> tainted_objs,
+                                                  const std::string& from) { // xqg
   CHECK(reactions->IsSmi() || reactions->IsPromiseReaction());
 
   // We need to reverse the {reactions} here, since we record them
@@ -5688,6 +5952,16 @@ Handle<Object> JSPromise::TriggerPromiseReactions(Isolate* isolate,
 
     bool has_handler_context = false;
     if (primary_handler->IsJSReceiver()) {
+      // xqg start
+      if (is_tainted == true && primary_handler->IsJSFunction() && type == PromiseReaction::kFulfill){
+//          Handle<String> fun_str;
+//          fun_str = JSFunction::ToString(Handle<JSFunction>::cast(primary_handler));
+          auto func = i::Handle<i::JSFunction>::cast(primary_handler);
+          for (size_t ii = 0; ii < tainted_objs.size(); ii++)
+              isolate->SetV8ObjectAsTaintSource(tainted_objs[ii], func, from);
+          isolate->MarkAsTaintSource(func);
+      }
+      // xqg end
       has_handler_context = JSReceiver::GetContextForMicrotask(
                                 Handle<JSReceiver>::cast(primary_handler))
                                 .ToHandle(&handler_context);
@@ -6566,14 +6840,39 @@ void JSMap::Rehash(Isolate* isolate) {
 }
 
 void JSWeakCollection::Initialize(Handle<JSWeakCollection> weak_collection,
-                                  Isolate* isolate) {
+                                  Isolate* isolate, bool is_pointer_map) {
+  // xqg start
+  if (is_pointer_map){
+      Handle<Object> table = Handle<Object>::cast(ObjectPointerHashTable::New(isolate, 0));
+      weak_collection->set_table(*table);
+      return;
+  }
+  // xqg end
+
   Handle<EphemeronHashTable> table = EphemeronHashTable::New(isolate, 0);
   weak_collection->set_table(*table);
 }
 
 void JSWeakCollection::Set(Handle<JSWeakCollection> weak_collection,
                            Handle<Object> key, Handle<Object> value,
-                           int32_t hash) {
+                           int32_t hash, bool is_pointer_map) {
+  // xqg start
+  if (is_pointer_map){
+        Handle <ObjectPointerHashTable> table(
+                ObjectPointerHashTable::cast(weak_collection->table()),
+                weak_collection->GetIsolate());
+        DCHECK(table->IsKey(weak_collection->GetReadOnlyRoots(), *key));
+        Handle <ObjectPointerHashTable> new_table = ObjectPointerHashTable::Put(
+                weak_collection->GetIsolate(), table, key, value, hash);
+        weak_collection->set_table(*new_table);
+        if (*table != *new_table) {
+            // Zap the old table since we didn't record slots for its elements.
+            ObjectPointerHashTable::FillEntriesWithHoles(table);
+        }
+        return;
+  }
+  // xqg end
+
   DCHECK(key->IsJSReceiver() || key->IsSymbol());
   Handle<EphemeronHashTable> table(
       EphemeronHashTable::cast(weak_collection->table()),
@@ -6589,7 +6888,25 @@ void JSWeakCollection::Set(Handle<JSWeakCollection> weak_collection,
 }
 
 bool JSWeakCollection::Delete(Handle<JSWeakCollection> weak_collection,
-                              Handle<Object> key, int32_t hash) {
+                              Handle<Object> key, int32_t hash, bool is_pointer_map) {
+
+  // xqg start
+  if (is_pointer_map){
+        Handle <ObjectPointerHashTable> table(
+                ObjectPointerHashTable::cast(weak_collection->table()),
+                weak_collection->GetIsolate());
+        DCHECK(table->IsKey(weak_collection->GetReadOnlyRoots(), *key));
+        bool was_present = false;
+        Handle <ObjectPointerHashTable> new_table = ObjectPointerHashTable::Remove(
+                weak_collection->GetIsolate(), table, key, &was_present, hash);
+        weak_collection->set_table(*new_table);
+        if (*table != *new_table) {
+            ObjectPointerHashTable::FillEntriesWithHoles(table);
+        }
+        return was_present;
+  }
+  // xqg end
+
   DCHECK(key->IsJSReceiver() || key->IsSymbol());
   Handle<EphemeronHashTable> table(
       EphemeronHashTable::cast(weak_collection->table()),
@@ -7005,6 +7322,7 @@ EXTERN_DEFINE_HASH_TABLE(RegisteredSymbolTable, RegisteredSymbolTableShape)
 
 EXTERN_DEFINE_OBJECT_BASE_HASH_TABLE(ObjectHashTable, ObjectHashTableShape)
 EXTERN_DEFINE_OBJECT_BASE_HASH_TABLE(EphemeronHashTable, ObjectHashTableShape)
+EXTERN_DEFINE_OBJECT_BASE_HASH_TABLE(ObjectPointerHashTable, ObjectPointerHashTableShape) // xqg
 
 EXTERN_DEFINE_DICTIONARY(SimpleNumberDictionary, SimpleNumberDictionaryShape)
 EXTERN_DEFINE_DICTIONARY(NumberDictionary, NumberDictionaryShape)
diff --git a/src/objects/objects.h b/src/objects/objects.h
index e1df081a5c7..3195fea337f 100644
--- a/src/objects/objects.h
+++ b/src/objects/objects.h
@@ -30,9 +30,12 @@
 #include "src/objects/tagged-impl.h"
 #include "src/utils/utils.h"
 
+
 // Has to be the last include (doesn't have include guards):
 #include "src/objects/object-macros.h"
 
+
+
 //
 // Most object types in the V8 JavaScript are described in this file.
 //
@@ -592,6 +595,7 @@ class Object : public TaggedImpl<HeapObjectReferenceType::STRONG, Address> {
   // undefined if not yet created.
   inline Object GetHash();
 
+
   // Returns the permanent hash code associated with this object depending on
   // the actual object type. May create and store a hash code if needed and none
   // exists.
@@ -612,6 +616,17 @@ class Object : public TaggedImpl<HeapObjectReferenceType::STRONG, Address> {
   // by ES6 Map and Set.
   bool SameValueZero(Object other);
 
+  // xqg start
+  MaybeHandle<Object> GetAllPropagationPaths(Isolate* isolate);
+  bool DoGetAllPropagationPaths(Isolate* isolate, Handle<Object>obj, Handle<JSObject>& report, std::vector<void*>& visited);
+  Handle<String> getPropagationPaths(Isolate* isolate);
+  bool ContainsTaintedValue(Isolate* isolate);
+  bool ContainsTaintedValueRecursive(Isolate* isolate, std::vector<void*>& visited);
+
+  void SetTaintForAll(Isolate* isolate, Handle<JSFunction> func, const std::string& from);
+  void DoSetTaintForAll(Isolate* isolate, Handle<JSFunction> func, const std::string& from, std::vector<void*>& visited);
+  // xqg end
+
   // ES6 section 9.4.2.3 ArraySpeciesCreate (part of it)
   V8_WARN_UNUSED_RESULT static MaybeHandle<Object> ArraySpeciesConstructor(
       Isolate* isolate, Handle<Object> original_array);
@@ -819,6 +834,7 @@ class Object : public TaggedImpl<HeapObjectReferenceType::STRONG, Address> {
   // reasons.
   static inline Object GetSimpleHash(Object object);
 
+
   // Helper for SetProperty and SetSuperProperty.
   // Return value is only meaningful if [found] is set to true on return.
   V8_WARN_UNUSED_RESULT static Maybe<bool> SetPropertyInternal(
diff --git a/src/objects/string.cc b/src/objects/string.cc
index cf7b0afd927..bfc0cc223fa 100644
--- a/src/objects/string.cc
+++ b/src/objects/string.cc
@@ -1665,7 +1665,7 @@ uint32_t HashString(String string, size_t start, int length, uint64_t seed,
 }  // namespace
 
 uint32_t String::ComputeAndSetRawHash() {
-  DCHECK(!SharedStringAccessGuardIfNeeded::IsNeeded(*this));
+//  DCHECK(!SharedStringAccessGuardIfNeeded::IsNeeded(*this));
   return ComputeAndSetRawHash(SharedStringAccessGuardIfNeeded::NotNeeded());
 }
 
diff --git a/src/runtime/runtime-regexp.cc b/src/runtime/runtime-regexp.cc
index 2fb47682a81..0704f83a524 100644
--- a/src/runtime/runtime-regexp.cc
+++ b/src/runtime/runtime-regexp.cc
@@ -810,7 +810,8 @@ RUNTIME_FUNCTION(Runtime_StringSplit) {
   int pattern_length = pattern->length();
   CHECK_LT(0, pattern_length);
 
-  if (limit == 0xFFFFFFFFu) {
+//  if (limit == 0xFFFFFFFFu) {
+    if (limit == 0xFFFFFFFFu && !isolate->IsV8ObjectTainted(subject)){
     FixedArray last_match_cache_unused;
     Handle<Object> cached_answer(
         RegExpResultsCache::Lookup(isolate->heap(), *subject, *pattern,
@@ -825,6 +826,8 @@ RUNTIME_FUNCTION(Runtime_StringSplit) {
     }
   }
 
+  std::vector<bool> *tainted_bytes = isolate->GetStringTaintedBytes(subject);
+
   // The limit can be very large (0xFFFFFFFFu), but since the pattern
   // isn't empty, we can never create more parts than ~half the length
   // of the subject.
@@ -857,16 +860,45 @@ RUNTIME_FUNCTION(Runtime_StringSplit) {
     elements->set(0, *subject);
   } else {
     int part_start = 0;
+    bool do_not_taint = false;  // Do not taint the result array.
     FOR_WITH_HANDLE_SCOPE(isolate, int, i = 0, i, i < part_count, i++, {
       int part_end = indices->at(i);
       Handle<String> substring =
           isolate->factory()->NewProperSubString(subject, part_start, part_end);
       elements->set(i, *substring);
+
+      // xqg start Fix up tainted bytes.
+      if (tainted_bytes != nullptr) {
+          std::vector<bool> element_tainted_bytes;
+          bool element_tainted = false;
+          bool wholly_tainted = true;
+          for (int j = 0; j < substring->length(); j++) {
+              bool byte_tainted = tainted_bytes->at(part_start + j);
+              if (byte_tainted)
+                  element_tainted = true;
+              else
+                  wholly_tainted = false;
+              element_tainted_bytes.push_back(byte_tainted);
+          }
+          if (element_tainted) {
+              if (wholly_tainted)
+                  isolate->SetTaintForV8Object(substring);
+              else
+                  isolate->SetTaintForV8Object(substring, element_tainted_bytes);
+          } else {
+              do_not_taint = true;  // If at least one element is not tainted.
+          }
+      }
+      // xqg end
       part_start = part_end + pattern_length;
     });
+    // xqg start
+    if (do_not_taint)
+        isolate->SetDoNotTaint(result);
+    // xqg end
   }
 
-  if (limit == 0xFFFFFFFFu) {
+  if (limit == 0xFFFFFFFFu && !isolate->IsV8ObjectTainted(subject)) { // xqg
     if (result->HasObjectElements()) {
       RegExpResultsCache::Enter(isolate, subject, pattern, elements,
                                 isolate->factory()->empty_fixed_array(),
diff --git a/src/runtime/runtime-taint.cc b/src/runtime/runtime-taint.cc
new file mode 100644
index 00000000000..766146cda7f
--- /dev/null
+++ b/src/runtime/runtime-taint.cc
@@ -0,0 +1,917 @@
+#include "src/runtime/runtime-taint.h"
+
+#include "src/json/json-parser.h"
+#include "src/json/json-stringifier.h"
+#include "src/codegen/unoptimized-compilation-info.h"
+#include "src/objects/js-array-inl.h"
+#include "src/objects/property-descriptor.h"
+#include <iostream>
+
+namespace v8 {
+    namespace internal {
+
+
+#ifdef IGNORE_NON_EXTENSION_CONTEXTS
+        // Ignore built-in and non-extension context functions.
+#define IGNORE_NON_PROPAGATION_CONTEXTS(isolate, ignore_builtin, retval)  \
+  do {                                                                    \
+    JavaScriptFrameIterator it(isolate);                                  \
+    Handle<Object> retval_handle(Object::cast(retval), isolate);          \
+    Handle<JSFunction> function(it.frame()->function(), isolate);         \
+    if ((ignore_builtin && !function->shared().IsUserJavaScript()) ||     \
+    !isolate->InExtensionContext(function)) {                             \
+      return (*retval_handle);                                            \
+    }                                                                     \
+  } while (false)
+#else
+// Ignore only built-in functions.
+#define IGNORE_NON_PROPAGATION_CONTEXTS(isolate, ignore_builtin, retval)  \
+  do {                                                                    \
+    JavaScriptFrameIterator it(isolate);                                  \
+    Handle<Object> retval_handle(Object::cast(retval), isolate);          \
+    Handle<JSFunction> function(it.frame()->function(), isolate);         \
+    if (ignore_builtin && !function->shared().IsUserJavaScript()) {       \
+      return (*retval_handle);                                            \
+    }                                                                     \
+  } while (false)
+#endif
+
+#define IGNORE_IF_HONEYPAGE(isolate, retval)                              \
+  do {                                                                    \
+      Handle<Object> retval_handle(Object::cast(retval), isolate);        \
+      if (isolate->InHoneyPage())                                         \
+          return (*retval_handle);                                        \
+  } while (false)
+
+#define UNDEFINED_VALUE_HEAP ReadOnlyRoots(isolate).undefined_value()
+
+#define CONVERT_ARG_HANDLE_CHECKED(Type, name, index) \
+  CHECK(args[index].Is##Type());                      \
+  Handle<Type> name = args.at<Type>(index);
+
+
+// TODO: We don't need per-scope DFGs any more (per function is more natural
+// and would have worked if we didn't resolve variables).
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnScopeExit) {
+    CHECK(args.length() == 1);
+    HandleScope handle_scope(isolate);
+    bool show = false;
+    i::OFStream os(stdout);
+
+    if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+        return UNDEFINED_VALUE_HEAP;
+    }
+
+    JavaScriptFrameIterator it(isolate);
+    Handle<JSFunction> function(it.frame()->function(), isolate);
+
+    bool ignore_builtin = true;
+    if (ignore_builtin && !function->shared().IsUserJavaScript()){
+        return UNDEFINED_VALUE_HEAP;
+    }
+
+//    IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//    IGNORE_IF_HONEYPAGE(isolate, UNDEFINED_VALUE_HEAP);
+
+    CONVERT_ARG_HANDLE_CHECKED(Smi, position, 0);
+
+    if (show){
+        os << "Enter OnScopeExit, position="<<position<<"\n";
+    }
+
+    UnoptimizedCompilationInfo *info = isolate->GetCompilationInfo(function);
+    ScopeDFG *dfg = isolate->GetScopeDFG(info, position->value());
+    if (dfg != nullptr)
+        dfg->PropagateTaint(it.frame());
+
+    return UNDEFINED_VALUE_HEAP;
+}
+
+
+// Discard any stale AST TT and OBJMAP that were left behind by
+// a previous function which wasn't properly cleaned up.
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnFunctionEnter) {
+    CHECK(args.length() == 0);
+    HandleScope handle_scope(isolate);
+
+    if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+        return UNDEFINED_VALUE_HEAP;
+    }
+//    IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//    IGNORE_IF_HONEYPAGE(isolate, UNDEFINED_VALUE_HEAP);
+
+    JavaScriptFrameIterator it(isolate);
+    Handle<JSFunction> function(it.frame()->function(), isolate);
+    bool ignore_builtin = true;
+    if (ignore_builtin && !function->shared().IsUserJavaScript()){
+        return UNDEFINED_VALUE_HEAP;
+    }
+    isolate->DropAstTaintTable(reinterpret_cast<void*>(it.frame()->fp()));
+    isolate->DropObjectMap(reinterpret_cast<void*>(it.frame()->fp()));
+
+    return UNDEFINED_VALUE_HEAP;
+}
+
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnReturnFromCall){
+    CHECK(args.length() == 2);
+    HandleScope handle_scope(isolate);
+    bool show = false;
+    i::OFStream os(stdout);
+
+//  IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+    if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+        return UNDEFINED_VALUE_HEAP;
+    }
+    JavaScriptFrameIterator it(isolate);
+    Handle<JSFunction> function(it.frame()->function(), isolate);
+    bool ignore_builtin = true;
+    if (ignore_builtin && !function->shared().IsUserJavaScript()){
+        return UNDEFINED_VALUE_HEAP;
+    }
+
+    CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+    CONVERT_ARG_HANDLE_CHECKED(Smi, position, 1);
+
+    obj = FilterInvalidV8Objects(isolate, obj);
+    if (obj.is_null()) return UNDEFINED_VALUE_HEAP;
+
+    if (show){
+            os << "Enter TaintAnalysis_OnReturnFromCall()\n";
+            os << obj <<","<<position<<","<<isolate->IsV8ObjectTainted(obj)<<","<<isolate->IsV8ObjectPartiallyTainted(obj)<<"\n";
+    }
+
+    if (isolate->IsV8ObjectTainted(obj) && !isolate->IsV8ObjectPartiallyTainted(obj)) {
+            Handle<JSFunction> function(it.frame()->function(), isolate);
+            isolate->SetTaintForAstNode(function, reinterpret_cast<void*>(it.frame()->fp()),
+                                                position->value(), AstNode::kCall);
+    }
+    isolate->AddToObjectMap(reinterpret_cast<void*>(it.frame()->fp()), position->value(), AstNode::kCall, obj);
+
+    return UNDEFINED_VALUE_HEAP;
+}
+
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnVisitVariableProxy) {
+
+    CHECK_EQ(args.length(), 3);
+    i::OFStream os(stdout);
+    bool show = false;
+
+    HandleScope handle_scope(isolate);
+
+    if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+        return UNDEFINED_VALUE_HEAP;
+    }
+
+    JavaScriptFrameIterator it(isolate);
+    Handle<JSFunction> function(it.frame()->function(), isolate);
+    bool ignore_builtin = true;
+    if (ignore_builtin && !function->shared().IsUserJavaScript()){
+        return UNDEFINED_VALUE_HEAP;
+    }
+
+//    IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//    IGNORE_IF_HONEYPAGE(isolate, UNDEFINED_VALUE_HEAP);
+
+    CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+//    CONVERT_ARG_HANDLE_CHECKED(Smi, scope_position, 1);
+    CONVERT_ARG_HANDLE_CHECKED(Smi, expr_position, 2);
+
+    if (show){
+        os << "Enter TaintAnalysis_OnVisitVariableProxy()\n";
+        os << obj <<","<<expr_position<<","<<isolate->IsV8ObjectTainted(obj)<<","<<isolate->IsV8ObjectPartiallyTainted(obj)<<"\n";
+        if (obj->IsHeapObject() && *obj == ReadOnlyRoots(isolate).the_hole_value()) {
+            os << "it's the hole value" <<"\n";
+        }
+    }
+
+    // Update AST taint.
+    if (isolate->IsV8ObjectTainted(obj) && !isolate->IsV8ObjectPartiallyTainted(obj)) {
+                    isolate->SetTaintForAstNode(function, reinterpret_cast<void*>(it.frame()->fp()),
+                                                expr_position->value(), AstNode::kVariableProxy);
+    } else {
+        isolate->UntaintAstNode(reinterpret_cast<void *>(it.frame()->fp()),
+                                            expr_position->value(), AstNode::kVariableProxy);
+    }
+
+    // Update object map.
+    isolate->AddToObjectMap(reinterpret_cast<void*>(it.frame()->fp()),
+                            expr_position->value(), AstNode::kVariableProxy, obj);
+    return UNDEFINED_VALUE_HEAP;
+}
+
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnVisitProperty) {
+    CHECK(args.length() == 3);
+    HandleScope handle_scope(isolate);
+    bool show = false;
+    i::OFStream os(stdout);
+
+    if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+        return UNDEFINED_VALUE_HEAP;
+    }
+    JavaScriptFrameIterator it(isolate);
+    Handle<JSFunction> function(it.frame()->function(), isolate);
+    bool ignore_builtin = true;
+    if (ignore_builtin && !function->shared().IsUserJavaScript()){
+        return UNDEFINED_VALUE_HEAP;
+    }
+
+//  IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//  IGNORE_IF_HONEYPAGE(isolate, UNDEFINED_VALUE_HEAP);
+
+    // Get rid of home object. We don't need it here due to the fact
+    // that we recursively generate DFG edges for the obj expression.
+    // CONVERT_ARG_HANDLE_CHECKED(Object, home, 0);
+
+    CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+    CONVERT_ARG_HANDLE_CHECKED(Smi, scope_position, 1);
+    CONVERT_ARG_HANDLE_CHECKED(Smi, expr_position, 2);
+
+    if (show){
+        os << "Enter TaintAnalysis_OnVisitProperty()\n";
+        os << obj <<","<<scope_position<<","<<expr_position<<","<<isolate->IsV8ObjectTainted(obj)<<","<<isolate->IsV8ObjectPartiallyTainted(obj)<<"\n";
+    }
+
+    // Update AST taint.
+    if (isolate->IsV8ObjectTainted(obj) && !isolate->IsV8ObjectPartiallyTainted(obj)) {
+        isolate->SetTaintForAstNode(function, reinterpret_cast<void*>(it.frame()->fp()),
+                                                expr_position->value(), AstNode::kProperty);
+    } else {
+        isolate->UntaintAstNode(reinterpret_cast<void*>(it.frame()->fp()),
+                                            expr_position->value(), AstNode::kProperty);
+    }
+
+    // Update object map.
+    isolate->AddToObjectMap(reinterpret_cast<void*>(it.frame()->fp()),expr_position->value(), AstNode::kProperty, obj);
+
+    return UNDEFINED_VALUE_HEAP;
+}
+
+// xqg: Same as OnVisitProperty,
+// just want to check how to trigger optional chain for log.
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnVisitPropertyOptionalChain) {
+
+    CHECK(args.length() == 3);
+    HandleScope handle_scope(isolate);
+    bool show = true;
+    i::OFStream os(stdout);
+
+    if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+        return UNDEFINED_VALUE_HEAP;
+    }
+    JavaScriptFrameIterator it(isolate);
+    Handle<JSFunction> function(it.frame()->function(), isolate);
+    bool ignore_builtin = true;
+    if (ignore_builtin && !function->shared().IsUserJavaScript()){
+        return UNDEFINED_VALUE_HEAP;
+    }
+
+//  IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//  IGNORE_IF_HONEYPAGE(isolate, UNDEFINED_VALUE_HEAP);
+
+    CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+    CONVERT_ARG_HANDLE_CHECKED(Smi, scope_position, 1);
+    CONVERT_ARG_HANDLE_CHECKED(Smi, expr_position, 2);
+
+    if (show){
+        os << "Enter TaintAnalysis_OnVisitPropertyOptionalChain()\n";
+        os << obj <<","<<scope_position<<","<<expr_position<<","<<isolate->IsV8ObjectTainted(obj)<<","<<isolate->IsV8ObjectPartiallyTainted(obj)<<"\n";
+    }
+
+    // Update AST taint.
+    if (isolate->IsV8ObjectTainted(obj) && !isolate->IsV8ObjectPartiallyTainted(obj)) {
+        isolate->SetTaintForAstNode(function, reinterpret_cast<void*>(it.frame()->fp()),
+                                    expr_position->value(), AstNode::kProperty);
+    } else {
+        isolate->UntaintAstNode(reinterpret_cast<void*>(it.frame()->fp()),
+                                            expr_position->value(), AstNode::kProperty);
+    }
+    // Update object map.
+    isolate->AddToObjectMap(reinterpret_cast<void*>(it.frame()->fp()),
+                            expr_position->value(), AstNode::kProperty, obj);
+
+    return UNDEFINED_VALUE_HEAP;
+}
+
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_Check) {
+    i::OFStream os(stdout);
+                HandleScope handle_scope(isolate);
+                CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, flag, 1);
+
+
+                IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//                IGNORE_IF_HONEYPAGE(isolate, *num);
+                os << "Enter Runtime_TaintAnalysis_Check\n";
+                os << "flag="<<flag<<",obj="<<obj<<"\n";
+                return UNDEFINED_VALUE_HEAP;
+}
+
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_CheckArray) {
+                i::OFStream os(stdout);
+                HandleScope handle_scope(isolate);
+                CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, flag, 1);
+
+
+                IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//                IGNORE_IF_HONEYPAGE(isolate, *num);
+                os << "Enter Runtime_TaintAnalysis_CheckArray\n";
+                os << "flag="<<flag<<",obj="<<obj<<"\n";
+                // working....
+                MaybeHandle<FixedArray> maybe_list =
+                Object::CreateListFromArrayLike(isolate, obj, ElementTypes::kAll);
+                if (!maybe_list.is_null()) {
+                    Handle <FixedArray> list = maybe_list.ToHandleChecked();
+                    for (int j = 0; j < list->length(); j++) {
+                        Handle <Object> element = FixedArray::get(*list, j, isolate);
+                        os << "j="<<j<<",ele="<<element<<"\n";
+                    }
+                }
+                return UNDEFINED_VALUE_HEAP;
+}
+
+
+
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_ReplaceSmiResult) {
+    i::OFStream os(stdout);
+    CHECK(args.length() == 1);
+    HandleScope handle_scope(isolate);
+    bool show = false;
+
+
+//  IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, *num);
+//  IGNORE_IF_HONEYPAGE(isolate, *num);
+
+    CONVERT_ARG_HANDLE_CHECKED(Smi, num, 0);
+
+    if (show) os << "Enter Runtime_TaintAnalysis_ReplaceSmiResult\n";
+    if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+        return *num;
+    }
+    JavaScriptFrameIterator it(isolate);
+    Handle<JSFunction> function(it.frame()->function(), isolate);
+    bool ignore_builtin = true;
+    if (ignore_builtin && !function->shared().IsUserJavaScript()){
+        return *num;
+    }
+
+    Handle<HeapNumber> heap_number = Handle<HeapNumber>::cast(isolate->factory()->NewHeapNumber((double)(num->value())));
+    if (show) os << "smi = " << num << ", heap number = " << heap_number << "\n";
+    return *heap_number;
+}
+
+// This is for Array that has <Leading Spread>
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_ReplaceSmiResultArray) {
+    i::OFStream os(stdout);
+    CHECK(args.length() == 1);
+    HandleScope handle_scope(isolate);
+    bool show = false;
+
+
+    CONVERT_ARG_HANDLE_CHECKED(Object, receiver, 0);
+    if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+        return *receiver;
+    }
+    JavaScriptFrameIterator it(isolate);
+    Handle<JSFunction> function(it.frame()->function(), isolate);
+    bool ignore_builtin = true;
+    if (ignore_builtin && !function->shared().IsUserJavaScript()){
+        return *receiver;
+    }
+//                IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, *receiver);
+//                IGNORE_IF_HONEYPAGE(isolate, *receiver);
+
+    Handle<JSArray> array = Handle<JSArray>::cast(receiver);
+
+    uint32_t len = static_cast<uint32_t>(array->length().Number());
+    if (len == 0) return *array;
+
+    if (show) os << "Enter Runtime_TaintAnalysis_ReplaceSmiResultArray, len="<<len<<"\n";
+
+                // We have to use accessor and EnsureWritableFastElements first!
+    JSObject::EnsureWritableFastElements(array);
+    ElementsAccessor* accessor = array->GetElementsAccessor();
+    size_t length = accessor->GetCapacity(*array, array->elements());
+    int index = -1;
+    for (InternalIndex entry : InternalIndex::Range(length)) {
+                    if (!accessor->HasEntry(*array, entry)) continue;
+                    Handle<Object> element = accessor->Get(isolate, array, entry);
+                    index = index + 1;
+                    if (!element->IsSmi()) continue;
+                    Handle<HeapNumber> heap_number = Handle<HeapNumber>::cast(
+                            isolate->factory()->NewHeapNumber((double)(Handle<Smi>::cast(element)->value())));
+                    accessor->Set(array, entry, *heap_number);
+
+                    if (show) {
+                        os << "index = " << index << ", smi = " << element << ", heap number = " << heap_number << "\n";
+                        Handle <Object> new_element;
+                        ASSIGN_RETURN_ON_EXCEPTION_VALUE(
+                                isolate, new_element,
+                                JSReceiver::GetElement(isolate, array, index), *array);
+                        os << "new element=" << new_element << "\n";
+                    }
+    }
+    return *array;
+}
+
+// Taint propagation point for the returning function. Also propagates
+// taint for the implicit assignment from the return value statement.
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnVisitReturnStatement) {
+    CHECK(args.length() == 2);
+    HandleScope handle_scope(isolate);
+    bool show = false;
+    i::OFStream os(stdout);
+
+    if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+        return UNDEFINED_VALUE_HEAP;
+    }
+
+    JavaScriptFrameIterator it(isolate);
+    Handle<JSFunction> function(it.frame()->function(), isolate);
+    bool ignore_builtin = true;
+    if (ignore_builtin && !function->shared().IsUserJavaScript()){
+        return UNDEFINED_VALUE_HEAP;
+    }
+
+//                IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//                IGNORE_IF_HONEYPAGE(isolate, UNDEFINED_VALUE_HEAP);
+
+    CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+    CONVERT_ARG_HANDLE_CHECKED(Smi, position, 1);
+
+    if (show) os << "Enter TaintAnalysis_OnVisitReturnStatement(), position="<<position<<", obj="<<obj<<"\n";
+
+    // TODO: Replace the return value if it's Smi. Replace done
+    obj = FilterInvalidV8Objects(isolate, obj);
+    if (obj.is_null() || obj->IsSmi() || isolate->IsDoNotTaint(obj))
+        return UNDEFINED_VALUE_HEAP;
+
+    UnoptimizedCompilationInfo *info = isolate->GetCompilationInfo(function);
+
+    ReturnStatementLocator locator(isolate, info->literal()->scope(), position->value());
+    locator.Locate(info, info->literal()->body());
+    if (locator.found()) {
+                    ScopeDFG *dfg = isolate->GetScopeDFG(info,
+                                                         locator.LocatedScope()->start_position());
+
+                    if (dfg != nullptr)
+                        dfg->PropagateTaint(it.frame());
+
+                    ExpressionTaintChecker checker(isolate, locator.LocatedScope(), it.frame());
+                    if (checker.Check(locator.LocatedNode()->expression())) {
+                        if (show) os << "check is true\n";
+                        isolate->SetTaintForV8Object(obj);
+                        checker.PopulatePropagatedFrom(obj);
+                    }
+    }
+    return UNDEFINED_VALUE_HEAP;
+}
+
+
+
+// Taint propagation point. Also propagates taint for the
+// implicit assignments from the element expressions.
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnVisitArrayLiteral) {
+
+    HandleScope handle_scope(isolate);
+    bool show = false;
+    i::OFStream os(stdout);
+
+    if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+                    return UNDEFINED_VALUE_HEAP;
+    }
+
+    JavaScriptFrameIterator it(isolate);
+    Handle<JSFunction> function(it.frame()->function(), isolate);
+    bool ignore_builtin = true;
+    if (ignore_builtin && !function->shared().IsUserJavaScript()){
+        return UNDEFINED_VALUE_HEAP;
+    }
+
+//                IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//                IGNORE_IF_HONEYPAGE(isolate, UNDEFINED_VALUE_HEAP);
+
+                CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, scope_position, 1);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, expr_position, 2);
+                int spread_count = args.length() - 3;
+
+                if (show) {
+                    Handle<JSArray> array = Handle<JSArray>::cast(obj);
+                    os << "Enter TaintAnalysis_OnVisitArrayLiteral, obj=" << obj<<", " << scope_position <<"," << expr_position <<"\n";
+                    uint32_t len = static_cast<uint32_t>(array->length().Number());
+                    if (len != 0) {
+                        for (uint32_t index = 0; index < len; ++index) {
+                            Handle<Object> element;
+                            ASSIGN_RETURN_ON_EXCEPTION_VALUE(
+                                    isolate, element, JSReceiver::GetElement(isolate, array, index), *array);
+                            os << "i="<<index<<", element="<<element<<", is smi?"<<element->IsSmi()<<"\n";
+                        }
+                    }
+                    os << "spread count="<<spread_count<<"\n";
+                    for (int i = 0; i < spread_count; i++) {
+                        CONVERT_ARG_HANDLE_CHECKED(Object, temp_obj, 3+i);
+                        os << "spread_obj="<<temp_obj<<"\n";
+                    }
+                }
+
+                UnoptimizedCompilationInfo *info = isolate->GetCompilationInfo(function);
+
+                ScopeDFG *dfg = isolate->GetScopeDFG(info, scope_position->value());
+                if (dfg != nullptr)
+                dfg->PropagateTaint(it.frame());
+
+                ArrayLiteralLocator locator(isolate, info->scope(), expr_position->value());
+                locator.Locate(info, info->literal()->body());
+                if (locator.found()) {
+                    ArrayLiteral *expr = locator.LocatedNode();
+
+                    // This will potentially trigger GC!
+                    MaybeHandle<FixedArray> maybe_list =
+                            Object::CreateListFromArrayLike(isolate, obj, ElementTypes::kAll);
+                    isolate->clear_pending_exception();
+
+                    if (!maybe_list.is_null()) {
+                        Handle<FixedArray> list = maybe_list.ToHandleChecked();
+                        int element_index = 0;
+                        int spread_index = 0;
+                        for (int i = 0; i < expr->values()->length(); i++) {
+                            Expression *subexpr = expr->values()->at(i);
+                            if (subexpr->IsCompileTimeValue()) {
+//                    os << "is CompileTimeValue, i="<<i<<",element_index="<<element_index<<"\n";
+                                element_index = element_index + 1;
+                                continue;
+                            }
+                            if (subexpr->IsSpread()) {
+                                CONVERT_ARG_HANDLE_CHECKED(Object, spread_obj, 3+spread_index);
+                                spread_index = spread_index + 1;
+                                MaybeHandle<FixedArray> spread_maybe_list =
+                                        Object::CreateListFromArrayLike(isolate, spread_obj, ElementTypes::kAll);
+                                isolate->clear_pending_exception();
+                                if (show){
+                                    os << "subexpr is spread, expr index = " << i << "obj=" << spread_obj << "element_index=" << element_index<<"\n";
+                                }
+                                if (!spread_maybe_list.is_null()) {
+                                    Handle<FixedArray> spread_list = spread_maybe_list.ToHandleChecked();
+                                    if (show){os << "spread_list length = " << spread_list->length() << "\n";}
+                                    for (int j = 0; j < spread_list->length(); j++) {
+                                        Handle<Object> spread_element = FixedArray::get(*spread_list, j, isolate);
+                                        if ( show){os << "j="<<j<<",element_index="<<element_index<<",spread_element="<<spread_element<<"\n";}
+                                        if (!spread_element.is_null() && !spread_element->IsSmi()) {
+                                            if (isolate->IsV8ObjectTainted(spread_element)) {
+                                                Handle<Object> element = FixedArray::get(*list, element_index, isolate);
+                                                isolate->SetTaintForV8Object(element);
+                                                // TODO: checker.PopulatePropagatedFrom(element);
+                                                if (show){os << "this spread element is tainted, coresponding element=" << element <<"\n";}
+                                            }
+                                        }
+                                        element_index = element_index + 1;
+                                    }
+                                }
+                                continue;
+                            }
+
+                            ExpressionTaintChecker checker(
+                                    isolate, locator.LocatedScope(),it.frame());
+                            if (show) os << "not compile not spread, element_index=" << element_index << ",element="<<FixedArray::get(*list, element_index, isolate)<<"\n";
+                            if (checker.Check(subexpr)) {
+                                CHECK(!subexpr->IsSpread());
+                                Handle<Object> element = FixedArray::get(*list, element_index, isolate);
+                                if (show) os << "this element is checked taint: "<<element<<"\n";
+                                element = FilterInvalidV8Objects(isolate, element);
+                                // TODO: Can we replace the Smi's here?
+                                if (!element.is_null() && !element->IsSmi()) {
+                                    isolate->SetTaintForV8Object(element);
+                                    checker.PopulatePropagatedFrom(element);
+                                }
+                            }
+                            element_index = element_index + 1;
+                        }
+                    }
+                }
+                return UNDEFINED_VALUE_HEAP;
+        }
+
+// Taint propagation point. Also propagates taint for the
+// implicit assignments from the property expressions.
+
+// TODO: Is there a way to group the entire object literal
+// into one runtime call (instead of one for each property)?
+        RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnVisitObjectLiteral){
+                HandleScope handle_scope(isolate);
+                bool show = false;
+                i::OFStream os(stdout);
+
+                if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+                    return UNDEFINED_VALUE_HEAP;
+                }
+                JavaScriptFrameIterator it(isolate);
+                Handle<JSFunction> function(it.frame()->function(), isolate);
+                bool ignore_builtin = true;
+                if (ignore_builtin && !function->shared().IsUserJavaScript()){
+                    return UNDEFINED_VALUE_HEAP;
+                }
+
+//                IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//                IGNORE_IF_HONEYPAGE(isolate, UNDEFINED_VALUE_HEAP);
+
+                CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, scope_position, 1);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, expr_position, 2);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, index, 3);
+
+                if (show){
+                    os << "Enter TaintAnalysis_OnVisitObjectLiteral: obj=" << obj << ","<< scope_position<<","<<expr_position<<","<<index<<"\n";
+                }
+
+                obj = FilterInvalidV8Objects(isolate, obj);
+                if (obj.is_null() || obj->IsSmi())
+                return UNDEFINED_VALUE_HEAP;
+
+                UnoptimizedCompilationInfo *info = isolate->GetCompilationInfo(function);
+
+                ScopeDFG *dfg = isolate->GetScopeDFG(info, scope_position->value());
+                if (dfg != nullptr)
+                dfg->PropagateTaint(it.frame());
+
+                ObjectLiteralLocator locator(isolate, info->scope(), expr_position->value());
+                locator.Locate(info, info->literal()->body());
+                if (locator.found()) {
+                    ObjectLiteral *expr = locator.LocatedNode();
+                    ObjectLiteral::Property *property = expr->properties()->at(index->value());
+                    CHECK(property->kind() != ObjectLiteral::Property::SPREAD);
+//        if (show) os << "property->kind()="<<property->kind()<<"\n";
+                    ExpressionTaintChecker checker(isolate, locator.LocatedScope(), it.frame());
+                    if (checker.Check(property->value())) {
+                        if (show) os <<"this property is tainted\n";
+                        isolate->SetTaintForV8Object(obj);
+                        checker.PopulatePropagatedFrom(obj);
+                    }
+                    else {
+                        if (show) os <<"this property is not tainted\n";
+                    }
+                }
+                return UNDEFINED_VALUE_HEAP;
+        }
+
+        RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnVisitObjectLiteralSpread){
+                HandleScope handle_scope(isolate);
+                bool show = false;
+                i::OFStream os(stdout);
+
+                if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+                    return UNDEFINED_VALUE_HEAP;
+                }
+                JavaScriptFrameIterator it(isolate);
+                Handle<JSFunction> function(it.frame()->function(), isolate);
+                bool ignore_builtin = true;
+                if (ignore_builtin && !function->shared().IsUserJavaScript()){
+                    return UNDEFINED_VALUE_HEAP;
+                }
+
+//                IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//                IGNORE_IF_HONEYPAGE(isolate, UNDEFINED_VALUE_HEAP);
+
+                CONVERT_ARG_HANDLE_CHECKED(Object, target, 0);
+                CONVERT_ARG_HANDLE_CHECKED(Object, source, 1);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, scope_position, 2);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, expr_position, 3);
+
+                if (show){
+                    os << "Enter TaintAnalysis_OnVisitObjectLiteralSpread: target=" << target << ",source="<<source<<","<< scope_position<<","<<expr_position<<"\n";
+                }
+
+                if (source->IsUndefined(isolate) || source->IsNull(isolate))
+                return UNDEFINED_VALUE_HEAP;
+
+                UnoptimizedCompilationInfo *info = isolate->GetCompilationInfo(function);
+
+                ScopeDFG *dfg = isolate->GetScopeDFG(info, scope_position->value());
+                if (dfg != nullptr)
+                dfg->PropagateTaint(it.frame());
+
+                Handle<JSReceiver> from = Object::ToObject(isolate, source).ToHandleChecked();
+                Handle<JSReceiver> to = Object::ToObject(isolate, target).ToHandleChecked();
+
+                Handle<FixedArray> keys;
+                ASSIGN_RETURN_ON_EXCEPTION_VALUE(isolate, keys,
+                KeyAccumulator::GetKeys(isolate, from, KeyCollectionMode::kOwnOnly,
+                ALL_PROPERTIES, GetKeysConversion::kKeepNumbers),UNDEFINED_VALUE_HEAP);
+
+                if (show){os << "source key length = "<<keys->length()<<"\n";}
+                for (int i = 0; i < keys->length(); ++i) {
+                    Handle <Object> next_key(keys->get(i), isolate);
+
+                    PropertyDescriptor desc;
+                    Maybe<bool> found =
+                            JSReceiver::GetOwnPropertyDescriptor(isolate, from, next_key, &desc);
+                    if (found.IsNothing()) return UNDEFINED_VALUE_HEAP;
+                    if (found.FromJust() && desc.enumerable()) {
+                        Handle <Object> prop_value;
+                        ASSIGN_RETURN_ON_EXCEPTION_VALUE(
+                                isolate, prop_value,
+                                Runtime::GetObjectProperty(isolate, from, next_key), UNDEFINED_VALUE_HEAP);
+                        if (show) { os << "i=" << i << ",key=" << next_key << ",val=" << prop_value << "\n"; }
+                        if (!prop_value.is_null() && !prop_value->IsSmi()) {
+                            if (isolate->IsV8ObjectTainted(prop_value)) {
+                                Handle <Object> target_prop_value;
+                                ASSIGN_RETURN_ON_EXCEPTION_VALUE(
+                                        isolate, target_prop_value,
+                                        Runtime::GetObjectProperty(isolate, to, next_key), UNDEFINED_VALUE_HEAP);
+                                if (show) {
+                                    os << "i=" << i << ",target val=" << target_prop_value << "\n";
+                                }
+                                isolate->SetTaintForV8Object(target_prop_value);
+                                // TODO: add prop
+                            }
+                        }
+                    }
+                }
+
+                return UNDEFINED_VALUE_HEAP;
+        }
+
+
+// Taint propagation point for the caller. Also propagates taint for
+// the implicit assignments from the actual argument expressions.
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_OnVisitCallArguments) {
+                HandleScope handle_scope(isolate);
+                bool show = false;
+                if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+                    return UNDEFINED_VALUE_HEAP;
+                }
+                JavaScriptFrameIterator it(isolate);
+                Handle<JSFunction> function(it.frame()->function(), isolate);
+                bool ignore_builtin = true;
+                if (ignore_builtin && !function->shared().IsUserJavaScript()){
+                    return UNDEFINED_VALUE_HEAP;
+                }
+//                IGNORE_NON_PROPAGATION_CONTEXTS(isolate, true, UNDEFINED_VALUE_HEAP);
+//                IGNORE_IF_HONEYPAGE(isolate, UNDEFINED_VALUE_HEAP);
+                i::OFStream os(stdout);
+
+                CONVERT_ARG_HANDLE_CHECKED(Object, callee_init, 0);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, scope_position, 1);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, expr_position, 2);
+                CONVERT_ARG_HANDLE_CHECKED(Smi, arg_count, 3);
+
+                if (arg_count->value() == -1){ // HasNonFinalSpread
+                    CHECK_EQ(args.length(), 5);
+                    if(show) {
+                        CONVERT_ARG_HANDLE_CHECKED(Object, arr, 4);
+                        os <<"OnVisitCallArguments, HasNonFinalSpread, obj="<<arr<<"\n";
+                    }
+                } else {
+                    CHECK_EQ(args.length(), 4 + arg_count->value());
+//        os <<"OnVisitCallArguments, other\n";
+                    for (int i = 4; i < args.length(); i++){
+                        if (show) {
+                            CONVERT_ARG_HANDLE_CHECKED(Object, obj, i);
+                            os << "i="<<i-4<<"obj="<<obj << "\n";
+                        }
+                    }
+                }
+                Handle<JSFunction> callee;
+                if (callee_init->IsJSFunction())
+                callee = Handle<JSFunction>(JSFunction::cast(args[0]), isolate);
+
+                if (show){
+                    os << args.length() <<"," << arg_count << ","<<scope_position<<","<<expr_position<<"\n";
+                    os << "callee:"<<"\n";
+                    PrintJSFunction(callee, isolate);
+
+                    os <<"caller:"<<"\n";
+                    PrintJSFunction(function, isolate);
+                }
+
+                // Read before clear (caller and callee might be the same).
+                bool do_not_propagate = DoNotPropagate(isolate);
+                isolate->ClearDoNotPropagate(function);
+
+                if (!callee.is_null() && do_not_propagate) {
+                    // Propagate do-not-propagate down the call chain.
+                    isolate->AddDoNotPropagate(function, callee);
+                }
+
+                UnoptimizedCompilationInfo *info = isolate->GetCompilationInfo(function);
+                ScopeDFG *dfg = isolate->GetScopeDFG(info, scope_position->value());
+                if (dfg != nullptr) {
+                    if (!dfg->PropagateTaint(it.frame())) {
+                        return UNDEFINED_VALUE_HEAP; // No tainted values in scope.
+                    }
+                }
+
+                CallLocator locator(isolate, info->scope(), expr_position->value());
+                locator.Locate(info, info->literal()->body());
+                if (locator.found()) {
+                    JQueryRHSChecker j_checker(isolate, locator.LocatedScope());
+                    if (j_checker.Check(locator.LocatedNode())) {
+                        CHECK(!callee.is_null());
+                        isolate->AddDoNotPropagate(function, callee);
+                        return UNDEFINED_VALUE_HEAP;
+                    }
+                    // this could be
+                    const ZonePtrList<Expression>* expr_args = locator.LocatedNode()->arguments();
+                    if (show) os << "expr_args="<<expr_args->length()<<"\n";
+                    if (arg_count->value() == -1){
+                        // this is natually handled ?
+                    }
+                    else {
+                        for (int i = 0; i < expr_args->length(); i++) {
+                            if (expr_args->at(i)->IsSpread()) { // this has to be in the end.
+                                CHECK_EQ(i, expr_args->length()-1);
+                                // this is natually handled in array!!!!!!!!!
+//                    if (show){
+//                        os << "is spread, expr index = " << i << "obj=" << spread_obj << "\n";
+//                    }
+                                break;
+                            }
+                            ExpressionTaintChecker checker(isolate, locator.LocatedScope(), it.frame());
+                            if (checker.Check(expr_args->at(i))) {
+                                CONVERT_ARG_HANDLE_CHECKED(Object, arg_obj, i+4);
+                                if (show){
+                                    os << "not spread, i="<<i<<",arg_obj="<<arg_obj<<"\n";
+                                }
+                                if (arg_obj->IsSmi()){
+                                    Handle<HeapNumber> heap_number = Handle<HeapNumber>::cast(isolate->factory()->NewHeapNumber<AllocationType::kOld>(
+                                            double((Handle<Smi>::cast(arg_obj)->value()))));
+                                    arg_obj.PatchValue(*heap_number);
+                                }
+                                isolate->SetTaintForV8Object(arg_obj);
+                                checker.PopulatePropagatedFrom(arg_obj);
+                            }
+                        }
+                    }
+
+
+                }
+                return UNDEFINED_VALUE_HEAP;
+        }
+
+
+/************************************************************************************/
+/********************************for js************************************************/
+
+
+        RUNTIME_FUNCTION(Runtime_TaintAnalysis_SetTaint) {
+                CHECK(args.length() == 1);
+                HandleScope handle_scope(isolate);
+                i::OFStream os(stdout);
+                bool show = false;
+                IGNORE_NON_PROPAGATION_CONTEXTS(isolate, false, UNDEFINED_VALUE_HEAP);
+                CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+
+                obj = FilterInvalidV8Objects(isolate, obj);
+                if (obj.is_null() || obj->IsSmi())
+                return UNDEFINED_VALUE_HEAP;
+                if (show) os << "Enter Runtime_TaintAnalysis_SetTaint, obj="<<obj<<"\n";
+
+                isolate->SetTaintForV8Object(obj);
+
+                return UNDEFINED_VALUE_HEAP;
+        }
+
+        RUNTIME_FUNCTION(Runtime_TaintAnalysis_IsTainted){
+                CHECK(args.length() == 1);
+                HandleScope handle_scope(isolate);
+
+                CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+//    IGNORE_NON_PROPAGATION_CONTEXTS(isolate, false, UNDEFINED_VALUE_HEAP);
+
+
+                if (isolate->IsV8ObjectTainted(obj))
+                return ReadOnlyRoots(isolate).true_value();
+
+                return ReadOnlyRoots(isolate).false_value();
+        }
+
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_ContainsTaintedValue) {
+        CHECK(args.length() == 1);
+        HandleScope handle_scope(isolate);
+
+        if (!isolate->IsExtensionContextFast(reinterpret_cast<void*>(isolate->raw_native_context().ptr()))){
+            return isolate->heap()->ToBoolean(false);
+        }
+//                IGNORE_NON_PROPAGATION_CONTEXTS(isolate, false, isolate->heap()->ToBoolean(false));
+        CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+
+        bool result = obj->ContainsTaintedValue(isolate);
+        return isolate->heap()->ToBoolean(result);
+}
+
+RUNTIME_FUNCTION(Runtime_TaintAnalysis_SetPropagationPaths) {
+
+                CHECK(args.length() == 2);
+                HandleScope handle_scope(isolate);
+                JavaScriptFrameIterator it(isolate);
+                CONVERT_ARG_HANDLE_CHECKED(Object, obj, 0);
+                CONVERT_ARG_HANDLE_CHECKED(Object, res, 1);
+
+                Handle<String> report = Handle<String>::cast(obj->GetAllPropagationPaths(isolate).ToHandleChecked());
+                isolate->AddPropagatedFrom(res, Handle<JSFunction>(it.frame()->function(), isolate), report);
+                return UNDEFINED_VALUE_HEAP;
+}
+
+
+    }
+}
\ No newline at end of file
diff --git a/src/runtime/runtime-taint.h b/src/runtime/runtime-taint.h
new file mode 100644
index 00000000000..421da9c8f5d
--- /dev/null
+++ b/src/runtime/runtime-taint.h
@@ -0,0 +1,1612 @@
+#ifndef V8_RUNTIME_TAINT_H_
+#define V8_RUNTIME_TAINT_H_
+
+#include "src/execution/arguments.h"
+#include "src/execution/frames-inl.h"
+#include "src/runtime/runtime-utils.h"
+#include "src/parsing/parser.h"
+#include "src/parsing/parse-info.h"
+#include "src/common/globals.h"
+#include "src/objects/oddball-inl.h"
+#include "src/commons.h"
+#include "src/codegen/compiler.h"
+#include "src/ast/prettyprinter.h"
+#include <iostream>
+
+namespace v8 {
+    namespace internal {
+
+#define IGNORE_NON_EXTENSION_CONTEXTS
+//#define DISABLE_PROPAGATION_REPORT
+#define POPULATE_CFG_EDGES
+#define PROPAGATION_PATHS_OUT_DIR  "/ram/analysis/v8logs/"
+
+#define PREPEND_MARKER  "// HONEYPAGE1"
+#define APPEND_MARKER   "// HONEYPAGE2"
+
+// AST node position is of type int, and I don't think there ever
+// will be more than 2^11 AST node types. So this scheme is fine
+// as long as void* is 8 bytes.e
+#define KEY_FROM_POSITION_AND_TYPE(pos, type) \
+    reinterpret_cast<void *>(((unsigned long)pos << 12) | \
+        ((type << 1) & 0xffe))
+
+        static inline bool HandleStringEquals(Handle<String> locales, const std::string& str) {
+//    if (locales->IsUndefined(isolate)) return str == "";
+            return locales->IsEqualTo(base::VectorOf(str.c_str(), str.length()));
+        }
+
+        static inline Handle<Object> FilterInvalidV8Objects(Isolate *isolate,
+                                                            Handle<Object> obj) {
+
+            if (obj.is_null() || *obj == Smi::FromInt(0) ||
+                *obj == ReadOnlyRoots(isolate).null_value() ||
+                *obj == ReadOnlyRoots(isolate).undefined_value() ||
+                *obj == ReadOnlyRoots(isolate).the_hole_value() ||
+                *obj == ReadOnlyRoots(isolate).true_value() ||
+                *obj == ReadOnlyRoots(isolate).false_value() ||
+                *obj == ReadOnlyRoots(isolate).empty_string()) {
+                return Handle<Object>::null();
+            }
+            return obj;
+        }
+
+
+        static inline bool DoNotPropagate(Isolate *isolate) {
+            // Is the current function in our whitelist of do-not-propagate functions?
+            JavaScriptFrameIterator it_current(isolate);
+            Handle<JSFunction> current(it_current.frame()->function(), isolate);
+            if (isolate->IsDoNotPropagateFunction(current))
+                return true;
+
+            // Otherwise do we have any do-not-propagates on the current
+            // call chain (indicated by the do-not-propagate table)?
+            JavaScriptFrameIterator it_caller(isolate);
+            it_caller.Advance();
+            if (!it_caller.done()) {
+                Handle<JSFunction> caller(it_caller.frame()->function(), isolate);
+                return isolate->IsDoNotPropagate(caller, current);
+            }
+
+            return false;
+        }
+
+
+        static inline void PrintJSFunction(Handle<JSFunction> function, Isolate* isolate) {
+
+            i::OFStream os(stdout);
+
+            Handle<SharedFunctionInfo> shared(function->shared(), isolate);
+            std::unique_ptr<char[]> name = shared->DebugNameCStr();
+            os << name.get() << ":\n";
+
+            if (shared->HasSourceCode()) {
+                String source = String::cast(Script::cast(shared->script()).source());
+                int start = shared->StartPosition();
+                int length = shared->EndPosition() - start;
+                std::unique_ptr<char[]> source_string = source.ToCString(
+                        DISALLOW_NULLS, FAST_STRING_TRAVERSAL, start, length, nullptr);
+                os << source_string.get() << "\n\n";
+            }
+        }
+
+
+        class ASTVisitor: public AstVisitor<ASTVisitor> { // should done? TODO: check again
+        public:
+            ASTVisitor(Isolate *isolate, Scope *scope)
+                    : isolate_(isolate),
+                      scope_(scope),
+                      scope_statements_(nullptr),
+                      stack_limit_(stack_limit_ = isolate_->stack_guard()->real_climit()) {}
+
+            virtual ~ASTVisitor() { }
+
+            Isolate *isolate() const { return isolate_; }
+
+            Scope *scope() const { return scope_; }
+
+            ZoneList<Statement *> *scope_statements() { return scope_statements_; }
+
+            commons::LinkedList *scope_dependencies() { return &scope_dependencies_; }
+
+            commons::LinkedList *dependency_scopes() { return &dependency_scopes_; }
+
+            class EnterScope {
+            public:
+                EnterScope(ASTVisitor *visitor,
+                           Scope *scope, ZoneList<Statement *> *statements)
+                        : visitor_(visitor) {
+                    i::OFStream os(stdout);
+                    saved_scope_ = visitor_->scope_;
+                    saved_statements_ = visitor_->scope_statements_;
+
+                    visitor_->scope_ = scope;
+                    visitor_->scope_statements_ = statements;
+                    visitor_->NotifyScopeEntry();
+                }
+
+                EnterScope(ASTVisitor *visitor, Scope *scope, Expression *expr): visitor_(visitor) {
+                    i::OFStream os(stdout);
+                    saved_scope_ = visitor_->scope_;
+                    saved_statements_ = visitor->scope_statements_;
+
+                    visitor_->scope_ = scope;
+                    visitor_->scope_statements_ = nullptr;
+                    visitor_->NotifyScopeEntry();
+                }
+
+                // xqg start
+                EnterScope(ASTVisitor *visitor, Scope *scope, Expression *expr, bool show): visitor_(visitor) {
+//                    i::OFStream os(stdout);
+//                    os << "init3, "<<show<<"\n";
+                    saved_scope_ = visitor_->scope_;
+                    saved_statements_ = visitor->scope_statements_;
+
+                    visitor_->scope_ = scope;
+                    visitor_->scope_statements_ = nullptr;
+
+                    if (show) visitor_->NotifyScopeEntryShow();
+                    else visitor_->NotifyScopeEntry();
+                }
+
+                EnterScope(ASTVisitor *visitor,
+                           Scope *scope, ZoneList<Statement *> *statements, bool show)
+                        : visitor_(visitor) {
+//                    i::OFStream os(stdout);
+//                    os << "init4, "<<show<<"\n";
+                    saved_scope_ = visitor_->scope_;
+                    saved_statements_ = visitor_->scope_statements_;
+
+                    visitor_->scope_ = scope;
+                    visitor_->scope_statements_ = statements;
+                    if (show) visitor_->NotifyScopeEntryShow();
+                    else visitor_->NotifyScopeEntry();
+                }
+                // xqg end
+
+                ~EnterScope() {
+                    visitor_->scope_ = saved_scope_;
+                    visitor_->scope_statements_ = saved_statements_;
+                }
+
+            private:
+                ASTVisitor *visitor_;
+                Scope *saved_scope_;
+                ZoneList<Statement *> *saved_statements_;
+
+            };
+
+            virtual void Visit(AstNode *node) { // done
+//        i::OFStream os(stdout);
+//        os << "so inside <AST> virtual visit\n";
+                while (GetCurrentStackPosition() < stack_limit_) {
+//            os << "while, "<< GetCurrentStackPosition()<<","<<stack_limit_<<"\n";
+                    // Increase limit by 1 MiB.
+                    isolate_->stack_guard()->SetStackLimit(stack_limit_ - (0x1 << 20));
+                    stack_limit_ = isolate_->stack_guard()->real_climit();
+                }
+//        os << "after while\n";
+//        node->Print(isolate_);
+                GENERATE_AST_VISITOR_SWITCH()
+//        os << "after GENERATE_AST_VISITOR_SWITCH\n";
+            }
+
+            // Assuming |statements| are in the same scope the visitor was initialized with.
+            virtual void StartVisit(ZoneList<Statement *> *statements, bool show = false) {
+                i::OFStream os(stdout);
+                if (show) {os << "Enter StartVisit()\n";}
+                if (show) EnterScope enter_scope(this, scope_, statements, show);
+                else EnterScope enter_scope(this, scope_, statements);
+                if (show) {os << "done enter_scope()\n";}
+                AstVisitor::VisitStatements(statements);
+                if (show) {os << "done VisitStatements\n";}
+
+            }
+
+            virtual void StartVisit(Expression *expr) {
+                EnterScope enter_scope(this, scope_, expr);
+                Visit(expr);
+            }
+
+            //
+            // Declarations.
+            //
+
+            virtual void VisitVariableDeclaration(VariableDeclaration *decl) { } // ok checked, remain the same
+            virtual void VisitFunctionDeclaration(FunctionDeclaration *decl) { } // ok checked, remain the same
+
+            //
+            // Statements.
+            //
+
+            virtual void VisitBlock(Block *block) {
+                if (block->scope() != nullptr && ShouldEnterScope()) {
+                    EnterScope enter_scope(this, block->scope(), block->statements());
+                    VisitStatements(block->statements()); // TODO: maybe we don't need visit declaration?
+                } else {
+                    // |block| is part of the current scope, visit normally.
+                    VisitStatements(block->statements());
+                }
+            }
+
+            virtual void VisitExpressionStatement(ExpressionStatement *stmt) { // done checking
+                Visit(stmt->expression());
+            }
+
+            virtual void VisitEmptyStatement(EmptyStatement *stmt) { } // done checking
+
+            virtual void VisitSloppyBlockFunctionStatement(SloppyBlockFunctionStatement *stmt) {
+                // Do nothing; don't visit nested function definitions. // TODO: why?
+            }
+
+            virtual void VisitIfStatement(IfStatement *stmt) { // done checking
+                scope_dependencies_.append(stmt->condition(), nullptr);
+                dependency_scopes_.append(scope(), nullptr);
+                Visit(stmt->condition());
+                Visit(stmt->then_statement());
+                if (stmt->HasElseStatement())
+                    Visit(stmt->else_statement());
+                scope_dependencies_.pop_tail();
+                dependency_scopes_.pop_tail();
+            }
+
+            virtual void VisitContinueStatement(ContinueStatement *stmt) { } // done checking
+            virtual void VisitBreakStatement(BreakStatement *stmt) { } // done checking
+
+            virtual void VisitReturnStatement(ReturnStatement *stmt) { // done checking
+                Visit(stmt->expression());
+            }
+
+            virtual void VisitWithStatement(WithStatement *stmt) { // TODO: idk
+                /*
+                 * with (expression)
+                   statement
+                 */
+                Visit(stmt->expression());
+                if (ShouldEnterScope()) {
+                    Zone *zone = stmt->scope()->zone();
+                    // TODO: Memory overhead, what if entered multiple times?
+                    ZonePtrList<Statement>* statements = zone->New<ZonePtrList<Statement>>(1, zone);
+                    statements->Add(stmt->statement(), zone);
+
+                    EnterScope enter_scope_(this, stmt->scope(), statements);
+                    Visit(stmt->statement());
+                }
+            }
+
+            virtual void VisitSwitchStatement(SwitchStatement *stmt) { // done checking
+                scope_dependencies_.append(stmt->tag(), nullptr);
+                dependency_scopes_.append(scope(), nullptr);
+                Visit(stmt->tag());
+                ZonePtrList<CaseClause> *cases = stmt->cases();
+                for (int i = 0; i < cases->length(); i++) {
+                    CaseClause* clause = cases->at(i);
+                    if (!clause->is_default())
+                        Visit(clause->label());
+                    VisitStatements(clause->statements());
+                }
+                scope_dependencies_.pop_tail();
+                dependency_scopes_.pop_tail();
+            }
+
+            virtual void VisitDoWhileStatement(DoWhileStatement *stmt) { // doe checking
+                scope_dependencies_.append(stmt->cond(), nullptr);
+                dependency_scopes_.append(scope(), nullptr);
+                Visit(stmt->cond());
+                Visit(stmt->body());
+                scope_dependencies_.pop_tail();
+                dependency_scopes_.pop_tail();
+            }
+
+
+            virtual void VisitWhileStatement(WhileStatement *stmt) { // done checking
+                scope_dependencies_.append(stmt->cond(), nullptr);
+                dependency_scopes_.append(scope(), nullptr);
+                Visit(stmt->cond());
+                Visit(stmt->body());
+                scope_dependencies_.pop_tail();
+                dependency_scopes_.pop_tail();
+            }
+
+            virtual void VisitForStatement(ForStatement *stmt) {
+                if (stmt->cond() != nullptr) {
+                    scope_dependencies_.append(stmt->cond(), nullptr);
+                    dependency_scopes_.append(scope(), nullptr);
+                }
+
+                if (stmt->init() != nullptr)
+                    Visit(stmt->init());
+                if (stmt->cond() != nullptr)
+                    Visit(stmt->cond());
+                Visit(stmt->body());
+                if (stmt->next() != nullptr)
+                    Visit(stmt->next());
+
+                if (stmt->cond() != nullptr) {
+                    scope_dependencies_.pop_tail();
+                    dependency_scopes_.pop_tail();
+                }
+            }
+
+            virtual void VisitForInStatement(ForInStatement *stmt) {
+                Visit(stmt->subject()); //note
+                Visit(stmt->each());
+                Visit(stmt->body());
+            }
+
+            virtual void VisitForOfStatement(ForOfStatement *stmt) { // different
+                Visit(stmt->subject()); //note
+                Visit(stmt->each());
+                Visit(stmt->body());
+            }
+            virtual void VisitTryCatchStatement(TryCatchStatement *stmt) {
+                // working
+//                i::OFStream os(stdout);
+//                os << "Enter VisitTryCatchStatement\n";
+//                stmt->Print(isolate_);
+                Visit(stmt->try_block());
+//                os << "after visit try block\n";
+                if (ShouldEnterScope() && stmt->scope()) {
+//                    os << "ShouldEnterScope\n";
+//                    os << "ShouldEnterScope2\n";
+//                    os << "scope()=stmt->scope()="<<stmt->scope();
+//                    os << "zone="<<stmt->scope()->zone()<<"\n";
+                    Zone *zone = stmt->scope()->zone();
+//                    os << "get zone\n";
+                    // TODO: Memory overhead, what if entered multiple times?
+                    ZonePtrList<Statement>* statements = zone->New<ZonePtrList<Statement>>(1, zone);
+//                    os << "before add\n";
+                    statements->Add(stmt->catch_block(), zone);
+//                    os << "before enter\n";
+
+                    EnterScope enter_scope_(this, stmt->scope(), statements);
+//                    os << "before visit catch\n";
+
+                    Visit(stmt->catch_block());
+//                    os << "after visit catch\n";
+
+                }
+//                os << "before return\n";
+
+            }
+            virtual void VisitTryFinallyStatement(TryFinallyStatement *stmt) {
+                Visit(stmt->try_block());
+                Visit(stmt->finally_block());
+            }
+
+            // only in new chromium
+            virtual void VisitDebuggerStatement(DebuggerStatement *stmt) { /* do nothing */} // check done
+
+            virtual void VisitInitializeClassMembersStatement(InitializeClassMembersStatement* node){ // check done
+                ZonePtrList<ClassLiteral::Property>* props = node->fields();
+                for (int i = 0; i < props->length(); ++i) {
+                    ClassLiteralProperty* prop = props->at(i);
+                    if (!prop->key()->IsLiteral()) {
+                        Visit(prop->key());
+                    }
+                    Visit(prop->value());
+                }
+            } // new
+
+            virtual void VisitInitializeClassStaticElementsStatement(InitializeClassStaticElementsStatement *node){ // check done
+                ZonePtrList<ClassLiteral::StaticElement>* elements = node->elements();
+                for (int i = 0; i < elements->length(); ++i) {
+                    ClassLiteral::StaticElement* element = elements->at(i);
+                    switch (element->kind()) {
+                        case ClassLiteral::StaticElement::PROPERTY: {
+                            ClassLiteral::Property* prop = element->property();
+                            if (!prop->key()->IsLiteral()) {
+                                Visit(prop->key());
+                            }
+                            Visit(prop->value());
+                            break;
+                        }
+                        case ClassLiteral::StaticElement::STATIC_BLOCK:
+                            Visit(element->static_block());
+                            break;
+                    }
+                }
+            } //new
+
+            virtual void VisitAwait(Await* expr){
+                Visit(expr->expression());
+            }
+            virtual void VisitNaryOperation(NaryOperation* node){  // a + a + a ... xqg added, done
+                Visit(node->first());
+                for (size_t i = 0; i < node->subsequent_length(); ++i) {
+                    Visit(node->subsequent(i));
+                }
+            }
+
+            virtual void VisitCompoundAssignment(CompoundAssignment* expr){ // e.g., a += b; xqg added, done
+                VisitAssignment(expr); // should be visitiassignment not visit!!!!!!!!!!!!!!!!!!!!!! tongku
+            }
+
+            virtual void VisitGetTemplateObject(GetTemplateObject* expr){/* do nothing*/} // check done
+
+            virtual void VisitImportCallExpression(ImportCallExpression* expr){ // check done
+                Visit(expr->specifier());
+                if (expr->import_assertions()) {
+                    Visit(expr->import_assertions());
+                }
+            }
+
+            virtual void VisitOptionalChain(OptionalChain* expr){ // xqg added, done.
+                Visit(expr->expression());
+            }
+
+            virtual void VisitTemplateLiteral(TemplateLiteral* expr){ // check done
+                /* do nonthing*/
+                for (Expression* sub : *expr->substitutions()) {
+                    Visit(sub);
+                }
+            }
+
+            virtual void VisitYieldStar(YieldStar* expr){ // check done
+                Visit(expr->expression());
+            }
+
+            //
+            // Expressions.
+            //
+
+            virtual void VisitFunctionLiteral(FunctionLiteral *literal) { /* do nothing */}
+
+            virtual void VisitClassLiteral(ClassLiteral *literal) { /* do nothing */ }
+
+            virtual void VisitNativeFunctionLiteral(NativeFunctionLiteral *literal) { /* do nothing */ }
+
+            virtual void VisitConditional(Conditional *cond) { // done
+                Visit(cond->condition());
+                Visit(cond->then_expression());
+                Visit(cond->else_expression());
+            }
+
+            virtual void VisitVariableProxy(VariableProxy *proxy) { /* do nothing */} // done
+
+            virtual void VisitLiteral(Literal *literal) {/* do nothing */ } // done
+
+            virtual void VisitRegExpLiteral(RegExpLiteral *literal) { /* do nothing */} // why?????
+
+            virtual void VisitObjectLiteral(ObjectLiteral *literal) { // done
+                const ZonePtrList<ObjectLiteralProperty>* props = literal->properties();
+                for (int i = 0; i < props->length(); ++i) {
+                    ObjectLiteralProperty* prop = props->at(i);
+                    Visit(prop->key());
+                    Visit(prop->value());
+                }
+            }
+
+            virtual void VisitArrayLiteral(ArrayLiteral *literal) { // done
+                VisitExpressions(literal->values());
+            }
+
+            virtual void VisitAssignment(Assignment *expr) { // done
+                Visit(expr->target());
+                Visit(expr->value());
+            }
+
+            virtual void VisitYield(Yield *expr) { // done
+                Visit(expr->expression());
+            }
+
+            virtual void VisitThrow(Throw *expr) { // done
+                Visit(expr->exception());
+            }
+
+            virtual void VisitProperty(Property *prop) { // done
+                Visit(prop->obj());
+                Visit(prop->key());
+            }
+
+            virtual void VisitCall(Call *call) { // done
+                Visit(call->expression());
+                VisitExpressions(call->arguments());
+            }
+
+            virtual void VisitCallNew(CallNew *call) { // done
+                Visit(call->expression());
+                VisitExpressions(call->arguments());
+            }
+            virtual void VisitCallRuntime(CallRuntime *call) { // done
+                VisitExpressions(call->arguments());
+            }
+            virtual void VisitUnaryOperation(UnaryOperation *expr) { // done
+                Visit(expr->expression());
+            }
+            virtual void VisitCountOperation(CountOperation *expr) { // done
+                Visit(expr->expression());
+            }
+            virtual void VisitBinaryOperation(BinaryOperation *expr) { // done
+                Visit(expr->left());
+                Visit(expr->right());
+            }
+            virtual void VisitCompareOperation(CompareOperation *comp) { // done
+                Visit(comp->left());
+                Visit(comp->right());
+            }
+
+            /* TODO: Esoteric stuff. I'll handle later. */
+
+            virtual void VisitSpread(Spread *expr) { // done
+                Visit(expr->expression());
+            }
+
+            virtual void VisitThisExpression(ThisExpression *expr) { /* do nothing */ } // done
+
+            virtual void VisitSuperPropertyReference(SuperPropertyReference *expr) {  /* do nothing */} // done
+
+            virtual void VisitSuperCallReference(SuperCallReference *expr) { /* do nothing, about proxy */  } // done
+
+//    virtual void VisitCaseClause(CaseClause *expr) { } // no VisitCaseClause now
+
+            virtual void VisitEmptyParentheses(EmptyParentheses *expr) {/* do nothing */ } // done
+
+//    virtual void VisitDoExpression(DoExpression *expr) { } // no DoExpression now, done
+
+//    virtual void VisitRewritableExpression(RewritableExpression *expr) { } // no RewritableExpression now, done
+
+        protected:
+            virtual void NotifyScopeEntry() { }
+            virtual void NotifyScopeEntryShow() { } // xqg
+            virtual bool ShouldEnterScope() { return true; }
+
+        private:
+            Isolate *isolate_;
+            Scope *scope_;
+            ZoneList<Statement *> *scope_statements_;
+            uintptr_t stack_limit_;
+
+            commons::LinkedList scope_dependencies_;
+            commons::LinkedList dependency_scopes_;
+        };
+
+        class ScopeLocator : public ASTVisitor { // done
+        public:
+            ScopeLocator(Isolate *isolate, Scope *scope, long position)
+                    : ASTVisitor(isolate, scope),
+                      position_(position),
+                      found_(false),
+                      located_scope_(nullptr),
+                      located_scope_statements_(nullptr) {}
+
+            void Locate(ZoneList<Statement *> *statements) {
+                StartVisit(statements);
+            }
+
+            bool found() const { return found_; }
+
+            Scope *LocatedScope() { return located_scope_; }
+
+            ZoneList<Statement *> *LocatedScopeStatements() {
+                return located_scope_statements_;
+            }
+
+            commons::LinkedList *scope_dependencies() { return &scope_dependencies_; }
+
+            commons::LinkedList *dependency_scopes() { return &dependency_scopes_; }
+
+        private:
+            void NotifyScopeEntry() {
+                if (scope()->start_position() == position_) {
+                    found_ = true;
+                    located_scope_ = scope();
+                    located_scope_statements_ = scope_statements();
+                    // Make a copy of the current scope dependencies.
+                    scope_dependencies_ = *(ASTVisitor::scope_dependencies());
+                    dependency_scopes_ = *(ASTVisitor::dependency_scopes());
+                }
+            }
+
+            void NotifyScopeEntryShow() {
+                i::OFStream os(stdout);
+//                os << "Enter NotifyScopeEntry()\n";
+//                os << scope()->start_position()<<","<<position_<<"\n";
+                if (scope()->start_position() == position_) {
+                    found_ = true;
+                    located_scope_ = scope();
+                    located_scope_statements_ = scope_statements();
+                    // Make a copy of the current scope dependencies.
+                    scope_dependencies_ = *(ASTVisitor::scope_dependencies());
+                    dependency_scopes_ = *(ASTVisitor::dependency_scopes());
+                }
+            }
+
+            void Visit(AstNode *node) {
+                if (located_scope_ != nullptr)
+                    return;
+                ASTVisitor::Visit(node);
+            }
+
+            long position_;
+            bool found_;
+            Scope *located_scope_;
+            ZoneList<Statement *> *located_scope_statements_;
+            commons::LinkedList scope_dependencies_;
+            commons::LinkedList dependency_scopes_;
+        };
+
+        struct ScopeAndNode { // done
+            Scope *scope;
+            AstNode *node;
+        };
+
+        class AstNodeLocator : public ASTVisitor { // done
+        public:
+            AstNodeLocator(Isolate *isolate, Scope *scope, int position)
+                    : ASTVisitor(isolate, scope),
+                      position_(position),
+                      found_(false),
+                      located_node_(nullptr),
+                      located_scope_(NULL) {
+
+            }
+
+            void Visit(AstNode *node) {
+                i::OFStream os(stdout);
+//        os << node->position() << ","<<position_<<"\n";
+                if (node->position() == position_ && IsNodeType(node)) {
+                    found_ = true;
+                    located_node_ = node;
+                    located_scope_ = scope();
+                    return;
+                }
+                ASTVisitor::Visit(node);
+            }
+
+            void Locate(UnoptimizedCompilationInfo *info, ZoneList<Statement *> *statements, bool show = false) {
+                found_ = false;
+                i::OFStream os(stdout);
+                ScopeAndNode *cached = isolate()->LocatedScopeAndNode(info, node_type(), position_);
+
+                if (show) {
+                    os << "Enter Locate(), cached=" << cached <<",found="<<found_<<"\n";
+                }
+
+                if (cached != nullptr) {
+                    found_ = true;
+                    located_node_ = cached->node;
+                    located_scope_ = cached->scope;
+                } else {
+                    StartVisit(statements, show);
+//            os << "after startvisit found="<<found_<<"\n";
+                    if (found_) {
+                        cached = new ScopeAndNode;
+                        cached->scope = located_scope_;
+                        cached->node = located_node_;
+                        isolate()->AddLocatedScopeAndNode(info, node_type(), position_, cached);
+                    }
+                }
+            }
+            bool found() const { return found_; }
+
+            AstNode *LocatedNode() { return located_node_; }
+
+            Scope *LocatedScope() { return located_scope_; }
+
+        protected:
+            virtual bool IsNodeType(AstNode *node) = 0;
+            virtual AstNode::NodeType node_type() = 0;
+
+        private:
+            int position_;
+            bool found_;
+            AstNode *located_node_;
+            Scope *located_scope_;
+        };
+
+#define SPECIALIZE_AST_NODE_LOCATOR(name)                        \
+  class name##Locator : public AstNodeLocator {                  \
+   public:                                                       \
+    name##Locator(Isolate *isolate, Scope *scope, int position)  \
+        : AstNodeLocator(isolate, scope, position) {             \
+    }                                                            \
+    name *LocatedNode() {                                        \
+      return AstNodeLocator::LocatedNode()->As##name();          \
+    }                                                            \
+   private:                                                      \
+    bool IsNodeType(AstNode *node) { return node->Is##name(); }  \
+    AstNode::NodeType node_type() { return AstNode::k##name; }   \
+};
+
+        SPECIALIZE_AST_NODE_LOCATOR(Call)
+        SPECIALIZE_AST_NODE_LOCATOR(ReturnStatement)
+        SPECIALIZE_AST_NODE_LOCATOR(Property)
+        SPECIALIZE_AST_NODE_LOCATOR(ArrayLiteral)
+        SPECIALIZE_AST_NODE_LOCATOR(ObjectLiteral)
+        SPECIALIZE_AST_NODE_LOCATOR(VariableProxy)
+        SPECIALIZE_AST_NODE_LOCATOR(CallRuntime)
+
+#undef SPECIALIZE_AST_NODE_LOCATOR
+
+        class ScopeDFG { // done
+        public:
+            ScopeDFG(Isolate *isolate, Scope *scope)
+                    : isolate_(isolate),
+                      scope_(scope) {
+            }
+
+            static void IterateScopeDFGDestructor(void *key, void *value, void *data) {
+                delete (commons::HashTable *)value;
+            }
+
+            ~ScopeDFG() {
+                nodes_.iterate(IterateScopeDFGDestructor, nullptr);
+            }
+
+            Isolate *isolate() const { return isolate_; }
+
+            Scope *scope() const { return scope_; }
+
+            void AddEdge(AstNode *from, AstNode *to) {
+                CHECK(from != to);
+                commons::HashTable *adj_list =
+                        reinterpret_cast<commons::HashTable *>(nodes_.get(from));
+
+                if (adj_list == nullptr) {
+                    adj_list = new commons::HashTable();
+                    nodes_.insert(from, adj_list);
+                }
+                adj_list->insert(to, nullptr);
+            }
+
+            static void IteratePropagateTaint(void *key, void *value, void *data) {
+                ScopeDFG *dfg = (ScopeDFG *)data;
+                if (dfg->visited_->search(key))
+                    return;
+                dfg->visited_->insert(key, nullptr);
+
+                Isolate *isolate = dfg->isolate_;
+                //Scope *scope = dfg->scope_; // unused
+                JavaScriptFrame *frame = dfg->frame_;
+                void *fp = reinterpret_cast<void*>(frame->fp());
+                Handle<JSFunction> function(frame->function(), isolate);
+
+                Handle<Object> obj;
+                AstNode *node = reinterpret_cast<AstNode *>(key);
+                obj = isolate->LookupObjectMap(fp, node->position(), node->node_type()); // daiding
+                obj = FilterInvalidV8Objects(isolate, obj);
+
+                if (!obj.is_null() && !isolate->IsDoNotTaint(obj)) {
+                    if (obj->IsSmi()) {
+                        // TODO: Replace Smi.
+                    }
+
+                    isolate->SetTaintForV8Object(obj);
+                    // This will also set taint for the AST node if obj is
+                    // an Smi and was not replaced above - desired behavior.
+
+                    if (!isolate->IsV8ObjectPartiallyTainted(obj)) {
+                        isolate->SetTaintForAstNode(function, fp,
+                                                    node->position(), node->node_type());
+                    }
+
+                    if (dfg->propagated_from_ != nullptr) {
+                        AstNode *from = reinterpret_cast<AstNode *>(dfg->propagated_from_);
+                        Handle<Object> from_obj = dfg->propagated_from_obj_;
+                        isolate->AddPropagatedFrom(obj, function, from, from_obj);
+                    }
+                }
+
+                commons::HashTable *adj_list =
+                        reinterpret_cast<commons::HashTable *>(dfg->nodes_.get(key));
+
+                if (adj_list != nullptr) {
+                    void *saved_from = dfg->propagated_from_;
+                    Handle<Object> saved_from_obj = dfg->propagated_from_obj_;
+
+                    dfg->propagated_from_ = key;
+                    dfg->propagated_from_obj_ = obj;
+
+                    adj_list->iterate(IteratePropagateTaint, data);
+
+                    dfg->propagated_from_ = saved_from;
+                    dfg->propagated_from_obj_ = saved_from_obj;
+
+                }
+            }
+
+            static void IteratePopulateTaintedNodes(void *key, void *value, void *data) {
+                ScopeDFG *dfg = reinterpret_cast<ScopeDFG *>(data);
+                AstNode *node = reinterpret_cast<AstNode *>(key);
+                void *mapped_key =
+                        KEY_FROM_POSITION_AND_TYPE(node->position(), node->node_type());
+                if (dfg->ast_taint_table_->search(mapped_key)) {
+                    dfg->list_->append(key, value);
+                }
+            }
+
+            bool PropagateTaint(JavaScriptFrame *frame) {
+                if (DoNotPropagate(isolate_)) {
+                    return false;
+                }
+
+                Handle<JSFunction> function(frame->function(), isolate_);
+                if (isolate_->IsJSFunctionTainted(function))
+                    return TaintLHSNodes(frame);
+
+                commons::HashTable *ast_taint_table =
+                        isolate_->GetAstTaintTable(reinterpret_cast<void*>(frame->fp()), false);
+                if (ast_taint_table == nullptr)
+                    return false;
+
+                // Need to make a copy - cannot iterate on the AST taint table itself!
+                //
+                // Also filter out nodes that are not in the DFG.
+                list_ = new commons::LinkedList();
+                //ast_taint_table->iterate(IterateCopyAstTaintTable, this);
+                ast_taint_table_ = ast_taint_table;
+                nodes_.iterate(IteratePopulateTaintedNodes, this);
+
+                frame_ = frame;
+                visited_ = new commons::HashTable();
+                propagated_from_ = nullptr;
+                propagated_from_obj_ = Handle<Object>::null();
+                list_->iterate(IteratePropagateTaint, this);
+
+                delete visited_;
+                delete list_;
+
+                return true;
+
+            }
+
+
+            static void IterateDoTaintLHSNodes(void *key, void *value, void *data) {
+                ScopeDFG *dfg = (ScopeDFG *)data;
+                Isolate *isolate = dfg->isolate_;
+                JavaScriptFrame *frame = dfg->frame_;
+                void *fp = reinterpret_cast<void*>(frame->fp());
+                Handle<JSFunction> function(frame->function(), isolate);
+
+                Handle<String> report = isolate->GetPropagationPathForJSFunction(function); // add
+                CHECK(!report.is_null());
+
+                Handle<Object> obj;
+
+                AstNode *node = reinterpret_cast<AstNode*>(key);
+                obj = isolate->LookupObjectMap(fp, node->position(), node->node_type());
+                obj = FilterInvalidV8Objects(isolate, obj);
+
+                if (!obj.is_null() && !isolate->IsDoNotTaint(obj)) {
+                    if (obj->IsSmi()) {
+                        // TODO: Replace Smi.
+                    }
+
+                    isolate->SetTaintForV8Object(obj);
+                    // This will also set taint for the AST node if obj is
+                    // an Smi and was not replaced above - desired behavior.
+                    if (!isolate->IsV8ObjectPartiallyTainted(obj)) {
+                        isolate->SetTaintForAstNode(function, fp,
+                                                    node->position(), node->node_type());
+                    }
+
+                    isolate->AddPropagatedFrom(obj, function, report);
+                }
+                dfg->propagated_ = true;
+            }
+
+            static void IterateTaintLHSNodes(void *key, void *value, void *data) {
+                commons::HashTable *adj_list =
+                        reinterpret_cast<commons::HashTable *>(value);
+                adj_list->iterate(IterateDoTaintLHSNodes, data);
+
+            }
+
+            // Taint any node that has at least one in edge.
+            bool TaintLHSNodes(JavaScriptFrame *frame) {
+                if (DoNotPropagate(isolate_)) return false;
+
+                frame_ = frame;
+                propagated_ = false;
+                nodes_.iterate(IterateTaintLHSNodes, this);
+                return propagated_;
+
+            }
+
+        private:
+            Isolate *isolate_;
+            Scope *scope_;
+            commons::HashTable nodes_;
+
+            // Taint propagation.
+            JavaScriptFrame *frame_;
+            commons::HashTable *visited_;
+            commons::LinkedList *list_;
+            void *propagated_from_;
+            Handle<Object> propagated_from_obj_;
+            bool propagated_;
+            commons::HashTable *ast_taint_table_;
+
+        };
+
+        class RHSCollector : public ASTVisitor { // done
+        public:
+            RHSCollector(Isolate *isolate, Scope *scope)
+                    : ASTVisitor(isolate, scope) {
+            }
+
+            void Collect(AstNode *node, commons::LinkedList *output) {
+                output_ = output;
+                Visit(node);
+            }
+
+            void VisitVariableProxy(VariableProxy *proxy) {
+                output_->append(proxy, nullptr);
+            }
+
+            void VisitProperty(Property *property) {
+                output_->append(property, nullptr);
+            }
+
+            void VisitCall(Call *call) {
+                output_->append(call, nullptr);
+            }
+
+        private:
+            commons::LinkedList *output_;
+        };
+
+        class JQueryRHSChecker : public ASTVisitor { // xqg: final check done
+        public:
+            JQueryRHSChecker(Isolate *isolate, Scope *scope)
+                    :  ASTVisitor(isolate, scope) {
+
+            }
+
+            bool Check(Expression *rhs) {
+                state_ = CHECK_START;
+                ASTVisitor::StartVisit(rhs);
+                return (state_ == URL_OR_OPERATION_2) || (state_ == URL_OR_OPERATION_1);
+            }
+
+            /*
+             * A state machine matching RHS of this assignment (i.e., jQuery signature):
+             *
+             * s.url = ( ( url || s.url || ajaxLocation ) + "" )
+             *     .replace( rhash, "" )
+             *     .replace( rprotocol, ajaxLocParts[ 1 ] + "//" );
+             *
+             * Furthermore, some jQuery versions omit the inner replace, that is:
+             *
+             * s.url = ( ( url || s.url || location.href ) + "" )
+             *    .replace( rprotocol, location.protocol + "//" );
+            */
+
+            void Visit(AstNode *node) {
+                if (node->IsCall()) {
+                    Call *expr = node->AsCall();
+                    if (state_ == CHECK_START && IsOuterReplace(expr)) {
+                        state_ = OUTER_REPLACE_CALL;
+                        Visit(expr->expression()->AsProperty()->obj());
+                    } else if (state_ == OUTER_REPLACE_CALL && IsInnerReplace(expr)) {
+                        state_ = INNER_REPLACE_CALL;
+                        Visit(expr->expression()->AsProperty()->obj());
+                    }
+                }
+                else if (node->IsBinaryOperation()) {
+                    BinaryOperation *expr = node->AsBinaryOperation();
+                    if ((state_ == INNER_REPLACE_CALL ||
+                         state_ == OUTER_REPLACE_CALL) && IsConcatEmptyString(expr)) {
+                        state_ = CONCAT_EMPTY_STRING;
+                        Visit(expr->left());
+                    } else if (state_ == CONCAT_EMPTY_STRING && IsOrOperation(expr)) {
+                        state_ = URL_OR_OPERATION_1;
+                        Visit(expr->left());
+                    } else if (state_ == URL_OR_OPERATION_1 && IsOrOperation(expr)) {
+                        state_ = URL_OR_OPERATION_2;
+                    }
+                }
+            }
+
+        private:
+            enum State {
+                CHECK_START,
+                OUTER_REPLACE_CALL,
+                INNER_REPLACE_CALL,
+                CONCAT_EMPTY_STRING,
+                URL_OR_OPERATION_1,
+                URL_OR_OPERATION_2
+            };
+
+            bool IsOuterReplace(Call *expr) {
+                if (expr->expression()->IsProperty()) {
+                    Property *property = expr->expression()->AsProperty();
+                    if (property->key()->IsPropertyName() && HandleStringEquals(
+                            property->key()->AsLiteral()->AsRawString()->string(), "replace")) {
+                        return true;
+                    }
+                }
+                return false;
+            }
+
+            bool IsInnerReplace(Call *expr) {
+                if (expr->expression()->IsProperty()) {
+                    Property *property = expr->expression()->AsProperty();
+                    if (property->key()->IsPropertyName() && HandleStringEquals(
+                            property->key()->AsLiteral()->AsRawString()->string(), "replace")) {
+                        return true;
+                    }
+                }
+                return false;
+            }
+
+            bool IsConcatEmptyString(BinaryOperation *expr) {
+                if (expr->op() == Token::ADD) {
+                    if (expr->right()->IsLiteral() && HandleStringEquals(
+                            Handle<String>::cast(expr->right()->AsLiteral()->AsRawString()->string()), "")) {
+                        return true;
+                    }
+                }
+                return false;
+            }
+
+
+            bool IsOrOperation(BinaryOperation *expr) {
+                if (expr->op() == Token::OR) {
+                    return true;
+                }
+                return false;
+            }
+
+            State state_;
+        };
+
+
+        class ScopeDFGBuilder : public ASTVisitor { // checking....
+        public:
+            ScopeDFGBuilder(Isolate *isolate, Scope *scope,
+                            commons::LinkedList *scope_dependencies,
+                            commons::LinkedList *dependency_scopes)
+                    : ASTVisitor(isolate, scope),
+                      nested_property_(false),
+                      visit_for_(NONE),
+                      control_visit_for_(NONE) {
+                CHECK(scope_dependencies->size() == dependency_scopes->size());
+
+                if (!scope_dependencies->empty()) {
+                    // Make a copy, don't operate on the original lists.
+                    commons::LinkedList dependencies(*scope_dependencies);
+                    commons::LinkedList scopes(*dependency_scopes);
+
+                    while (!dependencies.empty()) {
+                        AstNode *node = (AstNode *)dependencies.head_key();
+                        Scope *scope = (Scope *)scopes.head_key();
+                        RHSCollector collector(isolate, scope);
+                        collector.Collect(node, &scope_dependencies_);
+
+                        dependencies.pop_head();
+                        scopes.pop_head();
+                    }
+                }
+            }
+
+            ScopeDFG *Build(ZoneList<Statement *> *statements) {
+                nested_property_ = false;
+                dfg_ = new ScopeDFG(isolate(), scope());
+                StartVisit(statements);
+                return dfg_;
+
+            }
+
+            /*
+             * Control dependencies.
+             */
+
+            void VisitIfStatement(IfStatement *stmt) {
+                i::OFStream os(stdout);
+//                os << "inside VisitIfStatement, before populate\n";
+//                os << "before if control visit, lsh="<<CurrentLHS()<<"\n";
+                ControlVisitForRHS(stmt->condition());
+                ControlVisitForLHS(stmt->then_statement());
+//                os << "after if control visit, lsh="<<CurrentLHS()<<"\n";
+
+                if (stmt->HasElseStatement())
+                    ControlVisitForLHS(stmt->else_statement(), false);
+                PopulateControlDFGEdges();
+//                os << "inside VisitIfStatement, after populate\n";
+
+            }
+
+            void VisitWhileStatement(WhileStatement *stmt) {
+                ControlVisitForRHS(stmt->cond());
+                ControlVisitForLHS(stmt->body());
+                i::OFStream os(stdout);
+//                os << "inside VisitWhileStatement, before populate\n";
+                PopulateControlDFGEdges();
+//                os << "inside VisitWhileStatement, after populate\n";
+
+            }
+
+            void VisitForStatement(ForStatement *stmt) {
+                if (stmt->init() != nullptr)
+                    Visit(stmt->init());
+
+                if (stmt->cond() != nullptr) {
+                    ControlVisitForRHS(stmt->cond());
+                    ControlVisitForLHS(stmt->body());
+                    if (stmt->next() != nullptr)
+                        ControlVisitForLHS(stmt->next(), false);
+                    i::OFStream os(stdout);
+
+//                    os << "inside VisitForStatement, before populate\n";
+                    PopulateControlDFGEdges();
+//                    os << "inside VisitForStatement, after populate\n";
+
+                } else {
+                    Visit(stmt->body());
+                    if (stmt->next() != nullptr)
+                        Visit(stmt->next());
+                }
+            }
+
+
+            void VisitDoWhileStatement(DoWhileStatement *stmt) {
+                ControlVisitForRHS(stmt->cond());
+                ControlVisitForLHS(stmt->body());
+                i::OFStream os(stdout);
+
+//                os << "inside VisitDoWhileStatement, before populate\n";
+                PopulateControlDFGEdges();
+//                os << "inside VisitDoWhileStatement, after populate\n";
+
+            }
+
+            void VisitSwitchStatement(SwitchStatement *stmt) {
+                i::OFStream os(stdout);
+//                os << "inside VisitSwitchStatement, before populate\n";
+                ControlVisitForRHS(stmt->tag());
+
+                bool first = true;
+                ZonePtrList<CaseClause> *cases = stmt->cases();
+//                os << "cases length="<<cases->length()<<"\n";
+                for (int i = 0; i < cases->length(); i++) {
+                    CaseClause* clause = cases->at(i);
+//                    os << "i ="<<i<<","<< clause->statements()->length()<<"\n";
+                    for (int j = 0; j < clause->statements()->length(); j++) {
+//                        os << "j ="<<j<<"\n";
+                        ControlVisitForLHS(clause->statements()->at(j), first);
+                        first = false;
+                    }
+                }
+
+                PopulateControlDFGEdges();
+//                os << "inside VisitSwitchStatement, after populate\n";
+            }
+
+            void VisitConditional(Conditional *expr) {
+                ControlVisitForRHS(expr->condition());
+                ControlVisitForLHS(expr->then_expression());
+                ControlVisitForLHS(expr->else_expression(), false);
+//                i::OFStream os(stdout);
+
+//                os << "inside VisitConditional, before populate\n";
+                PopulateControlDFGEdges();
+//                os << "inside VisitConditional, after populate\n";
+
+            }
+
+            // Not sure about these.
+
+            void VisitForInStatement(ForInStatement *stmt) {
+                // Does nothing due to how we handle Property.
+                ASTVisitor::VisitForInStatement(stmt);
+            }
+
+            void VisitForOfStatement(ForOfStatement *stmt) {
+                // Does nothing due to how we handle arrays.
+                ASTVisitor::VisitForOfStatement(stmt);
+            }
+
+            void VisitWithStatement(WithStatement *stmt) {
+                // I don't know WTF this is, seems irrelevant.
+                ASTVisitor::VisitWithStatement(stmt);
+            }
+
+            void VisitTryCatchStatement(TryCatchStatement *stmt) {
+                // What if a tainted object is thrown?
+                ASTVisitor::VisitTryCatchStatement(stmt);
+            }
+
+            /*
+            * Data dependencies.
+            */
+
+            void VisitAssignment(Assignment *expr) {
+                JQueryRHSChecker checker(isolate(), scope());
+                if (!checker.Check(expr->value())) {
+                    VisitForRHS(expr->value());
+                    VisitForLHS(expr->target());
+                    PopulateDFGEdges();
+                }
+            }
+
+            /*
+            * Terminal nodes, they are either RHS or LHS.
+            */
+
+            void VisitVariableProxy(VariableProxy *proxy) {
+                RecordVisitedAstNode(proxy);
+            }
+
+            void VisitProperty(Property *property) {
+                RecordVisitedAstNode(property);
+
+                bool saved_nested_property = nested_property_;
+                nested_property_ = true;
+                ASTVisitor::Visit(property->obj());
+                nested_property_ = saved_nested_property;
+            }
+
+            void VisitCall(Call *call) {
+                RecordVisitedAstNode(call);
+                ASTVisitor::VisitExpressions(call->arguments());
+            }
+
+            // Do nothing for compound types (already handled dynamically).
+            void VisitObjectLiteral(ObjectLiteral *expr) { }
+            void VisitArrayLiteral(ArrayLiteral *expr) { }
+
+        private:
+            bool ShouldEnterScope() { return false; }
+
+            // Collect data flows: RHS -> LHS.
+            enum VisitFor { NONE, LHS, RHS };
+
+            static void IteratePushControlLHS(void *key, void *value, void *data) {
+                commons::LinkedList *lhs = (commons::LinkedList *)key;
+                AstNode *node = (AstNode *)data;
+                lhs->append(node, nullptr);
+            }
+
+            void RecordVisitedAstNode(AstNode *node) {
+                if (node->IsLiteral() && !nested_property_)
+                    CHECK(node->AsLiteral()->IsPropertyName());
+
+                if (visit_for_ == RHS)
+                    CurrentRHS()->append(node, nullptr);
+                else if (visit_for_ == LHS && !nested_property_)
+                    CurrentLHS()->append(node, nullptr);
+
+                if (control_visit_for_ == RHS) {
+                    CurrentControlRHS()->append(node, nullptr);
+                } else if  (control_visit_for_ == LHS && visit_for_ == LHS && !nested_property_) {
+                    control_lhs_.iterate(IteratePushControlLHS, node);
+                }
+            }
+
+            void ControlVisitForRHS(AstNode *node) {
+#ifdef POPULATE_CFG_EDGES
+                commons::LinkedList *rhs = new commons::LinkedList();
+                control_rhs_.prepend(rhs, nullptr);
+
+                VisitFor saved_visit_for = control_visit_for_;
+                control_visit_for_ = RHS;
+                Visit(node);
+                control_visit_for_ = saved_visit_for;
+#endif
+            }
+
+            void ControlVisitForLHS(AstNode *node, bool push_new = true) {
+#ifdef POPULATE_CFG_EDGES
+                i::OFStream os(stdout);
+//                os << "Enter ControlVisitForLHS, push_new="<<push_new<<"\n";
+                if (push_new) {
+                    commons::LinkedList *lhs = new commons::LinkedList();
+                    control_lhs_.prepend(lhs, nullptr);
+                }
+
+                VisitFor saved_visit_for = control_visit_for_;
+                control_visit_for_ = LHS;
+                Visit(node);
+                control_visit_for_ = saved_visit_for;
+#endif
+            }
+
+            void VisitForRHS(AstNode *node) {
+                commons::LinkedList *rhs = new commons::LinkedList();
+                rhs_.prepend(rhs, nullptr);
+
+                VisitFor saved_visit_for = visit_for_;
+                visit_for_ = RHS;
+                Visit(node);
+                visit_for_ = saved_visit_for;
+            }
+
+            void VisitForLHS(AstNode *node) {
+                commons::LinkedList *lhs = new commons::LinkedList();
+                lhs_.prepend(lhs, nullptr);
+
+                VisitFor saved_visit_for = visit_for_;
+                visit_for_ = LHS;
+                Visit(node);
+                visit_for_ = saved_visit_for;
+            }
+
+            struct IterateData {
+                void *data;
+                ScopeDFGBuilder *builder;
+            };
+
+            static void IterateLHS(void *key, void *value, void *data) {
+                i::OFStream os(stdout);
+
+//                os << "in IterateLHS\n";
+                IterateData *lhs_data = (IterateData *)data;
+//                os << "after IterateLHS\n";
+                AstNode *lhs_node = (AstNode *)key;
+//                os << "after Astnode\n";
+
+                commons::LinkedList *rhs = (commons::LinkedList *)lhs_data->data;
+//                os << "after rhs\n";
+
+                IterateData rhs_data = { lhs_node, lhs_data->builder };
+                rhs->iterate(IterateRHS, &rhs_data);
+//                os << "after iterateRhs\n";
+
+            }
+
+            static void IterateRHS(void *key, void *value, void *data) {
+                AstNode *rhs_node = (AstNode *)key;
+                IterateData *rhs_data = (IterateData *)data;
+                AstNode *lhs_node = (AstNode *)rhs_data->data;
+                rhs_data->builder->dfg_->AddEdge(rhs_node, lhs_node);
+            }
+
+            void PopulateDFGEdges() {
+                commons::LinkedList *rhs = CurrentRHS();
+                commons::LinkedList *lhs = CurrentLHS();
+
+                if (!rhs->empty() && !lhs->empty()) {
+                    IterateData data = { rhs, this };
+                    lhs->iterate(IterateLHS, &data);
+                }
+
+                if (!scope_dependencies_.empty() && !lhs->empty()) {
+                    IterateData data = { &scope_dependencies_, this };
+                    lhs->iterate(IterateLHS, &data);
+                }
+
+                rhs_.remove(rhs);
+                lhs_.remove(lhs);
+                delete rhs;
+                delete lhs;
+
+            }
+
+            void PopulateControlDFGEdges() {
+                i::OFStream os(stdout);
+#ifdef POPULATE_CFG_EDGES
+                commons::LinkedList *rhs = CurrentControlRHS();
+                commons::LinkedList *lhs = CurrentControlLHS();
+
+                IterateData data = { rhs, this };
+//                os << "in PopulateControlDFGEdges, before lhs->iterate\n";
+//                os << "lhs="<<lhs<<"\n";
+//                os << "lhempty?"<<control_lhs_.empty()<<"\n";
+                if (!control_lhs_.empty()) {
+                    lhs->iterate(IterateLHS, &data);
+                }
+//                os << "in PopulateControlDFGEdges, after lhs->iterate\n";
+
+                control_rhs_.remove(rhs);
+                control_lhs_.remove(lhs);
+                delete rhs;
+                delete lhs;
+#endif
+            }
+
+            commons::LinkedList *CurrentControlRHS() {
+                return reinterpret_cast<commons::LinkedList *>(control_rhs_.head_key());
+            }
+
+            commons::LinkedList *CurrentControlLHS() {
+                return reinterpret_cast<commons::LinkedList *>(control_lhs_.head_key());
+            }
+
+            commons::LinkedList *CurrentRHS() {
+                return reinterpret_cast<commons::LinkedList *>(rhs_.head_key());
+            }
+
+            commons::LinkedList *CurrentLHS() {
+                return reinterpret_cast<commons::LinkedList *>(lhs_.head_key());
+            }
+
+            ScopeDFG *dfg_;
+            bool nested_property_;
+            VisitFor visit_for_;
+            VisitFor control_visit_for_;
+            commons::LinkedList rhs_;
+            commons::LinkedList lhs_;
+            commons::LinkedList control_rhs_;
+            commons::LinkedList control_lhs_;
+            commons::LinkedList scope_dependencies_;
+};
+
+        class ExpressionTaintChecker : public ASTVisitor {
+        public:
+            ExpressionTaintChecker(Isolate *isolate, Scope *scope, JavaScriptFrame *frame)
+                    : ASTVisitor(isolate, scope),
+                      tainted_(false),
+                      frame_(frame),
+                      show_(false){
+
+            }
+
+            bool Check(Expression *expr, bool show = false) {
+                function_ = Handle<JSFunction>(frame_->function(), isolate());
+                show_ = show;
+                i::OFStream os(stdout);
+                //os << show_<<"\n";
+                if (isolate()->IsJSFunctionTainted(function_))
+                    return true; // Taint all LHS nodes.
+
+                tainted_ = false;
+                tainted_nodes_.clear();
+                ASTVisitor::StartVisit(expr);
+                return tainted_;
+            }
+
+            void PopulatePropagatedFrom(Handle<Object> obj) {
+                obj = FilterInvalidV8Objects(isolate(), obj);
+                if (obj.is_null())
+                    return;
+
+                function_ = Handle<JSFunction>(frame_->function(), isolate());
+                obj_ = obj;
+
+                if (isolate()->IsJSFunctionTainted(function_)) {
+                    Handle<String> report =
+                            isolate()->GetPropagationPathForJSFunction(function_);
+                    CHECK(!report.is_null());
+                    isolate()->AddPropagatedFrom(obj_, function_, report);
+                } else {
+                    tainted_nodes_.iterate(IteratePopulatePropagatedFrom, this);
+                }
+            }
+
+            void VisitLiteral(Literal *literal) {
+                // TODO: Can we have a property name here?
+                i::OFStream os(stdout);
+                if (show_) {
+                    os << "In Check:VisitLiteral() "<<literal->BuildValue(isolate())<<":";
+                }
+                if (!literal->IsPropertyName() &&
+                    isolate()->IsV8ObjectTainted(literal->BuildValue(isolate()))) {
+                    if (show_) {
+                        os << "set tainted_ as true\n";
+                    }
+                    tainted_ = true;
+                    tainted_nodes_.append(literal, nullptr);
+                }
+                else {
+                    if (show_) os << "not tainted.\n";
+                }
+            }
+
+            void VisitVariableProxy(VariableProxy *proxy) {
+                i::OFStream os(stdout);
+                if (show_) {
+                    os << "In Check:VisitVariableProxy() "<<proxy->position()<<":";
+                }
+                if (isolate()->IsAstNodeTainted(reinterpret_cast<void*>(frame_->fp()),
+                                                proxy->position(), AstNode::kVariableProxy)) {
+                    if (show_) {
+                        os << "set tainted_ as true\n";
+                    }
+                    tainted_ = true;
+                    tainted_nodes_.append(proxy, nullptr);
+                }
+                else {
+                    if (show_) os << "not tainted.\n";
+                }
+            }
+
+            void VisitProperty(Property *property) {
+                i::OFStream os(stdout);
+                if (show_) {
+                    os << "In Check:VisitProperty() "<<property->position()<<":";
+                }
+                if (isolate()->IsAstNodeTainted(reinterpret_cast<void*>(frame_->fp()),
+                                                property->position(), AstNode::kProperty)) {
+                    if (show_) {
+                        os << "set tainted_ as true\n";
+                    }
+                    tainted_ = true;
+                    tainted_nodes_.append(property, nullptr);
+                }
+                else {
+                    if (show_) os << "not tainted.\n";
+                }
+                ASTVisitor::Visit(property->obj());
+            }
+
+            void VisitCall(Call *expr) {
+                i::OFStream os(stdout);
+                if (show_) {
+                    os << "In Check:VisitCall() "<<expr->position()<<":";
+                }
+                if (isolate()->IsAstNodeTainted(reinterpret_cast<void*>(frame_->fp()),
+                                                expr->position(), AstNode::kCall)) {
+                    if (show_) {
+                        os << "set tainted_ as true\n";
+                    }
+                    tainted_ = true;
+                    tainted_nodes_.append(expr, nullptr);
+                }
+                else {
+                    if (show_) os << "not tainted.\n";
+                }
+                ASTVisitor::VisitExpressions(expr->arguments());
+            }
+
+//    void VisitSpread(Spread* expr){
+//        i::OFStream os(stdout);
+//        if (show_) {
+//            os << "In Check:VisitSpread() "<<expr->position()<<":";
+//            os << "isarray?"<<expr->AsSpread()->expression()->IsArrayLiteral()<<"\n";
+//            os << "isspread?"<<expr->AsSpread()->expression()->IsSpread()<<"\n";
+//
+//        }
+//
+//        ASTVisitor::Visit(expr->AsSpread()->expression());
+//    }
+
+            // Do nothing for compound types (already handled dynamically).
+            void VisitObjectLiteral(ObjectLiteral *expr) { }
+            void VisitArrayLiteral(ArrayLiteral *expr) {
+                // I  think we should do something here
+
+            }
+
+
+        private:
+            bool ShouldEnterScope() { return false; }
+
+            static void IteratePopulatePropagatedFrom(void *key,
+                                                      void *value,
+                                                      void *data) {
+                AstNode *node = (AstNode *)key;
+                ExpressionTaintChecker *checker = (ExpressionTaintChecker *)data;
+                Isolate *isolate = checker->isolate();
+//        Scope *scope = checker->scope();
+                Handle<JSFunction> function = checker->function_;
+                void *fp = reinterpret_cast<void*>(checker->frame_->fp());
+
+                Handle<Object> obj = checker->obj_;
+                Handle<Object> from_obj;
+
+
+                if (node->IsLiteral()) {
+                    from_obj = node->AsLiteral()->BuildValue(isolate);
+                    from_obj = FilterInvalidV8Objects(isolate, from_obj);
+                    isolate->AddPropagatedFrom(obj, function, node, from_obj);
+                } else if (node->IsVariableProxy()) {
+                    VariableProxy *proxy = node->AsVariableProxy();
+                    from_obj = isolate->LookupObjectMap(fp,
+                                                        proxy->position(), AstNode::kVariableProxy);
+                    isolate->AddPropagatedFrom(obj, function, proxy, from_obj);
+                } else if (node->IsProperty()) {
+                    Property *property = node->AsProperty();
+                    from_obj = isolate->LookupObjectMap(fp,
+                                                        property->position(), AstNode::kProperty);
+                    isolate->AddPropagatedFrom(obj, function, property, from_obj);
+                } else if (node->IsCall()) {
+                    from_obj = isolate->LookupObjectMap(fp, node->position(), AstNode::kCall);
+                    isolate->AddPropagatedFrom(obj, function, node, from_obj);
+                }
+            }
+
+            bool tainted_;
+            commons::LinkedList tainted_nodes_;
+            JavaScriptFrame *frame_;
+
+            Handle<JSFunction> function_;
+            Handle<Object> obj_;
+            bool show_;
+
+        };
+
+    }
+}
+#endif
\ No newline at end of file
diff --git a/src/runtime/runtime.h b/src/runtime/runtime.h
index b15ed40d20b..beda8676c15 100644
--- a/src/runtime/runtime.h
+++ b/src/runtime/runtime.h
@@ -705,6 +705,27 @@ namespace internal {
   F(KeyedHasIC_Miss, 4, 1)                   \
   F(HasElementWithInterceptor, 2, 1)
 
+#define FOR_EACH_INTRINSIC_TAINT_ANALYSIS(F, I) \
+  F(TaintAnalysis_OnScopeExit , 1, 1)           \
+  F(TaintAnalysis_OnFunctionEnter, 0, 1) /*done*/ \
+  F(TaintAnalysis_OnReturnFromCall, 2, 1)/*done*/ \
+  F(TaintAnalysis_OnVisitVariableProxy, 3, 1 )/*done*/  \
+  F(TaintAnalysis_OnVisitProperty, 3, 1)/*done*/\
+  F(TaintAnalysis_OnVisitPropertyOptionalChain, 3, 1)/*done*/ \
+  F(TaintAnalysis_ReplaceSmiResult, 1, 1)         \
+  F(TaintAnalysis_ReplaceSmiResultArray, 1, 1)  \
+  F(TaintAnalysis_OnVisitReturnStatement, 2, 1) /*done*/  \
+  F(TaintAnalysis_OnVisitArrayLiteral, -1,/*3*/ 1)\
+  F(TaintAnalysis_OnVisitObjectLiteral, 4,/*3*/ 1)\
+  F(TaintAnalysis_OnVisitObjectLiteralSpread, 4,/*3*/ 1)\
+  F(TaintAnalysis_OnVisitCallArguments, -1,/*?*/ 1) \
+  F(TaintAnalysis_Check, -1,/*3 debug */ 1)            \
+  F(TaintAnalysis_CheckArray, -1,/*3 debug */ 1)    \
+  F(TaintAnalysis_IsTainted, 1, 1)              \
+  F(TaintAnalysis_ContainsTaintedValue, 1, 1)   \
+  F(TaintAnalysis_SetTaint, 1, 1)               \
+  F(TaintAnalysis_SetPropagationPaths, 2, 1)
+
 #define FOR_EACH_INTRINSIC_RETURN_OBJECT_IMPL(F, I) \
   FOR_EACH_INTRINSIC_ARRAY(F, I)                    \
   FOR_EACH_INTRINSIC_ATOMICS(F, I)                  \
@@ -718,6 +739,7 @@ namespace internal {
   FOR_EACH_INTRINSIC_FUNCTION(F, I)                 \
   FOR_EACH_INTRINSIC_GENERATOR(F, I)                \
   FOR_EACH_INTRINSIC_IC(F, I)                       \
+  FOR_EACH_INTRINSIC_TAINT_ANALYSIS(F, I)           \
   FOR_EACH_INTRINSIC_INTERNAL(F, I)                 \
   FOR_EACH_INTRINSIC_TRACE(F, I)                    \
   FOR_EACH_INTRINSIC_INTL(F, I)                     \
